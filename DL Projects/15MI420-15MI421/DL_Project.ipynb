{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Transmitter,  Channel and Receiver using Autoencoder\n",
    "Apoorva Jha (15MI420), Harish (15MI421)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref : An Introduction to Deep Learning for the Physical Layer, Tim Oâ€™Shea, Senior Member, IEEE, and Jakob Hoydis, Member, IEEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing required libs\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Input, Dense, GaussianNoise, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 2 2 1.0\n"
     ]
    }
   ],
   "source": [
    "# k is bits used in a message\n",
    "# M is possible message\n",
    "# n = no of channels\n",
    "# R is communication rate\n",
    "# n is used in encoder layers and R is used for defining noise for channel\n",
    "M = 4\n",
    "k = np.log2(M)\n",
    "k = int(k)\n",
    "n = 2\n",
    "R = k/n\n",
    "print (M,k,n,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 4)\n",
      "[1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#generating data of size N\n",
    "N = 5000\n",
    "from numpy.random import seed\n",
    "seed(10)\n",
    "pos = np.random.randint(M,size=N)\n",
    "\n",
    "# creating one hot encoded vectors\n",
    "train_data = []\n",
    "for i in pos:\n",
    "    arr = np.zeros(M)\n",
    "    arr[i] = 1\n",
    "    train_data.append(arr)\n",
    "\n",
    "# checking data shape\n",
    "train_data = np.array(train_data)\n",
    "print (train_data.shape)\n",
    "\n",
    "print(train_data[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "gaussian_noise_3 (GaussianNo (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 20        \n",
      "=================================================================\n",
      "Total params: 62\n",
      "Trainable params: 62\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "5000/5000 [==============================] - 1s 100us/step - loss: 1.4905\n",
      "Epoch 2/100\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 1.4760\n",
      "Epoch 3/100\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 1.4698\n",
      "Epoch 4/100\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 1.4679\n",
      "Epoch 5/100\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 1.4667\n",
      "Epoch 6/100\n",
      "5000/5000 [==============================] - 0s 42us/step - loss: 1.4666\n",
      "Epoch 7/100\n",
      "5000/5000 [==============================] - 0s 42us/step - loss: 1.4662\n",
      "Epoch 8/100\n",
      "5000/5000 [==============================] - 0s 42us/step - loss: 1.4662\n",
      "Epoch 9/100\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 1.4661\n",
      "Epoch 10/100\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 1.4663\n",
      "Epoch 11/100\n",
      "5000/5000 [==============================] - 0s 52us/step - loss: 1.4473\n",
      "Epoch 12/100\n",
      "5000/5000 [==============================] - 0s 54us/step - loss: 1.2637\n",
      "Epoch 13/100\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 1.0660\n",
      "Epoch 14/100\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.9300\n",
      "Epoch 15/100\n",
      "5000/5000 [==============================] - 0s 42us/step - loss: 0.9037\n",
      "Epoch 16/100\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.8958\n",
      "Epoch 17/100\n",
      "5000/5000 [==============================] - 0s 57us/step - loss: 0.8779\n",
      "Epoch 18/100\n",
      "5000/5000 [==============================] - 0s 42us/step - loss: 0.8818\n",
      "Epoch 19/100\n",
      "5000/5000 [==============================] - 0s 41us/step - loss: 0.8754\n",
      "Epoch 20/100\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.8759\n",
      "Epoch 21/100\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.8696\n",
      "Epoch 22/100\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.8638\n",
      "Epoch 23/100\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.8681\n",
      "Epoch 24/100\n",
      "5000/5000 [==============================] - 0s 64us/step - loss: 0.8715\n",
      "Epoch 25/100\n",
      "5000/5000 [==============================] - 0s 60us/step - loss: 0.8776\n",
      "Epoch 26/100\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.8624\n",
      "Epoch 27/100\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.8549\n",
      "Epoch 28/100\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.8596\n",
      "Epoch 29/100\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.8735\n",
      "Epoch 30/100\n",
      "5000/5000 [==============================] - 0s 57us/step - loss: 0.8501\n",
      "Epoch 31/100\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.8757\n",
      "Epoch 32/100\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.8533\n",
      "Epoch 33/100\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.8473\n",
      "Epoch 34/100\n",
      "5000/5000 [==============================] - 0s 42us/step - loss: 0.8675\n",
      "Epoch 35/100\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.8488\n",
      "Epoch 36/100\n",
      "5000/5000 [==============================] - 0s 62us/step - loss: 0.8576\n",
      "Epoch 37/100\n",
      "5000/5000 [==============================] - 0s 62us/step - loss: 0.8568\n",
      "Epoch 38/100\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.8684\n",
      "Epoch 39/100\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.8482\n",
      "Epoch 40/100\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.8509\n",
      "Epoch 41/100\n",
      "5000/5000 [==============================] - 0s 51us/step - loss: 0.8662\n",
      "Epoch 42/100\n",
      "5000/5000 [==============================] - 0s 53us/step - loss: 0.8600\n",
      "Epoch 43/100\n",
      "5000/5000 [==============================] - 0s 54us/step - loss: 0.8571\n",
      "Epoch 44/100\n",
      "5000/5000 [==============================] - 0s 54us/step - loss: 0.8498\n",
      "Epoch 45/100\n",
      "5000/5000 [==============================] - 0s 56us/step - loss: 0.8624\n",
      "Epoch 46/100\n",
      "5000/5000 [==============================] - 0s 42us/step - loss: 0.8485\n",
      "Epoch 47/100\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.8578\n",
      "Epoch 48/100\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.8595\n",
      "Epoch 49/100\n",
      "5000/5000 [==============================] - 0s 63us/step - loss: 0.8451\n",
      "Epoch 50/100\n",
      "5000/5000 [==============================] - 0s 64us/step - loss: 0.8497\n",
      "Epoch 51/100\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.8517\n",
      "Epoch 52/100\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.8525\n",
      "Epoch 53/100\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.8466\n",
      "Epoch 54/100\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.8508\n",
      "Epoch 55/100\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.8493\n",
      "Epoch 56/100\n",
      "5000/5000 [==============================] - 0s 52us/step - loss: 0.8371\n",
      "Epoch 57/100\n",
      "5000/5000 [==============================] - 0s 42us/step - loss: 0.8359\n",
      "Epoch 58/100\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.8520\n",
      "Epoch 59/100\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.8577\n",
      "Epoch 60/100\n",
      "5000/5000 [==============================] - 0s 49us/step - loss: 0.8480\n",
      "Epoch 61/100\n",
      "5000/5000 [==============================] - 0s 53us/step - loss: 0.8471\n",
      "Epoch 62/100\n",
      "5000/5000 [==============================] - 0s 65us/step - loss: 0.8504\n",
      "Epoch 63/100\n",
      "5000/5000 [==============================] - 0s 52us/step - loss: 0.8343\n",
      "Epoch 64/100\n",
      "5000/5000 [==============================] - 0s 52us/step - loss: 0.8407\n",
      "Epoch 65/100\n",
      "5000/5000 [==============================] - 0s 53us/step - loss: 0.8556\n",
      "Epoch 66/100\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.8502\n",
      "Epoch 67/100\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.8503\n",
      "Epoch 68/100\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.8343\n",
      "Epoch 69/100\n",
      "5000/5000 [==============================] - 0s 42us/step - loss: 0.8610\n",
      "Epoch 70/100\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.8600\n",
      "Epoch 71/100\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.8456\n",
      "Epoch 72/100\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.8559\n",
      "Epoch 73/100\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.8432\n",
      "Epoch 74/100\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.8429\n",
      "Epoch 75/100\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.8416\n",
      "Epoch 76/100\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.8516\n",
      "Epoch 77/100\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.8483\n",
      "Epoch 78/100\n",
      "5000/5000 [==============================] - 0s 48us/step - loss: 0.8636\n",
      "Epoch 79/100\n",
      "5000/5000 [==============================] - 0s 47us/step - loss: 0.8392\n",
      "Epoch 80/100\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.8533\n",
      "Epoch 81/100\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.8430\n",
      "Epoch 82/100\n",
      "5000/5000 [==============================] - 0s 46us/step - loss: 0.8484\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 51us/step - loss: 0.8475\n",
      "Epoch 84/100\n",
      "5000/5000 [==============================] - 0s 52us/step - loss: 0.8519\n",
      "Epoch 85/100\n",
      "5000/5000 [==============================] - 0s 58us/step - loss: 0.8327\n",
      "Epoch 86/100\n",
      "5000/5000 [==============================] - 0s 56us/step - loss: 0.8655\n",
      "Epoch 87/100\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.8428\n",
      "Epoch 88/100\n",
      "5000/5000 [==============================] - 0s 52us/step - loss: 0.8528\n",
      "Epoch 89/100\n",
      "5000/5000 [==============================] - 0s 45us/step - loss: 0.8504\n",
      "Epoch 90/100\n",
      "5000/5000 [==============================] - 0s 61us/step - loss: 0.8527\n",
      "Epoch 91/100\n",
      "5000/5000 [==============================] - 0s 64us/step - loss: 0.8537\n",
      "Epoch 92/100\n",
      "5000/5000 [==============================] - 0s 65us/step - loss: 0.8488\n",
      "Epoch 93/100\n",
      "5000/5000 [==============================] - 0s 64us/step - loss: 0.8520\n",
      "Epoch 94/100\n",
      "5000/5000 [==============================] - 0s 56us/step - loss: 0.8554\n",
      "Epoch 95/100\n",
      "5000/5000 [==============================] - 0s 44us/step - loss: 0.8687\n",
      "Epoch 96/100\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.8627\n",
      "Epoch 97/100\n",
      "5000/5000 [==============================] - 0s 50us/step - loss: 0.8382\n",
      "Epoch 98/100\n",
      "5000/5000 [==============================] - 0s 65us/step - loss: 0.8652\n",
      "Epoch 99/100\n",
      "5000/5000 [==============================] - 0s 55us/step - loss: 0.8463\n",
      "Epoch 100/100\n",
      "5000/5000 [==============================] - 0s 43us/step - loss: 0.8438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe3cc647ac8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transmitter\n",
    "message_signal = Input(shape=(M,))\n",
    "transmitter1 = Dense(M, activation='relu')(message_signal)\n",
    "transmitter2= Dense(n, activation='softmax',kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l2(0.01))(transmitter1)\n",
    "\n",
    "# to avoid overfitting\n",
    "\n",
    "\n",
    "#noise in channel\n",
    "SNR = 10**(0.7) #  coverted 7 db of EbNo, values used from paper\n",
    "channel = GaussianNoise(np.sqrt(1/(2*R*SNR)))(transmitter2)\n",
    "#receiver\n",
    "receiver1 = Dense(M, activation='relu')(channel)\n",
    "receiver2 = Dense(M, activation='softmax')(receiver1)\n",
    "autoencoder = Model(message_signal, receiver2)\n",
    "autoencoder.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy') # learning rate value from paper\n",
    "\n",
    "print (autoencoder.summary())\n",
    "\n",
    "autoencoder.fit(train_data,train_data,\n",
    "                epochs=100,\n",
    "                batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transmitter model\n",
    "transmitter = Model(message_signal, transmitter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# receiver model\n",
    "encoded_input = Input(shape=(n,))\n",
    "\n",
    "deco = autoencoder.layers[-2](encoded_input)\n",
    "deco = autoencoder.layers[-1](deco)\n",
    "receiver = Model(encoded_input, deco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "[0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "N = 1000\n",
    "from numpy.random import seed\n",
    "seed(10)\n",
    "test_pos = np.random.randint(M,size=N)\n",
    "test_data = []\n",
    "\n",
    "for i in test_pos:\n",
    "    arr = np.zeros(M)\n",
    "    arr[i] = 1\n",
    "    test_data.append(arr)\n",
    "    \n",
    "test_data = np.array(test_data)\n",
    "print (test_data.shape)\n",
    "print (test_data[44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR: -15 BER: 0.73\n",
      "SNR: -14 BER: 0.722\n",
      "SNR: -13 BER: 0.715\n",
      "SNR: -12 BER: 0.708\n",
      "SNR: -11 BER: 0.703\n",
      "SNR: -10 BER: 0.689\n",
      "SNR: -9 BER: 0.688\n",
      "SNR: -8 BER: 0.692\n",
      "SNR: -7 BER: 0.682\n",
      "SNR: -6 BER: 0.67\n",
      "SNR: -5 BER: 0.661\n",
      "SNR: -4 BER: 0.649\n",
      "SNR: -3 BER: 0.633\n",
      "SNR: -2 BER: 0.624\n",
      "SNR: -1 BER: 0.603\n",
      "SNR: 0 BER: 0.586\n",
      "SNR: 1 BER: 0.565\n",
      "SNR: 2 BER: 0.54\n",
      "SNR: 3 BER: 0.514\n",
      "SNR: 4 BER: 0.485\n",
      "SNR: 5 BER: 0.462\n",
      "SNR: 6 BER: 0.434\n",
      "SNR: 7 BER: 0.407\n",
      "SNR: 8 BER: 0.374\n",
      "SNR: 9 BER: 0.34\n",
      "SNR: 10 BER: 0.318\n",
      "SNR: 11 BER: 0.297\n",
      "SNR: 12 BER: 0.28\n",
      "SNR: 13 BER: 0.264\n",
      "SNR: 14 BER: 0.26\n",
      "SNR: 15 BER: 0.256\n"
     ]
    }
   ],
   "source": [
    "# we now make our test data pass through the transmitter and rciever with different noise in the channel\n",
    "#the bit error rate vs SNR graph is plotted showing how well the autoencoder models a communication system\n",
    "\n",
    "SNR_range = (range(-15,16)) # decibel values\n",
    "ber = [0]*len(SNR_range) # block error rate\n",
    "for i in range(0,len(SNR_range)):\n",
    "    SNR=10**(SNR_range[i]*0.1) # converting from decibel\n",
    "    std = np.sqrt(1/(2*R*SNR))\n",
    "    errors = 0\n",
    "    from numpy.random import seed\n",
    "    seed(10)\n",
    "    noise = std * np.random.randn(N,n)# noise for channel\n",
    "    #print(n,noise.shape)\n",
    "    msg_signal = transmitter.predict(test_data) \n",
    "    transmit_signal = msg_signal + noise\n",
    "    transmit_signal_received =  receiver.predict(transmit_signal)\n",
    "    #print(transmit_signal)\n",
    "    received_signal = np.argmax(transmit_signal_received,axis=1) #finding pos of bit 1\n",
    "    #print(received_signal)\n",
    "    errors = (received_signal != test_pos)# checking pos for bit 1\n",
    "    #print(errors)\n",
    "    errors =  errors.sum() \n",
    "    ber[i] = errors / N\n",
    "   # errors=errors.sum()\n",
    "   # ber[i] =(errors)/ N # normalizing\n",
    "    #print(1)\n",
    "    print ('SNR:',SNR_range[i],'BER:',ber[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Block Error Rate')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ploting ber curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(SNR_range, ber,'bo')\n",
    "plt.xlabel('SNR Range')\n",
    "plt.ylabel('Block Error Rate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
