{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Class_Assignment(15MI442-15MI443).ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjC0TGoef_0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xlwt \n",
        "from google.colab import files\n",
        "import io\n",
        "from xlwt import Workbook \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZlNmGpnf_2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmLc1Njwf_4R",
        "colab_type": "code",
        "outputId": "17fd4e79-b0a6-4e7c-86da-77eb341e3d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "d = pd.read_csv('dataset1.csv')\n",
        "X = d[d.columns[0:3]].values\n",
        "y = d[d.columns[3]].values\n",
        "print(y.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(59,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2datIgOBHCQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=X/10\n",
        "y=y/1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thvmCYk0f_5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
        "\n",
        "\n",
        "#model = Sequential()\n",
        "# adding the first input layert  and the first hidden layer\n",
        "#model.add(Dense(output_dim = 7,init = 'uniform', activation = 'relu', input_dim = 2))\n",
        "#model.add(Dense(output_dim = 5,init = 'uniform', activation = 'relu'))\n",
        "#model.add(Dense(output_dim = 3,init = 'uniform', activation = 'relu'))\n",
        "#model.add(Dense(output_dim = 1,init = 'uniform', activation = 'sigmoid'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBrgYreoqi9z",
        "colab_type": "code",
        "outputId": "ab7d0621-97ff-41da-8a40-82a404d1c8bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(40, activation='relu',input_dim = 3))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "print(model.summary())"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 40)                160       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 20)                820       \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 5)                 105       \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 1,091\n",
            "Trainable params: 1,091\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLGsIYnWf_6M",
        "colab_type": "code",
        "outputId": "5a199033-49e4-4652-ab45-2665e40033df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "#model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=100,\n",
        "          epochs=500,  \n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "print(history.history.keys())\n",
        "\n",
        "\n",
        "#  loss\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "model.save('model.h5')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 47 samples, validate on 12 samples\n",
            "Epoch 1/500\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 4.4253e-04 - val_loss: 6.1403e-05\n",
            "Epoch 2/500\n",
            "47/47 [==============================] - 0s 73us/step - loss: 2.8439e-04 - val_loss: 7.0408e-05\n",
            "Epoch 3/500\n",
            "47/47 [==============================] - 0s 79us/step - loss: 2.1105e-04 - val_loss: 1.0715e-04\n",
            "Epoch 4/500\n",
            "47/47 [==============================] - 0s 137us/step - loss: 1.9870e-04 - val_loss: 1.3472e-04\n",
            "Epoch 5/500\n",
            "47/47 [==============================] - 0s 71us/step - loss: 1.9658e-04 - val_loss: 1.3348e-04\n",
            "Epoch 6/500\n",
            "47/47 [==============================] - 0s 77us/step - loss: 1.7668e-04 - val_loss: 1.0884e-04\n",
            "Epoch 7/500\n",
            "47/47 [==============================] - 0s 62us/step - loss: 1.3882e-04 - val_loss: 7.4060e-05\n",
            "Epoch 8/500\n",
            "47/47 [==============================] - 0s 62us/step - loss: 9.6601e-05 - val_loss: 4.1117e-05\n",
            "Epoch 9/500\n",
            "47/47 [==============================] - 0s 93us/step - loss: 6.1611e-05 - val_loss: 1.7425e-05\n",
            "Epoch 10/500\n",
            "47/47 [==============================] - 0s 60us/step - loss: 4.2380e-05 - val_loss: 5.6355e-06\n",
            "Epoch 11/500\n",
            "47/47 [==============================] - 0s 69us/step - loss: 4.1182e-05 - val_loss: 3.3433e-06\n",
            "Epoch 12/500\n",
            "47/47 [==============================] - 0s 64us/step - loss: 4.6186e-05 - val_loss: 4.9055e-06\n",
            "Epoch 13/500\n",
            "47/47 [==============================] - 0s 70us/step - loss: 4.5166e-05 - val_loss: 6.0520e-06\n",
            "Epoch 14/500\n",
            "47/47 [==============================] - 0s 72us/step - loss: 3.8712e-05 - val_loss: 6.1427e-06\n",
            "Epoch 15/500\n",
            "47/47 [==============================] - 0s 73us/step - loss: 3.1753e-05 - val_loss: 5.7153e-06\n",
            "Epoch 16/500\n",
            "47/47 [==============================] - 0s 75us/step - loss: 2.5127e-05 - val_loss: 5.0158e-06\n",
            "Epoch 17/500\n",
            "47/47 [==============================] - 0s 72us/step - loss: 2.0775e-05 - val_loss: 4.6022e-06\n",
            "Epoch 18/500\n",
            "47/47 [==============================] - 0s 78us/step - loss: 2.0093e-05 - val_loss: 4.5644e-06\n",
            "Epoch 19/500\n",
            "47/47 [==============================] - 0s 71us/step - loss: 2.1082e-05 - val_loss: 4.6732e-06\n",
            "Epoch 20/500\n",
            "47/47 [==============================] - 0s 75us/step - loss: 2.2967e-05 - val_loss: 4.5506e-06\n",
            "Epoch 21/500\n",
            "47/47 [==============================] - 0s 72us/step - loss: 2.4301e-05 - val_loss: 4.1570e-06\n",
            "Epoch 22/500\n",
            "47/47 [==============================] - 0s 70us/step - loss: 2.4335e-05 - val_loss: 3.7413e-06\n",
            "Epoch 23/500\n",
            "47/47 [==============================] - 0s 76us/step - loss: 2.2966e-05 - val_loss: 3.6703e-06\n",
            "Epoch 24/500\n",
            "47/47 [==============================] - 0s 68us/step - loss: 2.0733e-05 - val_loss: 4.2855e-06\n",
            "Epoch 25/500\n",
            "47/47 [==============================] - 0s 71us/step - loss: 1.8614e-05 - val_loss: 5.6598e-06\n",
            "Epoch 26/500\n",
            "47/47 [==============================] - 0s 70us/step - loss: 1.6785e-05 - val_loss: 7.6354e-06\n",
            "Epoch 27/500\n",
            "47/47 [==============================] - 0s 74us/step - loss: 1.5951e-05 - val_loss: 9.7965e-06\n",
            "Epoch 28/500\n",
            "47/47 [==============================] - 0s 71us/step - loss: 1.5919e-05 - val_loss: 1.1642e-05\n",
            "Epoch 29/500\n",
            "47/47 [==============================] - 0s 67us/step - loss: 1.6184e-05 - val_loss: 1.2710e-05\n",
            "Epoch 30/500\n",
            "47/47 [==============================] - 0s 63us/step - loss: 1.6166e-05 - val_loss: 1.2733e-05\n",
            "Epoch 31/500\n",
            "47/47 [==============================] - 0s 128us/step - loss: 1.5512e-05 - val_loss: 1.1793e-05\n",
            "Epoch 32/500\n",
            "47/47 [==============================] - 0s 64us/step - loss: 1.4247e-05 - val_loss: 1.0213e-05\n",
            "Epoch 33/500\n",
            "47/47 [==============================] - 0s 90us/step - loss: 1.2693e-05 - val_loss: 8.3816e-06\n",
            "Epoch 34/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.1270e-05 - val_loss: 6.7563e-06\n",
            "Epoch 35/500\n",
            "47/47 [==============================] - 0s 56us/step - loss: 1.0159e-05 - val_loss: 5.6205e-06\n",
            "Epoch 36/500\n",
            "47/47 [==============================] - 0s 82us/step - loss: 9.3979e-06 - val_loss: 4.9665e-06\n",
            "Epoch 37/500\n",
            "47/47 [==============================] - 0s 79us/step - loss: 8.9133e-06 - val_loss: 4.6412e-06\n",
            "Epoch 38/500\n",
            "47/47 [==============================] - 0s 69us/step - loss: 8.4968e-06 - val_loss: 4.5085e-06\n",
            "Epoch 39/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 7.9409e-06 - val_loss: 4.4269e-06\n",
            "Epoch 40/500\n",
            "47/47 [==============================] - 0s 71us/step - loss: 7.5471e-06 - val_loss: 4.3330e-06\n",
            "Epoch 41/500\n",
            "47/47 [==============================] - 0s 73us/step - loss: 6.8203e-06 - val_loss: 4.2196e-06\n",
            "Epoch 42/500\n",
            "47/47 [==============================] - 0s 82us/step - loss: 5.9065e-06 - val_loss: 4.1216e-06\n",
            "Epoch 43/500\n",
            "47/47 [==============================] - 0s 99us/step - loss: 5.1680e-06 - val_loss: 4.0445e-06\n",
            "Epoch 44/500\n",
            "47/47 [==============================] - 0s 86us/step - loss: 4.8470e-06 - val_loss: 3.9574e-06\n",
            "Epoch 45/500\n",
            "47/47 [==============================] - 0s 94us/step - loss: 4.8812e-06 - val_loss: 3.8163e-06\n",
            "Epoch 46/500\n",
            "47/47 [==============================] - 0s 94us/step - loss: 4.9984e-06 - val_loss: 3.6035e-06\n",
            "Epoch 47/500\n",
            "47/47 [==============================] - 0s 91us/step - loss: 4.9563e-06 - val_loss: 3.3458e-06\n",
            "Epoch 48/500\n",
            "47/47 [==============================] - 0s 88us/step - loss: 4.6765e-06 - val_loss: 3.1140e-06\n",
            "Epoch 49/500\n",
            "47/47 [==============================] - 0s 96us/step - loss: 4.2498e-06 - val_loss: 2.9796e-06\n",
            "Epoch 50/500\n",
            "47/47 [==============================] - 0s 85us/step - loss: 3.8577e-06 - val_loss: 2.9688e-06\n",
            "Epoch 51/500\n",
            "47/47 [==============================] - 0s 77us/step - loss: 3.6509e-06 - val_loss: 3.0454e-06\n",
            "Epoch 52/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 3.6300e-06 - val_loss: 3.1411e-06\n",
            "Epoch 53/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 3.6928e-06 - val_loss: 3.1830e-06\n",
            "Epoch 54/500\n",
            "47/47 [==============================] - 0s 86us/step - loss: 3.7048e-06 - val_loss: 3.1306e-06\n",
            "Epoch 55/500\n",
            "47/47 [==============================] - 0s 89us/step - loss: 3.5929e-06 - val_loss: 2.9849e-06\n",
            "Epoch 56/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 3.3793e-06 - val_loss: 2.7912e-06\n",
            "Epoch 57/500\n",
            "47/47 [==============================] - 0s 76us/step - loss: 3.1512e-06 - val_loss: 2.6023e-06\n",
            "Epoch 58/500\n",
            "47/47 [==============================] - 0s 73us/step - loss: 2.9927e-06 - val_loss: 2.4575e-06\n",
            "Epoch 59/500\n",
            "47/47 [==============================] - 0s 74us/step - loss: 2.9205e-06 - val_loss: 2.3685e-06\n",
            "Epoch 60/500\n",
            "47/47 [==============================] - 0s 73us/step - loss: 2.8884e-06 - val_loss: 2.3260e-06\n",
            "Epoch 61/500\n",
            "47/47 [==============================] - 0s 74us/step - loss: 2.8291e-06 - val_loss: 2.3074e-06\n",
            "Epoch 62/500\n",
            "47/47 [==============================] - 0s 74us/step - loss: 2.7078e-06 - val_loss: 2.2927e-06\n",
            "Epoch 63/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 2.5416e-06 - val_loss: 2.2748e-06\n",
            "Epoch 64/500\n",
            "47/47 [==============================] - 0s 85us/step - loss: 2.3763e-06 - val_loss: 2.2522e-06\n",
            "Epoch 65/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 2.2502e-06 - val_loss: 2.2245e-06\n",
            "Epoch 66/500\n",
            "47/47 [==============================] - 0s 73us/step - loss: 2.1682e-06 - val_loss: 2.1821e-06\n",
            "Epoch 67/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 2.1051e-06 - val_loss: 2.1284e-06\n",
            "Epoch 68/500\n",
            "47/47 [==============================] - 0s 78us/step - loss: 2.0277e-06 - val_loss: 2.0711e-06\n",
            "Epoch 69/500\n",
            "47/47 [==============================] - 0s 79us/step - loss: 1.9188e-06 - val_loss: 2.0209e-06\n",
            "Epoch 70/500\n",
            "47/47 [==============================] - 0s 86us/step - loss: 1.8002e-06 - val_loss: 1.9878e-06\n",
            "Epoch 71/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.7036e-06 - val_loss: 1.9702e-06\n",
            "Epoch 72/500\n",
            "47/47 [==============================] - 0s 88us/step - loss: 1.6359e-06 - val_loss: 1.9561e-06\n",
            "Epoch 73/500\n",
            "47/47 [==============================] - 0s 90us/step - loss: 1.5933e-06 - val_loss: 1.9357e-06\n",
            "Epoch 74/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 1.5571e-06 - val_loss: 1.8984e-06\n",
            "Epoch 75/500\n",
            "47/47 [==============================] - 0s 82us/step - loss: 1.5104e-06 - val_loss: 1.8409e-06\n",
            "Epoch 76/500\n",
            "47/47 [==============================] - 0s 97us/step - loss: 1.4470e-06 - val_loss: 1.7684e-06\n",
            "Epoch 77/500\n",
            "47/47 [==============================] - 0s 89us/step - loss: 1.3711e-06 - val_loss: 1.6916e-06\n",
            "Epoch 78/500\n",
            "47/47 [==============================] - 0s 93us/step - loss: 1.3008e-06 - val_loss: 1.6204e-06\n",
            "Epoch 79/500\n",
            "47/47 [==============================] - 0s 86us/step - loss: 1.2463e-06 - val_loss: 1.5611e-06\n",
            "Epoch 80/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 1.2035e-06 - val_loss: 1.5154e-06\n",
            "Epoch 81/500\n",
            "47/47 [==============================] - 0s 85us/step - loss: 1.1600e-06 - val_loss: 1.4825e-06\n",
            "Epoch 82/500\n",
            "47/47 [==============================] - 0s 73us/step - loss: 1.1068e-06 - val_loss: 1.4607e-06\n",
            "Epoch 83/500\n",
            "47/47 [==============================] - 0s 72us/step - loss: 1.0455e-06 - val_loss: 1.4472e-06\n",
            "Epoch 84/500\n",
            "47/47 [==============================] - 0s 75us/step - loss: 9.8642e-07 - val_loss: 1.4378e-06\n",
            "Epoch 85/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 9.3726e-07 - val_loss: 1.4269e-06\n",
            "Epoch 86/500\n",
            "47/47 [==============================] - 0s 88us/step - loss: 8.9885e-07 - val_loss: 1.4089e-06\n",
            "Epoch 87/500\n",
            "47/47 [==============================] - 0s 87us/step - loss: 8.6679e-07 - val_loss: 1.3788e-06\n",
            "Epoch 88/500\n",
            "47/47 [==============================] - 0s 88us/step - loss: 8.3637e-07 - val_loss: 1.3407e-06\n",
            "Epoch 89/500\n",
            "47/47 [==============================] - 0s 81us/step - loss: 8.0357e-07 - val_loss: 1.3000e-06\n",
            "Epoch 90/500\n",
            "47/47 [==============================] - 0s 95us/step - loss: 7.7538e-07 - val_loss: 1.2615e-06\n",
            "Epoch 91/500\n",
            "47/47 [==============================] - 0s 92us/step - loss: 7.5368e-07 - val_loss: 1.2283e-06\n",
            "Epoch 92/500\n",
            "47/47 [==============================] - 0s 85us/step - loss: 7.3698e-07 - val_loss: 1.2021e-06\n",
            "Epoch 93/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 7.2125e-07 - val_loss: 1.1833e-06\n",
            "Epoch 94/500\n",
            "47/47 [==============================] - 0s 96us/step - loss: 7.0295e-07 - val_loss: 1.1719e-06\n",
            "Epoch 95/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 6.8232e-07 - val_loss: 1.1656e-06\n",
            "Epoch 96/500\n",
            "47/47 [==============================] - 0s 88us/step - loss: 6.6205e-07 - val_loss: 1.1640e-06\n",
            "Epoch 97/500\n",
            "47/47 [==============================] - 0s 94us/step - loss: 6.4424e-07 - val_loss: 1.1641e-06\n",
            "Epoch 98/500\n",
            "47/47 [==============================] - 0s 96us/step - loss: 6.2883e-07 - val_loss: 1.1640e-06\n",
            "Epoch 99/500\n",
            "47/47 [==============================] - 0s 78us/step - loss: 6.1333e-07 - val_loss: 1.1630e-06\n",
            "Epoch 100/500\n",
            "47/47 [==============================] - 0s 78us/step - loss: 5.9632e-07 - val_loss: 1.1604e-06\n",
            "Epoch 101/500\n",
            "47/47 [==============================] - 0s 96us/step - loss: 5.7933e-07 - val_loss: 1.1570e-06\n",
            "Epoch 102/500\n",
            "47/47 [==============================] - 0s 87us/step - loss: 5.6400e-07 - val_loss: 1.1541e-06\n",
            "Epoch 103/500\n",
            "47/47 [==============================] - 0s 91us/step - loss: 5.5034e-07 - val_loss: 1.1531e-06\n",
            "Epoch 104/500\n",
            "47/47 [==============================] - 0s 94us/step - loss: 5.3814e-07 - val_loss: 1.1551e-06\n",
            "Epoch 105/500\n",
            "47/47 [==============================] - 0s 93us/step - loss: 5.2637e-07 - val_loss: 1.1601e-06\n",
            "Epoch 106/500\n",
            "47/47 [==============================] - 0s 89us/step - loss: 5.1445e-07 - val_loss: 1.1673e-06\n",
            "Epoch 107/500\n",
            "47/47 [==============================] - 0s 90us/step - loss: 5.0239e-07 - val_loss: 1.1754e-06\n",
            "Epoch 108/500\n",
            "47/47 [==============================] - 0s 96us/step - loss: 4.9092e-07 - val_loss: 1.1821e-06\n",
            "Epoch 109/500\n",
            "47/47 [==============================] - 0s 103us/step - loss: 4.8059e-07 - val_loss: 1.1850e-06\n",
            "Epoch 110/500\n",
            "47/47 [==============================] - 0s 98us/step - loss: 4.7091e-07 - val_loss: 1.1837e-06\n",
            "Epoch 111/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 4.6114e-07 - val_loss: 1.1790e-06\n",
            "Epoch 112/500\n",
            "47/47 [==============================] - 0s 89us/step - loss: 4.5119e-07 - val_loss: 1.1720e-06\n",
            "Epoch 113/500\n",
            "47/47 [==============================] - 0s 92us/step - loss: 4.4141e-07 - val_loss: 1.1646e-06\n",
            "Epoch 114/500\n",
            "47/47 [==============================] - 0s 93us/step - loss: 4.3222e-07 - val_loss: 1.1586e-06\n",
            "Epoch 115/500\n",
            "47/47 [==============================] - 0s 94us/step - loss: 4.2371e-07 - val_loss: 1.1550e-06\n",
            "Epoch 116/500\n",
            "47/47 [==============================] - 0s 88us/step - loss: 4.1556e-07 - val_loss: 1.1542e-06\n",
            "Epoch 117/500\n",
            "47/47 [==============================] - 0s 67us/step - loss: 4.0750e-07 - val_loss: 1.1558e-06\n",
            "Epoch 118/500\n",
            "47/47 [==============================] - 0s 67us/step - loss: 3.9951e-07 - val_loss: 1.1588e-06\n",
            "Epoch 119/500\n",
            "47/47 [==============================] - 0s 70us/step - loss: 3.9182e-07 - val_loss: 1.1618e-06\n",
            "Epoch 120/500\n",
            "47/47 [==============================] - 0s 81us/step - loss: 3.8458e-07 - val_loss: 1.1637e-06\n",
            "Epoch 121/500\n",
            "47/47 [==============================] - 0s 71us/step - loss: 3.7773e-07 - val_loss: 1.1637e-06\n",
            "Epoch 122/500\n",
            "47/47 [==============================] - 0s 110us/step - loss: 3.7110e-07 - val_loss: 1.1612e-06\n",
            "Epoch 123/500\n",
            "47/47 [==============================] - 0s 102us/step - loss: 3.6460e-07 - val_loss: 1.1566e-06\n",
            "Epoch 124/500\n",
            "47/47 [==============================] - 0s 93us/step - loss: 3.5822e-07 - val_loss: 1.1506e-06\n",
            "Epoch 125/500\n",
            "47/47 [==============================] - 0s 101us/step - loss: 3.5200e-07 - val_loss: 1.1443e-06\n",
            "Epoch 126/500\n",
            "47/47 [==============================] - 0s 90us/step - loss: 3.4603e-07 - val_loss: 1.1384e-06\n",
            "Epoch 127/500\n",
            "47/47 [==============================] - 0s 108us/step - loss: 3.4023e-07 - val_loss: 1.1337e-06\n",
            "Epoch 128/500\n",
            "47/47 [==============================] - 0s 103us/step - loss: 3.3466e-07 - val_loss: 1.1303e-06\n",
            "Epoch 129/500\n",
            "47/47 [==============================] - 0s 103us/step - loss: 3.2917e-07 - val_loss: 1.1282e-06\n",
            "Epoch 130/500\n",
            "47/47 [==============================] - 0s 110us/step - loss: 3.2381e-07 - val_loss: 1.1268e-06\n",
            "Epoch 131/500\n",
            "47/47 [==============================] - 0s 111us/step - loss: 3.1872e-07 - val_loss: 1.1254e-06\n",
            "Epoch 132/500\n",
            "47/47 [==============================] - 0s 108us/step - loss: 3.1383e-07 - val_loss: 1.1241e-06\n",
            "Epoch 133/500\n",
            "47/47 [==============================] - 0s 115us/step - loss: 3.0909e-07 - val_loss: 1.1230e-06\n",
            "Epoch 134/500\n",
            "47/47 [==============================] - 0s 106us/step - loss: 3.0445e-07 - val_loss: 1.1228e-06\n",
            "Epoch 135/500\n",
            "47/47 [==============================] - 0s 100us/step - loss: 2.9989e-07 - val_loss: 1.1217e-06\n",
            "Epoch 136/500\n",
            "47/47 [==============================] - 0s 96us/step - loss: 2.9550e-07 - val_loss: 1.1209e-06\n",
            "Epoch 137/500\n",
            "47/47 [==============================] - 0s 99us/step - loss: 2.9148e-07 - val_loss: 1.1204e-06\n",
            "Epoch 138/500\n",
            "47/47 [==============================] - 0s 96us/step - loss: 2.8759e-07 - val_loss: 1.1205e-06\n",
            "Epoch 139/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 2.8377e-07 - val_loss: 1.1210e-06\n",
            "Epoch 140/500\n",
            "47/47 [==============================] - 0s 85us/step - loss: 2.8001e-07 - val_loss: 1.1216e-06\n",
            "Epoch 141/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 2.7635e-07 - val_loss: 1.1221e-06\n",
            "Epoch 142/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 2.7300e-07 - val_loss: 1.1220e-06\n",
            "Epoch 143/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 2.6975e-07 - val_loss: 1.1211e-06\n",
            "Epoch 144/500\n",
            "47/47 [==============================] - 0s 87us/step - loss: 2.6668e-07 - val_loss: 1.1194e-06\n",
            "Epoch 145/500\n",
            "47/47 [==============================] - 0s 66us/step - loss: 2.6371e-07 - val_loss: 1.1162e-06\n",
            "Epoch 146/500\n",
            "47/47 [==============================] - 0s 67us/step - loss: 2.6083e-07 - val_loss: 1.1124e-06\n",
            "Epoch 147/500\n",
            "47/47 [==============================] - 0s 62us/step - loss: 2.5803e-07 - val_loss: 1.1086e-06\n",
            "Epoch 148/500\n",
            "47/47 [==============================] - 0s 74us/step - loss: 2.5534e-07 - val_loss: 1.1051e-06\n",
            "Epoch 149/500\n",
            "47/47 [==============================] - 0s 71us/step - loss: 2.5276e-07 - val_loss: 1.1016e-06\n",
            "Epoch 150/500\n",
            "47/47 [==============================] - 0s 76us/step - loss: 2.5025e-07 - val_loss: 1.0989e-06\n",
            "Epoch 151/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 2.4778e-07 - val_loss: 1.0968e-06\n",
            "Epoch 152/500\n",
            "47/47 [==============================] - 0s 78us/step - loss: 2.4542e-07 - val_loss: 1.0950e-06\n",
            "Epoch 153/500\n",
            "47/47 [==============================] - 0s 81us/step - loss: 2.4315e-07 - val_loss: 1.0932e-06\n",
            "Epoch 154/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 2.4097e-07 - val_loss: 1.0904e-06\n",
            "Epoch 155/500\n",
            "47/47 [==============================] - 0s 87us/step - loss: 2.3884e-07 - val_loss: 1.0871e-06\n",
            "Epoch 156/500\n",
            "47/47 [==============================] - 0s 87us/step - loss: 2.3697e-07 - val_loss: 1.0840e-06\n",
            "Epoch 157/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 2.3514e-07 - val_loss: 1.0809e-06\n",
            "Epoch 158/500\n",
            "47/47 [==============================] - 0s 74us/step - loss: 2.3332e-07 - val_loss: 1.0777e-06\n",
            "Epoch 159/500\n",
            "47/47 [==============================] - 0s 74us/step - loss: 2.3154e-07 - val_loss: 1.0745e-06\n",
            "Epoch 160/500\n",
            "47/47 [==============================] - 0s 71us/step - loss: 2.2982e-07 - val_loss: 1.0717e-06\n",
            "Epoch 161/500\n",
            "47/47 [==============================] - 0s 86us/step - loss: 2.2813e-07 - val_loss: 1.0698e-06\n",
            "Epoch 162/500\n",
            "47/47 [==============================] - 0s 89us/step - loss: 2.2647e-07 - val_loss: 1.0687e-06\n",
            "Epoch 163/500\n",
            "47/47 [==============================] - 0s 94us/step - loss: 2.2482e-07 - val_loss: 1.0686e-06\n",
            "Epoch 164/500\n",
            "47/47 [==============================] - 0s 91us/step - loss: 2.2319e-07 - val_loss: 1.0689e-06\n",
            "Epoch 165/500\n",
            "47/47 [==============================] - 0s 100us/step - loss: 2.2162e-07 - val_loss: 1.0694e-06\n",
            "Epoch 166/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 2.2006e-07 - val_loss: 1.0699e-06\n",
            "Epoch 167/500\n",
            "47/47 [==============================] - 0s 77us/step - loss: 2.1852e-07 - val_loss: 1.0704e-06\n",
            "Epoch 168/500\n",
            "47/47 [==============================] - 0s 77us/step - loss: 2.1698e-07 - val_loss: 1.0708e-06\n",
            "Epoch 169/500\n",
            "47/47 [==============================] - 0s 91us/step - loss: 2.1543e-07 - val_loss: 1.0713e-06\n",
            "Epoch 170/500\n",
            "47/47 [==============================] - 0s 82us/step - loss: 2.1390e-07 - val_loss: 1.0717e-06\n",
            "Epoch 171/500\n",
            "47/47 [==============================] - 0s 92us/step - loss: 2.1240e-07 - val_loss: 1.0722e-06\n",
            "Epoch 172/500\n",
            "47/47 [==============================] - 0s 86us/step - loss: 2.1093e-07 - val_loss: 1.0731e-06\n",
            "Epoch 173/500\n",
            "47/47 [==============================] - 0s 98us/step - loss: 2.0949e-07 - val_loss: 1.0743e-06\n",
            "Epoch 174/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 2.0807e-07 - val_loss: 1.0760e-06\n",
            "Epoch 175/500\n",
            "47/47 [==============================] - 0s 75us/step - loss: 2.0667e-07 - val_loss: 1.0778e-06\n",
            "Epoch 176/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 2.0532e-07 - val_loss: 1.0795e-06\n",
            "Epoch 177/500\n",
            "47/47 [==============================] - 0s 90us/step - loss: 2.0404e-07 - val_loss: 1.0808e-06\n",
            "Epoch 178/500\n",
            "47/47 [==============================] - 0s 92us/step - loss: 2.0279e-07 - val_loss: 1.0817e-06\n",
            "Epoch 179/500\n",
            "47/47 [==============================] - 0s 88us/step - loss: 2.0155e-07 - val_loss: 1.0820e-06\n",
            "Epoch 180/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 2.0035e-07 - val_loss: 1.0820e-06\n",
            "Epoch 181/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.9915e-07 - val_loss: 1.0818e-06\n",
            "Epoch 182/500\n",
            "47/47 [==============================] - 0s 85us/step - loss: 1.9796e-07 - val_loss: 1.0811e-06\n",
            "Epoch 183/500\n",
            "47/47 [==============================] - 0s 78us/step - loss: 1.9681e-07 - val_loss: 1.0801e-06\n",
            "Epoch 184/500\n",
            "47/47 [==============================] - 0s 72us/step - loss: 1.9570e-07 - val_loss: 1.0786e-06\n",
            "Epoch 185/500\n",
            "47/47 [==============================] - 0s 74us/step - loss: 1.9460e-07 - val_loss: 1.0761e-06\n",
            "Epoch 186/500\n",
            "47/47 [==============================] - 0s 85us/step - loss: 1.9352e-07 - val_loss: 1.0737e-06\n",
            "Epoch 187/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.9246e-07 - val_loss: 1.0715e-06\n",
            "Epoch 188/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.9142e-07 - val_loss: 1.0692e-06\n",
            "Epoch 189/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 1.9039e-07 - val_loss: 1.0666e-06\n",
            "Epoch 190/500\n",
            "47/47 [==============================] - 0s 68us/step - loss: 1.8938e-07 - val_loss: 1.0638e-06\n",
            "Epoch 191/500\n",
            "47/47 [==============================] - 0s 87us/step - loss: 1.8838e-07 - val_loss: 1.0609e-06\n",
            "Epoch 192/500\n",
            "47/47 [==============================] - 0s 67us/step - loss: 1.8741e-07 - val_loss: 1.0580e-06\n",
            "Epoch 193/500\n",
            "47/47 [==============================] - 0s 71us/step - loss: 1.8653e-07 - val_loss: 1.0550e-06\n",
            "Epoch 194/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.8562e-07 - val_loss: 1.0521e-06\n",
            "Epoch 195/500\n",
            "47/47 [==============================] - 0s 72us/step - loss: 1.8469e-07 - val_loss: 1.0497e-06\n",
            "Epoch 196/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 1.8377e-07 - val_loss: 1.0478e-06\n",
            "Epoch 197/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 1.8288e-07 - val_loss: 1.0467e-06\n",
            "Epoch 198/500\n",
            "47/47 [==============================] - 0s 94us/step - loss: 1.8203e-07 - val_loss: 1.0460e-06\n",
            "Epoch 199/500\n",
            "47/47 [==============================] - 0s 90us/step - loss: 1.8118e-07 - val_loss: 1.0455e-06\n",
            "Epoch 200/500\n",
            "47/47 [==============================] - 0s 88us/step - loss: 1.8033e-07 - val_loss: 1.0451e-06\n",
            "Epoch 201/500\n",
            "47/47 [==============================] - 0s 85us/step - loss: 1.7950e-07 - val_loss: 1.0445e-06\n",
            "Epoch 202/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.7872e-07 - val_loss: 1.0432e-06\n",
            "Epoch 203/500\n",
            "47/47 [==============================] - 0s 74us/step - loss: 1.7794e-07 - val_loss: 1.0414e-06\n",
            "Epoch 204/500\n",
            "47/47 [==============================] - 0s 85us/step - loss: 1.7715e-07 - val_loss: 1.0392e-06\n",
            "Epoch 205/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.7636e-07 - val_loss: 1.0371e-06\n",
            "Epoch 206/500\n",
            "47/47 [==============================] - 0s 75us/step - loss: 1.7561e-07 - val_loss: 1.0355e-06\n",
            "Epoch 207/500\n",
            "47/47 [==============================] - 0s 91us/step - loss: 1.7486e-07 - val_loss: 1.0343e-06\n",
            "Epoch 208/500\n",
            "47/47 [==============================] - 0s 76us/step - loss: 1.7412e-07 - val_loss: 1.0333e-06\n",
            "Epoch 209/500\n",
            "47/47 [==============================] - 0s 78us/step - loss: 1.7339e-07 - val_loss: 1.0322e-06\n",
            "Epoch 210/500\n",
            "47/47 [==============================] - 0s 81us/step - loss: 1.7269e-07 - val_loss: 1.0309e-06\n",
            "Epoch 211/500\n",
            "47/47 [==============================] - 0s 92us/step - loss: 1.7199e-07 - val_loss: 1.0291e-06\n",
            "Epoch 212/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 1.7129e-07 - val_loss: 1.0271e-06\n",
            "Epoch 213/500\n",
            "47/47 [==============================] - 0s 102us/step - loss: 1.7059e-07 - val_loss: 1.0252e-06\n",
            "Epoch 214/500\n",
            "47/47 [==============================] - 0s 108us/step - loss: 1.6993e-07 - val_loss: 1.0237e-06\n",
            "Epoch 215/500\n",
            "47/47 [==============================] - 0s 112us/step - loss: 1.6927e-07 - val_loss: 1.0226e-06\n",
            "Epoch 216/500\n",
            "47/47 [==============================] - 0s 116us/step - loss: 1.6863e-07 - val_loss: 1.0216e-06\n",
            "Epoch 217/500\n",
            "47/47 [==============================] - 0s 118us/step - loss: 1.6800e-07 - val_loss: 1.0206e-06\n",
            "Epoch 218/500\n",
            "47/47 [==============================] - 0s 106us/step - loss: 1.6737e-07 - val_loss: 1.0196e-06\n",
            "Epoch 219/500\n",
            "47/47 [==============================] - 0s 109us/step - loss: 1.6676e-07 - val_loss: 1.0187e-06\n",
            "Epoch 220/500\n",
            "47/47 [==============================] - 0s 113us/step - loss: 1.6617e-07 - val_loss: 1.0178e-06\n",
            "Epoch 221/500\n",
            "47/47 [==============================] - 0s 123us/step - loss: 1.6555e-07 - val_loss: 1.0166e-06\n",
            "Epoch 222/500\n",
            "47/47 [==============================] - 0s 118us/step - loss: 1.6497e-07 - val_loss: 1.0152e-06\n",
            "Epoch 223/500\n",
            "47/47 [==============================] - 0s 112us/step - loss: 1.6440e-07 - val_loss: 1.0135e-06\n",
            "Epoch 224/500\n",
            "47/47 [==============================] - 0s 105us/step - loss: 1.6383e-07 - val_loss: 1.0119e-06\n",
            "Epoch 225/500\n",
            "47/47 [==============================] - 0s 86us/step - loss: 1.6326e-07 - val_loss: 1.0105e-06\n",
            "Epoch 226/500\n",
            "47/47 [==============================] - 0s 98us/step - loss: 1.6270e-07 - val_loss: 1.0092e-06\n",
            "Epoch 227/500\n",
            "47/47 [==============================] - 0s 91us/step - loss: 1.6215e-07 - val_loss: 1.0079e-06\n",
            "Epoch 228/500\n",
            "47/47 [==============================] - 0s 85us/step - loss: 1.6157e-07 - val_loss: 1.0068e-06\n",
            "Epoch 229/500\n",
            "47/47 [==============================] - 0s 81us/step - loss: 1.6100e-07 - val_loss: 1.0059e-06\n",
            "Epoch 230/500\n",
            "47/47 [==============================] - 0s 77us/step - loss: 1.6046e-07 - val_loss: 1.0049e-06\n",
            "Epoch 231/500\n",
            "47/47 [==============================] - 0s 76us/step - loss: 1.5990e-07 - val_loss: 1.0039e-06\n",
            "Epoch 232/500\n",
            "47/47 [==============================] - 0s 89us/step - loss: 1.5933e-07 - val_loss: 1.0025e-06\n",
            "Epoch 233/500\n",
            "47/47 [==============================] - 0s 85us/step - loss: 1.5877e-07 - val_loss: 1.0007e-06\n",
            "Epoch 234/500\n",
            "47/47 [==============================] - 0s 77us/step - loss: 1.5825e-07 - val_loss: 1.0002e-06\n",
            "Epoch 235/500\n",
            "47/47 [==============================] - 0s 93us/step - loss: 1.5777e-07 - val_loss: 9.9903e-07\n",
            "Epoch 236/500\n",
            "47/47 [==============================] - 0s 90us/step - loss: 1.5728e-07 - val_loss: 9.9751e-07\n",
            "Epoch 237/500\n",
            "47/47 [==============================] - 0s 95us/step - loss: 1.5677e-07 - val_loss: 9.9583e-07\n",
            "Epoch 238/500\n",
            "47/47 [==============================] - 0s 102us/step - loss: 1.5626e-07 - val_loss: 9.9427e-07\n",
            "Epoch 239/500\n",
            "47/47 [==============================] - 0s 93us/step - loss: 1.5575e-07 - val_loss: 9.9300e-07\n",
            "Epoch 240/500\n",
            "47/47 [==============================] - 0s 97us/step - loss: 1.5524e-07 - val_loss: 9.9207e-07\n",
            "Epoch 241/500\n",
            "47/47 [==============================] - 0s 88us/step - loss: 1.5475e-07 - val_loss: 9.9162e-07\n",
            "Epoch 242/500\n",
            "47/47 [==============================] - 0s 93us/step - loss: 1.5429e-07 - val_loss: 9.9125e-07\n",
            "Epoch 243/500\n",
            "47/47 [==============================] - 0s 94us/step - loss: 1.5381e-07 - val_loss: 9.9018e-07\n",
            "Epoch 244/500\n",
            "47/47 [==============================] - 0s 97us/step - loss: 1.5333e-07 - val_loss: 9.8831e-07\n",
            "Epoch 245/500\n",
            "47/47 [==============================] - 0s 87us/step - loss: 1.5287e-07 - val_loss: 9.8566e-07\n",
            "Epoch 246/500\n",
            "47/47 [==============================] - 0s 86us/step - loss: 1.5242e-07 - val_loss: 9.8284e-07\n",
            "Epoch 247/500\n",
            "47/47 [==============================] - 0s 100us/step - loss: 1.5197e-07 - val_loss: 9.8030e-07\n",
            "Epoch 248/500\n",
            "47/47 [==============================] - 0s 86us/step - loss: 1.5152e-07 - val_loss: 9.7842e-07\n",
            "Epoch 249/500\n",
            "47/47 [==============================] - 0s 96us/step - loss: 1.5112e-07 - val_loss: 9.7762e-07\n",
            "Epoch 250/500\n",
            "47/47 [==============================] - 0s 97us/step - loss: 1.5068e-07 - val_loss: 9.7758e-07\n",
            "Epoch 251/500\n",
            "47/47 [==============================] - 0s 103us/step - loss: 1.5025e-07 - val_loss: 9.7743e-07\n",
            "Epoch 252/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.4984e-07 - val_loss: 9.7688e-07\n",
            "Epoch 253/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.4946e-07 - val_loss: 9.7573e-07\n",
            "Epoch 254/500\n",
            "47/47 [==============================] - 0s 98us/step - loss: 1.4905e-07 - val_loss: 9.7409e-07\n",
            "Epoch 255/500\n",
            "47/47 [==============================] - 0s 94us/step - loss: 1.4863e-07 - val_loss: 9.7226e-07\n",
            "Epoch 256/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.4825e-07 - val_loss: 9.7060e-07\n",
            "Epoch 257/500\n",
            "47/47 [==============================] - 0s 92us/step - loss: 1.4788e-07 - val_loss: 9.6925e-07\n",
            "Epoch 258/500\n",
            "47/47 [==============================] - 0s 95us/step - loss: 1.4750e-07 - val_loss: 9.6820e-07\n",
            "Epoch 259/500\n",
            "47/47 [==============================] - 0s 101us/step - loss: 1.4715e-07 - val_loss: 9.6750e-07\n",
            "Epoch 260/500\n",
            "47/47 [==============================] - 0s 96us/step - loss: 1.4679e-07 - val_loss: 9.6693e-07\n",
            "Epoch 261/500\n",
            "47/47 [==============================] - 0s 98us/step - loss: 1.4643e-07 - val_loss: 9.6596e-07\n",
            "Epoch 262/500\n",
            "47/47 [==============================] - 0s 95us/step - loss: 1.4609e-07 - val_loss: 9.6599e-07\n",
            "Epoch 263/500\n",
            "47/47 [==============================] - 0s 93us/step - loss: 1.4578e-07 - val_loss: 9.6529e-07\n",
            "Epoch 264/500\n",
            "47/47 [==============================] - 0s 94us/step - loss: 1.4548e-07 - val_loss: 9.6382e-07\n",
            "Epoch 265/500\n",
            "47/47 [==============================] - 0s 95us/step - loss: 1.4517e-07 - val_loss: 9.6151e-07\n",
            "Epoch 266/500\n",
            "47/47 [==============================] - 0s 99us/step - loss: 1.4483e-07 - val_loss: 9.5868e-07\n",
            "Epoch 267/500\n",
            "47/47 [==============================] - 0s 92us/step - loss: 1.4449e-07 - val_loss: 9.5558e-07\n",
            "Epoch 268/500\n",
            "47/47 [==============================] - 0s 88us/step - loss: 1.4415e-07 - val_loss: 9.5255e-07\n",
            "Epoch 269/500\n",
            "47/47 [==============================] - 0s 89us/step - loss: 1.4382e-07 - val_loss: 9.5002e-07\n",
            "Epoch 270/500\n",
            "47/47 [==============================] - 0s 88us/step - loss: 1.4349e-07 - val_loss: 9.4806e-07\n",
            "Epoch 271/500\n",
            "47/47 [==============================] - 0s 86us/step - loss: 1.4316e-07 - val_loss: 9.4654e-07\n",
            "Epoch 272/500\n",
            "47/47 [==============================] - 0s 93us/step - loss: 1.4283e-07 - val_loss: 9.4522e-07\n",
            "Epoch 273/500\n",
            "47/47 [==============================] - 0s 76us/step - loss: 1.4251e-07 - val_loss: 9.4380e-07\n",
            "Epoch 274/500\n",
            "47/47 [==============================] - 0s 81us/step - loss: 1.4219e-07 - val_loss: 9.4215e-07\n",
            "Epoch 275/500\n",
            "47/47 [==============================] - 0s 79us/step - loss: 1.4188e-07 - val_loss: 9.4025e-07\n",
            "Epoch 276/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 1.4156e-07 - val_loss: 9.3828e-07\n",
            "Epoch 277/500\n",
            "47/47 [==============================] - 0s 62us/step - loss: 1.4125e-07 - val_loss: 9.3650e-07\n",
            "Epoch 278/500\n",
            "47/47 [==============================] - 0s 82us/step - loss: 1.4094e-07 - val_loss: 9.3514e-07\n",
            "Epoch 279/500\n",
            "47/47 [==============================] - 0s 91us/step - loss: 1.4065e-07 - val_loss: 9.3437e-07\n",
            "Epoch 280/500\n",
            "47/47 [==============================] - 0s 92us/step - loss: 1.4036e-07 - val_loss: 9.3394e-07\n",
            "Epoch 281/500\n",
            "47/47 [==============================] - 0s 98us/step - loss: 1.4007e-07 - val_loss: 9.3343e-07\n",
            "Epoch 282/500\n",
            "47/47 [==============================] - 0s 100us/step - loss: 1.3978e-07 - val_loss: 9.3239e-07\n",
            "Epoch 283/500\n",
            "47/47 [==============================] - 0s 107us/step - loss: 1.3951e-07 - val_loss: 9.3024e-07\n",
            "Epoch 284/500\n",
            "47/47 [==============================] - 0s 108us/step - loss: 1.3923e-07 - val_loss: 9.2736e-07\n",
            "Epoch 285/500\n",
            "47/47 [==============================] - 0s 108us/step - loss: 1.3895e-07 - val_loss: 9.2421e-07\n",
            "Epoch 286/500\n",
            "47/47 [==============================] - 0s 103us/step - loss: 1.3868e-07 - val_loss: 9.2141e-07\n",
            "Epoch 287/500\n",
            "47/47 [==============================] - 0s 98us/step - loss: 1.3842e-07 - val_loss: 9.1932e-07\n",
            "Epoch 288/500\n",
            "47/47 [==============================] - 0s 95us/step - loss: 1.3816e-07 - val_loss: 9.1797e-07\n",
            "Epoch 289/500\n",
            "47/47 [==============================] - 0s 94us/step - loss: 1.3789e-07 - val_loss: 9.1679e-07\n",
            "Epoch 290/500\n",
            "47/47 [==============================] - 0s 95us/step - loss: 1.3764e-07 - val_loss: 9.1536e-07\n",
            "Epoch 291/500\n",
            "47/47 [==============================] - 0s 111us/step - loss: 1.3740e-07 - val_loss: 9.1367e-07\n",
            "Epoch 292/500\n",
            "47/47 [==============================] - 0s 101us/step - loss: 1.3715e-07 - val_loss: 9.1180e-07\n",
            "Epoch 293/500\n",
            "47/47 [==============================] - 0s 110us/step - loss: 1.3690e-07 - val_loss: 9.0990e-07\n",
            "Epoch 294/500\n",
            "47/47 [==============================] - 0s 114us/step - loss: 1.3667e-07 - val_loss: 9.0808e-07\n",
            "Epoch 295/500\n",
            "47/47 [==============================] - 0s 114us/step - loss: 1.3644e-07 - val_loss: 9.0650e-07\n",
            "Epoch 296/500\n",
            "47/47 [==============================] - 0s 103us/step - loss: 1.3621e-07 - val_loss: 9.0508e-07\n",
            "Epoch 297/500\n",
            "47/47 [==============================] - 0s 118us/step - loss: 1.3597e-07 - val_loss: 9.0357e-07\n",
            "Epoch 298/500\n",
            "47/47 [==============================] - 0s 110us/step - loss: 1.3576e-07 - val_loss: 9.0243e-07\n",
            "Epoch 299/500\n",
            "47/47 [==============================] - 0s 111us/step - loss: 1.3554e-07 - val_loss: 9.0120e-07\n",
            "Epoch 300/500\n",
            "47/47 [==============================] - 0s 117us/step - loss: 1.3531e-07 - val_loss: 9.0006e-07\n",
            "Epoch 301/500\n",
            "47/47 [==============================] - 0s 114us/step - loss: 1.3510e-07 - val_loss: 8.9891e-07\n",
            "Epoch 302/500\n",
            "47/47 [==============================] - 0s 114us/step - loss: 1.3489e-07 - val_loss: 8.9792e-07\n",
            "Epoch 303/500\n",
            "47/47 [==============================] - 0s 110us/step - loss: 1.3468e-07 - val_loss: 8.9643e-07\n",
            "Epoch 304/500\n",
            "47/47 [==============================] - 0s 105us/step - loss: 1.3447e-07 - val_loss: 8.9493e-07\n",
            "Epoch 305/500\n",
            "47/47 [==============================] - 0s 104us/step - loss: 1.3427e-07 - val_loss: 8.9329e-07\n",
            "Epoch 306/500\n",
            "47/47 [==============================] - 0s 100us/step - loss: 1.3408e-07 - val_loss: 8.9153e-07\n",
            "Epoch 307/500\n",
            "47/47 [==============================] - 0s 105us/step - loss: 1.3388e-07 - val_loss: 8.8966e-07\n",
            "Epoch 308/500\n",
            "47/47 [==============================] - 0s 96us/step - loss: 1.3369e-07 - val_loss: 8.8769e-07\n",
            "Epoch 309/500\n",
            "47/47 [==============================] - 0s 79us/step - loss: 1.3356e-07 - val_loss: 8.8732e-07\n",
            "Epoch 310/500\n",
            "47/47 [==============================] - 0s 100us/step - loss: 1.3333e-07 - val_loss: 8.8677e-07\n",
            "Epoch 311/500\n",
            "47/47 [==============================] - 0s 91us/step - loss: 1.3318e-07 - val_loss: 8.8586e-07\n",
            "Epoch 312/500\n",
            "47/47 [==============================] - 0s 87us/step - loss: 1.3302e-07 - val_loss: 8.8451e-07\n",
            "Epoch 313/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 1.3285e-07 - val_loss: 8.8281e-07\n",
            "Epoch 314/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 1.3268e-07 - val_loss: 8.8096e-07\n",
            "Epoch 315/500\n",
            "47/47 [==============================] - 0s 95us/step - loss: 1.3252e-07 - val_loss: 8.7921e-07\n",
            "Epoch 316/500\n",
            "47/47 [==============================] - 0s 96us/step - loss: 1.3235e-07 - val_loss: 8.7772e-07\n",
            "Epoch 317/500\n",
            "47/47 [==============================] - 0s 91us/step - loss: 1.3217e-07 - val_loss: 8.7673e-07\n",
            "Epoch 318/500\n",
            "47/47 [==============================] - 0s 88us/step - loss: 1.3200e-07 - val_loss: 8.7604e-07\n",
            "Epoch 319/500\n",
            "47/47 [==============================] - 0s 74us/step - loss: 1.3182e-07 - val_loss: 8.7519e-07\n",
            "Epoch 320/500\n",
            "47/47 [==============================] - 0s 89us/step - loss: 1.3166e-07 - val_loss: 8.7417e-07\n",
            "Epoch 321/500\n",
            "47/47 [==============================] - 0s 87us/step - loss: 1.3149e-07 - val_loss: 8.7283e-07\n",
            "Epoch 322/500\n",
            "47/47 [==============================] - 0s 81us/step - loss: 1.3133e-07 - val_loss: 8.7135e-07\n",
            "Epoch 323/500\n",
            "47/47 [==============================] - 0s 85us/step - loss: 1.3117e-07 - val_loss: 8.6984e-07\n",
            "Epoch 324/500\n",
            "47/47 [==============================] - 0s 103us/step - loss: 1.3102e-07 - val_loss: 8.6831e-07\n",
            "Epoch 325/500\n",
            "47/47 [==============================] - 0s 93us/step - loss: 1.3087e-07 - val_loss: 8.6675e-07\n",
            "Epoch 326/500\n",
            "47/47 [==============================] - 0s 95us/step - loss: 1.3072e-07 - val_loss: 8.6527e-07\n",
            "Epoch 327/500\n",
            "47/47 [==============================] - 0s 100us/step - loss: 1.3057e-07 - val_loss: 8.6411e-07\n",
            "Epoch 328/500\n",
            "47/47 [==============================] - 0s 122us/step - loss: 1.3042e-07 - val_loss: 8.6317e-07\n",
            "Epoch 329/500\n",
            "47/47 [==============================] - 0s 96us/step - loss: 1.3028e-07 - val_loss: 8.6235e-07\n",
            "Epoch 330/500\n",
            "47/47 [==============================] - 0s 87us/step - loss: 1.3015e-07 - val_loss: 8.6140e-07\n",
            "Epoch 331/500\n",
            "47/47 [==============================] - 0s 94us/step - loss: 1.3001e-07 - val_loss: 8.6007e-07\n",
            "Epoch 332/500\n",
            "47/47 [==============================] - 0s 78us/step - loss: 1.2987e-07 - val_loss: 8.5855e-07\n",
            "Epoch 333/500\n",
            "47/47 [==============================] - 0s 98us/step - loss: 1.2973e-07 - val_loss: 8.5716e-07\n",
            "Epoch 334/500\n",
            "47/47 [==============================] - 0s 88us/step - loss: 1.2961e-07 - val_loss: 8.5631e-07\n",
            "Epoch 335/500\n",
            "47/47 [==============================] - 0s 88us/step - loss: 1.2947e-07 - val_loss: 8.5572e-07\n",
            "Epoch 336/500\n",
            "47/47 [==============================] - 0s 92us/step - loss: 1.2935e-07 - val_loss: 8.5490e-07\n",
            "Epoch 337/500\n",
            "47/47 [==============================] - 0s 75us/step - loss: 1.2923e-07 - val_loss: 8.5381e-07\n",
            "Epoch 338/500\n",
            "47/47 [==============================] - 0s 78us/step - loss: 1.2911e-07 - val_loss: 8.5246e-07\n",
            "Epoch 339/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.2897e-07 - val_loss: 8.5105e-07\n",
            "Epoch 340/500\n",
            "47/47 [==============================] - 0s 78us/step - loss: 1.2886e-07 - val_loss: 8.4988e-07\n",
            "Epoch 341/500\n",
            "47/47 [==============================] - 0s 88us/step - loss: 1.2874e-07 - val_loss: 8.4892e-07\n",
            "Epoch 342/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 1.2861e-07 - val_loss: 8.4793e-07\n",
            "Epoch 343/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 1.2849e-07 - val_loss: 8.4690e-07\n",
            "Epoch 344/500\n",
            "47/47 [==============================] - 0s 89us/step - loss: 1.2838e-07 - val_loss: 8.4592e-07\n",
            "Epoch 345/500\n",
            "47/47 [==============================] - 0s 87us/step - loss: 1.2827e-07 - val_loss: 8.4496e-07\n",
            "Epoch 346/500\n",
            "47/47 [==============================] - 0s 86us/step - loss: 1.2816e-07 - val_loss: 8.4409e-07\n",
            "Epoch 347/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.2804e-07 - val_loss: 8.4313e-07\n",
            "Epoch 348/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 1.2794e-07 - val_loss: 8.4196e-07\n",
            "Epoch 349/500\n",
            "47/47 [==============================] - 0s 87us/step - loss: 1.2783e-07 - val_loss: 8.4065e-07\n",
            "Epoch 350/500\n",
            "47/47 [==============================] - 0s 89us/step - loss: 1.2773e-07 - val_loss: 8.3945e-07\n",
            "Epoch 351/500\n",
            "47/47 [==============================] - 0s 92us/step - loss: 1.2762e-07 - val_loss: 8.3854e-07\n",
            "Epoch 352/500\n",
            "47/47 [==============================] - 0s 88us/step - loss: 1.2753e-07 - val_loss: 8.3791e-07\n",
            "Epoch 353/500\n",
            "47/47 [==============================] - 0s 91us/step - loss: 1.2742e-07 - val_loss: 8.3739e-07\n",
            "Epoch 354/500\n",
            "47/47 [==============================] - 0s 92us/step - loss: 1.2732e-07 - val_loss: 8.3639e-07\n",
            "Epoch 355/500\n",
            "47/47 [==============================] - 0s 91us/step - loss: 1.2723e-07 - val_loss: 8.3493e-07\n",
            "Epoch 356/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 1.2713e-07 - val_loss: 8.3318e-07\n",
            "Epoch 357/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 1.2703e-07 - val_loss: 8.3141e-07\n",
            "Epoch 358/500\n",
            "47/47 [==============================] - 0s 89us/step - loss: 1.2693e-07 - val_loss: 8.2988e-07\n",
            "Epoch 359/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 1.2684e-07 - val_loss: 8.2909e-07\n",
            "Epoch 360/500\n",
            "47/47 [==============================] - 0s 87us/step - loss: 1.2675e-07 - val_loss: 8.2889e-07\n",
            "Epoch 361/500\n",
            "47/47 [==============================] - 0s 89us/step - loss: 1.2665e-07 - val_loss: 8.2860e-07\n",
            "Epoch 362/500\n",
            "47/47 [==============================] - 0s 90us/step - loss: 1.2657e-07 - val_loss: 8.2801e-07\n",
            "Epoch 363/500\n",
            "47/47 [==============================] - 0s 96us/step - loss: 1.2648e-07 - val_loss: 8.2697e-07\n",
            "Epoch 364/500\n",
            "47/47 [==============================] - 0s 103us/step - loss: 1.2638e-07 - val_loss: 8.2564e-07\n",
            "Epoch 365/500\n",
            "47/47 [==============================] - 0s 87us/step - loss: 1.2630e-07 - val_loss: 8.2446e-07\n",
            "Epoch 366/500\n",
            "47/47 [==============================] - 0s 108us/step - loss: 1.2621e-07 - val_loss: 8.2369e-07\n",
            "Epoch 367/500\n",
            "47/47 [==============================] - 0s 122us/step - loss: 1.2612e-07 - val_loss: 8.2287e-07\n",
            "Epoch 368/500\n",
            "47/47 [==============================] - 0s 107us/step - loss: 1.2604e-07 - val_loss: 8.2188e-07\n",
            "Epoch 369/500\n",
            "47/47 [==============================] - 0s 98us/step - loss: 1.2596e-07 - val_loss: 8.2071e-07\n",
            "Epoch 370/500\n",
            "47/47 [==============================] - 0s 105us/step - loss: 1.2588e-07 - val_loss: 8.1948e-07\n",
            "Epoch 371/500\n",
            "47/47 [==============================] - 0s 85us/step - loss: 1.2579e-07 - val_loss: 8.1831e-07\n",
            "Epoch 372/500\n",
            "47/47 [==============================] - 0s 103us/step - loss: 1.2571e-07 - val_loss: 8.1730e-07\n",
            "Epoch 373/500\n",
            "47/47 [==============================] - 0s 104us/step - loss: 1.2563e-07 - val_loss: 8.1634e-07\n",
            "Epoch 374/500\n",
            "47/47 [==============================] - 0s 99us/step - loss: 1.2555e-07 - val_loss: 8.1555e-07\n",
            "Epoch 375/500\n",
            "47/47 [==============================] - 0s 100us/step - loss: 1.2547e-07 - val_loss: 8.1498e-07\n",
            "Epoch 376/500\n",
            "47/47 [==============================] - 0s 104us/step - loss: 1.2540e-07 - val_loss: 8.1446e-07\n",
            "Epoch 377/500\n",
            "47/47 [==============================] - 0s 94us/step - loss: 1.2532e-07 - val_loss: 8.1388e-07\n",
            "Epoch 378/500\n",
            "47/47 [==============================] - 0s 97us/step - loss: 1.2525e-07 - val_loss: 8.1298e-07\n",
            "Epoch 379/500\n",
            "47/47 [==============================] - 0s 105us/step - loss: 1.2518e-07 - val_loss: 8.1190e-07\n",
            "Epoch 380/500\n",
            "47/47 [==============================] - 0s 117us/step - loss: 1.2511e-07 - val_loss: 8.1075e-07\n",
            "Epoch 381/500\n",
            "47/47 [==============================] - 0s 114us/step - loss: 1.2503e-07 - val_loss: 8.0969e-07\n",
            "Epoch 382/500\n",
            "47/47 [==============================] - 0s 119us/step - loss: 1.2504e-07 - val_loss: 8.1104e-07\n",
            "Epoch 383/500\n",
            "47/47 [==============================] - 0s 117us/step - loss: 1.2499e-07 - val_loss: 8.1152e-07\n",
            "Epoch 384/500\n",
            "47/47 [==============================] - 0s 104us/step - loss: 1.2501e-07 - val_loss: 8.1063e-07\n",
            "Epoch 385/500\n",
            "47/47 [==============================] - 0s 96us/step - loss: 1.2493e-07 - val_loss: 8.0847e-07\n",
            "Epoch 386/500\n",
            "47/47 [==============================] - 0s 103us/step - loss: 1.2481e-07 - val_loss: 8.0563e-07\n",
            "Epoch 387/500\n",
            "47/47 [==============================] - 0s 101us/step - loss: 1.2474e-07 - val_loss: 8.0310e-07\n",
            "Epoch 388/500\n",
            "47/47 [==============================] - 0s 93us/step - loss: 1.2472e-07 - val_loss: 8.0167e-07\n",
            "Epoch 389/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 1.2469e-07 - val_loss: 8.0144e-07\n",
            "Epoch 390/500\n",
            "47/47 [==============================] - 0s 82us/step - loss: 1.2460e-07 - val_loss: 8.0190e-07\n",
            "Epoch 391/500\n",
            "47/47 [==============================] - 0s 81us/step - loss: 1.2451e-07 - val_loss: 8.0229e-07\n",
            "Epoch 392/500\n",
            "47/47 [==============================] - 0s 86us/step - loss: 1.2444e-07 - val_loss: 8.0201e-07\n",
            "Epoch 393/500\n",
            "47/47 [==============================] - 0s 90us/step - loss: 1.2439e-07 - val_loss: 8.0083e-07\n",
            "Epoch 394/500\n",
            "47/47 [==============================] - 0s 81us/step - loss: 1.2432e-07 - val_loss: 7.9921e-07\n",
            "Epoch 395/500\n",
            "47/47 [==============================] - 0s 82us/step - loss: 1.2425e-07 - val_loss: 7.9769e-07\n",
            "Epoch 396/500\n",
            "47/47 [==============================] - 0s 74us/step - loss: 1.2417e-07 - val_loss: 7.9667e-07\n",
            "Epoch 397/500\n",
            "47/47 [==============================] - 0s 76us/step - loss: 1.2411e-07 - val_loss: 7.9621e-07\n",
            "Epoch 398/500\n",
            "47/47 [==============================] - 0s 86us/step - loss: 1.2405e-07 - val_loss: 7.9621e-07\n",
            "Epoch 399/500\n",
            "47/47 [==============================] - 0s 86us/step - loss: 1.2399e-07 - val_loss: 7.9629e-07\n",
            "Epoch 400/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.2392e-07 - val_loss: 7.9599e-07\n",
            "Epoch 401/500\n",
            "47/47 [==============================] - 0s 73us/step - loss: 1.2387e-07 - val_loss: 7.9501e-07\n",
            "Epoch 402/500\n",
            "47/47 [==============================] - 0s 73us/step - loss: 1.2381e-07 - val_loss: 7.9351e-07\n",
            "Epoch 403/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 1.2375e-07 - val_loss: 7.9174e-07\n",
            "Epoch 404/500\n",
            "47/47 [==============================] - 0s 82us/step - loss: 1.2369e-07 - val_loss: 7.9018e-07\n",
            "Epoch 405/500\n",
            "47/47 [==============================] - 0s 86us/step - loss: 1.2364e-07 - val_loss: 7.8931e-07\n",
            "Epoch 406/500\n",
            "47/47 [==============================] - 0s 92us/step - loss: 1.2359e-07 - val_loss: 7.8919e-07\n",
            "Epoch 407/500\n",
            "47/47 [==============================] - 0s 74us/step - loss: 1.2352e-07 - val_loss: 7.8933e-07\n",
            "Epoch 408/500\n",
            "47/47 [==============================] - 0s 66us/step - loss: 1.2347e-07 - val_loss: 7.8936e-07\n",
            "Epoch 409/500\n",
            "47/47 [==============================] - 0s 65us/step - loss: 1.2342e-07 - val_loss: 7.8911e-07\n",
            "Epoch 410/500\n",
            "47/47 [==============================] - 0s 82us/step - loss: 1.2337e-07 - val_loss: 7.8832e-07\n",
            "Epoch 411/500\n",
            "47/47 [==============================] - 0s 82us/step - loss: 1.2331e-07 - val_loss: 7.8724e-07\n",
            "Epoch 412/500\n",
            "47/47 [==============================] - 0s 73us/step - loss: 1.2325e-07 - val_loss: 7.8604e-07\n",
            "Epoch 413/500\n",
            "47/47 [==============================] - 0s 67us/step - loss: 1.2320e-07 - val_loss: 7.8497e-07\n",
            "Epoch 414/500\n",
            "47/47 [==============================] - 0s 82us/step - loss: 1.2315e-07 - val_loss: 7.8434e-07\n",
            "Epoch 415/500\n",
            "47/47 [==============================] - 0s 67us/step - loss: 1.2309e-07 - val_loss: 7.8406e-07\n",
            "Epoch 416/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 1.2303e-07 - val_loss: 7.8374e-07\n",
            "Epoch 417/500\n",
            "47/47 [==============================] - 0s 82us/step - loss: 1.2298e-07 - val_loss: 7.8322e-07\n",
            "Epoch 418/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 1.2292e-07 - val_loss: 7.8233e-07\n",
            "Epoch 419/500\n",
            "47/47 [==============================] - 0s 79us/step - loss: 1.2287e-07 - val_loss: 7.8117e-07\n",
            "Epoch 420/500\n",
            "47/47 [==============================] - 0s 93us/step - loss: 1.2281e-07 - val_loss: 7.7992e-07\n",
            "Epoch 421/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 1.2276e-07 - val_loss: 7.7897e-07\n",
            "Epoch 422/500\n",
            "47/47 [==============================] - 0s 93us/step - loss: 1.2270e-07 - val_loss: 7.7831e-07\n",
            "Epoch 423/500\n",
            "47/47 [==============================] - 0s 94us/step - loss: 1.2265e-07 - val_loss: 7.7771e-07\n",
            "Epoch 424/500\n",
            "47/47 [==============================] - 0s 97us/step - loss: 1.2262e-07 - val_loss: 7.7930e-07\n",
            "Epoch 425/500\n",
            "47/47 [==============================] - 0s 91us/step - loss: 1.2262e-07 - val_loss: 7.7952e-07\n",
            "Epoch 426/500\n",
            "47/47 [==============================] - 0s 100us/step - loss: 1.2267e-07 - val_loss: 7.7807e-07\n",
            "Epoch 427/500\n",
            "47/47 [==============================] - 0s 88us/step - loss: 1.2261e-07 - val_loss: 7.7553e-07\n",
            "Epoch 428/500\n",
            "47/47 [==============================] - 0s 91us/step - loss: 1.2251e-07 - val_loss: 7.7291e-07\n",
            "Epoch 429/500\n",
            "47/47 [==============================] - 0s 93us/step - loss: 1.2246e-07 - val_loss: 7.7104e-07\n",
            "Epoch 430/500\n",
            "47/47 [==============================] - 0s 82us/step - loss: 1.2246e-07 - val_loss: 7.7038e-07\n",
            "Epoch 431/500\n",
            "47/47 [==============================] - 0s 78us/step - loss: 1.2243e-07 - val_loss: 7.7066e-07\n",
            "Epoch 432/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 1.2235e-07 - val_loss: 7.7106e-07\n",
            "Epoch 433/500\n",
            "47/47 [==============================] - 0s 81us/step - loss: 1.2229e-07 - val_loss: 7.7072e-07\n",
            "Epoch 434/500\n",
            "47/47 [==============================] - 0s 92us/step - loss: 1.2225e-07 - val_loss: 7.6916e-07\n",
            "Epoch 435/500\n",
            "47/47 [==============================] - 0s 91us/step - loss: 1.2219e-07 - val_loss: 7.6658e-07\n",
            "Epoch 436/500\n",
            "47/47 [==============================] - 0s 94us/step - loss: 1.2210e-07 - val_loss: 7.6372e-07\n",
            "Epoch 437/500\n",
            "47/47 [==============================] - 0s 96us/step - loss: 1.2204e-07 - val_loss: 7.6156e-07\n",
            "Epoch 438/500\n",
            "47/47 [==============================] - 0s 95us/step - loss: 1.2199e-07 - val_loss: 7.6056e-07\n",
            "Epoch 439/500\n",
            "47/47 [==============================] - 0s 77us/step - loss: 1.2193e-07 - val_loss: 7.6056e-07\n",
            "Epoch 440/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 1.2185e-07 - val_loss: 7.6106e-07\n",
            "Epoch 441/500\n",
            "47/47 [==============================] - 0s 95us/step - loss: 1.2179e-07 - val_loss: 7.6141e-07\n",
            "Epoch 442/500\n",
            "47/47 [==============================] - 0s 92us/step - loss: 1.2174e-07 - val_loss: 7.6111e-07\n",
            "Epoch 443/500\n",
            "47/47 [==============================] - 0s 87us/step - loss: 1.2169e-07 - val_loss: 7.6000e-07\n",
            "Epoch 444/500\n",
            "47/47 [==============================] - 0s 91us/step - loss: 1.2163e-07 - val_loss: 7.5832e-07\n",
            "Epoch 445/500\n",
            "47/47 [==============================] - 0s 75us/step - loss: 1.2157e-07 - val_loss: 7.5657e-07\n",
            "Epoch 446/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 1.2152e-07 - val_loss: 7.5510e-07\n",
            "Epoch 447/500\n",
            "47/47 [==============================] - 0s 86us/step - loss: 1.2147e-07 - val_loss: 7.5416e-07\n",
            "Epoch 448/500\n",
            "47/47 [==============================] - 0s 89us/step - loss: 1.2141e-07 - val_loss: 7.5370e-07\n",
            "Epoch 449/500\n",
            "47/47 [==============================] - 0s 88us/step - loss: 1.2135e-07 - val_loss: 7.5345e-07\n",
            "Epoch 450/500\n",
            "47/47 [==============================] - 0s 91us/step - loss: 1.2130e-07 - val_loss: 7.5282e-07\n",
            "Epoch 451/500\n",
            "47/47 [==============================] - 0s 89us/step - loss: 1.2125e-07 - val_loss: 7.5161e-07\n",
            "Epoch 452/500\n",
            "47/47 [==============================] - 0s 92us/step - loss: 1.2120e-07 - val_loss: 7.4996e-07\n",
            "Epoch 453/500\n",
            "47/47 [==============================] - 0s 87us/step - loss: 1.2114e-07 - val_loss: 7.4826e-07\n",
            "Epoch 454/500\n",
            "47/47 [==============================] - 0s 85us/step - loss: 1.2109e-07 - val_loss: 7.4685e-07\n",
            "Epoch 455/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 1.2104e-07 - val_loss: 7.4588e-07\n",
            "Epoch 456/500\n",
            "47/47 [==============================] - 0s 77us/step - loss: 1.2098e-07 - val_loss: 7.4534e-07\n",
            "Epoch 457/500\n",
            "47/47 [==============================] - 0s 98us/step - loss: 1.2093e-07 - val_loss: 7.4482e-07\n",
            "Epoch 458/500\n",
            "47/47 [==============================] - 0s 85us/step - loss: 1.2088e-07 - val_loss: 7.4401e-07\n",
            "Epoch 459/500\n",
            "47/47 [==============================] - 0s 92us/step - loss: 1.2083e-07 - val_loss: 7.4289e-07\n",
            "Epoch 460/500\n",
            "47/47 [==============================] - 0s 106us/step - loss: 1.2078e-07 - val_loss: 7.4159e-07\n",
            "Epoch 461/500\n",
            "47/47 [==============================] - 0s 98us/step - loss: 1.2073e-07 - val_loss: 7.4050e-07\n",
            "Epoch 462/500\n",
            "47/47 [==============================] - 0s 98us/step - loss: 1.2068e-07 - val_loss: 7.3964e-07\n",
            "Epoch 463/500\n",
            "47/47 [==============================] - 0s 94us/step - loss: 1.2063e-07 - val_loss: 7.3901e-07\n",
            "Epoch 464/500\n",
            "47/47 [==============================] - 0s 92us/step - loss: 1.2059e-07 - val_loss: 7.3852e-07\n",
            "Epoch 465/500\n",
            "47/47 [==============================] - 0s 100us/step - loss: 1.2054e-07 - val_loss: 7.3785e-07\n",
            "Epoch 466/500\n",
            "47/47 [==============================] - 0s 102us/step - loss: 1.2049e-07 - val_loss: 7.3698e-07\n",
            "Epoch 467/500\n",
            "47/47 [==============================] - 0s 94us/step - loss: 1.2045e-07 - val_loss: 7.3598e-07\n",
            "Epoch 468/500\n",
            "47/47 [==============================] - 0s 96us/step - loss: 1.2040e-07 - val_loss: 7.3487e-07\n",
            "Epoch 469/500\n",
            "47/47 [==============================] - 0s 111us/step - loss: 1.2035e-07 - val_loss: 7.3364e-07\n",
            "Epoch 470/500\n",
            "47/47 [==============================] - 0s 97us/step - loss: 1.2031e-07 - val_loss: 7.3249e-07\n",
            "Epoch 471/500\n",
            "47/47 [==============================] - 0s 98us/step - loss: 1.2037e-07 - val_loss: 7.3388e-07\n",
            "Epoch 472/500\n",
            "47/47 [==============================] - 0s 105us/step - loss: 1.2030e-07 - val_loss: 7.3402e-07\n",
            "Epoch 473/500\n",
            "47/47 [==============================] - 0s 96us/step - loss: 1.2036e-07 - val_loss: 7.3253e-07\n",
            "Epoch 474/500\n",
            "47/47 [==============================] - 0s 89us/step - loss: 1.2032e-07 - val_loss: 7.2996e-07\n",
            "Epoch 475/500\n",
            "47/47 [==============================] - 0s 81us/step - loss: 1.2022e-07 - val_loss: 7.2751e-07\n",
            "Epoch 476/500\n",
            "47/47 [==============================] - 0s 79us/step - loss: 1.2018e-07 - val_loss: 7.2608e-07\n",
            "Epoch 477/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 1.2019e-07 - val_loss: 7.2581e-07\n",
            "Epoch 478/500\n",
            "47/47 [==============================] - 0s 95us/step - loss: 1.2017e-07 - val_loss: 7.2624e-07\n",
            "Epoch 479/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 1.2010e-07 - val_loss: 7.2643e-07\n",
            "Epoch 480/500\n",
            "47/47 [==============================] - 0s 81us/step - loss: 1.2006e-07 - val_loss: 7.2553e-07\n",
            "Epoch 481/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 1.2002e-07 - val_loss: 7.2328e-07\n",
            "Epoch 482/500\n",
            "47/47 [==============================] - 0s 73us/step - loss: 1.1996e-07 - val_loss: 7.2017e-07\n",
            "Epoch 483/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 1.1990e-07 - val_loss: 7.1717e-07\n",
            "Epoch 484/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.1986e-07 - val_loss: 7.1517e-07\n",
            "Epoch 485/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 1.1983e-07 - val_loss: 7.1458e-07\n",
            "Epoch 486/500\n",
            "47/47 [==============================] - 0s 86us/step - loss: 1.1978e-07 - val_loss: 7.1519e-07\n",
            "Epoch 487/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.1971e-07 - val_loss: 7.1624e-07\n",
            "Epoch 488/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.1967e-07 - val_loss: 7.1688e-07\n",
            "Epoch 489/500\n",
            "47/47 [==============================] - 0s 84us/step - loss: 1.1964e-07 - val_loss: 7.1658e-07\n",
            "Epoch 490/500\n",
            "47/47 [==============================] - 0s 73us/step - loss: 1.1961e-07 - val_loss: 7.1532e-07\n",
            "Epoch 491/500\n",
            "47/47 [==============================] - 0s 77us/step - loss: 1.1956e-07 - val_loss: 7.1357e-07\n",
            "Epoch 492/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 1.1952e-07 - val_loss: 7.1198e-07\n",
            "Epoch 493/500\n",
            "47/47 [==============================] - 0s 80us/step - loss: 1.1949e-07 - val_loss: 7.1097e-07\n",
            "Epoch 494/500\n",
            "47/47 [==============================] - 0s 87us/step - loss: 1.1945e-07 - val_loss: 7.1060e-07\n",
            "Epoch 495/500\n",
            "47/47 [==============================] - 0s 85us/step - loss: 1.1941e-07 - val_loss: 7.1068e-07\n",
            "Epoch 496/500\n",
            "47/47 [==============================] - 0s 73us/step - loss: 1.1937e-07 - val_loss: 7.1063e-07\n",
            "Epoch 497/500\n",
            "47/47 [==============================] - 0s 77us/step - loss: 1.1934e-07 - val_loss: 7.1016e-07\n",
            "Epoch 498/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.1930e-07 - val_loss: 7.0927e-07\n",
            "Epoch 499/500\n",
            "47/47 [==============================] - 0s 83us/step - loss: 1.1926e-07 - val_loss: 7.0824e-07\n",
            "Epoch 500/500\n",
            "47/47 [==============================] - 0s 95us/step - loss: 1.1922e-07 - val_loss: 7.0741e-07\n",
            "dict_keys(['val_loss', 'loss'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A4lcOIqJBOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result=model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVV4p1H2Jz3o",
        "colab_type": "code",
        "outputId": "826405bf-0d62-40f4-e4ff-b72505a98d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "result"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00074535],\n",
              "       [-0.00168527],\n",
              "       [ 0.00095186],\n",
              "       [ 0.00074535],\n",
              "       [ 0.00119218],\n",
              "       [ 0.00326217],\n",
              "       [-0.00156778],\n",
              "       [ 0.00074535],\n",
              "       [-0.00031599],\n",
              "       [ 0.00074535],\n",
              "       [ 0.00318054],\n",
              "       [ 0.00117476]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RmcoC9iN7ba",
        "colab_type": "code",
        "outputId": "4bded7b7-330a-4778-f70a-846f997db45c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "X_test"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.08, 0.09, 0.08],\n",
              "       [0.51, 0.03, 0.09],\n",
              "       [0.75, 0.28, 0.  ],\n",
              "       [0.1 , 0.12, 0.12],\n",
              "       [0.13, 0.09, 0.11],\n",
              "       [0.11, 0.03, 0.14],\n",
              "       [0.52, 0.01, 0.08],\n",
              "       [0.1 , 0.6 , 0.09],\n",
              "       [0.81, 0.07, 0.18],\n",
              "       [0.05, 0.07, 0.01],\n",
              "       [0.14, 0.03, 0.16],\n",
              "       [0.13, 0.08, 0.1 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhzlD6n3JS-S",
        "colab_type": "code",
        "outputId": "6d53a16a-f1ed-4b7b-9137-cf54f902016e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "plt.scatter(range(12),result,c='r')\n",
        "plt.scatter(range(12),y_test,c='g')\n",
        "plt.show()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqivbvlYivLs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d4a00114-0320-43b2-9c7b-f2bc60e65606"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.001, 0.   , 0.   , 0.001, 0.002, 0.003, 0.   , 0.   , 0.   ,\n",
              "       0.001, 0.003, 0.002])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prP_OCYnsz4f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "ed7fa77c-77ae-40b0-c9ac-d9feea02efb6"
      },
      "source": [
        "np.round(y_predict)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-b85d0118c523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_predict' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2KjUbHjsldW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}