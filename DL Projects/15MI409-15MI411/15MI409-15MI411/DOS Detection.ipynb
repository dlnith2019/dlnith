{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "import pandas\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of CSV file? Data1.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_file = input(\"Name of CSV file? \") # Get name of Dataset CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model?n\n"
     ]
    }
   ],
   "source": [
    "load = input(\"Load model?\") # Train New Model or use old one.\n",
    "if load == 'y':\n",
    "    model_file = input(\"Model to load?\")\n",
    "    mlp = pickle.load(open(model_file, 'rb'))\n",
    "    print(mlp.coefs_)\n",
    "    print(mlp.loss_)\n",
    "else:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(15,15),activation='logistic', max_iter=1000, verbose=True, tol=0.0001, early_stopping = True, shuffle = True, learning_rate_init = 0.0001) \n",
    "    #hidden_layer_sizes = array of 2 layers, both with 100 nodes\n",
    "    #activation = logistic is f(x) = 1 / (1 + exp(-x))\n",
    "    #max_iter = max num of iterations that the model will do\n",
    "    #tol = minimum improvement required for certain number of itterations to avoid invoking early stepping\n",
    "    #early_stopping checks for increase in validation score and stops model if it stops increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv(dataset_file, delimiter=',') #Change file to text dataset you wish to test on\n",
    "columnsToEncode = list(data.select_dtypes(include=['category', 'object']))  \n",
    "le = LabelEncoder()\n",
    "for feature in columnsToEncode:\n",
    "    try:\n",
    "        data[feature] = le.fit_transform(data[feature])\n",
    "    except:\n",
    "        print ('error' + feature)\n",
    "X = data[['Highest Layer', 'Transport Layer', 'Source IP', 'Dest IP', 'Source Port', 'Dest Port','Packet Length', 'Packets/Time']] \n",
    "y = data['target'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #Needed to split the data into the training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.68447454\n",
      "Validation score: 1.000000\n",
      "Iteration 2, loss = 0.68367088\n",
      "Validation score: 1.000000\n",
      "Iteration 3, loss = 0.68286788\n",
      "Validation score: 1.000000\n",
      "Iteration 4, loss = 0.68206556\n",
      "Validation score: 1.000000\n",
      "Iteration 5, loss = 0.68126393\n",
      "Validation score: 1.000000\n",
      "Iteration 6, loss = 0.68046300\n",
      "Validation score: 1.000000\n",
      "Iteration 7, loss = 0.67966278\n",
      "Validation score: 1.000000\n",
      "Iteration 8, loss = 0.67886328\n",
      "Validation score: 1.000000\n",
      "Iteration 9, loss = 0.67806452\n",
      "Validation score: 1.000000\n",
      "Iteration 10, loss = 0.67726650\n",
      "Validation score: 1.000000\n",
      "Iteration 11, loss = 0.67646923\n",
      "Validation score: 1.000000\n",
      "Iteration 12, loss = 0.67567272\n",
      "Validation score: 1.000000\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "              beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(15, 15), learning_rate='constant',\n",
       "              learning_rate_init=0.0001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train, y_train) #Actually training the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 50 Predictions:  \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "First 50 Probabilities:  \n",
      " [[9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.96173771e-01 3.82622851e-03]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.96173771e-01 3.82622851e-03]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.96173771e-01 3.82622851e-03]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.96173771e-01 3.82622851e-03]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.96173771e-01 3.82622851e-03]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.96173771e-01 3.82622851e-03]\n",
      " [9.96173771e-01 3.82622851e-03]\n",
      " [9.99923266e-01 7.67339769e-05]\n",
      " [9.96173771e-01 3.82622851e-03]\n",
      " [9.96173771e-01 3.82622851e-03]\n",
      " [9.96173771e-01 3.82622851e-03]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.96173771e-01 3.82622851e-03]\n",
      " [9.99954070e-01 4.59301490e-05]\n",
      " [9.96173771e-01 3.82622851e-03]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.96173771e-01 3.82622851e-03]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.96173771e-01 3.82622851e-03]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.96173771e-01 3.82622851e-03]\n",
      " [9.99987089e-01 1.29106497e-05]\n",
      " [9.99987089e-01 1.29106497e-05]]\n",
      "Number of Iterations:  20\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test)\n",
    "print(\"First 50 Predictions: \", \"\\n\" ,mlp.predict(X_test)[0:50]) #Prints first 50 predictions\n",
    "print(\"First 50 Probabilities: \", \"\\n\",mlp.predict_proba(X_test)[0:50])#Prints first 50 probabilities\n",
    "print(\"Number of Iterations: \", mlp.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labled Safe Packets:  256717\n",
      "Labled Hostile Packets:  1022\n",
      "Predicted Safe Packets:  257381\n",
      "Predicted Hostile Packets:  358\n"
     ]
    }
   ],
   "source": [
    "hostile = 0\n",
    "safe = 0\n",
    "for check in y_test:\n",
    "    if check == 1:\n",
    "        hostile += 1\n",
    "    else:\n",
    "        safe += 1\n",
    "print(\"Labled Safe Packets: \", safe)\n",
    "print(\"Labled Hostile Packets: \", hostile)\n",
    "safe = 0\n",
    "hostile = 0\n",
    "for check in predictions:\n",
    "    if check == 1:\n",
    "        hostile += 1\n",
    "    else:\n",
    "        safe += 1\n",
    "print(\"Predicted Safe Packets: \", safe)\n",
    "print(\"Predicted Hostile Packets: \", hostile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:  \n",
      " [[256717      0]\n",
      " [   664    358]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"Confusion Matrix: \", \"\\n\", confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    256717\n",
      "           1       1.00      0.35      0.52      1022\n",
      "\n",
      "    accuracy                           1.00    257739\n",
      "   macro avg       1.00      0.68      0.76    257739\n",
      "weighted avg       1.00      1.00      1.00    257739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Classification Report: \", \"\\n\",  classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "see weights and intercepts? n\n"
     ]
    }
   ],
   "source": [
    "ci = input(\"see weights and intercepts? \" )\n",
    "if ci == 'y':\n",
    "    print(\"Model Coefficients (Weights): \", \"\\n\", mlp.coefs_)\n",
    "    print()\n",
    "    print(\"Model Intercepts (Nodes): \", \"\\n\", mlp.intercepts_)\n",
    "else:\n",
    "     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model?(y/n)\n",
      "y\n",
      "model_file for saving?: \n",
      "ltcpmodel.sav\n"
     ]
    }
   ],
   "source": [
    "save = input(\"Save model?(y/n)\\n\")\n",
    "if save == 'y':\n",
    "        model_file = input(\"model_file for saving?: \\n\")\n",
    "        pickle.dump(mlp, open(model_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
