{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_devices_per_cell is also max number of rows in circuit files in the training set\n",
    "max_devices_per_cell = 351; \n",
    "# feature_per_device is different from max number of cols (14) in circuit files in training set\n",
    "feature_per_device   = 5; \n",
    "feature_indices = (0,2,5,8,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_one_cell(cell_file):\n",
    "    cell_cols = 14\n",
    "    cell_data = np.zeros(shape=(max_devices_per_cell, cell_cols), dtype=np.float32)\n",
    "    cell_mat  = np.loadtxt(cell_file, dtype=np.float32, ndmin=2)\n",
    "    nrows     = cell_mat.shape[0]\n",
    "    ncols     = cell_mat.shape[1]\n",
    "    cell_data[:nrows, :ncols] = cell_mat\n",
    "    cell_data = cell_data[:, feature_indices]\n",
    "    return cell_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cells(folder):\n",
    "  #Load the data for a single label.\n",
    "  cell_files = os.listdir(folder)\n",
    "  dataset = np.zeros(shape=(len(cell_files), max_devices_per_cell, feature_per_device),\n",
    "                         dtype=np.float32)\n",
    "  cell_index = 0\n",
    "  for cell in cell_files:\n",
    "    cell_file = os.path.join(folder, cell)\n",
    "    try:\n",
    "      cell_data = load_one_cell(cell_file)\n",
    "\n",
    "      cell_rows = cell_data.shape[0]\n",
    "      cell_cols = cell_data.shape[1]\n",
    "      dataset[cell_index, :cell_rows, :cell_cols] = cell_data\n",
    "\n",
    "      cell_index = cell_index + 1\n",
    "    except IOError as e:\n",
    "      print('Could not read:', cell_file, ':', e, '- it\\'s ok, skipping.')\n",
    "    \n",
    "  dataset = dataset[0:cell_index, :, :]\n",
    "\n",
    "  print(os.path.basename(folder), ': shape=', dataset.shape, ', Mean=', np.mean(dataset), ', sigma=', np.std(dataset))\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMB : shape= (10, 351, 5) , Mean= 0.0988604 , sigma= 1.033829\n",
      "SQNC : shape= (10, 351, 5) , Mean= 1.4900855 , sigma= 5.138047\n"
     ]
    }
   ],
   "source": [
    "current_folder = globals()['_dh'][0]\n",
    "comb_dataset = load_cells(os.path.join(current_folder,'COMB'))\n",
    "sqnc_dataset = load_cells(os.path.join(current_folder,'SEQ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray([[1.0, 0.0] if (i<comb_dataset.shape[0]) else [0.0, 1.0] for i in range(comb_dataset.shape[0]+sqnc_dataset.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(comb_dataset)\n",
    "np.random.shuffle(seq_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined dataset\n",
    "dataset = np.append(comb_dataset, seq_dataset, axis=0)\t  \n",
    "\n",
    "dataset = dataset.reshape((-1, max_devices_per_cell*feature_per_device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1755)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = 0;\n",
    "data_std  = (np.max(dataset)-np.min(dataset));\n",
    "\n",
    "def normalize(d, mean, std):\n",
    "    return (d - mean) / std\n",
    "\n",
    "dataset = normalize(dataset, data_mean, data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_index = int(dataset.shape[0]*0.8)\n",
    "    Xtrain = dataset[:train_index, :]\n",
    "    Ytrain = labels[:train_index,:]\n",
    "    Xtest = dataset[train_index:,:]\n",
    "    Ytest = labels[train_index:,:]\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1755)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1122 11:51:34.890354 14092 deprecation_wrapper.py:119] From C:\\Users\\NITISH\\Miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1122 11:51:34.928350 14092 deprecation_wrapper.py:119] From C:\\Users\\NITISH\\Miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1122 11:51:34.933333 14092 deprecation_wrapper.py:119] From C:\\Users\\NITISH\\Miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1122 11:51:35.002310 14092 deprecation_wrapper.py:119] From C:\\Users\\NITISH\\Miniconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(16,activation='softmax',input_shape=(1755,)))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='mse',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                28096     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 28,130\n",
      "Trainable params: 28,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1122 11:51:35.406075 14092 deprecation_wrapper.py:119] From C:\\Users\\NITISH\\Miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W1122 11:51:35.525988 14092 deprecation_wrapper.py:119] From C:\\Users\\NITISH\\Miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples, validate on 4 samples\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2630 - acc: 0.3750 - val_loss: 0.2015 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 311us/step - loss: 0.2611 - acc: 0.3750 - val_loss: 0.1977 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.2590 - acc: 0.3750 - val_loss: 0.1939 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 562us/step - loss: 0.2567 - acc: 0.3750 - val_loss: 0.1900 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.2544 - acc: 0.3750 - val_loss: 0.1862 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 250us/step - loss: 0.2521 - acc: 0.3750 - val_loss: 0.1825 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.2499 - acc: 0.3750 - val_loss: 0.1789 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 563us/step - loss: 0.2476 - acc: 0.3750 - val_loss: 0.1755 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 437us/step - loss: 0.2455 - acc: 0.3750 - val_loss: 0.1723 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 499us/step - loss: 0.2434 - acc: 0.3750 - val_loss: 0.1692 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.2413 - acc: 0.3750 - val_loss: 0.1663 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.2393 - acc: 0.3750 - val_loss: 0.1635 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.2374 - acc: 0.3750 - val_loss: 0.1609 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 313us/step - loss: 0.2355 - acc: 0.3750 - val_loss: 0.1583 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 250us/step - loss: 0.2336 - acc: 0.3750 - val_loss: 0.1558 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.2318 - acc: 0.3750 - val_loss: 0.1535 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 437us/step - loss: 0.2300 - acc: 0.3750 - val_loss: 0.1513 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.2283 - acc: 0.3750 - val_loss: 0.1492 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.2265 - acc: 0.3750 - val_loss: 0.1471 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.2249 - acc: 0.3750 - val_loss: 0.1452 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.2232 - acc: 0.3750 - val_loss: 0.1434 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 437us/step - loss: 0.2216 - acc: 0.3750 - val_loss: 0.1416 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 250us/step - loss: 0.2200 - acc: 0.3750 - val_loss: 0.1398 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 250us/step - loss: 0.2184 - acc: 0.3750 - val_loss: 0.1381 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 250us/step - loss: 0.2169 - acc: 0.3750 - val_loss: 0.1364 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.2153 - acc: 0.3750 - val_loss: 0.1348 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.2138 - acc: 0.3750 - val_loss: 0.1331 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 437us/step - loss: 0.2122 - acc: 0.3750 - val_loss: 0.1314 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.2106 - acc: 0.3750 - val_loss: 0.1297 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 0.2091 - acc: 0.3750 - val_loss: 0.1279 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.2075 - acc: 0.3750 - val_loss: 0.1261 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.2059 - acc: 0.3750 - val_loss: 0.1243 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 0.2043 - acc: 0.3750 - val_loss: 0.1225 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 250us/step - loss: 0.2027 - acc: 0.3750 - val_loss: 0.1207 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 687us/step - loss: 0.2011 - acc: 1.0000 - val_loss: 0.1188 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.1994 - acc: 1.0000 - val_loss: 0.1170 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1978 - acc: 1.0000 - val_loss: 0.1151 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1962 - acc: 1.0000 - val_loss: 0.1133 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 500us/step - loss: 0.1945 - acc: 1.0000 - val_loss: 0.1115 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 437us/step - loss: 0.1929 - acc: 1.0000 - val_loss: 0.1097 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 437us/step - loss: 0.1913 - acc: 1.0000 - val_loss: 0.1080 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 437us/step - loss: 0.1897 - acc: 1.0000 - val_loss: 0.1063 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.1881 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1865 - acc: 1.0000 - val_loss: 0.1033 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 562us/step - loss: 0.1850 - acc: 1.0000 - val_loss: 0.1019 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1835 - acc: 1.0000 - val_loss: 0.1006 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 500us/step - loss: 0.1821 - acc: 1.0000 - val_loss: 0.0994 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 0.1807 - acc: 1.0000 - val_loss: 0.0983 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 500us/step - loss: 0.1793 - acc: 1.0000 - val_loss: 0.0973 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1779 - acc: 1.0000 - val_loss: 0.0964 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1766 - acc: 1.0000 - val_loss: 0.0956 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 437us/step - loss: 0.1753 - acc: 1.0000 - val_loss: 0.0948 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1740 - acc: 1.0000 - val_loss: 0.0941 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.1728 - acc: 1.0000 - val_loss: 0.0935 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 0.1716 - acc: 1.0000 - val_loss: 0.0929 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 562us/step - loss: 0.1704 - acc: 1.0000 - val_loss: 0.0924 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.1692 - acc: 1.0000 - val_loss: 0.0919 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 437us/step - loss: 0.1680 - acc: 1.0000 - val_loss: 0.0915 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1669 - acc: 1.0000 - val_loss: 0.0911 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.1658 - acc: 1.0000 - val_loss: 0.0907 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 437us/step - loss: 0.1647 - acc: 1.0000 - val_loss: 0.0903 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 313us/step - loss: 0.1636 - acc: 1.0000 - val_loss: 0.0900 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1625 - acc: 1.0000 - val_loss: 0.0897 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1615 - acc: 1.0000 - val_loss: 0.0894 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 438us/step - loss: 0.1604 - acc: 1.0000 - val_loss: 0.0891 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.1594 - acc: 1.0000 - val_loss: 0.0889 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.1583 - acc: 1.0000 - val_loss: 0.0887 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.1573 - acc: 1.0000 - val_loss: 0.0884 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 437us/step - loss: 0.1563 - acc: 1.0000 - val_loss: 0.0882 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1553 - acc: 1.0000 - val_loss: 0.0880 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1543 - acc: 1.0000 - val_loss: 0.0878 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 499us/step - loss: 0.1533 - acc: 1.0000 - val_loss: 0.0876 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1524 - acc: 1.0000 - val_loss: 0.0874 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1514 - acc: 1.0000 - val_loss: 0.0872 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1504 - acc: 1.0000 - val_loss: 0.0871 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1495 - acc: 1.0000 - val_loss: 0.0869 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 437us/step - loss: 0.1485 - acc: 1.0000 - val_loss: 0.0867 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1476 - acc: 1.0000 - val_loss: 0.0866 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.1467 - acc: 1.0000 - val_loss: 0.0864 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.1458 - acc: 1.0000 - val_loss: 0.0863 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1448 - acc: 1.0000 - val_loss: 0.0861 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 437us/step - loss: 0.1439 - acc: 1.0000 - val_loss: 0.0860 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.1431 - acc: 1.0000 - val_loss: 0.0859 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1422 - acc: 1.0000 - val_loss: 0.0857 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 187us/step - loss: 0.1413 - acc: 1.0000 - val_loss: 0.0856 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.1404 - acc: 1.0000 - val_loss: 0.0854 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.1395 - acc: 1.0000 - val_loss: 0.0853 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.1387 - acc: 1.0000 - val_loss: 0.0852 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 188us/step - loss: 0.1378 - acc: 1.0000 - val_loss: 0.0850 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1370 - acc: 1.0000 - val_loss: 0.0849 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1361 - acc: 1.0000 - val_loss: 0.0848 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1353 - acc: 1.0000 - val_loss: 0.0847 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 375us/step - loss: 0.1345 - acc: 1.0000 - val_loss: 0.0845 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 250us/step - loss: 0.1337 - acc: 1.0000 - val_loss: 0.0844 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.1328 - acc: 1.0000 - val_loss: 0.0843 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 250us/step - loss: 0.1320 - acc: 1.0000 - val_loss: 0.0842 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.1312 - acc: 1.0000 - val_loss: 0.0840 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 250us/step - loss: 0.1305 - acc: 1.0000 - val_loss: 0.0839 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 312us/step - loss: 0.1297 - acc: 1.0000 - val_loss: 0.0838 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 250us/step - loss: 0.1289 - acc: 1.0000 - val_loss: 0.0837 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(Xtrain,Ytrain, epochs=100,validation_data=(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.625, 0.625, 0.625, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(history.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
