{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "15mi426_project_antenna.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXwaoOQ8f_zv",
        "colab_type": "text"
      },
      "source": [
        "# #IMPORT THE LIBRARIES REQUIRED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjC0TGoef_0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xlwt \n",
        "from google.colab import files\n",
        "import io\n",
        "from xlwt import Workbook \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_TexJ_Ff_16",
        "colab_type": "raw"
      },
      "source": [
        "NOW WE FIRST IMPORT THE LIBRARIES WHICH ARE REQUIRED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZlNmGpnf_2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IAuszDgaGy0",
        "colab_type": "text"
      },
      "source": [
        "uploading the dataset for antenna frequency and dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmLc1Njwf_4R",
        "colab_type": "code",
        "outputId": "dcc07ea1-da0d-4db8-ab00-eb024c292ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "d = pd.read_csv('DATASET_ANTENNA.csv')\n",
        "X = d[d.columns[0:2]].values\n",
        "y = d[d.columns[2:4]]\n",
        "print(y.shape)\n"
      ],
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(51, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPR6jdKzaRr3",
        "colab_type": "text"
      },
      "source": [
        "Normalizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2datIgOBHCQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=X/10\n",
        "y=y/1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc_qEoDPf_5c",
        "colab_type": "text"
      },
      "source": [
        "WE CREATE OUR MODEL IN WHICH WE HAVE  2 NURON IN INPIUT LAYER, WE USE THREE HIDDEN LAYER OF NUMBER OF NODES \n",
        "7,5,2 AND ONE NODE AT THE OUTPUT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thvmCYk0f_5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBrgYreoqi9z",
        "colab_type": "code",
        "outputId": "ba35a2f4-8a14-48b0-9ea5-601729afcadf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(7, activation='relu',input_dim = 2))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(2))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "print(model.summary())"
      ],
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_28 (Dense)             (None, 7)                 21        \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 5)                 40        \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 2)                 12        \n",
            "=================================================================\n",
            "Total params: 73\n",
            "Trainable params: 73\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9IQoAD1VPfk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a7c5c002-b177-44b9-d0a6-4448f0806181"
      },
      "source": [
        "print(type(X_test))"
      ],
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWSUykvlf_6D",
        "colab_type": "text"
      },
      "source": [
        "HERE WE SET THE OPTIMIZER, LOSS FUNCTION BATCH_SIZE AND EPOCHS FOR GIVEN MODEL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLGsIYnWf_6M",
        "colab_type": "code",
        "outputId": "7b7b3f84-3153-4bc8-d8f1-f96b4ba1ccb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=100,epochs=300,verbose=1,validation_data=(X_test, y_test))\n",
        "\n",
        "print(history.history.keys())\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "model.save('model.h5')"
      ],
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40 samples, validate on 11 samples\n",
            "Epoch 1/100\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 0.0508 - val_loss: 0.0517\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - 0s 180us/step - loss: 0.0485 - val_loss: 0.0489\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - 0s 124us/step - loss: 0.0458 - val_loss: 0.0460\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - 0s 80us/step - loss: 0.0430 - val_loss: 0.0431\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - 0s 104us/step - loss: 0.0402 - val_loss: 0.0402\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - 0s 98us/step - loss: 0.0375 - val_loss: 0.0374\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - 0s 102us/step - loss: 0.0348 - val_loss: 0.0347\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - 0s 78us/step - loss: 0.0323 - val_loss: 0.0321\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - 0s 108us/step - loss: 0.0298 - val_loss: 0.0296\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - 0s 68us/step - loss: 0.0275 - val_loss: 0.0272\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - 0s 59us/step - loss: 0.0252 - val_loss: 0.0250\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - 0s 101us/step - loss: 0.0231 - val_loss: 0.0228\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - 0s 88us/step - loss: 0.0211 - val_loss: 0.0208\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - 0s 101us/step - loss: 0.0191 - val_loss: 0.0189\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - 0s 94us/step - loss: 0.0174 - val_loss: 0.0171\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - 0s 92us/step - loss: 0.0157 - val_loss: 0.0154\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - 0s 86us/step - loss: 0.0141 - val_loss: 0.0138\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - 0s 93us/step - loss: 0.0126 - val_loss: 0.0124\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - 0s 78us/step - loss: 0.0113 - val_loss: 0.0111\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - 0s 88us/step - loss: 0.0100 - val_loss: 0.0098\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - 0s 103us/step - loss: 0.0089 - val_loss: 0.0087\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - 0s 94us/step - loss: 0.0078 - val_loss: 0.0077\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - 0s 108us/step - loss: 0.0069 - val_loss: 0.0067\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - 0s 93us/step - loss: 0.0060 - val_loss: 0.0059\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - 0s 85us/step - loss: 0.0052 - val_loss: 0.0051\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - 0s 94us/step - loss: 0.0045 - val_loss: 0.0045\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - 0s 83us/step - loss: 0.0039 - val_loss: 0.0039\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - 0s 83us/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 29/100\n",
            "40/40 [==============================] - 0s 108us/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 30/100\n",
            "40/40 [==============================] - 0s 96us/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 31/100\n",
            "40/40 [==============================] - 0s 93us/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 32/100\n",
            "40/40 [==============================] - 0s 92us/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 33/100\n",
            "40/40 [==============================] - 0s 84us/step - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 34/100\n",
            "40/40 [==============================] - 0s 77us/step - loss: 0.0014 - val_loss: 0.0015\n",
            "Epoch 35/100\n",
            "40/40 [==============================] - 0s 102us/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 36/100\n",
            "40/40 [==============================] - 0s 82us/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 37/100\n",
            "40/40 [==============================] - 0s 84us/step - loss: 9.9998e-04 - val_loss: 0.0011\n",
            "Epoch 38/100\n",
            "40/40 [==============================] - 0s 109us/step - loss: 9.1583e-04 - val_loss: 9.6672e-04\n",
            "Epoch 39/100\n",
            "40/40 [==============================] - 0s 120us/step - loss: 8.5107e-04 - val_loss: 8.9931e-04\n",
            "Epoch 40/100\n",
            "40/40 [==============================] - 0s 115us/step - loss: 8.0193e-04 - val_loss: 8.4601e-04\n",
            "Epoch 41/100\n",
            "40/40 [==============================] - 0s 119us/step - loss: 7.6502e-04 - val_loss: 8.0369e-04\n",
            "Epoch 42/100\n",
            "40/40 [==============================] - 0s 110us/step - loss: 7.3734e-04 - val_loss: 7.6961e-04\n",
            "Epoch 43/100\n",
            "40/40 [==============================] - 0s 110us/step - loss: 7.1630e-04 - val_loss: 7.4143e-04\n",
            "Epoch 44/100\n",
            "40/40 [==============================] - 0s 127us/step - loss: 6.9969e-04 - val_loss: 7.1722e-04\n",
            "Epoch 45/100\n",
            "40/40 [==============================] - 0s 132us/step - loss: 6.8566e-04 - val_loss: 6.9536e-04\n",
            "Epoch 46/100\n",
            "40/40 [==============================] - 0s 121us/step - loss: 6.7273e-04 - val_loss: 6.7461e-04\n",
            "Epoch 47/100\n",
            "40/40 [==============================] - 0s 121us/step - loss: 6.5974e-04 - val_loss: 6.5401e-04\n",
            "Epoch 48/100\n",
            "40/40 [==============================] - 0s 124us/step - loss: 6.4584e-04 - val_loss: 6.3288e-04\n",
            "Epoch 49/100\n",
            "40/40 [==============================] - 0s 105us/step - loss: 6.3041e-04 - val_loss: 6.1078e-04\n",
            "Epoch 50/100\n",
            "40/40 [==============================] - 0s 115us/step - loss: 6.1310e-04 - val_loss: 5.8747e-04\n",
            "Epoch 51/100\n",
            "40/40 [==============================] - 0s 105us/step - loss: 5.9373e-04 - val_loss: 5.6286e-04\n",
            "Epoch 52/100\n",
            "40/40 [==============================] - 0s 121us/step - loss: 5.7229e-04 - val_loss: 5.3703e-04\n",
            "Epoch 53/100\n",
            "40/40 [==============================] - 0s 105us/step - loss: 5.4891e-04 - val_loss: 5.1014e-04\n",
            "Epoch 54/100\n",
            "40/40 [==============================] - 0s 113us/step - loss: 5.2381e-04 - val_loss: 4.8243e-04\n",
            "Epoch 55/100\n",
            "40/40 [==============================] - 0s 130us/step - loss: 4.9730e-04 - val_loss: 4.5419e-04\n",
            "Epoch 56/100\n",
            "40/40 [==============================] - 0s 127us/step - loss: 4.6971e-04 - val_loss: 4.2575e-04\n",
            "Epoch 57/100\n",
            "40/40 [==============================] - 0s 135us/step - loss: 4.4141e-04 - val_loss: 3.9744e-04\n",
            "Epoch 58/100\n",
            "40/40 [==============================] - 0s 127us/step - loss: 4.1280e-04 - val_loss: 3.6957e-04\n",
            "Epoch 59/100\n",
            "40/40 [==============================] - 0s 121us/step - loss: 3.8423e-04 - val_loss: 3.4246e-04\n",
            "Epoch 60/100\n",
            "40/40 [==============================] - 0s 112us/step - loss: 3.5605e-04 - val_loss: 3.1636e-04\n",
            "Epoch 61/100\n",
            "40/40 [==============================] - 0s 125us/step - loss: 3.2857e-04 - val_loss: 2.9152e-04\n",
            "Epoch 62/100\n",
            "40/40 [==============================] - 0s 113us/step - loss: 3.0208e-04 - val_loss: 2.6812e-04\n",
            "Epoch 63/100\n",
            "40/40 [==============================] - 0s 131us/step - loss: 2.7681e-04 - val_loss: 2.4631e-04\n",
            "Epoch 64/100\n",
            "40/40 [==============================] - 0s 127us/step - loss: 2.5294e-04 - val_loss: 2.2619e-04\n",
            "Epoch 65/100\n",
            "40/40 [==============================] - 0s 136us/step - loss: 2.3061e-04 - val_loss: 2.0782e-04\n",
            "Epoch 66/100\n",
            "40/40 [==============================] - 0s 124us/step - loss: 2.0991e-04 - val_loss: 1.9121e-04\n",
            "Epoch 67/100\n",
            "40/40 [==============================] - 0s 116us/step - loss: 1.9090e-04 - val_loss: 1.7634e-04\n",
            "Epoch 68/100\n",
            "40/40 [==============================] - 0s 120us/step - loss: 1.7359e-04 - val_loss: 1.6316e-04\n",
            "Epoch 69/100\n",
            "40/40 [==============================] - 0s 131us/step - loss: 1.5797e-04 - val_loss: 1.5159e-04\n",
            "Epoch 70/100\n",
            "40/40 [==============================] - 0s 124us/step - loss: 1.4397e-04 - val_loss: 1.4152e-04\n",
            "Epoch 71/100\n",
            "40/40 [==============================] - 0s 121us/step - loss: 1.3152e-04 - val_loss: 1.3289e-04\n",
            "Epoch 72/100\n",
            "40/40 [==============================] - 0s 137us/step - loss: 1.2060e-04 - val_loss: 1.2545e-04\n",
            "Epoch 73/100\n",
            "40/40 [==============================] - 0s 137us/step - loss: 1.1096e-04 - val_loss: 1.1912e-04\n",
            "Epoch 74/100\n",
            "40/40 [==============================] - 0s 136us/step - loss: 1.0254e-04 - val_loss: 1.1376e-04\n",
            "Epoch 75/100\n",
            "40/40 [==============================] - 0s 120us/step - loss: 9.5228e-05 - val_loss: 1.0924e-04\n",
            "Epoch 76/100\n",
            "40/40 [==============================] - 0s 117us/step - loss: 8.8894e-05 - val_loss: 1.0540e-04\n",
            "Epoch 77/100\n",
            "40/40 [==============================] - 0s 118us/step - loss: 8.3415e-05 - val_loss: 1.0214e-04\n",
            "Epoch 78/100\n",
            "40/40 [==============================] - 0s 116us/step - loss: 7.8671e-05 - val_loss: 9.9320e-05\n",
            "Epoch 79/100\n",
            "40/40 [==============================] - 0s 108us/step - loss: 7.4551e-05 - val_loss: 9.6841e-05\n",
            "Epoch 80/100\n",
            "40/40 [==============================] - 0s 108us/step - loss: 7.0951e-05 - val_loss: 9.4607e-05\n",
            "Epoch 81/100\n",
            "40/40 [==============================] - 0s 96us/step - loss: 6.7780e-05 - val_loss: 9.2537e-05\n",
            "Epoch 82/100\n",
            "40/40 [==============================] - 0s 100us/step - loss: 6.4954e-05 - val_loss: 9.0562e-05\n",
            "Epoch 83/100\n",
            "40/40 [==============================] - 0s 100us/step - loss: 6.2404e-05 - val_loss: 8.8626e-05\n",
            "Epoch 84/100\n",
            "40/40 [==============================] - 0s 117us/step - loss: 6.0070e-05 - val_loss: 8.6686e-05\n",
            "Epoch 85/100\n",
            "40/40 [==============================] - 0s 103us/step - loss: 5.7901e-05 - val_loss: 8.4710e-05\n",
            "Epoch 86/100\n",
            "40/40 [==============================] - 0s 118us/step - loss: 5.5861e-05 - val_loss: 8.2677e-05\n",
            "Epoch 87/100\n",
            "40/40 [==============================] - 0s 108us/step - loss: 5.3918e-05 - val_loss: 8.0575e-05\n",
            "Epoch 88/100\n",
            "40/40 [==============================] - 0s 104us/step - loss: 5.2051e-05 - val_loss: 7.8401e-05\n",
            "Epoch 89/100\n",
            "40/40 [==============================] - 0s 103us/step - loss: 5.0246e-05 - val_loss: 7.6155e-05\n",
            "Epoch 90/100\n",
            "40/40 [==============================] - 0s 102us/step - loss: 4.8494e-05 - val_loss: 7.3859e-05\n",
            "Epoch 91/100\n",
            "40/40 [==============================] - 0s 105us/step - loss: 4.6800e-05 - val_loss: 7.1497e-05\n",
            "Epoch 92/100\n",
            "40/40 [==============================] - 0s 100us/step - loss: 4.5106e-05 - val_loss: 6.9097e-05\n",
            "Epoch 93/100\n",
            "40/40 [==============================] - 0s 99us/step - loss: 4.3463e-05 - val_loss: 6.6675e-05\n",
            "Epoch 94/100\n",
            "40/40 [==============================] - 0s 114us/step - loss: 4.1873e-05 - val_loss: 6.4250e-05\n",
            "Epoch 95/100\n",
            "40/40 [==============================] - 0s 106us/step - loss: 4.0344e-05 - val_loss: 6.1840e-05\n",
            "Epoch 96/100\n",
            "40/40 [==============================] - 0s 115us/step - loss: 3.8882e-05 - val_loss: 5.9462e-05\n",
            "Epoch 97/100\n",
            "40/40 [==============================] - 0s 110us/step - loss: 3.7464e-05 - val_loss: 5.7123e-05\n",
            "Epoch 98/100\n",
            "40/40 [==============================] - 0s 112us/step - loss: 3.6119e-05 - val_loss: 5.4801e-05\n",
            "Epoch 99/100\n",
            "40/40 [==============================] - 0s 106us/step - loss: 3.4840e-05 - val_loss: 5.2549e-05\n",
            "Epoch 100/100\n",
            "40/40 [==============================] - 0s 109us/step - loss: 3.3644e-05 - val_loss: 5.0379e-05\n",
            "dict_keys(['val_loss', 'loss'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIhIWv8fp0+GU7dAzzsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A4lcOIqJBOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result=model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP7dCZkMakBe",
        "colab_type": "text"
      },
      "source": [
        "Result array obtained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVV4p1H2Jz3o",
        "colab_type": "code",
        "outputId": "c504ce06-da37-412b-bcd0-fc3a696b7851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "result"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00638971, 0.01098653],\n",
              "       [0.0142553 , 0.01556463],\n",
              "       [0.01069755, 0.01378859],\n",
              "       [0.02721945, 0.02316631],\n",
              "       [0.00547848, 0.01056422],\n",
              "       [0.00547848, 0.01056422],\n",
              "       [0.02194653, 0.02031628],\n",
              "       [0.00867436, 0.01225735],\n",
              "       [0.00383035, 0.00954601],\n",
              "       [0.00748848, 0.01166535],\n",
              "       [0.00949844, 0.01276646]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YYNu6XYGd64",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "0f8c5f27-7abe-4dea-99a0-e7a10948edd9"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>17.7</th>\n",
              "      <th>13.34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.017859</td>\n",
              "      <td>0.013901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.018800</td>\n",
              "      <td>0.014850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.018800</td>\n",
              "      <td>0.014350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.021800</td>\n",
              "      <td>0.017850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.017700</td>\n",
              "      <td>0.013850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.017832</td>\n",
              "      <td>0.013876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.021225</td>\n",
              "      <td>0.016937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.018039</td>\n",
              "      <td>0.014061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.017691</td>\n",
              "      <td>0.013751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.017700</td>\n",
              "      <td>0.014150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.018144</td>\n",
              "      <td>0.014154</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        17.7     13.34\n",
              "29  0.017859  0.013901\n",
              "11  0.018800  0.014850\n",
              "10  0.018800  0.014350\n",
              "22  0.021800  0.017850\n",
              "2   0.017700  0.013850\n",
              "28  0.017832  0.013876\n",
              "45  0.021225  0.016937\n",
              "32  0.018039  0.014061\n",
              "26  0.017691  0.013751\n",
              "4   0.017700  0.014150\n",
              "33  0.018144  0.014154"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKjS7RUu63dp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7f96f092-0df7-45e8-f834-a8edd3f60cbf"
      },
      "source": [
        "print(result.shape)"
      ],
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RmcoC9iN7ba",
        "colab_type": "code",
        "outputId": "8f451b85-7252-461d-909f-513e298ed723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "X_test"
      ],
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.477, 0.485],\n",
              "       [0.449, 0.455],\n",
              "       [0.461, 0.47 ],\n",
              "       [0.402, 0.404],\n",
              "       [0.48 , 0.489],\n",
              "       [0.48 , 0.489],\n",
              "       [0.421, 0.427],\n",
              "       [0.469, 0.476],\n",
              "       [0.486, 0.495],\n",
              "       [0.473, 0.481],\n",
              "       [0.466, 0.473]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 336
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6VkKPxg1aps",
        "colab_type": "code",
        "outputId": "48358d4e-9551-4a2b-bf05-07e0aa540b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(X_test.shape)\n"
      ],
      "execution_count": 337,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4-H0WOEX0XG",
        "colab_type": "text"
      },
      "source": [
        "Scatter plot of result and test data for Length and width"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhzlD6n3JS-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plt.scatter(range(11),result,c='r')\n",
        "#plt.scatter(range(11),y_test,c='g')\n",
        "#plt.scatter(range(11),y_test,result.iloc[:,0].values,c='g')\n",
        "#plt.scatter(result[:, 0], result[:, 1], color ='r')\n",
        "#plt.scatter(y_test[2:4], color ='g')\n",
        "#plt.show()\n",
        "#from matplotlib import pyplot as plt\n",
        "#result = np.matrix(np.random.rand(11,2))\n",
        "#y_test = np.matrix(np.random.rand(11,2))\n",
        "#plt.scatter(result[:, 0], result[:, 1],'o',c='r')\n",
        "#plt.plot(y_test[:, 0], y_test[:, 1],'o',c='g')\n",
        "\n",
        "#plt.legend()\n",
        "#plt.show()\n",
        "#for width\n",
        "#plt.scatter(range(11),result[:,1],c='r')\n",
        "#plt.scatter(range(11),y_test,c='g')\n",
        "\n",
        "#plt.scatter(range(11),z_test,c='g')\n",
        "#plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39UNSHw2asJn",
        "colab_type": "text"
      },
      "source": [
        "input lower and higher cutoff frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE3IU-rKy6qs",
        "colab_type": "code",
        "outputId": "ab8998ba-61aa-4d98-fc15-d4495ef15b79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "f1=input('Lower Frequency')#divided by 10 e.g-4.5/10=0.45\n",
        "f2=input('Higher Frequency')#divided by 10 e.g-4.56/10=0.456\n",
        "arr=np.array([[f1,f2]])\n",
        "print(arr.shape)\n",
        "\n"
      ],
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lower Frequency0.45\n",
            "Higher Frequency0.456\n",
            "(1, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pNSy63o2lW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "res=model.predict(arr)*1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duZbtCPWaz5V",
        "colab_type": "text"
      },
      "source": [
        "Predicted dimensions of antenna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_svOc-PyfFm",
        "colab_type": "code",
        "outputId": "f6ff886b-10b8-45b5-a58f-3d1cab3a7e0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "res[:,0]\n",
        "print(res[:,0],'(mm)Predicted Length')\n",
        "res[:,1]\n",
        "print(res[:,1],'(mm)Predicted Width')"
      ],
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[13.980612] (mm)Predicted Length\n",
            "[15.394904] (mm)Predicted Width\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}