{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Gray_to_Binary_Code_Converter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjC0TGoef_0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xlwt \n",
        "from google.colab import files\n",
        "import io\n",
        "from xlwt import Workbook \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZlNmGpnf_2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmLc1Njwf_4R",
        "colab_type": "code",
        "outputId": "fd00d2a6-89ed-44ea-c9c6-95cb13f97d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "d = pd.read_csv('Book12.csv')\n",
        "X = d[d.columns[0:2]].values\n",
        "y = d[d.columns[2]].values\n",
        "print(y.shape)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thvmCYk0f_5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBrgYreoqi9z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "1aee08d7-4590-4ede-d002-e80facee4296"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(9, activation='relu',input_dim = 2))\n",
        "model.add(Dense(7, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(3, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "print(model.summary())"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_71 (Dense)             (None, 9)                 27        \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 7)                 70        \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 5)                 40        \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 3)                 18        \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 159\n",
            "Trainable params: 159\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLGsIYnWf_6M",
        "colab_type": "code",
        "outputId": "0f5af2f5-ba88-45ca-cd1c-d2b78c580c3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=100,\n",
        "          epochs=500,  \n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "print(history.history.keys())\n",
        "\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "model.save('model.h5')"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25 samples, validate on 7 samples\n",
            "Epoch 1/500\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 41189456.0000 - val_loss: 32324132.0000\n",
            "Epoch 2/500\n",
            "25/25 [==============================] - 0s 252us/step - loss: 40968228.0000 - val_loss: 32112800.0000\n",
            "Epoch 3/500\n",
            "25/25 [==============================] - 0s 182us/step - loss: 40711404.0000 - val_loss: 31887318.0000\n",
            "Epoch 4/500\n",
            "25/25 [==============================] - 0s 151us/step - loss: 40437352.0000 - val_loss: 31652996.0000\n",
            "Epoch 5/500\n",
            "25/25 [==============================] - 0s 151us/step - loss: 40152500.0000 - val_loss: 31412324.0000\n",
            "Epoch 6/500\n",
            "25/25 [==============================] - 0s 130us/step - loss: 39859888.0000 - val_loss: 31166610.0000\n",
            "Epoch 7/500\n",
            "25/25 [==============================] - 0s 142us/step - loss: 39561092.0000 - val_loss: 30916660.0000\n",
            "Epoch 8/500\n",
            "25/25 [==============================] - 0s 154us/step - loss: 39257104.0000 - val_loss: 30663004.0000\n",
            "Epoch 9/500\n",
            "25/25 [==============================] - 0s 195us/step - loss: 38948544.0000 - val_loss: 30403680.0000\n",
            "Epoch 10/500\n",
            "25/25 [==============================] - 0s 356us/step - loss: 38633036.0000 - val_loss: 30143574.0000\n",
            "Epoch 11/500\n",
            "25/25 [==============================] - 0s 161us/step - loss: 38316524.0000 - val_loss: 29880534.0000\n",
            "Epoch 12/500\n",
            "25/25 [==============================] - 0s 146us/step - loss: 37996376.0000 - val_loss: 29614734.0000\n",
            "Epoch 13/500\n",
            "25/25 [==============================] - 0s 161us/step - loss: 37672808.0000 - val_loss: 29346268.0000\n",
            "Epoch 14/500\n",
            "25/25 [==============================] - 0s 163us/step - loss: 37345932.0000 - val_loss: 29075190.0000\n",
            "Epoch 15/500\n",
            "25/25 [==============================] - 0s 167us/step - loss: 37015812.0000 - val_loss: 28801604.0000\n",
            "Epoch 16/500\n",
            "25/25 [==============================] - 0s 188us/step - loss: 36682564.0000 - val_loss: 28525548.0000\n",
            "Epoch 17/500\n",
            "25/25 [==============================] - 0s 165us/step - loss: 36346236.0000 - val_loss: 28247070.0000\n",
            "Epoch 18/500\n",
            "25/25 [==============================] - 0s 198us/step - loss: 36006888.0000 - val_loss: 27966182.0000\n",
            "Epoch 19/500\n",
            "25/25 [==============================] - 0s 162us/step - loss: 35664524.0000 - val_loss: 27682954.0000\n",
            "Epoch 20/500\n",
            "25/25 [==============================] - 0s 157us/step - loss: 35319228.0000 - val_loss: 27397394.0000\n",
            "Epoch 21/500\n",
            "25/25 [==============================] - 0s 166us/step - loss: 34971020.0000 - val_loss: 27109540.0000\n",
            "Epoch 22/500\n",
            "25/25 [==============================] - 0s 140us/step - loss: 34619916.0000 - val_loss: 26819408.0000\n",
            "Epoch 23/500\n",
            "25/25 [==============================] - 0s 218us/step - loss: 34265956.0000 - val_loss: 26530346.0000\n",
            "Epoch 24/500\n",
            "25/25 [==============================] - 0s 239us/step - loss: 33913212.0000 - val_loss: 26235762.0000\n",
            "Epoch 25/500\n",
            "25/25 [==============================] - 0s 149us/step - loss: 33553638.0000 - val_loss: 25938972.0000\n",
            "Epoch 26/500\n",
            "25/25 [==============================] - 0s 128us/step - loss: 33191280.0000 - val_loss: 25639986.0000\n",
            "Epoch 27/500\n",
            "25/25 [==============================] - 0s 218us/step - loss: 32826138.0000 - val_loss: 25338846.0000\n",
            "Epoch 28/500\n",
            "25/25 [==============================] - 0s 160us/step - loss: 32458270.0000 - val_loss: 25035588.0000\n",
            "Epoch 29/500\n",
            "25/25 [==============================] - 0s 147us/step - loss: 32087708.0000 - val_loss: 24730236.0000\n",
            "Epoch 30/500\n",
            "25/25 [==============================] - 0s 183us/step - loss: 31714478.0000 - val_loss: 24422826.0000\n",
            "Epoch 31/500\n",
            "25/25 [==============================] - 0s 155us/step - loss: 31338622.0000 - val_loss: 24113390.0000\n",
            "Epoch 32/500\n",
            "25/25 [==============================] - 0s 147us/step - loss: 30960174.0000 - val_loss: 23802042.0000\n",
            "Epoch 33/500\n",
            "25/25 [==============================] - 0s 142us/step - loss: 30579274.0000 - val_loss: 23488740.0000\n",
            "Epoch 34/500\n",
            "25/25 [==============================] - 0s 224us/step - loss: 30195858.0000 - val_loss: 23173522.0000\n",
            "Epoch 35/500\n",
            "25/25 [==============================] - 0s 150us/step - loss: 29809966.0000 - val_loss: 22856430.0000\n",
            "Epoch 36/500\n",
            "25/25 [==============================] - 0s 141us/step - loss: 29421658.0000 - val_loss: 22537556.0000\n",
            "Epoch 37/500\n",
            "25/25 [==============================] - 0s 152us/step - loss: 29031030.0000 - val_loss: 22216946.0000\n",
            "Epoch 38/500\n",
            "25/25 [==============================] - 0s 314us/step - loss: 28638134.0000 - val_loss: 21894700.0000\n",
            "Epoch 39/500\n",
            "25/25 [==============================] - 0s 318us/step - loss: 28243090.0000 - val_loss: 21570778.0000\n",
            "Epoch 40/500\n",
            "25/25 [==============================] - 0s 310us/step - loss: 27845844.0000 - val_loss: 21245238.0000\n",
            "Epoch 41/500\n",
            "25/25 [==============================] - 0s 224us/step - loss: 27446464.0000 - val_loss: 20918158.0000\n",
            "Epoch 42/500\n",
            "25/25 [==============================] - 0s 193us/step - loss: 27045032.0000 - val_loss: 20589586.0000\n",
            "Epoch 43/500\n",
            "25/25 [==============================] - 0s 161us/step - loss: 26641606.0000 - val_loss: 20259612.0000\n",
            "Epoch 44/500\n",
            "25/25 [==============================] - 0s 179us/step - loss: 26236288.0000 - val_loss: 19928318.0000\n",
            "Epoch 45/500\n",
            "25/25 [==============================] - 0s 142us/step - loss: 25829172.0000 - val_loss: 19595760.0000\n",
            "Epoch 46/500\n",
            "25/25 [==============================] - 0s 157us/step - loss: 25420326.0000 - val_loss: 19262002.0000\n",
            "Epoch 47/500\n",
            "25/25 [==============================] - 0s 131us/step - loss: 25009820.0000 - val_loss: 18930402.0000\n",
            "Epoch 48/500\n",
            "25/25 [==============================] - 0s 138us/step - loss: 24601766.0000 - val_loss: 18594738.0000\n",
            "Epoch 49/500\n",
            "25/25 [==============================] - 0s 149us/step - loss: 24188518.0000 - val_loss: 18258178.0000\n",
            "Epoch 50/500\n",
            "25/25 [==============================] - 0s 221us/step - loss: 23773968.0000 - val_loss: 17920918.0000\n",
            "Epoch 51/500\n",
            "25/25 [==============================] - 0s 160us/step - loss: 23358342.0000 - val_loss: 17585940.0000\n",
            "Epoch 52/500\n",
            "25/25 [==============================] - 0s 142us/step - loss: 22945306.0000 - val_loss: 17247452.0000\n",
            "Epoch 53/500\n",
            "25/25 [==============================] - 0s 117us/step - loss: 22527716.0000 - val_loss: 16908572.0000\n",
            "Epoch 54/500\n",
            "25/25 [==============================] - 0s 579us/step - loss: 22109410.0000 - val_loss: 16569402.0000\n",
            "Epoch 55/500\n",
            "25/25 [==============================] - 0s 364us/step - loss: 21690502.0000 - val_loss: 16230050.0000\n",
            "Epoch 56/500\n",
            "25/25 [==============================] - 0s 335us/step - loss: 21271122.0000 - val_loss: 15893307.0000\n",
            "Epoch 57/500\n",
            "25/25 [==============================] - 0s 152us/step - loss: 20854706.0000 - val_loss: 15553819.0000\n",
            "Epoch 58/500\n",
            "25/25 [==============================] - 0s 343us/step - loss: 20434636.0000 - val_loss: 15214517.0000\n",
            "Epoch 59/500\n",
            "25/25 [==============================] - 0s 291us/step - loss: 20014516.0000 - val_loss: 14875534.0000\n",
            "Epoch 60/500\n",
            "25/25 [==============================] - 0s 422us/step - loss: 19594506.0000 - val_loss: 14536997.0000\n",
            "Epoch 61/500\n",
            "25/25 [==============================] - 0s 352us/step - loss: 19174758.0000 - val_loss: 14199035.0000\n",
            "Epoch 62/500\n",
            "25/25 [==============================] - 0s 160us/step - loss: 18755422.0000 - val_loss: 13861878.0000\n",
            "Epoch 63/500\n",
            "25/25 [==============================] - 0s 120us/step - loss: 18336714.0000 - val_loss: 13525831.0000\n",
            "Epoch 64/500\n",
            "25/25 [==============================] - 0s 203us/step - loss: 17918856.0000 - val_loss: 13204929.0000\n",
            "Epoch 65/500\n",
            "25/25 [==============================] - 0s 230us/step - loss: 17521414.0000 - val_loss: 12907605.0000\n",
            "Epoch 66/500\n",
            "25/25 [==============================] - 0s 204us/step - loss: 17151352.0000 - val_loss: 12609771.0000\n",
            "Epoch 67/500\n",
            "25/25 [==============================] - 0s 264us/step - loss: 16780366.0000 - val_loss: 12311806.0000\n",
            "Epoch 68/500\n",
            "25/25 [==============================] - 0s 267us/step - loss: 16408924.0000 - val_loss: 12014038.0000\n",
            "Epoch 69/500\n",
            "25/25 [==============================] - 0s 270us/step - loss: 16037423.0000 - val_loss: 11716774.0000\n",
            "Epoch 70/500\n",
            "25/25 [==============================] - 0s 182us/step - loss: 15666234.0000 - val_loss: 11420286.0000\n",
            "Epoch 71/500\n",
            "25/25 [==============================] - 0s 180us/step - loss: 15295686.0000 - val_loss: 11126688.0000\n",
            "Epoch 72/500\n",
            "25/25 [==============================] - 0s 418us/step - loss: 14928419.0000 - val_loss: 10832405.0000\n",
            "Epoch 73/500\n",
            "25/25 [==============================] - 0s 149us/step - loss: 14559944.0000 - val_loss: 10539630.0000\n",
            "Epoch 74/500\n",
            "25/25 [==============================] - 0s 162us/step - loss: 14192998.0000 - val_loss: 10248471.0000\n",
            "Epoch 75/500\n",
            "25/25 [==============================] - 0s 245us/step - loss: 13827707.0000 - val_loss: 9959261.0000\n",
            "Epoch 76/500\n",
            "25/25 [==============================] - 0s 241us/step - loss: 13464470.0000 - val_loss: 9672185.0000\n",
            "Epoch 77/500\n",
            "25/25 [==============================] - 0s 139us/step - loss: 13103521.0000 - val_loss: 9387367.0000\n",
            "Epoch 78/500\n",
            "25/25 [==============================] - 0s 206us/step - loss: 12745007.0000 - val_loss: 9105066.0000\n",
            "Epoch 79/500\n",
            "25/25 [==============================] - 0s 206us/step - loss: 12389235.0000 - val_loss: 8827021.0000\n",
            "Epoch 80/500\n",
            "25/25 [==============================] - 0s 215us/step - loss: 12038400.0000 - val_loss: 8550165.0000\n",
            "Epoch 81/500\n",
            "25/25 [==============================] - 0s 239us/step - loss: 11688620.0000 - val_loss: 8276349.0000\n",
            "Epoch 82/500\n",
            "25/25 [==============================] - 0s 164us/step - loss: 11342226.0000 - val_loss: 8005623.0000\n",
            "Epoch 83/500\n",
            "25/25 [==============================] - 0s 301us/step - loss: 10999268.0000 - val_loss: 7738271.0000\n",
            "Epoch 84/500\n",
            "25/25 [==============================] - 0s 128us/step - loss: 10660099.0000 - val_loss: 7474432.0000\n",
            "Epoch 85/500\n",
            "25/25 [==============================] - 0s 431us/step - loss: 10324890.0000 - val_loss: 7214264.5000\n",
            "Epoch 86/500\n",
            "25/25 [==============================] - 0s 220us/step - loss: 9993827.0000 - val_loss: 6957905.0000\n",
            "Epoch 87/500\n",
            "25/25 [==============================] - 0s 227us/step - loss: 9667086.0000 - val_loss: 6705499.5000\n",
            "Epoch 88/500\n",
            "25/25 [==============================] - 0s 282us/step - loss: 9344845.0000 - val_loss: 6457090.5000\n",
            "Epoch 89/500\n",
            "25/25 [==============================] - 0s 282us/step - loss: 9027150.0000 - val_loss: 6212917.5000\n",
            "Epoch 90/500\n",
            "25/25 [==============================] - 0s 254us/step - loss: 8714304.0000 - val_loss: 5974364.5000\n",
            "Epoch 91/500\n",
            "25/25 [==============================] - 0s 217us/step - loss: 8408072.0000 - val_loss: 5738937.5000\n",
            "Epoch 92/500\n",
            "25/25 [==============================] - 0s 235us/step - loss: 8105259.5000 - val_loss: 5508081.0000\n",
            "Epoch 93/500\n",
            "25/25 [==============================] - 0s 173us/step - loss: 7807704.5000 - val_loss: 5281962.5000\n",
            "Epoch 94/500\n",
            "25/25 [==============================] - 0s 162us/step - loss: 7515624.5000 - val_loss: 5060689.0000\n",
            "Epoch 95/500\n",
            "25/25 [==============================] - 0s 230us/step - loss: 7229150.5000 - val_loss: 4844289.0000\n",
            "Epoch 96/500\n",
            "25/25 [==============================] - 0s 224us/step - loss: 6948324.0000 - val_loss: 4632876.5000\n",
            "Epoch 97/500\n",
            "25/25 [==============================] - 0s 170us/step - loss: 6673285.0000 - val_loss: 4426620.5000\n",
            "Epoch 98/500\n",
            "25/25 [==============================] - 0s 206us/step - loss: 6404254.0000 - val_loss: 4225607.0000\n",
            "Epoch 99/500\n",
            "25/25 [==============================] - 0s 231us/step - loss: 6141344.0000 - val_loss: 4029912.0000\n",
            "Epoch 100/500\n",
            "25/25 [==============================] - 0s 243us/step - loss: 5884656.5000 - val_loss: 3841766.2500\n",
            "Epoch 101/500\n",
            "25/25 [==============================] - 0s 196us/step - loss: 5636393.0000 - val_loss: 3660850.7500\n",
            "Epoch 102/500\n",
            "25/25 [==============================] - 0s 165us/step - loss: 5397393.5000 - val_loss: 3484655.7500\n",
            "Epoch 103/500\n",
            "25/25 [==============================] - 0s 347us/step - loss: 5164157.0000 - val_loss: 3311123.5000\n",
            "Epoch 104/500\n",
            "25/25 [==============================] - 0s 198us/step - loss: 4933629.5000 - val_loss: 3141472.5000\n",
            "Epoch 105/500\n",
            "25/25 [==============================] - 0s 193us/step - loss: 4707416.5000 - val_loss: 2977205.2500\n",
            "Epoch 106/500\n",
            "25/25 [==============================] - 0s 269us/step - loss: 4487965.0000 - val_loss: 2820728.0000\n",
            "Epoch 107/500\n",
            "25/25 [==============================] - 0s 155us/step - loss: 4278094.5000 - val_loss: 2670413.7500\n",
            "Epoch 108/500\n",
            "25/25 [==============================] - 0s 219us/step - loss: 4075179.0000 - val_loss: 2526150.7500\n",
            "Epoch 109/500\n",
            "25/25 [==============================] - 0s 195us/step - loss: 3879551.2500 - val_loss: 2387294.5000\n",
            "Epoch 110/500\n",
            "25/25 [==============================] - 0s 199us/step - loss: 3690355.5000 - val_loss: 2260916.5000\n",
            "Epoch 111/500\n",
            "25/25 [==============================] - 0s 171us/step - loss: 3517238.0000 - val_loss: 2129718.7500\n",
            "Epoch 112/500\n",
            "25/25 [==============================] - 0s 217us/step - loss: 3336651.0000 - val_loss: 2002909.7500\n",
            "Epoch 113/500\n",
            "25/25 [==============================] - 0s 181us/step - loss: 3161137.5000 - val_loss: 1885360.8750\n",
            "Epoch 114/500\n",
            "25/25 [==============================] - 0s 203us/step - loss: 2997410.0000 - val_loss: 1773279.1250\n",
            "Epoch 115/500\n",
            "25/25 [==============================] - 0s 268us/step - loss: 2840265.5000 - val_loss: 1667005.2500\n",
            "Epoch 116/500\n",
            "25/25 [==============================] - 0s 199us/step - loss: 2690236.5000 - val_loss: 1565632.8750\n",
            "Epoch 117/500\n",
            "25/25 [==============================] - 0s 216us/step - loss: 2546079.7500 - val_loss: 1469891.8750\n",
            "Epoch 118/500\n",
            "25/25 [==============================] - 0s 231us/step - loss: 2408861.5000 - val_loss: 1379295.8750\n",
            "Epoch 119/500\n",
            "25/25 [==============================] - 0s 207us/step - loss: 2277931.7500 - val_loss: 1293451.1250\n",
            "Epoch 120/500\n",
            "25/25 [==============================] - 0s 240us/step - loss: 2152754.2500 - val_loss: 1212914.1250\n",
            "Epoch 121/500\n",
            "25/25 [==============================] - 0s 237us/step - loss: 2034185.5000 - val_loss: 1136963.6250\n",
            "Epoch 122/500\n",
            "25/25 [==============================] - 0s 230us/step - loss: 1921207.5000 - val_loss: 1066079.6250\n",
            "Epoch 123/500\n",
            "25/25 [==============================] - 0s 277us/step - loss: 1814591.3750 - val_loss: 999595.5625\n",
            "Epoch 124/500\n",
            "25/25 [==============================] - 0s 285us/step - loss: 1713391.8750 - val_loss: 937750.5000\n",
            "Epoch 125/500\n",
            "25/25 [==============================] - 0s 264us/step - loss: 1617921.2500 - val_loss: 880619.3125\n",
            "Epoch 126/500\n",
            "25/25 [==============================] - 0s 208us/step - loss: 1528461.5000 - val_loss: 827691.6875\n",
            "Epoch 127/500\n",
            "25/25 [==============================] - 0s 194us/step - loss: 1444634.7500 - val_loss: 779011.6250\n",
            "Epoch 128/500\n",
            "25/25 [==============================] - 0s 237us/step - loss: 1365965.6250 - val_loss: 733892.8125\n",
            "Epoch 129/500\n",
            "25/25 [==============================] - 0s 268us/step - loss: 1291909.7500 - val_loss: 692264.8125\n",
            "Epoch 130/500\n",
            "25/25 [==============================] - 0s 269us/step - loss: 1222269.0000 - val_loss: 654476.3750\n",
            "Epoch 131/500\n",
            "25/25 [==============================] - 0s 208us/step - loss: 1157464.0000 - val_loss: 620176.3750\n",
            "Epoch 132/500\n",
            "25/25 [==============================] - 0s 290us/step - loss: 1097388.7500 - val_loss: 589292.9375\n",
            "Epoch 133/500\n",
            "25/25 [==============================] - 0s 279us/step - loss: 1041827.0625 - val_loss: 561415.1250\n",
            "Epoch 134/500\n",
            "25/25 [==============================] - 0s 155us/step - loss: 990186.9375 - val_loss: 536485.0625\n",
            "Epoch 135/500\n",
            "25/25 [==============================] - 0s 350us/step - loss: 942475.1250 - val_loss: 514399.9375\n",
            "Epoch 136/500\n",
            "25/25 [==============================] - 0s 274us/step - loss: 898647.1250 - val_loss: 494905.1562\n",
            "Epoch 137/500\n",
            "25/25 [==============================] - 0s 419us/step - loss: 858351.0625 - val_loss: 477836.1875\n",
            "Epoch 138/500\n",
            "25/25 [==============================] - 0s 158us/step - loss: 821397.6250 - val_loss: 463024.0312\n",
            "Epoch 139/500\n",
            "25/25 [==============================] - 0s 246us/step - loss: 787604.0625 - val_loss: 450307.3438\n",
            "Epoch 140/500\n",
            "25/25 [==============================] - 0s 163us/step - loss: 756786.3750 - val_loss: 439528.1562\n",
            "Epoch 141/500\n",
            "25/25 [==============================] - 0s 179us/step - loss: 728759.3750 - val_loss: 430530.0625\n",
            "Epoch 142/500\n",
            "25/25 [==============================] - 0s 223us/step - loss: 703329.9375 - val_loss: 423136.0938\n",
            "Epoch 143/500\n",
            "25/25 [==============================] - 0s 231us/step - loss: 680301.3750 - val_loss: 417159.2812\n",
            "Epoch 144/500\n",
            "25/25 [==============================] - 0s 229us/step - loss: 659484.0625 - val_loss: 412470.7188\n",
            "Epoch 145/500\n",
            "25/25 [==============================] - 0s 184us/step - loss: 640825.8750 - val_loss: 409212.0938\n",
            "Epoch 146/500\n",
            "25/25 [==============================] - 0s 240us/step - loss: 624258.2500 - val_loss: 407068.3125\n",
            "Epoch 147/500\n",
            "25/25 [==============================] - 0s 248us/step - loss: 609536.7500 - val_loss: 405889.2500\n",
            "Epoch 148/500\n",
            "25/25 [==============================] - 0s 286us/step - loss: 596390.5000 - val_loss: 405576.7812\n",
            "Epoch 149/500\n",
            "25/25 [==============================] - 0s 261us/step - loss: 584702.7500 - val_loss: 406031.9062\n",
            "Epoch 150/500\n",
            "25/25 [==============================] - 0s 257us/step - loss: 574406.8750 - val_loss: 407155.8438\n",
            "Epoch 151/500\n",
            "25/25 [==============================] - 0s 278us/step - loss: 565438.5000 - val_loss: 408946.3438\n",
            "Epoch 152/500\n",
            "25/25 [==============================] - 0s 263us/step - loss: 557640.3750 - val_loss: 411180.8438\n",
            "Epoch 153/500\n",
            "25/25 [==============================] - 0s 202us/step - loss: 550920.0625 - val_loss: 413731.0938\n",
            "Epoch 154/500\n",
            "25/25 [==============================] - 0s 205us/step - loss: 545102.4375 - val_loss: 416526.6562\n",
            "Epoch 155/500\n",
            "25/25 [==============================] - 0s 243us/step - loss: 540061.9375 - val_loss: 419504.5312\n",
            "Epoch 156/500\n",
            "25/25 [==============================] - 0s 173us/step - loss: 535768.8125 - val_loss: 422706.7812\n",
            "Epoch 157/500\n",
            "25/25 [==============================] - 0s 257us/step - loss: 532117.6250 - val_loss: 426049.2188\n",
            "Epoch 158/500\n",
            "25/25 [==============================] - 0s 170us/step - loss: 529085.8125 - val_loss: 429476.6562\n",
            "Epoch 159/500\n",
            "25/25 [==============================] - 0s 237us/step - loss: 526578.0625 - val_loss: 432945.7812\n",
            "Epoch 160/500\n",
            "25/25 [==============================] - 0s 188us/step - loss: 524504.5000 - val_loss: 436416.8438\n",
            "Epoch 161/500\n",
            "25/25 [==============================] - 0s 152us/step - loss: 522807.0000 - val_loss: 439854.2500\n",
            "Epoch 162/500\n",
            "25/25 [==============================] - 0s 297us/step - loss: 521436.1875 - val_loss: 443218.3438\n",
            "Epoch 163/500\n",
            "25/25 [==============================] - 0s 222us/step - loss: 520350.7188 - val_loss: 446500.2188\n",
            "Epoch 164/500\n",
            "25/25 [==============================] - 0s 141us/step - loss: 519502.0312 - val_loss: 449670.2812\n",
            "Epoch 165/500\n",
            "25/25 [==============================] - 0s 152us/step - loss: 518857.6250 - val_loss: 452705.0625\n",
            "Epoch 166/500\n",
            "25/25 [==============================] - 0s 168us/step - loss: 518384.8438 - val_loss: 455583.5312\n",
            "Epoch 167/500\n",
            "25/25 [==============================] - 0s 160us/step - loss: 518061.0000 - val_loss: 458286.4062\n",
            "Epoch 168/500\n",
            "25/25 [==============================] - 0s 454us/step - loss: 517852.4375 - val_loss: 460804.6875\n",
            "Epoch 169/500\n",
            "25/25 [==============================] - 0s 197us/step - loss: 517731.8750 - val_loss: 463118.5312\n",
            "Epoch 170/500\n",
            "25/25 [==============================] - 0s 187us/step - loss: 517670.9688 - val_loss: 465239.4062\n",
            "Epoch 171/500\n",
            "25/25 [==============================] - 0s 215us/step - loss: 517660.1250 - val_loss: 467183.5000\n",
            "Epoch 172/500\n",
            "25/25 [==============================] - 0s 197us/step - loss: 517697.9688 - val_loss: 468954.4062\n",
            "Epoch 173/500\n",
            "25/25 [==============================] - 0s 127us/step - loss: 517762.3125 - val_loss: 470549.9062\n",
            "Epoch 174/500\n",
            "25/25 [==============================] - 0s 208us/step - loss: 517844.2500 - val_loss: 471971.6562\n",
            "Epoch 175/500\n",
            "25/25 [==============================] - 0s 131us/step - loss: 517935.4688 - val_loss: 473226.9375\n",
            "Epoch 176/500\n",
            "25/25 [==============================] - 0s 234us/step - loss: 518029.4062 - val_loss: 474317.2188\n",
            "Epoch 177/500\n",
            "25/25 [==============================] - 0s 195us/step - loss: 518121.5938 - val_loss: 475255.7812\n",
            "Epoch 178/500\n",
            "25/25 [==============================] - 0s 202us/step - loss: 518208.3125 - val_loss: 476045.2188\n",
            "Epoch 179/500\n",
            "25/25 [==============================] - 0s 233us/step - loss: 518286.2500 - val_loss: 476695.6562\n",
            "Epoch 180/500\n",
            "25/25 [==============================] - 0s 198us/step - loss: 518353.4375 - val_loss: 477214.5938\n",
            "Epoch 181/500\n",
            "25/25 [==============================] - 0s 201us/step - loss: 518409.7188 - val_loss: 477610.3438\n",
            "Epoch 182/500\n",
            "25/25 [==============================] - 0s 213us/step - loss: 518453.9688 - val_loss: 477891.7188\n",
            "Epoch 183/500\n",
            "25/25 [==============================] - 0s 201us/step - loss: 518485.1250 - val_loss: 478067.7188\n",
            "Epoch 184/500\n",
            "25/25 [==============================] - 0s 229us/step - loss: 518504.7188 - val_loss: 478146.6875\n",
            "Epoch 185/500\n",
            "25/25 [==============================] - 0s 229us/step - loss: 518513.3750 - val_loss: 478137.0312\n",
            "Epoch 186/500\n",
            "25/25 [==============================] - 0s 181us/step - loss: 518511.8125 - val_loss: 478048.5000\n",
            "Epoch 187/500\n",
            "25/25 [==============================] - 0s 230us/step - loss: 518500.4062 - val_loss: 477888.0938\n",
            "Epoch 188/500\n",
            "25/25 [==============================] - 0s 284us/step - loss: 518480.4062 - val_loss: 477664.4375\n",
            "Epoch 189/500\n",
            "25/25 [==============================] - 0s 172us/step - loss: 518453.5312 - val_loss: 477383.9375\n",
            "Epoch 190/500\n",
            "25/25 [==============================] - 0s 215us/step - loss: 518421.4062 - val_loss: 477055.6562\n",
            "Epoch 191/500\n",
            "25/25 [==============================] - 0s 219us/step - loss: 518383.4375 - val_loss: 476683.8438\n",
            "Epoch 192/500\n",
            "25/25 [==============================] - 0s 154us/step - loss: 518341.9062 - val_loss: 476276.6562\n",
            "Epoch 193/500\n",
            "25/25 [==============================] - 0s 228us/step - loss: 518298.2500 - val_loss: 475838.5938\n",
            "Epoch 194/500\n",
            "25/25 [==============================] - 0s 229us/step - loss: 518252.2812 - val_loss: 475377.8438\n",
            "Epoch 195/500\n",
            "25/25 [==============================] - 0s 174us/step - loss: 518205.5312 - val_loss: 474899.0625\n",
            "Epoch 196/500\n",
            "25/25 [==============================] - 0s 172us/step - loss: 518158.4062 - val_loss: 474403.7188\n",
            "Epoch 197/500\n",
            "25/25 [==============================] - 0s 196us/step - loss: 518112.5625 - val_loss: 473899.3438\n",
            "Epoch 198/500\n",
            "25/25 [==============================] - 0s 190us/step - loss: 518066.6250 - val_loss: 473388.0000\n",
            "Epoch 199/500\n",
            "25/25 [==============================] - 0s 248us/step - loss: 518022.7188 - val_loss: 472874.6562\n",
            "Epoch 200/500\n",
            "25/25 [==============================] - 0s 260us/step - loss: 517980.5938 - val_loss: 472362.7188\n",
            "Epoch 201/500\n",
            "25/25 [==============================] - 0s 240us/step - loss: 517940.6250 - val_loss: 471852.4062\n",
            "Epoch 202/500\n",
            "25/25 [==============================] - 0s 219us/step - loss: 517903.4375 - val_loss: 471348.5938\n",
            "Epoch 203/500\n",
            "25/25 [==============================] - 0s 216us/step - loss: 517868.4688 - val_loss: 470853.5000\n",
            "Epoch 204/500\n",
            "25/25 [==============================] - 0s 243us/step - loss: 517836.0938 - val_loss: 470369.2188\n",
            "Epoch 205/500\n",
            "25/25 [==============================] - 0s 149us/step - loss: 517806.5625 - val_loss: 469895.9062\n",
            "Epoch 206/500\n",
            "25/25 [==============================] - 0s 217us/step - loss: 517779.3750 - val_loss: 469438.7188\n",
            "Epoch 207/500\n",
            "25/25 [==============================] - 0s 248us/step - loss: 517755.1250 - val_loss: 468994.6562\n",
            "Epoch 208/500\n",
            "25/25 [==============================] - 0s 181us/step - loss: 517733.4062 - val_loss: 468567.5312\n",
            "Epoch 209/500\n",
            "25/25 [==============================] - 0s 222us/step - loss: 517713.3750 - val_loss: 468156.6562\n",
            "Epoch 210/500\n",
            "25/25 [==============================] - 0s 245us/step - loss: 517696.4688 - val_loss: 467763.5625\n",
            "Epoch 211/500\n",
            "25/25 [==============================] - 0s 216us/step - loss: 517681.3750 - val_loss: 467388.7188\n",
            "Epoch 212/500\n",
            "25/25 [==============================] - 0s 225us/step - loss: 517668.4688 - val_loss: 467032.0938\n",
            "Epoch 213/500\n",
            "25/25 [==============================] - 0s 197us/step - loss: 517657.1875 - val_loss: 466693.5000\n",
            "Epoch 214/500\n",
            "25/25 [==============================] - 0s 204us/step - loss: 517647.0000 - val_loss: 466373.4062\n",
            "Epoch 215/500\n",
            "25/25 [==============================] - 0s 197us/step - loss: 517639.0312 - val_loss: 466071.5625\n",
            "Epoch 216/500\n",
            "25/25 [==============================] - 0s 200us/step - loss: 517632.1875 - val_loss: 465789.4375\n",
            "Epoch 217/500\n",
            "25/25 [==============================] - 0s 220us/step - loss: 517626.1562 - val_loss: 465525.0000\n",
            "Epoch 218/500\n",
            "25/25 [==============================] - 0s 184us/step - loss: 517621.2500 - val_loss: 465279.5000\n",
            "Epoch 219/500\n",
            "25/25 [==============================] - 0s 228us/step - loss: 517616.9062 - val_loss: 465050.2188\n",
            "Epoch 220/500\n",
            "25/25 [==============================] - 0s 178us/step - loss: 517614.1250 - val_loss: 464838.0625\n",
            "Epoch 221/500\n",
            "25/25 [==============================] - 0s 200us/step - loss: 517611.0938 - val_loss: 464641.7812\n",
            "Epoch 222/500\n",
            "25/25 [==============================] - 0s 229us/step - loss: 517609.3750 - val_loss: 464463.5000\n",
            "Epoch 223/500\n",
            "25/25 [==============================] - 0s 296us/step - loss: 517607.6250 - val_loss: 464299.5625\n",
            "Epoch 224/500\n",
            "25/25 [==============================] - 0s 235us/step - loss: 517606.0000 - val_loss: 464150.4375\n",
            "Epoch 225/500\n",
            "25/25 [==============================] - 0s 260us/step - loss: 517604.8125 - val_loss: 464016.6875\n",
            "Epoch 226/500\n",
            "25/25 [==============================] - 0s 276us/step - loss: 517603.8750 - val_loss: 463895.9375\n",
            "Epoch 227/500\n",
            "25/25 [==============================] - 0s 276us/step - loss: 517603.1562 - val_loss: 463787.3438\n",
            "Epoch 228/500\n",
            "25/25 [==============================] - 0s 286us/step - loss: 517602.6875 - val_loss: 463692.4062\n",
            "Epoch 229/500\n",
            "25/25 [==============================] - 0s 278us/step - loss: 517602.3125 - val_loss: 463609.8438\n",
            "Epoch 230/500\n",
            "25/25 [==============================] - 0s 185us/step - loss: 517601.7188 - val_loss: 463536.9062\n",
            "Epoch 231/500\n",
            "25/25 [==============================] - 0s 199us/step - loss: 517600.7500 - val_loss: 463474.4375\n",
            "Epoch 232/500\n",
            "25/25 [==============================] - 0s 240us/step - loss: 517600.6250 - val_loss: 463422.7188\n",
            "Epoch 233/500\n",
            "25/25 [==============================] - 0s 179us/step - loss: 517599.3125 - val_loss: 463380.0000\n",
            "Epoch 234/500\n",
            "25/25 [==============================] - 0s 160us/step - loss: 517599.1562 - val_loss: 463345.2812\n",
            "Epoch 235/500\n",
            "25/25 [==============================] - 0s 205us/step - loss: 517598.7500 - val_loss: 463318.7188\n",
            "Epoch 236/500\n",
            "25/25 [==============================] - 0s 197us/step - loss: 517597.4062 - val_loss: 463299.2812\n",
            "Epoch 237/500\n",
            "25/25 [==============================] - 0s 194us/step - loss: 517597.0938 - val_loss: 463285.9375\n",
            "Epoch 238/500\n",
            "25/25 [==============================] - 0s 194us/step - loss: 517596.1250 - val_loss: 463279.9375\n",
            "Epoch 239/500\n",
            "25/25 [==============================] - 0s 182us/step - loss: 517595.5312 - val_loss: 463279.6562\n",
            "Epoch 240/500\n",
            "25/25 [==============================] - 0s 162us/step - loss: 517594.5938 - val_loss: 463283.5000\n",
            "Epoch 241/500\n",
            "25/25 [==============================] - 0s 133us/step - loss: 517593.4375 - val_loss: 463291.9688\n",
            "Epoch 242/500\n",
            "25/25 [==============================] - 0s 148us/step - loss: 517592.4688 - val_loss: 463304.7812\n",
            "Epoch 243/500\n",
            "25/25 [==============================] - 0s 185us/step - loss: 517591.4688 - val_loss: 463320.9375\n",
            "Epoch 244/500\n",
            "25/25 [==============================] - 0s 243us/step - loss: 517590.0312 - val_loss: 463340.6562\n",
            "Epoch 245/500\n",
            "25/25 [==============================] - 0s 239us/step - loss: 517589.2812 - val_loss: 463362.2500\n",
            "Epoch 246/500\n",
            "25/25 [==============================] - 0s 227us/step - loss: 517588.0000 - val_loss: 463386.6562\n",
            "Epoch 247/500\n",
            "25/25 [==============================] - 0s 232us/step - loss: 517586.6875 - val_loss: 463413.1562\n",
            "Epoch 248/500\n",
            "25/25 [==============================] - 0s 248us/step - loss: 517585.6250 - val_loss: 463441.6875\n",
            "Epoch 249/500\n",
            "25/25 [==============================] - 0s 221us/step - loss: 517584.3125 - val_loss: 463470.9375\n",
            "Epoch 250/500\n",
            "25/25 [==============================] - 0s 191us/step - loss: 517583.2812 - val_loss: 463500.5000\n",
            "Epoch 251/500\n",
            "25/25 [==============================] - 0s 306us/step - loss: 517582.3125 - val_loss: 463531.7812\n",
            "Epoch 252/500\n",
            "25/25 [==============================] - 0s 235us/step - loss: 517581.1562 - val_loss: 463562.7812\n",
            "Epoch 253/500\n",
            "25/25 [==============================] - 0s 175us/step - loss: 517580.3750 - val_loss: 463594.5625\n",
            "Epoch 254/500\n",
            "25/25 [==============================] - 0s 201us/step - loss: 517579.0938 - val_loss: 463625.8125\n",
            "Epoch 255/500\n",
            "25/25 [==============================] - 0s 170us/step - loss: 517577.4375 - val_loss: 463657.1562\n",
            "Epoch 256/500\n",
            "25/25 [==============================] - 0s 351us/step - loss: 517577.0000 - val_loss: 463687.9062\n",
            "Epoch 257/500\n",
            "25/25 [==============================] - 0s 238us/step - loss: 517575.3750 - val_loss: 463718.4062\n",
            "Epoch 258/500\n",
            "25/25 [==============================] - 0s 175us/step - loss: 517574.3125 - val_loss: 463747.7812\n",
            "Epoch 259/500\n",
            "25/25 [==============================] - 0s 187us/step - loss: 517573.2812 - val_loss: 463775.7500\n",
            "Epoch 260/500\n",
            "25/25 [==============================] - 0s 161us/step - loss: 517572.2812 - val_loss: 463804.6562\n",
            "Epoch 261/500\n",
            "25/25 [==============================] - 0s 202us/step - loss: 517570.8125 - val_loss: 463830.2188\n",
            "Epoch 262/500\n",
            "25/25 [==============================] - 0s 145us/step - loss: 517569.9062 - val_loss: 463856.0625\n",
            "Epoch 263/500\n",
            "25/25 [==============================] - 0s 185us/step - loss: 517568.9062 - val_loss: 463879.7188\n",
            "Epoch 264/500\n",
            "25/25 [==============================] - 0s 146us/step - loss: 517567.8125 - val_loss: 463902.2188\n",
            "Epoch 265/500\n",
            "25/25 [==============================] - 0s 168us/step - loss: 517567.2812 - val_loss: 463924.5312\n",
            "Epoch 266/500\n",
            "25/25 [==============================] - 0s 325us/step - loss: 517565.8438 - val_loss: 463945.1562\n",
            "Epoch 267/500\n",
            "25/25 [==============================] - 0s 277us/step - loss: 517564.9062 - val_loss: 463965.2500\n",
            "Epoch 268/500\n",
            "25/25 [==============================] - 0s 230us/step - loss: 517563.6875 - val_loss: 463982.3438\n",
            "Epoch 269/500\n",
            "25/25 [==============================] - 0s 175us/step - loss: 517563.0312 - val_loss: 463999.4062\n",
            "Epoch 270/500\n",
            "25/25 [==============================] - 0s 179us/step - loss: 517561.5938 - val_loss: 464015.1562\n",
            "Epoch 271/500\n",
            "25/25 [==============================] - 0s 207us/step - loss: 517561.1562 - val_loss: 464028.2812\n",
            "Epoch 272/500\n",
            "25/25 [==============================] - 0s 166us/step - loss: 517559.3125 - val_loss: 464041.5312\n",
            "Epoch 273/500\n",
            "25/25 [==============================] - 0s 161us/step - loss: 517558.9688 - val_loss: 464052.7812\n",
            "Epoch 274/500\n",
            "25/25 [==============================] - 0s 183us/step - loss: 517557.5625 - val_loss: 464063.5625\n",
            "Epoch 275/500\n",
            "25/25 [==============================] - 0s 192us/step - loss: 517556.6875 - val_loss: 464072.0938\n",
            "Epoch 276/500\n",
            "25/25 [==============================] - 0s 147us/step - loss: 517555.3750 - val_loss: 464080.3438\n",
            "Epoch 277/500\n",
            "25/25 [==============================] - 0s 215us/step - loss: 517554.6250 - val_loss: 464087.5312\n",
            "Epoch 278/500\n",
            "25/25 [==============================] - 0s 239us/step - loss: 517553.6250 - val_loss: 464094.2188\n",
            "Epoch 279/500\n",
            "25/25 [==============================] - 0s 282us/step - loss: 517552.7188 - val_loss: 464098.8438\n",
            "Epoch 280/500\n",
            "25/25 [==============================] - 0s 244us/step - loss: 517551.3750 - val_loss: 464103.3125\n",
            "Epoch 281/500\n",
            "25/25 [==============================] - 0s 165us/step - loss: 517550.3750 - val_loss: 464106.6562\n",
            "Epoch 282/500\n",
            "25/25 [==============================] - 0s 196us/step - loss: 517549.4688 - val_loss: 464108.7812\n",
            "Epoch 283/500\n",
            "25/25 [==============================] - 0s 193us/step - loss: 517549.1250 - val_loss: 464111.0625\n",
            "Epoch 284/500\n",
            "25/25 [==============================] - 0s 202us/step - loss: 517547.5312 - val_loss: 464112.4375\n",
            "Epoch 285/500\n",
            "25/25 [==============================] - 0s 228us/step - loss: 517546.4375 - val_loss: 464112.6875\n",
            "Epoch 286/500\n",
            "25/25 [==============================] - 0s 195us/step - loss: 517545.2812 - val_loss: 464112.7188\n",
            "Epoch 287/500\n",
            "25/25 [==============================] - 0s 254us/step - loss: 517544.1875 - val_loss: 464111.9375\n",
            "Epoch 288/500\n",
            "25/25 [==============================] - 0s 248us/step - loss: 517542.7500 - val_loss: 464111.3438\n",
            "Epoch 289/500\n",
            "25/25 [==============================] - 0s 253us/step - loss: 517542.1562 - val_loss: 464110.2812\n",
            "Epoch 290/500\n",
            "25/25 [==============================] - 0s 269us/step - loss: 517541.1250 - val_loss: 464107.7812\n",
            "Epoch 291/500\n",
            "25/25 [==============================] - 0s 300us/step - loss: 517539.7188 - val_loss: 464106.1875\n",
            "Epoch 292/500\n",
            "25/25 [==============================] - 0s 337us/step - loss: 517539.0938 - val_loss: 464102.5625\n",
            "Epoch 293/500\n",
            "25/25 [==============================] - 0s 243us/step - loss: 517537.9062 - val_loss: 464101.0000\n",
            "Epoch 294/500\n",
            "25/25 [==============================] - 0s 152us/step - loss: 517537.4062 - val_loss: 464097.3438\n",
            "Epoch 295/500\n",
            "25/25 [==============================] - 0s 259us/step - loss: 517536.0000 - val_loss: 464093.7500\n",
            "Epoch 296/500\n",
            "25/25 [==============================] - 0s 134us/step - loss: 517535.0938 - val_loss: 464090.7812\n",
            "Epoch 297/500\n",
            "25/25 [==============================] - 0s 171us/step - loss: 517533.3125 - val_loss: 464087.7188\n",
            "Epoch 298/500\n",
            "25/25 [==============================] - 0s 127us/step - loss: 517532.3125 - val_loss: 464084.7188\n",
            "Epoch 299/500\n",
            "25/25 [==============================] - 0s 176us/step - loss: 517531.8438 - val_loss: 464081.4375\n",
            "Epoch 300/500\n",
            "25/25 [==============================] - 0s 231us/step - loss: 517530.6250 - val_loss: 464077.0000\n",
            "Epoch 301/500\n",
            "25/25 [==============================] - 0s 312us/step - loss: 517529.4688 - val_loss: 464073.1562\n",
            "Epoch 302/500\n",
            "25/25 [==============================] - 0s 232us/step - loss: 517528.2812 - val_loss: 464070.4375\n",
            "Epoch 303/500\n",
            "25/25 [==============================] - 0s 179us/step - loss: 517527.2812 - val_loss: 464066.8438\n",
            "Epoch 304/500\n",
            "25/25 [==============================] - 0s 256us/step - loss: 517526.1562 - val_loss: 464064.1562\n",
            "Epoch 305/500\n",
            "25/25 [==============================] - 0s 146us/step - loss: 517525.6250 - val_loss: 464059.7500\n",
            "Epoch 306/500\n",
            "25/25 [==============================] - 0s 283us/step - loss: 517523.8125 - val_loss: 464056.7500\n",
            "Epoch 307/500\n",
            "25/25 [==============================] - 0s 211us/step - loss: 517522.9062 - val_loss: 464052.9375\n",
            "Epoch 308/500\n",
            "25/25 [==============================] - 0s 458us/step - loss: 517522.0000 - val_loss: 464049.2812\n",
            "Epoch 309/500\n",
            "25/25 [==============================] - 0s 148us/step - loss: 517520.6875 - val_loss: 464046.2812\n",
            "Epoch 310/500\n",
            "25/25 [==============================] - 0s 198us/step - loss: 517519.5312 - val_loss: 464042.7188\n",
            "Epoch 311/500\n",
            "25/25 [==============================] - 0s 193us/step - loss: 517518.4375 - val_loss: 464039.9688\n",
            "Epoch 312/500\n",
            "25/25 [==============================] - 0s 227us/step - loss: 517517.5312 - val_loss: 464036.4062\n",
            "Epoch 313/500\n",
            "25/25 [==============================] - 0s 255us/step - loss: 517516.5312 - val_loss: 464033.9375\n",
            "Epoch 314/500\n",
            "25/25 [==============================] - 0s 174us/step - loss: 517515.2500 - val_loss: 464030.3438\n",
            "Epoch 315/500\n",
            "25/25 [==============================] - 0s 215us/step - loss: 517514.5312 - val_loss: 464027.5625\n",
            "Epoch 316/500\n",
            "25/25 [==============================] - 0s 226us/step - loss: 517513.1250 - val_loss: 464026.2812\n",
            "Epoch 317/500\n",
            "25/25 [==============================] - 0s 217us/step - loss: 517511.9688 - val_loss: 464023.2188\n",
            "Epoch 318/500\n",
            "25/25 [==============================] - 0s 193us/step - loss: 517510.5312 - val_loss: 464021.3438\n",
            "Epoch 319/500\n",
            "25/25 [==============================] - 0s 254us/step - loss: 517509.8438 - val_loss: 464017.4375\n",
            "Epoch 320/500\n",
            "25/25 [==============================] - 0s 307us/step - loss: 517508.3125 - val_loss: 464015.8438\n",
            "Epoch 321/500\n",
            "25/25 [==============================] - 0s 261us/step - loss: 517507.5625 - val_loss: 464013.9062\n",
            "Epoch 322/500\n",
            "25/25 [==============================] - 0s 186us/step - loss: 517506.8125 - val_loss: 464011.7188\n",
            "Epoch 323/500\n",
            "25/25 [==============================] - 0s 195us/step - loss: 517505.4688 - val_loss: 464008.9375\n",
            "Epoch 324/500\n",
            "25/25 [==============================] - 0s 193us/step - loss: 517504.0312 - val_loss: 464007.5938\n",
            "Epoch 325/500\n",
            "25/25 [==============================] - 0s 204us/step - loss: 517502.7500 - val_loss: 464005.6562\n",
            "Epoch 326/500\n",
            "25/25 [==============================] - 0s 212us/step - loss: 517502.2812 - val_loss: 464005.2188\n",
            "Epoch 327/500\n",
            "25/25 [==============================] - 0s 157us/step - loss: 517501.2812 - val_loss: 464003.5000\n",
            "Epoch 328/500\n",
            "25/25 [==============================] - 0s 271us/step - loss: 517499.8750 - val_loss: 464002.6875\n",
            "Epoch 329/500\n",
            "25/25 [==============================] - 0s 246us/step - loss: 517498.7500 - val_loss: 464002.2188\n",
            "Epoch 330/500\n",
            "25/25 [==============================] - 0s 150us/step - loss: 517498.0000 - val_loss: 464000.2188\n",
            "Epoch 331/500\n",
            "25/25 [==============================] - 0s 212us/step - loss: 517496.4375 - val_loss: 463999.4062\n",
            "Epoch 332/500\n",
            "25/25 [==============================] - 0s 174us/step - loss: 517495.0312 - val_loss: 463998.3438\n",
            "Epoch 333/500\n",
            "25/25 [==============================] - 0s 238us/step - loss: 517494.3750 - val_loss: 463997.2812\n",
            "Epoch 334/500\n",
            "25/25 [==============================] - 0s 197us/step - loss: 517493.1875 - val_loss: 463996.4688\n",
            "Epoch 335/500\n",
            "25/25 [==============================] - 0s 153us/step - loss: 517491.8750 - val_loss: 463995.6562\n",
            "Epoch 336/500\n",
            "25/25 [==============================] - 0s 149us/step - loss: 517490.8438 - val_loss: 463994.7812\n",
            "Epoch 337/500\n",
            "25/25 [==============================] - 0s 280us/step - loss: 517490.1562 - val_loss: 463994.2500\n",
            "Epoch 338/500\n",
            "25/25 [==============================] - 0s 273us/step - loss: 517488.1875 - val_loss: 463993.4375\n",
            "Epoch 339/500\n",
            "25/25 [==============================] - 0s 283us/step - loss: 517487.0000 - val_loss: 463992.0625\n",
            "Epoch 340/500\n",
            "25/25 [==============================] - 0s 220us/step - loss: 517486.0938 - val_loss: 463992.0625\n",
            "Epoch 341/500\n",
            "25/25 [==============================] - 0s 270us/step - loss: 517485.0938 - val_loss: 463991.2812\n",
            "Epoch 342/500\n",
            "25/25 [==============================] - 0s 312us/step - loss: 517483.5938 - val_loss: 463990.2188\n",
            "Epoch 343/500\n",
            "25/25 [==============================] - 0s 219us/step - loss: 517482.5625 - val_loss: 463988.0000\n",
            "Epoch 344/500\n",
            "25/25 [==============================] - 0s 215us/step - loss: 517481.4062 - val_loss: 463986.3438\n",
            "Epoch 345/500\n",
            "25/25 [==============================] - 0s 185us/step - loss: 517480.4688 - val_loss: 463985.0000\n",
            "Epoch 346/500\n",
            "25/25 [==============================] - 0s 228us/step - loss: 517479.2812 - val_loss: 463983.9375\n",
            "Epoch 347/500\n",
            "25/25 [==============================] - 0s 134us/step - loss: 517478.1250 - val_loss: 463981.7812\n",
            "Epoch 348/500\n",
            "25/25 [==============================] - 0s 240us/step - loss: 517476.2500 - val_loss: 463980.4375\n",
            "Epoch 349/500\n",
            "25/25 [==============================] - 0s 191us/step - loss: 517475.3750 - val_loss: 463976.8438\n",
            "Epoch 350/500\n",
            "25/25 [==============================] - 0s 177us/step - loss: 517474.4375 - val_loss: 463974.3438\n",
            "Epoch 351/500\n",
            "25/25 [==============================] - 0s 213us/step - loss: 517473.0938 - val_loss: 463972.7812\n",
            "Epoch 352/500\n",
            "25/25 [==============================] - 0s 151us/step - loss: 517472.2500 - val_loss: 463970.5625\n",
            "Epoch 353/500\n",
            "25/25 [==============================] - 0s 153us/step - loss: 517470.9062 - val_loss: 463968.1875\n",
            "Epoch 354/500\n",
            "25/25 [==============================] - 0s 268us/step - loss: 517469.7188 - val_loss: 463967.0938\n",
            "Epoch 355/500\n",
            "25/25 [==============================] - 0s 186us/step - loss: 517468.1875 - val_loss: 463964.4062\n",
            "Epoch 356/500\n",
            "25/25 [==============================] - 0s 243us/step - loss: 517467.5312 - val_loss: 463961.9062\n",
            "Epoch 357/500\n",
            "25/25 [==============================] - 0s 194us/step - loss: 517466.1562 - val_loss: 463959.7812\n",
            "Epoch 358/500\n",
            "25/25 [==============================] - 0s 199us/step - loss: 517464.7500 - val_loss: 463957.0000\n",
            "Epoch 359/500\n",
            "25/25 [==============================] - 0s 230us/step - loss: 517463.6250 - val_loss: 463955.7188\n",
            "Epoch 360/500\n",
            "25/25 [==============================] - 0s 226us/step - loss: 517462.2812 - val_loss: 463952.4062\n",
            "Epoch 361/500\n",
            "25/25 [==============================] - 0s 286us/step - loss: 517461.5625 - val_loss: 463950.8125\n",
            "Epoch 362/500\n",
            "25/25 [==============================] - 0s 141us/step - loss: 517459.8750 - val_loss: 463948.9375\n",
            "Epoch 363/500\n",
            "25/25 [==============================] - 0s 192us/step - loss: 517459.0938 - val_loss: 463946.7500\n",
            "Epoch 364/500\n",
            "25/25 [==============================] - 0s 139us/step - loss: 517457.7500 - val_loss: 463945.0625\n",
            "Epoch 365/500\n",
            "25/25 [==============================] - 0s 299us/step - loss: 517456.2812 - val_loss: 463942.9375\n",
            "Epoch 366/500\n",
            "25/25 [==============================] - 0s 350us/step - loss: 517455.3750 - val_loss: 463941.5625\n",
            "Epoch 367/500\n",
            "25/25 [==============================] - 0s 244us/step - loss: 517453.8125 - val_loss: 463940.0000\n",
            "Epoch 368/500\n",
            "25/25 [==============================] - 0s 138us/step - loss: 517452.7500 - val_loss: 463938.4375\n",
            "Epoch 369/500\n",
            "25/25 [==============================] - 0s 207us/step - loss: 517451.1562 - val_loss: 463936.7812\n",
            "Epoch 370/500\n",
            "25/25 [==============================] - 0s 185us/step - loss: 517450.2812 - val_loss: 463934.5625\n",
            "Epoch 371/500\n",
            "25/25 [==============================] - 0s 163us/step - loss: 517449.0312 - val_loss: 463933.8438\n",
            "Epoch 372/500\n",
            "25/25 [==============================] - 0s 176us/step - loss: 517447.8438 - val_loss: 463932.5000\n",
            "Epoch 373/500\n",
            "25/25 [==============================] - 0s 233us/step - loss: 517446.4062 - val_loss: 463930.8438\n",
            "Epoch 374/500\n",
            "25/25 [==============================] - 0s 236us/step - loss: 517445.6250 - val_loss: 463929.8438\n",
            "Epoch 375/500\n",
            "25/25 [==============================] - 0s 150us/step - loss: 517444.0938 - val_loss: 463929.0312\n",
            "Epoch 376/500\n",
            "25/25 [==============================] - 0s 201us/step - loss: 517442.5938 - val_loss: 463927.4375\n",
            "Epoch 377/500\n",
            "25/25 [==============================] - 0s 204us/step - loss: 517441.5625 - val_loss: 463926.0625\n",
            "Epoch 378/500\n",
            "25/25 [==============================] - 0s 141us/step - loss: 517440.1562 - val_loss: 463925.2812\n",
            "Epoch 379/500\n",
            "25/25 [==============================] - 0s 148us/step - loss: 517439.3750 - val_loss: 463923.6562\n",
            "Epoch 380/500\n",
            "25/25 [==============================] - 0s 170us/step - loss: 517437.7188 - val_loss: 463922.9062\n",
            "Epoch 381/500\n",
            "25/25 [==============================] - 0s 175us/step - loss: 517436.6875 - val_loss: 463922.4375\n",
            "Epoch 382/500\n",
            "25/25 [==============================] - 0s 176us/step - loss: 517435.7188 - val_loss: 463921.2812\n",
            "Epoch 383/500\n",
            "25/25 [==============================] - 0s 176us/step - loss: 517433.6250 - val_loss: 463920.5625\n",
            "Epoch 384/500\n",
            "25/25 [==============================] - 0s 138us/step - loss: 517432.9688 - val_loss: 463919.1875\n",
            "Epoch 385/500\n",
            "25/25 [==============================] - 0s 128us/step - loss: 517431.4375 - val_loss: 463917.5312\n",
            "Epoch 386/500\n",
            "25/25 [==============================] - 0s 154us/step - loss: 517430.7188 - val_loss: 463917.0625\n",
            "Epoch 387/500\n",
            "25/25 [==============================] - 0s 124us/step - loss: 517429.2812 - val_loss: 463916.3125\n",
            "Epoch 388/500\n",
            "25/25 [==============================] - 0s 138us/step - loss: 517428.0000 - val_loss: 463914.9375\n",
            "Epoch 389/500\n",
            "25/25 [==============================] - 0s 199us/step - loss: 517426.3125 - val_loss: 463914.1562\n",
            "Epoch 390/500\n",
            "25/25 [==============================] - 0s 226us/step - loss: 517425.5625 - val_loss: 463913.0938\n",
            "Epoch 391/500\n",
            "25/25 [==============================] - 0s 250us/step - loss: 517423.9062 - val_loss: 463912.0625\n",
            "Epoch 392/500\n",
            "25/25 [==============================] - 0s 257us/step - loss: 517423.2500 - val_loss: 463911.2812\n",
            "Epoch 393/500\n",
            "25/25 [==============================] - 0s 167us/step - loss: 517421.3750 - val_loss: 463910.5000\n",
            "Epoch 394/500\n",
            "25/25 [==============================] - 0s 173us/step - loss: 517420.2812 - val_loss: 463909.7500\n",
            "Epoch 395/500\n",
            "25/25 [==============================] - 0s 262us/step - loss: 517418.5625 - val_loss: 463908.3438\n",
            "Epoch 396/500\n",
            "25/25 [==============================] - 0s 237us/step - loss: 517417.5312 - val_loss: 463907.0000\n",
            "Epoch 397/500\n",
            "25/25 [==============================] - 0s 234us/step - loss: 517416.5625 - val_loss: 463905.9688\n",
            "Epoch 398/500\n",
            "25/25 [==============================] - 0s 231us/step - loss: 517414.9688 - val_loss: 463904.0312\n",
            "Epoch 399/500\n",
            "25/25 [==============================] - 0s 182us/step - loss: 517413.9062 - val_loss: 463904.0938\n",
            "Epoch 400/500\n",
            "25/25 [==============================] - 0s 209us/step - loss: 517412.3125 - val_loss: 463903.0938\n",
            "Epoch 401/500\n",
            "25/25 [==============================] - 0s 184us/step - loss: 517411.6875 - val_loss: 463902.0000\n",
            "Epoch 402/500\n",
            "25/25 [==============================] - 0s 291us/step - loss: 517409.8750 - val_loss: 463899.7812\n",
            "Epoch 403/500\n",
            "25/25 [==============================] - 0s 233us/step - loss: 517408.8438 - val_loss: 463899.6562\n",
            "Epoch 404/500\n",
            "25/25 [==============================] - 0s 218us/step - loss: 517407.4688 - val_loss: 463898.2188\n",
            "Epoch 405/500\n",
            "25/25 [==============================] - 0s 161us/step - loss: 517405.9688 - val_loss: 463896.6562\n",
            "Epoch 406/500\n",
            "25/25 [==============================] - 0s 176us/step - loss: 517404.7188 - val_loss: 463895.8438\n",
            "Epoch 407/500\n",
            "25/25 [==============================] - 0s 179us/step - loss: 517403.4688 - val_loss: 463895.0625\n",
            "Epoch 408/500\n",
            "25/25 [==============================] - 0s 179us/step - loss: 517402.4688 - val_loss: 463892.8438\n",
            "Epoch 409/500\n",
            "25/25 [==============================] - 0s 173us/step - loss: 517400.5312 - val_loss: 463893.5000\n",
            "Epoch 410/500\n",
            "25/25 [==============================] - 0s 255us/step - loss: 517399.2500 - val_loss: 463891.8438\n",
            "Epoch 411/500\n",
            "25/25 [==============================] - 0s 171us/step - loss: 517398.0000 - val_loss: 463890.5000\n",
            "Epoch 412/500\n",
            "25/25 [==============================] - 0s 185us/step - loss: 517396.5312 - val_loss: 463890.3438\n",
            "Epoch 413/500\n",
            "25/25 [==============================] - 0s 167us/step - loss: 517395.4062 - val_loss: 463889.2500\n",
            "Epoch 414/500\n",
            "25/25 [==============================] - 0s 151us/step - loss: 517394.0312 - val_loss: 463888.2188\n",
            "Epoch 415/500\n",
            "25/25 [==============================] - 0s 248us/step - loss: 517392.8750 - val_loss: 463886.8438\n",
            "Epoch 416/500\n",
            "25/25 [==============================] - 0s 268us/step - loss: 517391.5312 - val_loss: 463886.0938\n",
            "Epoch 417/500\n",
            "25/25 [==============================] - 0s 231us/step - loss: 517390.6250 - val_loss: 463884.1875\n",
            "Epoch 418/500\n",
            "25/25 [==============================] - 0s 258us/step - loss: 517389.0000 - val_loss: 463883.4062\n",
            "Epoch 419/500\n",
            "25/25 [==============================] - 0s 211us/step - loss: 517387.8125 - val_loss: 463882.6562\n",
            "Epoch 420/500\n",
            "25/25 [==============================] - 0s 195us/step - loss: 517385.9688 - val_loss: 463881.2812\n",
            "Epoch 421/500\n",
            "25/25 [==============================] - 0s 190us/step - loss: 517384.5938 - val_loss: 463879.6562\n",
            "Epoch 422/500\n",
            "25/25 [==============================] - 0s 223us/step - loss: 517383.5312 - val_loss: 463879.4688\n",
            "Epoch 423/500\n",
            "25/25 [==============================] - 0s 205us/step - loss: 517382.6250 - val_loss: 463878.7188\n",
            "Epoch 424/500\n",
            "25/25 [==============================] - 0s 194us/step - loss: 517381.3750 - val_loss: 463877.3438\n",
            "Epoch 425/500\n",
            "25/25 [==============================] - 0s 184us/step - loss: 517380.3125 - val_loss: 463875.7188\n",
            "Epoch 426/500\n",
            "25/25 [==============================] - 0s 160us/step - loss: 517378.1562 - val_loss: 463874.3438\n",
            "Epoch 427/500\n",
            "25/25 [==============================] - 0s 214us/step - loss: 517377.0000 - val_loss: 463873.3438\n",
            "Epoch 428/500\n",
            "25/25 [==============================] - 0s 191us/step - loss: 517375.6250 - val_loss: 463872.5625\n",
            "Epoch 429/500\n",
            "25/25 [==============================] - 0s 146us/step - loss: 517374.5938 - val_loss: 463870.9062\n",
            "Epoch 430/500\n",
            "25/25 [==============================] - 0s 250us/step - loss: 517372.7500 - val_loss: 463869.9062\n",
            "Epoch 431/500\n",
            "25/25 [==============================] - 0s 216us/step - loss: 517371.5938 - val_loss: 463869.0938\n",
            "Epoch 432/500\n",
            "25/25 [==============================] - 0s 185us/step - loss: 517370.3125 - val_loss: 463867.4062\n",
            "Epoch 433/500\n",
            "25/25 [==============================] - 0s 248us/step - loss: 517368.6875 - val_loss: 463866.8438\n",
            "Epoch 434/500\n",
            "25/25 [==============================] - 0s 186us/step - loss: 517367.5938 - val_loss: 463866.2812\n",
            "Epoch 435/500\n",
            "25/25 [==============================] - 0s 153us/step - loss: 517366.6250 - val_loss: 463864.5625\n",
            "Epoch 436/500\n",
            "25/25 [==============================] - 0s 127us/step - loss: 517364.3750 - val_loss: 463863.4688\n",
            "Epoch 437/500\n",
            "25/25 [==============================] - 0s 180us/step - loss: 517363.2500 - val_loss: 463861.4688\n",
            "Epoch 438/500\n",
            "25/25 [==============================] - 0s 106us/step - loss: 517362.4688 - val_loss: 463861.5625\n",
            "Epoch 439/500\n",
            "25/25 [==============================] - 0s 161us/step - loss: 517361.0312 - val_loss: 463859.5625\n",
            "Epoch 440/500\n",
            "25/25 [==============================] - 0s 135us/step - loss: 517359.1875 - val_loss: 463858.4688\n",
            "Epoch 441/500\n",
            "25/25 [==============================] - 0s 152us/step - loss: 517358.4062 - val_loss: 463857.9375\n",
            "Epoch 442/500\n",
            "25/25 [==============================] - 0s 125us/step - loss: 517356.8125 - val_loss: 463856.7812\n",
            "Epoch 443/500\n",
            "25/25 [==============================] - 0s 206us/step - loss: 517355.7500 - val_loss: 463854.5000\n",
            "Epoch 444/500\n",
            "25/25 [==============================] - 0s 169us/step - loss: 517353.9688 - val_loss: 463854.0000\n",
            "Epoch 445/500\n",
            "25/25 [==============================] - 0s 126us/step - loss: 517352.7500 - val_loss: 463853.1562\n",
            "Epoch 446/500\n",
            "25/25 [==============================] - 0s 169us/step - loss: 517351.4375 - val_loss: 463852.0312\n",
            "Epoch 447/500\n",
            "25/25 [==============================] - 0s 121us/step - loss: 517349.9688 - val_loss: 463850.3438\n",
            "Epoch 448/500\n",
            "25/25 [==============================] - 0s 159us/step - loss: 517348.6250 - val_loss: 463849.7812\n",
            "Epoch 449/500\n",
            "25/25 [==============================] - 0s 127us/step - loss: 517347.2812 - val_loss: 463849.0000\n",
            "Epoch 450/500\n",
            "25/25 [==============================] - 0s 278us/step - loss: 517346.0312 - val_loss: 463847.8438\n",
            "Epoch 451/500\n",
            "25/25 [==============================] - 0s 331us/step - loss: 517344.4062 - val_loss: 463845.8438\n",
            "Epoch 452/500\n",
            "25/25 [==============================] - 0s 149us/step - loss: 517342.9688 - val_loss: 463845.0625\n",
            "Epoch 453/500\n",
            "25/25 [==============================] - 0s 147us/step - loss: 517341.5312 - val_loss: 463843.4375\n",
            "Epoch 454/500\n",
            "25/25 [==============================] - 0s 148us/step - loss: 517340.1875 - val_loss: 463842.8438\n",
            "Epoch 455/500\n",
            "25/25 [==============================] - 0s 118us/step - loss: 517339.2812 - val_loss: 463841.1562\n",
            "Epoch 456/500\n",
            "25/25 [==============================] - 0s 188us/step - loss: 517337.4375 - val_loss: 463839.7500\n",
            "Epoch 457/500\n",
            "25/25 [==============================] - 0s 167us/step - loss: 517336.3750 - val_loss: 463838.9375\n",
            "Epoch 458/500\n",
            "25/25 [==============================] - 0s 419us/step - loss: 517334.8750 - val_loss: 463838.0938\n",
            "Epoch 459/500\n",
            "25/25 [==============================] - 0s 210us/step - loss: 517333.0312 - val_loss: 463836.1562\n",
            "Epoch 460/500\n",
            "25/25 [==============================] - 0s 479us/step - loss: 517331.5938 - val_loss: 463835.6562\n",
            "Epoch 461/500\n",
            "25/25 [==============================] - 0s 269us/step - loss: 517330.5625 - val_loss: 463834.4375\n",
            "Epoch 462/500\n",
            "25/25 [==============================] - 0s 129us/step - loss: 517329.1875 - val_loss: 463833.5625\n",
            "Epoch 463/500\n",
            "25/25 [==============================] - 0s 156us/step - loss: 517328.2500 - val_loss: 463831.9375\n",
            "Epoch 464/500\n",
            "25/25 [==============================] - 0s 165us/step - loss: 517325.8438 - val_loss: 463829.9375\n",
            "Epoch 465/500\n",
            "25/25 [==============================] - 0s 213us/step - loss: 517324.6250 - val_loss: 463829.4062\n",
            "Epoch 466/500\n",
            "25/25 [==============================] - 0s 128us/step - loss: 517322.8125 - val_loss: 463828.5625\n",
            "Epoch 467/500\n",
            "25/25 [==============================] - 0s 163us/step - loss: 517322.0938 - val_loss: 463826.9375\n",
            "Epoch 468/500\n",
            "25/25 [==============================] - 0s 148us/step - loss: 517320.4062 - val_loss: 463825.5000\n",
            "Epoch 469/500\n",
            "25/25 [==============================] - 0s 183us/step - loss: 517319.2812 - val_loss: 463823.5000\n",
            "Epoch 470/500\n",
            "25/25 [==============================] - 0s 202us/step - loss: 517318.0000 - val_loss: 463823.0000\n",
            "Epoch 471/500\n",
            "25/25 [==============================] - 0s 171us/step - loss: 517316.7500 - val_loss: 463822.1875\n",
            "Epoch 472/500\n",
            "25/25 [==============================] - 0s 181us/step - loss: 517314.8125 - val_loss: 463819.9375\n",
            "Epoch 473/500\n",
            "25/25 [==============================] - 0s 192us/step - loss: 517313.4062 - val_loss: 463819.0938\n",
            "Epoch 474/500\n",
            "25/25 [==============================] - 0s 170us/step - loss: 517312.1250 - val_loss: 463817.7500\n",
            "Epoch 475/500\n",
            "25/25 [==============================] - 0s 181us/step - loss: 517310.4688 - val_loss: 463815.7188\n",
            "Epoch 476/500\n",
            "25/25 [==============================] - 0s 208us/step - loss: 517309.4062 - val_loss: 463814.9062\n",
            "Epoch 477/500\n",
            "25/25 [==============================] - 0s 205us/step - loss: 517307.3750 - val_loss: 463812.9375\n",
            "Epoch 478/500\n",
            "25/25 [==============================] - 0s 154us/step - loss: 517306.3125 - val_loss: 463812.7188\n",
            "Epoch 479/500\n",
            "25/25 [==============================] - 0s 149us/step - loss: 517304.9688 - val_loss: 463811.0000\n",
            "Epoch 480/500\n",
            "25/25 [==============================] - 0s 203us/step - loss: 517303.8750 - val_loss: 463809.5938\n",
            "Epoch 481/500\n",
            "25/25 [==============================] - 0s 201us/step - loss: 517302.1875 - val_loss: 463808.2188\n",
            "Epoch 482/500\n",
            "25/25 [==============================] - 0s 186us/step - loss: 517300.7188 - val_loss: 463807.0625\n",
            "Epoch 483/500\n",
            "25/25 [==============================] - 0s 171us/step - loss: 517299.3750 - val_loss: 463806.2812\n",
            "Epoch 484/500\n",
            "25/25 [==============================] - 0s 237us/step - loss: 517297.6250 - val_loss: 463804.2812\n",
            "Epoch 485/500\n",
            "25/25 [==============================] - 0s 221us/step - loss: 517296.6875 - val_loss: 463802.3438\n",
            "Epoch 486/500\n",
            "25/25 [==============================] - 0s 152us/step - loss: 517295.3125 - val_loss: 463800.9375\n",
            "Epoch 487/500\n",
            "25/25 [==============================] - 0s 255us/step - loss: 517293.4062 - val_loss: 463800.1562\n",
            "Epoch 488/500\n",
            "25/25 [==============================] - 0s 265us/step - loss: 517291.8438 - val_loss: 463799.2812\n",
            "Epoch 489/500\n",
            "25/25 [==============================] - 0s 142us/step - loss: 517290.8125 - val_loss: 463797.3438\n",
            "Epoch 490/500\n",
            "25/25 [==============================] - 0s 166us/step - loss: 517288.8750 - val_loss: 463795.9375\n",
            "Epoch 491/500\n",
            "25/25 [==============================] - 0s 217us/step - loss: 517287.4375 - val_loss: 463795.6875\n",
            "Epoch 492/500\n",
            "25/25 [==============================] - 0s 223us/step - loss: 517286.0312 - val_loss: 463794.8438\n",
            "Epoch 493/500\n",
            "25/25 [==============================] - 0s 135us/step - loss: 517284.5938 - val_loss: 463792.8438\n",
            "Epoch 494/500\n",
            "25/25 [==============================] - 0s 202us/step - loss: 517283.2812 - val_loss: 463791.4688\n",
            "Epoch 495/500\n",
            "25/25 [==============================] - 0s 155us/step - loss: 517281.6250 - val_loss: 463790.9375\n",
            "Epoch 496/500\n",
            "25/25 [==============================] - 0s 268us/step - loss: 517280.3750 - val_loss: 463788.9688\n",
            "Epoch 497/500\n",
            "25/25 [==============================] - 0s 218us/step - loss: 517278.8750 - val_loss: 463787.8125\n",
            "Epoch 498/500\n",
            "25/25 [==============================] - 0s 280us/step - loss: 517277.3750 - val_loss: 463786.7500\n",
            "Epoch 499/500\n",
            "25/25 [==============================] - 0s 214us/step - loss: 517276.1875 - val_loss: 463785.9375\n",
            "Epoch 500/500\n",
            "25/25 [==============================] - 0s 173us/step - loss: 517274.7500 - val_loss: 463784.5312\n",
            "dict_keys(['val_loss', 'loss'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5hV9X3v8fdn7gyMgMPMcAcVlQEV\nUDQYY4MQL8Frc/HS3JvGpk9ykpymPdW2J2nS9jQ9PU0aYxJDok9immoaTVKjJkbxmnoJSFC5SASD\nMggy3O8MM/M9f+wFGccBZoZZs2bv/Xk9z37Ye63fXvu7YLM/e//WWr+fIgIzMyteJVkXYGZm2XIQ\nmJkVOQeBmVmRcxCYmRU5B4GZWZFzEJiZFTkHgVk3SfqupH/oZts1kt5xrNsx6w8OAjOzIucgMDMr\ncg4CKyhJl8xfSnpe0m5Jt0pqkPRzSTslPSRpeIf2V0haJmmbpEclNXZYN0PS4uR5PwSqOr3WZZKW\nJM99UtIZvaz5Y5JWSdoi6R5Jo5PlkvQVSRsl7ZD0gqTTknXzJC1Palsn6S969RdmhoPACtO7gQuB\nU4DLgZ8Dfw3UkXvPfwpA0inAHcBnknX3Az+TVCGpAvgp8H3geOBHyXZJnjsDuA34U6AW+BZwj6TK\nnhQqaQ7wT8DVwCjgFeDOZPVFwB8k+zE0abM5WXcr8KcRUQOcBjzck9c16ygvg0DSbcm3pKXdaPuV\n5FvbEkm/lbStP2q0TH0tIl6PiHXAE8AzEfGbiNgH/ASYkbS7BrgvIh6MiAPA/wMGAW8FZgHlwL9F\nxIGIuAtY2OE1rge+FRHPRERbRHwP2J88ryfeB9wWEYsjYj9wI3CupInAAaAGmAwoIlZExPrkeQeA\nKZKOi4itEbG4h69rdkheBgHwXeCS7jSMiP8ZEdMjYjrwNeDHaRZmA8LrHe7v7eLxkOT+aHLfwAGI\niHZgLTAmWbcu3jgq4ysd7k8APpt0C21LvmCMS57XE51r2EXuW/+YiHgYuBn4OrBR0nxJxyVN3w3M\nA16R9Jikc3v4umaH5GUQRMTjwJaOyySdJOkXkp6V9ISkyV089TpyXQFmAK+R+0AHcn3y5D7M1wHr\ngTHJsoPGd7i/FvjHiBjW4VYdET19f3WuYTC5rqZ1ABFxU0ScBUwh10X0l8nyhRFxJVBPrgvrP3v4\numaH5GUQHMZ84H8k/2n+AvhGx5WSJgAn4L5U+73/BC6VNFdSOfBZct07TwJPAa3ApySVS3oXcE6H\n534b+LiktyQHdQdLulRSTQ9ruAP4iKTpyfGF/0OuK2uNpLOT7ZcDu4F9QHtyDON9koYmXVo7gPZj\n+HuwIlcQQSBpCLl+3R9JWkLuwN2oTs2uBe6KiLb+rs8GpohYCbyfXJfhJnIHli+PiJaIaAHeBXyY\n3K/Pa+jQrRgRi4CPkeu62QqsStr2tIaHgP8N3E3uV8hJ5N6rAMeRC5yt5LqPNgP/kqz7ALBG0g7g\n4+SONZj1ivJ1YprkYNq9EXFa0m+6MiI6f/h3bP8b4BMR8WQ/lWhmlhcK4hdBROwAfifpvXDo/Otp\nB9cnxwuGk/u5b2ZmHeRlEEi6g9yH+qmSmiR9lNxP449Keg5YBlzZ4SnXAndGvv78MTNLUd52DZmZ\nWd/Iy18EZmbWd8qyLqCnRowYERMnTsy6DDOzvPLss89uioi6rtblXRBMnDiRRYsWZV2GmVlekfTK\n4da5a8jMrMg5CMzMipyDwMysyOXdMYKuHDhwgKamJvbt25d1Kamrqqpi7NixlJeXZ12KmRWIggiC\npqYmampqmDhxIm8cLLKwRASbN2+mqamJE044IetyzKxAFETX0L59+6itrS3oEACQRG1tbVH88jGz\n/lMQQQAUfAgcVCz7aWb9p2CC4Gj2HWjjtW17afeQGmZmb1A0QdDS2s6mXfvZsfdAn29727ZtfOMb\n3zh6w07mzZvHtm2eQtnMslU0QVBTVUZlWSnNu/bT1wPtHS4IWltbj/i8+++/n2HDhvVpLWZmPVU0\nQSCJEUMq2NvSxp6Wvp2k7IYbbmD16tVMnz6ds88+m/PPP58rrriCKVOmAHDVVVdx1llnMXXqVObP\nn3/oeRMnTmTTpk2sWbOGxsZGPvaxjzF16lQuuugi9u7d26c1mpkdTkGcPtrRF362jOWv7Tjs+j0t\nrZSWiMqy0m5vc8ro4/j85VMPu/5LX/oSS5cuZcmSJTz66KNceumlLF269NApnrfddhvHH388e/fu\n5eyzz+bd7343tbW1b9jGSy+9xB133MG3v/1trr76au6++27e//73d7tGM7PeKppfBAeVlZbQ2hak\necz4nHPOecN5/jfddBPTpk1j1qxZrF27lpdeeulNzznhhBOYPn06AGeddRZr1qxJr0Azsw4K7hfB\nkb65A+xvbWPlhp00HFdFw3FVqdQwePDgQ/cfffRRHnroIZ566imqq6uZPXt2l9cBVFZWHrpfWlrq\nriEz6zdF94ugsqyUIZVlbN3d0mcHjWtqati5c2eX67Zv387w4cOprq7mxRdf5Omnn+6T1zQz6ysF\n94ugO44fXMGrW/awa38rNVXHPmZPbW0t5513HqeddhqDBg2ioaHh0LpLLrmEW265hcbGRk499VRm\nzZp1zK9nZtaX8m7O4pkzZ0bniWlWrFhBY2Njt7fRHsGL63cwuLKMCbWDj/6EAaan+2tmJunZiJjZ\n1bqi6xoCKJEYVl3Bjr2tHGhrz7ocM7NMFWUQQK57KAi27mnJuhQzs0ylFgSSqiT9WtJzkpZJ+kIX\nbSol/VDSKknPSJrY29fraRdXVXkpgyvK2Lr7QJ9faZymfKrVzPJDmr8I9gNzImIaMB24RFLnI6Uf\nBbZGxCTgK8A/9+aFqqqq2Lx5c48/JIcPrmB/a99faZyWg/MRVFWlc9qrmRWn1M4aityn8q7kYXly\n6/xJfSXwd8n9u4CbJSl6+Ik+duxYmpqaaG5u7lGN7RE0b9/HrtdLGV5d0aPnZuXgDGVmZn0l1dNH\nJZUCzwKTgK9HxDOdmowB1gJERKuk7UAtsKknr1NeXt7rGbtu/eESHlyxgYV/8w6qyrs/7ISZWaFI\n9WBxRLRFxHRgLHCOpNN6sx1J10taJGlRT7/1H827zhzLzn2tPLTi9T7drplZvuiXs4YiYhvwCHBJ\np1XrgHEAksqAocDmLp4/PyJmRsTMurq6Pq3t3JNqGTW0irufberT7ZqZ5Ys0zxqqkzQsuT8IuBB4\nsVOze4APJfffAzzc0+MDx6q0RFw1YwyPv7SJjTs9F7CZFZ80fxGMAh6R9DywEHgwIu6V9EVJVyRt\nbgVqJa0C/hy4IcV6DuvdZ46hrT24Z8lrWby8mVmm0jxr6HlgRhfLP9fh/j7gvWnV0F2T6muYNnYo\ndy9ex5+cf2LW5ZiZ9auivbK4s3edOZYV63cccVIbM7NC5CBIXD5tNOWl4u7FPmhsZsXFQZA4fnAF\ns0+t52fPvUZbu4dxMLPi4SDo4Ippo9m4cz/P/O5NZ7CamRUsB0EH72hsoLqilJ8957OHzKx4OAg6\nGFRRyoVTGrj/hQ20tHqeAjMrDg6CTq6YNprtew/wxEt9O5SFmdlA5SDo5PyT6xg6qJx73D1kZkXC\nQdBJRVkJ804fyYPLX2dvnsxTYGZ2LBwEXbh82mj2tLR5RFIzKwoOgi685YRa6msq3T1kZkXBQdCF\n0hJx2RmjeWxlM9v3Hsi6HDOzVDkIDuOK6aNpaWvngaUbsi7FzCxVDoLDmDZ2KBNqq909ZGYFz0Fw\nGJK4/IzRPLl6E5t27c+6HDOz1DgIjuDSM0bRHvDAMncPmVnhchAcweSRNZwwYjD3v7A+61LMzFLj\nIDgCScw7fSRPrd7MZncPmVmBchAcxbzTD3YP+eIyMytMDoKjmDLqOCbWVvPzpe4eMrPC5CA4ilz3\n0CieXL2ZLbtbsi7HzKzPOQi6Yd7po2hrD37ps4fMrAClFgSSxkl6RNJyScskfbqLNrMlbZe0JLl9\nLq16jsXU0ccx/vhq7vPZQ2ZWgMpS3HYr8NmIWCypBnhW0oMRsbxTuyci4rIU6zhmB7uHvv3Ey2zd\n3cLwwRVZl2Rm1mdS+0UQEesjYnFyfyewAhiT1uul7dKD3UPL3T1kZoWlX44RSJoIzACe6WL1uZKe\nk/RzSVP7o57eOG3McYw7fhA/9yB0ZlZgUg8CSUOAu4HPRMSOTqsXAxMiYhrwNeCnh9nG9ZIWSVrU\n3JzNXMKSuHjKSJ5ctZmd+zw0tZkVjlSDQFI5uRD4QUT8uPP6iNgREbuS+/cD5ZJGdNFufkTMjIiZ\ndXV1aZZ8RBefNpKWtnYeXemJ7c2scKR51pCAW4EVEfHlw7QZmbRD0jlJPZvTqulYnTl+OLWDKzwI\nnZkVlDTPGjoP+ADwgqQlybK/BsYDRMQtwHuAP5PUCuwFro2ISLGmY1JaIi6c0sC9z69nf2sblWWl\nWZdkZnbMUguCiPgVoKO0uRm4Oa0a0nDx1JHcuXAtT67azAWT67Mux8zsmPnK4h5666RaBleU+jRS\nMysYDoIeqiwrZfbkeh5c/jpt7QO2F8vMrNscBL1w8dSRbNrVwuJXt2ZdipnZMXMQ9MIFp9ZRUVrC\nA764zMwKgIOgF2qqynnrpFp+ufx1BvBJTmZm3eIg6KWLp47k1S17eHHDzqxLMTM7Jg6CXnpHYwMS\nvrjMzPKeg6CX6moqOWv8cM9lbGZ5z0FwDC6eOpIV63ewdsuerEsxM+s1B8ExuHjqSMDdQ2aW3xwE\nx2B8bTWnNtTw0Ap3D5lZ/nIQHKO5jfUsXLOV7Xs8R4GZ5ScHwTGa29hAW3vw6G83Zl2KmVmvOAiO\n0fRxw6gdXMGCFQ4CM8tPDoJjVFoi5kyu59GVGznQ1p51OWZmPeYg6ANzGxvYsa+VRWs8CJ2Z5R8H\nQR84/+QRVJSWsMBnD5lZHnIQ9IHBlWWce1ItD63wIHRmln8cBH3kHY31rNm8h9XNu7MuxcysRxwE\nfWROYwOAu4fMLO84CPrImGGDaBx1nE8jNbO84yDoQxc21rPolS1s3d2SdSlmZt2WWhBIGifpEUnL\nJS2T9Oku2kjSTZJWSXpe0plp1dMf5jY20B74KmMzyytp/iJoBT4bEVOAWcAnJE3p1OadwMnJ7Xrg\nmynWk7rTxwylrqaSh9w9ZGZ5JLUgiIj1EbE4ub8TWAGM6dTsSuD2yHkaGCZpVFo1pa2kRMydXM/j\nK5tpafVVxmaWH/rlGIGkicAM4JlOq8YAazs8buLNYZFX5jY2sHN/KwvXbMm6FDOzbkk9CCQNAe4G\nPhMRO3q5jeslLZK0qLm5uW8L7GNvmzSCyrISz1FgZnkj1SCQVE4uBH4QET/uosk6YFyHx2OTZW8Q\nEfMjYmZEzKyrq0un2D4yqKKU8yaN8FXGZpY30jxrSMCtwIqI+PJhmt0DfDA5e2gWsD0i1qdVU395\nR2MDa7fsZdXGXVmXYmZ2VGUpbvs84APAC5KWJMv+GhgPEBG3APcD84BVwB7gIynW02/mTK4HYMGL\nGzm5oSbjaszMjiy1IIiIXwE6SpsAPpFWDVkZObSKqaOP4+EVG/n420/KuhwzsyPylcUpmTs5d5Xx\ntj2+ytjMBjYHQUrmJFcZP/bbgX2Wk5mZgyAlZ4wZyoghvsrYzAY+B0FKSkrEnMl1POa5jM1sgHMQ\npGjO5Nxcxs++4rmMzWzgchCk6G3JXMYPv+juITMbuBwEKRpSWcZbTjzes5aZ2YDmIEjZ3Mn1rG7e\nzZpNnsvYzAYmB0HK5h6cy9jdQ2Y2QDkIUjbu+GpOaRjCwy+6e8jMBiYHQT+YM7mBZ17ews59B7Iu\nxczsTboVBJI+Lem4ZJTQWyUtlnRR2sUVirmN9bS2B0+8tCnrUszM3qS7vwj+OJlU5iJgOLlRRb+U\nWlUFZsa4YQyrLmeBrzI2swGou0FwcBTRecD3I2IZRxlZ1H6vrLSE2afU8ejKjbS1e7IaMxtYuhsE\nz0r6JbkgeEBSDeBxE3pgTmMDm3e3sGTttqxLMTN7g+4GwUeBG4CzI2IPUE6BTCLTX95+ch2lJfLZ\nQ2Y24HQ3CM4FVkbENknvB/4W2J5eWYVnaHU5Z08c7uMEZjbgdDcIvgnskTQN+CywGrg9taoK1NzJ\nDby4YSfrtu3NuhQzs0O6GwStybSSVwI3R8TXAU/G20NzGnNzGXsQOjMbSLobBDsl3UjutNH7JJWQ\nO05gPXDiiMFMrK3mYQ9CZ2YDSHeD4BpgP7nrCTYAY4F/Sa2qAiWJOZMb+O/Vm9nT0pp1OWZmQDeD\nIPnw/wEwVNJlwL6I8DGCXpjbWE9Lazv/vWpz1qWYmQHdH2LiauDXwHuBq4FnJL3nKM+5TdJGSUsP\ns362pO2SliS3z/W0+Hx09sTjqaks82mkZjZglHWz3d+Qu4ZgI4CkOuAh4K4jPOe7wM0c+eyiJyLi\nsm7WUBAqykr4g1PqWLBiIxGB5Au0zSxb3T1GUHIwBBKbj/bciHgc2NLbwgrZnMn1bNy5n2Wv7ci6\nFDOzbgfBLyQ9IOnDkj4M3Afc3wevf66k5yT9XNLUPtheXph9ah0SvrjMzAaE7h4s/ktgPnBGcpsf\nEX91jK+9GJgQEdOArwE/PVxDSddLWiRpUXNz8zG+bPZqh1QyY9wwFvg4gZkNAN2emCYi7o6IP09u\nPznWF46IHRGxK7l/P1AuacRh2s6PiJkRMbOuru5YX3pAmNvYwPNN29m4Y1/WpZhZkTtiEEjaKWlH\nF7edko6pg1vSSCVHSiWdk9RSNOdUzpmcu8r4kZXuHjKzbB3xrKGI6PUwEpLuAGYDIyQ1AZ8nuRo5\nIm4B3gP8maRWYC9wbTKMRVGYPLKGMcMGsWDFRq45e3zW5ZhZEevu6aM9FhHXHWX9zeROLy1KuauM\n67l7cRP7DrRRVV6adUlmVqQ8eX2G5jTWs6eljWd+57NszSw7DoIMnXtiLYPKS1ngQejMLEMOggxV\nlZdy3qQRh64yNjPLgoMgY3Mb61m3bS+/fX1X1qWYWZFyEGTs4GmkvrjMzLLiIMhYw3FVnD5mKA97\nuAkzy4iDYACYM7mexa9uZcvulqxLMbMi5CAYAOY21tMe8KivMjazDDgIBoDTRg+lrqaSBZ7U3swy\n4CAYAEpKxJxT63l8ZTMH2tqzLsfMioyDYICY01jPzv2tLPRVxmbWzxwEA8T5J4+gsqyEB5ZtyLoU\nMysyDoIBorqijDmT67l/6Qba2n2VsZn1HwfBAHLpGaNo3rmfhWvcPWRm/cdBMIDMmVxPVXkJ9z2/\nPutSzKyIOAgGkOqKMuZObuDnS9fT6rOHzKyfOAgGmEvPGMWmXS382mcPmVk/cRAMMBecWk91RSn3\nvuDuITPrHw6CAWZQRSlzGxv4xdIN7h4ys37hIBiALj19FFt2t/DUy5uzLsXMioCDYACafWodgytK\nffaQmfULB8EAVFVeyjumNPCLZRs89pCZpS61IJB0m6SNkpYeZr0k3SRplaTnJZ2ZVi356LIzRrNt\nzwGeXO3uITNLV5q/CL4LXHKE9e8ETk5u1wPfTLGWvHP+ySOoqSzjvudfy7oUMytwqQVBRDwOHOlk\n+CuB2yPnaWCYpFFp1ZNvqspLuXBK7uyhllZ3D5lZerI8RjAGWNvhcVOy7E0kXS9pkaRFzc3N/VLc\nQHDpGaPYsa+V/161KetSzKyA5cXB4oiYHxEzI2JmXV1d1uX0m7edPIKaqjLu9dlDZpaiLINgHTCu\nw+OxyTJLVJaVcvHUkfxy+Qb2t7ZlXY6ZFagsg+Ae4IPJ2UOzgO0R4a++nVx6xih27mvlVy+5e8jM\n0lGW1oYl3QHMBkZIagI+D5QDRMQtwP3APGAVsAf4SFq15LPzThrBsOpy/mvJa8xtbMi6HDMrQKkF\nQURcd5T1AXwirdcvFBVlJVx6+ijuXtzErv2tDKlM7Z/MzIpUXhwsLnZXzRjDvgPt/NLzGZtZChwE\neeCs8cMZO3wQP13ii8vMrO85CPJASYm4avoYfvVSMxt37su6HDMrMA6CPHHVjNG0B/zsOZ9YZWZ9\ny0GQJybV13DamOP4ryW+1MLM+paDII9cNX0MzzdtZ9XGXVmXYmYFxEGQR66YNpoS4V8FZtanHAR5\npP64Ks6bNIKfLllH7jIMM7Nj5yDIM1dNH8PaLXtZuGZr1qWYWYFwEOSZd54+ksEVpfxo0dqjNzYz\n6wYHQZ6prijj8mmjue+F9eza35p1OWZWABwEeei9M8exp6XN01iaWZ9wEOShM8cPY1L9EH640N1D\nZnbsHAR5SBJXzxzL4le3sWrjzqzLMbM85yDIU384YyxlJeJHi5qyLsXM8pyDIE/V1VQyZ3I9dy9u\n4kBbe9blmFkecxDksWvOHsemXS08tPz1rEsxszzmIMhjs0+tZ8ywQdz+1CtZl2JmecxBkMdKS8T7\nZo3nqZc389LrPmhsZr3jIMhz18wcR0VpCd9/2r8KzKx3HAR5rnZIJZdNG8Xdzzaxc9+BrMsxszzk\nICgAHzx3Irtb2vjJbzw8tZn1XKpBIOkSSSslrZJ0QxfrPyypWdKS5PYnadZTqKaPG8YZY4dy+1Ov\neHhqM+ux1IJAUinwdeCdwBTgOklTumj6w4iYnty+k1Y9he4DsyawauMunly9OetSzCzPpPmL4Bxg\nVUS8HBEtwJ3AlSm+XlG7fNpoRgyp5FuPv5x1KWaWZ9IMgjFAx1HRmpJlnb1b0vOS7pI0rqsNSbpe\n0iJJi5qbm9OoNe9VlZfykfMm8vhvm1n+2o6syzGzPJL1weKfARMj4gzgQeB7XTWKiPkRMTMiZtbV\n1fVrgfnk/W+ZQHVFKfMfX511KWaWR9IMgnVAx2/4Y5Nlh0TE5ojYnzz8DnBWivUUvKHV5Vx3znh+\n9vx6mrbuybocM8sTaQbBQuBkSSdIqgCuBe7p2EDSqA4PrwBWpFhPUfjjt52AgO888busSzGzPJFa\nEEREK/BJ4AFyH/D/GRHLJH1R0hVJs09JWibpOeBTwIfTqqdYjBk2iKtmjOGOX7/Khu37si7HzPKA\n8u2885kzZ8aiRYuyLmNAe3XzHub866Ncd854/v6q07Iux8wGAEnPRsTMrtZlfbDYUjC+tpqrzx7H\nnQtf9bECMzsqB0GB+uQFkxDiawtWZV2KmQ1wDoICNXrYIP7oLeO5a3ETq5t3ZV2OmQ1gDoIC9sk5\nk6guL+Uf7/PJWGZ2eA6CAjZiSCWfmnsyD7+4kUdWbsy6HDMboBwEBe5Db53ICSMG8w/3Lvck92bW\nJQdBgasoK+FvL21kdfNuvvfkmqzLMbMByEFQBOZMrueCU+v411/+lrVbfDqpmb2Rg6AISOIf//B0\nSkvEDT9+3pPXmNkbOAiKxOhhg7hx3mT+e9Vm/v2ZV7Mux8wGEAdBEbnu7PH8wSl1/P29y1n22vas\nyzGzAcJBUERKSsSXr57GsEHlfPI/fsPOfQeyLsnMBgAHQZEZMaSSm66bwatb9vCZO5fQ1u7jBWbF\nzkFQhGadWMvnL5/Cghc38n8feDHrcswsY2VZF2DZ+MCsCazcsJNvPfYydUMq+ZPzT8y6JDPLiIOg\nSEniC1dMZeueFv7hvhWUl5bwobdOzLosM8uAg6CIlZWW8NVrZ3CgbTGfv2cZzTv389mLTkFS1qWZ\nWT/yMYIiV15awjfedybXnj2Omx9ZxSf/4zfs8NlEZkXFQWCUl5bwT+86nRvfOZlfLNvAvK8+wVOr\nN2ddlpn1EweBAbljBn/69pP40cfPpUTium8/zSf+YzEve1Ibs4LnyevtTfa2tDH/8Zf55mOr2N/a\nzoWNDbx35jjefkodFWX+7mCWj440eb2DwA6reed+bn9qDT945lW27G5hSGUZZ00YzjknHE/jqBom\n1A5mzLBBVJWX9mi7EUFbe9DaHhxoa6e1Lffngfagta09d78tcsvb2znQ2n6obXd052D30Vp053i5\njrqV7m6nG47SqD9rOdrfb9+9TjcaHWVL/bXP3dlOX7yn6moqGTm06ugb6vL1MwoCSZcAXwVKge9E\nxJc6ra8EbgfOAjYD10TEmiNt00HQ/w60tfOrVZt4cPnrLPzdFl7a+MbuosqyEmqqyqmu+H0gBEEE\ntLYFre3ttCQf5gc/3PPs+4fZgPDxt5/EDe+c3KvnHikIUjt9VFIp8HXgQqAJWCjpnohY3qHZR4Gt\nETFJ0rXAPwPXpFWT9U55aQkXnFrPBafWA7BtTwurm3fzyubdrN++jx37DrBjbyt7WloRv//2JKCs\nVJSXllBeWkJZiSgrLaGiNPdnWakoLymhPHlcXirKSkooLyuhvOT3yzo+92jfqroXMEdu1J1tdOdl\nurWdbjQ6Wovu1ds3O9VftfTFv0Ff/N12t9HR9ql774Wjt5lQW330Rr2Q5nUE5wCrIuJlAEl3AlcC\nHYPgSuDvkvt3ATdLUuRbf1WRGVZdwVkTKjhrwvCsSzGzPpDmkb8xwNoOj5uSZV22iYhWYDtQ23lD\nkq6XtEjSoubm5pTKNTMrTnlxCkhEzI+ImRExs66uLutyzMwKSppBsA4Y1+Hx2GRZl20klQFDyR00\nNjOzfpJmECwETpZ0gqQK4Frgnk5t7gE+lNx/D/Cwjw+YmfWv1A4WR0SrpE8CD5A7ffS2iFgm6YvA\nooi4B7gV+L6kVcAWcmFhZmb9KNXRRyPifuD+Tss+1+H+PuC9adZgZmZHlhcHi83MLD0OAjOzIpd3\nYw1JagZe6eXTRwCb+rCcfOB9Lg7e5+JwLPs8ISK6PP8+74LgWEhadLixNgqV97k4eJ+LQ1r77K4h\nM7Mi5yAwMytyxRYE87MuIAPe5+LgfS4OqexzUR0jMDOzNyu2XwRmZtaJg8DMrMgVTRBIukTSSkmr\nJN2QdT19RdJtkjZKWtph2fGSHpT0UvLn8GS5JN2U/B08L+nM7CrvPUnjJD0iabmkZZI+nSwv2P2W\nVCXp15KeS/b5C8nyEyQ9k+zbD5MBHpFUmTxelayfmGX9vSWpVNJvJN2bPC7o/QWQtEbSC5KWSFqU\nLEv1vV0UQdBh2sx3AlOA6yRNybaqPvNd4JJOy24AFkTEycCC5DHk9v/k5HY98M1+qrGvtQKfjYgp\nwCzgE8m/ZyHv935gTkRMA/y8zNMAAAQ2SURBVKYDl0iaRW56169ExCRgK7npX6HDNLDAV5J2+ejT\nwIoOjwt9fw+6ICKmd7hmIN33dkQU/A04F3igw+MbgRuzrqsP928isLTD45XAqOT+KGBlcv9bwHVd\ntcvnG/Bf5ObGLor9BqqBxcBbyF1lWpYsP/Q+Jzfq77nJ/bKknbKuvYf7OTb50JsD3EtuGuyC3d8O\n+70GGNFpWarv7aL4RUD3ps0sJA0RsT65vwFoSO4X3N9D0gUwA3iGAt/vpJtkCbAReBBYDWyL3DSv\n8Mb96tY0sAPcvwH/C2hPHtdS2Pt7UAC/lPSspOuTZam+t1MdhtqyFxEhqSDPEZY0BLgb+ExE7JB0\naF0h7ndEtAHTJQ0DfgJMzrik1Ei6DNgYEc9Kmp11Pf3sbRGxTlI98KCkFzuuTOO9XSy/CLozbWYh\neV3SKIDkz43J8oL5e5BUTi4EfhARP04WF/x+A0TENuARcl0jw5JpXuGN+5Xv08CeB1whaQ1wJ7nu\noa9SuPt7SESsS/7cSC7wzyHl93axBEF3ps0sJB2nAP0QuT70g8s/mJxpMAvY3uHnZt5Q7qv/rcCK\niPhyh1UFu9+S6pJfAkgaRO6YyApygfCepFnnfc7baWAj4saIGBsRE8n9f304It5Hge7vQZIGS6o5\neB+4CFhK2u/trA+M9OMBmHnAb8n1q/5N1vX04X7dAawHDpDrH/woub7RBcBLwEPA8UlbkTt7ajXw\nAjAz6/p7uc9vI9eP+jywJLnNK+T9Bs4AfpPs81Lgc8nyE4FfA6uAHwGVyfKq5PGqZP2JWe/DMez7\nbODeYtjfZP+eS27LDn5Wpf3e9hATZmZFrli6hszM7DAcBGZmRc5BYGZW5BwEZmZFzkFgZlbkHARm\n/UjS7IMjaZoNFA4CM7Mi5yAw64Kk9yfj/y+R9K1kwLddkr6SzAewQFJd0na6pKeT8eB/0mGs+EmS\nHkrmEFgs6aRk80Mk3SXpRUk/UMdBkswy4CAw60RSI3ANcF5ETAfagPcBg4FFETEVeAz4fPKU24G/\niogzyF3deXD5D4CvR24OgbeSuwIccqOlfobc3BgnkhtXxywzHn3U7M3mAmcBC5Mv64PIDfLVDvww\nafPvwI8lDQWGRcRjyfLvAT9KxosZExE/AYiIfQDJ9n4dEU3J4yXk5pP4Vfq7ZdY1B4HZmwn4XkTc\n+IaF0v/u1K6347Ps73C/Df8/tIy5a8jszRYA70nGgz84X+wEcv9fDo58+UfAryJiO7BV0vnJ8g8A\nj0XETqBJ0lXJNiolVffrXph1k7+JmHUSEcsl/S25WaJKyI3s+glgN3BOsm4jueMIkBsW+Jbkg/5l\n4CPJ8g8A35L0xWQb7+3H3TDrNo8+atZNknZFxJCs6zDra+4aMjMrcv5FYGZW5PyLwMysyDkIzMyK\nnIPAzKzIOQjMzIqcg8DMrMj9f1GRLGTyHRB8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A4lcOIqJBOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result=model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVV4p1H2Jz3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7b9e259a-e04c-4aed-ba43-34f1c3722a4e"
      },
      "source": [
        "result"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1114.218   ],\n",
              "       [11124.296   ],\n",
              "       [ 1115.1089  ],\n",
              "       [   11.627534],\n",
              "       [11022.218   ],\n",
              "       [ 1004.7365  ],\n",
              "       [10032.3     ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RmcoC9iN7ba",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "dc123585-38e0-4023-bc16-90ee547d2c99"
      },
      "source": [
        "X_test"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   11,  1110],\n",
              "       [   22, 11101],\n",
              "       [   10,  1111],\n",
              "       [    2,    11],\n",
              "       [   16, 11000],\n",
              "       [   14,  1001],\n",
              "       [   28, 10010]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhzlD6n3JS-S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a18d2ddb-b0ef-4ce4-d556-3ecf65b2abad"
      },
      "source": [
        "plt.scatter(range(7),result,c='r')\n",
        "plt.scatter(range(7),y_test,c='g')\n",
        "plt.show()"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O80Y37NMcMWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}