{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_15MI440.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVqqHEytn4zx",
        "colab_type": "code",
        "outputId": "d97d1490-ce2e-4ba6-83af-6b8cde6ddeb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from scipy.special import binom\n",
        "#from keras import backend as K\n",
        "\n",
        "N = 4 # number of sub-carriers\n",
        "K = 3 # number of active sub-carriers\n",
        "M = 4 # M-ary modulation order\n",
        "\n",
        "SNRdb = 15 # Training SNR\n",
        "\n",
        "traing_epochs = 1001\n",
        "l_rate = 0.001 \n",
        "total_batch = 20 # number of batches per epoch\n",
        "batch_size = 1000\n",
        "\n",
        "n_hidden_1 = 64 # smaller for Tanh, larger for ReLu\n",
        "n_input = 3*N\n",
        "\n",
        "m = int(np.log2(M))\n",
        "c = int(np.log2(binom(N,K)))\n",
        "q = K*m + c # number of bits per OFDM-IM symbol\n",
        "Q = 2**q\n",
        "n_output = q \n",
        "\n",
        "display_step = 5\n",
        "SNR = 10**(SNRdb/10)\n",
        "sigma = np.sqrt(1/SNR)\n",
        "qam_factor = (2/3)*(M-1)\n",
        "\n",
        "bits = np.random.binomial(n=1, p=0.5, size = (q,))\n",
        "a = 1/np.sqrt(2)\n",
        "\n",
        "# M-ary modulations\n",
        "if M==4:\n",
        "    QAM = np.array([1+1j, 1-1j, -1+1j, -1-1j], dtype=complex) # gray mapping\n",
        "elif M==8:\n",
        "    QAM = np.array([1, a+a*1j, -a+a*1j, 1j, a-a*1j, -1j, -1, -a-a*1j], dtype=complex) # 8PSK, not 8QAM indeed\n",
        "    qam_factor = 1\n",
        "elif M==16:\n",
        "    QAM = np.array([-3+3j, -3+1j, -3-3j, -3-1j, \n",
        "                    -1+3j, -1+1j, -1-3j, -1-1j, \n",
        "                    3+3j, 3+1j, 3-3j, 3-1j, \n",
        "                    1+3j, 1+1j, 1-3j, 1-1j], dtype=complex)\n",
        "else:\n",
        "    QAM = np.array([1, -1], dtype=complex) #BPSK\n",
        "    qam_factor = 1\n",
        "\n",
        "power = np.sqrt(N/K/qam_factor) # power allocation factor\n",
        "\n",
        "# index patterns for N=4 and K=1,2,3 only\n",
        "if K==1:\n",
        "    idx = np.array([[0],[1],[2],[3]])\n",
        "elif K==2:\n",
        "    idx = np.array([[0,1],[2,3],[0,2],[1,3]]) \n",
        "else:\n",
        "    idx = np.array([[0,1,2],[1,2,3],[0,2,3],[0,1,3]]) \n",
        "    \n",
        "def OFDM_IM_received(bits, SNRdb):   \n",
        "    bit_id = bits[0:c:1]\n",
        "    id_de = bit_id.dot(2**np.arange(bit_id.size)[::-1])\n",
        "    \n",
        "    bit_sy = bits[c:q:1]   \n",
        "    bit_K = bit_sy.reshape(-1,m)\n",
        "    sy_de = np.zeros((K,), dtype=int)\n",
        "    sym = np.zeros((K,), dtype=complex)\n",
        "    for i in range(K):\n",
        "        bit_sy_i = bit_K[i,:]\n",
        "        sy_de[i] = bit_sy_i.dot(2**np.arange(bit_sy_i.size)[::-1])\n",
        "        sym[i] = QAM[sy_de[i]]\n",
        "\n",
        "    tx_sym = np.zeros((N,), dtype=complex)\n",
        "    tx_sym[idx[id_de,:]] = sym\n",
        "    tx_sym = tx_sym*power\n",
        "    \n",
        "    SNR = 10**(SNRdb/10)\n",
        "    sigma = np.sqrt(1/SNR)\n",
        "    #eps = 1./(1 + SNR) # imperfect CSI\n",
        "    eps = 0.0\n",
        "    \n",
        "    noise = sigma*np.sqrt(1/2)*(np.random.randn(*tx_sym.shape)+1j*np.random.randn(*tx_sym.shape))\n",
        "    h = np.sqrt((1-eps)/2)*(np.random.randn(*tx_sym.shape)+1j*np.random.randn(*tx_sym.shape))\n",
        "    e = np.sqrt(eps/2)*(np.random.randn(*tx_sym.shape)+1j*np.random.randn(*tx_sym.shape))\n",
        "    h1 = h + e\n",
        "    \n",
        "    y = h1*tx_sym + noise\n",
        "    y_bar = y/h\n",
        "    y_con = np.concatenate((np.real(y_bar),np.imag(y_bar)))\n",
        "    y_m = np.absolute(y)\n",
        "    Y = np.concatenate((y_con,y_m))\n",
        "\n",
        "    return Y \n",
        "\n",
        "def OFDM_IM_received_test(bits, SNRdb):\n",
        "    bit_id = bits[0:c:1]\n",
        "    id_de = bit_id.dot(2 ** np.arange(bit_id.size)[::-1])\n",
        "\n",
        "    bit_sy = bits[c:q:1]\n",
        "    bit_K = bit_sy.reshape(-1, m)\n",
        "    sy_de = np.zeros((K,), dtype=int)\n",
        "    sym = np.zeros((K,), dtype=complex)\n",
        "    for i in range(K):\n",
        "        bit_sy_i = bit_K[i, :]\n",
        "        sy_de[i] = bit_sy_i.dot(2 ** np.arange(bit_sy_i.size)[::-1])\n",
        "        sym[i] = QAM[sy_de[i]]\n",
        "\n",
        "    tx_sym = np.zeros((N,), dtype=complex)\n",
        "    tx_sym[idx[id_de, :]] = sym\n",
        "    tx_sym = tx_sym * power\n",
        "\n",
        "    SNR = 10 ** (SNRdb / 10)\n",
        "    sigma = np.sqrt(1 / SNR)\n",
        "    #eps = 1./(1 + SNR) # imperfect CSI\n",
        "    eps = 0.00\n",
        "\n",
        "    noise = sigma * np.sqrt(1 / 2) * (np.random.randn(*tx_sym.shape) + 1j * np.random.randn(*tx_sym.shape))\n",
        "    h = np.sqrt((1 - eps) / 2) * (np.random.randn(*tx_sym.shape) + 1j * np.random.randn(*tx_sym.shape))\n",
        "    e = np.sqrt(eps / 2) * (np.random.randn(*tx_sym.shape) + 1j * np.random.randn(*tx_sym.shape))\n",
        "    h1 = h + e\n",
        "\n",
        "    y = h1 * tx_sym + noise\n",
        "    y_bar = y / h\n",
        "    y_con = np.concatenate((np.real(y_bar), np.imag(y_bar)))\n",
        "    y_m = np.absolute(y)\n",
        "    Y = np.concatenate((y_con, y_m))\n",
        "\n",
        "    return Y  \n",
        "   \n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_output])\n",
        "initializer = tf.contrib.layers.xavier_initializer()\n",
        "\n",
        "def encoder(x):\n",
        "    weights = {                    \n",
        "        'encoder_h1': tf.Variable(initializer([n_input, n_hidden_1])),\n",
        "        'encoder_h2': tf.Variable(initializer([n_hidden_1, n_output])),            \n",
        "    }\n",
        "    biases = {            \n",
        "        'encoder_b1': tf.Variable(initializer([n_hidden_1])),\n",
        "        'encoder_b2': tf.Variable(initializer([n_output])),          \n",
        "    \n",
        "    }\n",
        "    layer_1 = tf.nn.tanh(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n",
        "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))\n",
        "    return layer_2\n",
        "\n",
        "y_pred = encoder(X)\n",
        "y_true = Y\n",
        "\n",
        "cost = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
        "learning_rate = tf.placeholder(tf.float32, shape=[])\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "def frange(x, y, jump):\n",
        "  while x < y:\n",
        "    yield x\n",
        "    x += jump\n",
        "\n",
        "# Training and testing phases \n",
        "with tf.Session() as sess:\n",
        "    # Training\n",
        "    sess.run(init)\n",
        "    for epoch in range(traing_epochs):\n",
        "        avg_cost = 0.\n",
        "        for index_m in range(total_batch):\n",
        "            input_samples = []\n",
        "            input_labels = []\n",
        "            for index_k in range(0, batch_size):\n",
        "                bits = np.random.binomial(n=1, p=0.5, size=(q,))\n",
        "                signal_output = OFDM_IM_received(bits, SNRdb)  \n",
        "                input_labels.append(bits)\n",
        "                input_samples.append(signal_output)\n",
        " \n",
        "            batch_x = np.asarray(input_samples)\n",
        "            batch_y = np.asarray(input_labels)\n",
        "            _,cs = sess.run([optimizer,cost], feed_dict={X:batch_x,\n",
        "                                                        Y:batch_y,\n",
        "                                                        learning_rate:l_rate})\n",
        "            avg_cost += cs / total_batch\n",
        "        if epoch % display_step == 0:\n",
        "            print(\"Epoch:\",'%04d' % (epoch+1), \"cost=\", \\\n",
        "               \"{:.9f}\".format(avg_cost))\n",
        " \n",
        "    # Testing            \n",
        "    EbNodB_range = list(frange(0,35,5))\n",
        "    ber = [None]*len(EbNodB_range)\n",
        "    for n in range(0,len(EbNodB_range)):\n",
        "        input_samples_test = []\n",
        "        input_labels_test = []\n",
        "        test_number = 100000\n",
        "        if n>10:\n",
        "            test_number = 1000000\n",
        "        for i in range(0, test_number):\n",
        "            bits = np.random.binomial(n=1, p=0.5, size=(q, )) \n",
        "            signal_output = OFDM_IM_received_test(bits, EbNodB_range[n])\n",
        "            input_labels_test.append(bits)\n",
        "            input_samples_test.append(signal_output)\n",
        "            \n",
        "        batch_x = np.asarray(input_samples_test)\n",
        "        batch_y = np.asarray(input_labels_test)\n",
        "        \n",
        "        #print('Predicted y is ', sess.run(tf.sign(y_pred-0.5), feed_dict = {X:batch_x}))\n",
        "        #print('Batch_y is \\n', sess.run(tf.cast(tf.sign(batch_y-0.5),tf.float32)))\n",
        "        mean_error = tf.reduce_mean(abs(y_pred - batch_y)) # mean_error.eval({X:batch_x}),\n",
        "        mean_error_rate = 1-tf.reduce_mean(tf.reduce_mean(tf.to_float(tf.equal(tf.sign(y_pred-0.5), tf.cast(tf.sign(batch_y-0.5),tf.float32))),1))\n",
        "        ber[n]  = mean_error_rate.eval({X:batch_x}) # eval\n",
        "        print(\"SNR=\", EbNodB_range[n], \"BER:\", ber[n])\n",
        "        \n",
        "        \n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.plot(EbNodB_range, ber, 'bo',label='DL detection')\n",
        "    #plt.plot(list(EbNodB_range), ber_theory, 'ro-',label='BPSK BER')\n",
        "    plt.yscale('log')\n",
        "    plt.xlabel('SNR Range')\n",
        "    plt.ylabel('BER')\n",
        "    plt.grid()\n",
        "    plt.legend(loc='upper right',ncol = 1)\n",
        "    #plt.savefig('DL_Detection_IM_BER_matplotlib')\n",
        "    plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 cost= 0.253437102\n",
            "Epoch: 0006 cost= 0.125442729\n",
            "Epoch: 0011 cost= 0.091587715\n",
            "Epoch: 0016 cost= 0.078893715\n",
            "Epoch: 0021 cost= 0.073983027\n",
            "Epoch: 0026 cost= 0.071164837\n",
            "Epoch: 0031 cost= 0.068112805\n",
            "Epoch: 0036 cost= 0.065743477\n",
            "Epoch: 0041 cost= 0.063543469\n",
            "Epoch: 0046 cost= 0.059660450\n",
            "Epoch: 0051 cost= 0.056229529\n",
            "Epoch: 0056 cost= 0.051601711\n",
            "Epoch: 0061 cost= 0.047798401\n",
            "Epoch: 0066 cost= 0.043569364\n",
            "Epoch: 0071 cost= 0.038903585\n",
            "Epoch: 0076 cost= 0.036434158\n",
            "Epoch: 0081 cost= 0.034417279\n",
            "Epoch: 0086 cost= 0.032654840\n",
            "Epoch: 0091 cost= 0.031149092\n",
            "Epoch: 0096 cost= 0.029465447\n",
            "Epoch: 0101 cost= 0.028302927\n",
            "Epoch: 0106 cost= 0.026982048\n",
            "Epoch: 0111 cost= 0.026038414\n",
            "Epoch: 0116 cost= 0.025332600\n",
            "Epoch: 0121 cost= 0.024873860\n",
            "Epoch: 0126 cost= 0.024229553\n",
            "Epoch: 0131 cost= 0.023829255\n",
            "Epoch: 0136 cost= 0.023729050\n",
            "Epoch: 0141 cost= 0.022701124\n",
            "Epoch: 0146 cost= 0.022604803\n",
            "Epoch: 0151 cost= 0.020945313\n",
            "Epoch: 0156 cost= 0.020545272\n",
            "Epoch: 0161 cost= 0.021038239\n",
            "Epoch: 0166 cost= 0.020084857\n",
            "Epoch: 0171 cost= 0.020566477\n",
            "Epoch: 0176 cost= 0.019821370\n",
            "Epoch: 0181 cost= 0.019857484\n",
            "Epoch: 0186 cost= 0.018795380\n",
            "Epoch: 0191 cost= 0.018140948\n",
            "Epoch: 0196 cost= 0.019061872\n",
            "Epoch: 0201 cost= 0.018289929\n",
            "Epoch: 0206 cost= 0.018365080\n",
            "Epoch: 0211 cost= 0.017598612\n",
            "Epoch: 0216 cost= 0.017300221\n",
            "Epoch: 0221 cost= 0.017551678\n",
            "Epoch: 0226 cost= 0.017820202\n",
            "Epoch: 0231 cost= 0.017655511\n",
            "Epoch: 0236 cost= 0.017842605\n",
            "Epoch: 0241 cost= 0.016592669\n",
            "Epoch: 0246 cost= 0.016240702\n",
            "Epoch: 0251 cost= 0.016867088\n",
            "Epoch: 0256 cost= 0.017139594\n",
            "Epoch: 0261 cost= 0.016760207\n",
            "Epoch: 0266 cost= 0.016899162\n",
            "Epoch: 0271 cost= 0.016522428\n",
            "Epoch: 0276 cost= 0.016257627\n",
            "Epoch: 0281 cost= 0.016238441\n",
            "Epoch: 0286 cost= 0.016661674\n",
            "Epoch: 0291 cost= 0.016154565\n",
            "Epoch: 0296 cost= 0.016493444\n",
            "Epoch: 0301 cost= 0.016304187\n",
            "Epoch: 0306 cost= 0.015690719\n",
            "Epoch: 0311 cost= 0.015681606\n",
            "Epoch: 0316 cost= 0.015580148\n",
            "Epoch: 0321 cost= 0.016000358\n",
            "Epoch: 0326 cost= 0.015651405\n",
            "Epoch: 0331 cost= 0.015794138\n",
            "Epoch: 0336 cost= 0.015202385\n",
            "Epoch: 0341 cost= 0.015903322\n",
            "Epoch: 0346 cost= 0.015784258\n",
            "Epoch: 0351 cost= 0.015274446\n",
            "Epoch: 0356 cost= 0.015550981\n",
            "Epoch: 0361 cost= 0.016165720\n",
            "Epoch: 0366 cost= 0.014860138\n",
            "Epoch: 0371 cost= 0.015097128\n",
            "Epoch: 0376 cost= 0.014255863\n",
            "Epoch: 0381 cost= 0.015424641\n",
            "Epoch: 0386 cost= 0.014930051\n",
            "Epoch: 0391 cost= 0.014340303\n",
            "Epoch: 0396 cost= 0.015012123\n",
            "Epoch: 0401 cost= 0.014799060\n",
            "Epoch: 0406 cost= 0.014421508\n",
            "Epoch: 0411 cost= 0.014777642\n",
            "Epoch: 0416 cost= 0.015021534\n",
            "Epoch: 0421 cost= 0.014764916\n",
            "Epoch: 0426 cost= 0.014362544\n",
            "Epoch: 0431 cost= 0.014070080\n",
            "Epoch: 0436 cost= 0.014361227\n",
            "Epoch: 0441 cost= 0.013959173\n",
            "Epoch: 0446 cost= 0.014605372\n",
            "Epoch: 0451 cost= 0.014465156\n",
            "Epoch: 0456 cost= 0.013663365\n",
            "Epoch: 0461 cost= 0.014615828\n",
            "Epoch: 0466 cost= 0.013749006\n",
            "Epoch: 0471 cost= 0.014156625\n",
            "Epoch: 0476 cost= 0.014346099\n",
            "Epoch: 0481 cost= 0.014463836\n",
            "Epoch: 0486 cost= 0.014175161\n",
            "Epoch: 0491 cost= 0.014363314\n",
            "Epoch: 0496 cost= 0.014105225\n",
            "Epoch: 0501 cost= 0.014356337\n",
            "Epoch: 0506 cost= 0.014099331\n",
            "Epoch: 0511 cost= 0.014166112\n",
            "Epoch: 0516 cost= 0.014236170\n",
            "Epoch: 0521 cost= 0.014000929\n",
            "Epoch: 0526 cost= 0.014069619\n",
            "Epoch: 0531 cost= 0.014072158\n",
            "Epoch: 0536 cost= 0.013804761\n",
            "Epoch: 0541 cost= 0.013514023\n",
            "Epoch: 0546 cost= 0.013660135\n",
            "Epoch: 0551 cost= 0.013997167\n",
            "Epoch: 0556 cost= 0.013542304\n",
            "Epoch: 0561 cost= 0.014004134\n",
            "Epoch: 0566 cost= 0.014321142\n",
            "Epoch: 0571 cost= 0.013821793\n",
            "Epoch: 0576 cost= 0.013774671\n",
            "Epoch: 0581 cost= 0.013371943\n",
            "Epoch: 0586 cost= 0.013543334\n",
            "Epoch: 0591 cost= 0.013952250\n",
            "Epoch: 0596 cost= 0.013485555\n",
            "Epoch: 0601 cost= 0.013729085\n",
            "Epoch: 0606 cost= 0.013594466\n",
            "Epoch: 0611 cost= 0.013486796\n",
            "Epoch: 0616 cost= 0.013944389\n",
            "Epoch: 0621 cost= 0.013839073\n",
            "Epoch: 0626 cost= 0.014119133\n",
            "Epoch: 0631 cost= 0.013390698\n",
            "Epoch: 0636 cost= 0.013634542\n",
            "Epoch: 0641 cost= 0.013512689\n",
            "Epoch: 0646 cost= 0.013737446\n",
            "Epoch: 0651 cost= 0.013068191\n",
            "Epoch: 0656 cost= 0.013539379\n",
            "Epoch: 0661 cost= 0.013261749\n",
            "Epoch: 0666 cost= 0.013379801\n",
            "Epoch: 0671 cost= 0.012940956\n",
            "Epoch: 0676 cost= 0.013776397\n",
            "Epoch: 0681 cost= 0.013306869\n",
            "Epoch: 0686 cost= 0.014168345\n",
            "Epoch: 0691 cost= 0.013702554\n",
            "Epoch: 0696 cost= 0.013212856\n",
            "Epoch: 0701 cost= 0.013148940\n",
            "Epoch: 0706 cost= 0.013109615\n",
            "Epoch: 0711 cost= 0.013277421\n",
            "Epoch: 0716 cost= 0.013202718\n",
            "Epoch: 0721 cost= 0.013543170\n",
            "Epoch: 0726 cost= 0.013633135\n",
            "Epoch: 0731 cost= 0.012820355\n",
            "Epoch: 0736 cost= 0.012925137\n",
            "Epoch: 0741 cost= 0.013447658\n",
            "Epoch: 0746 cost= 0.013700280\n",
            "Epoch: 0751 cost= 0.013025991\n",
            "Epoch: 0756 cost= 0.013681814\n",
            "Epoch: 0761 cost= 0.013335294\n",
            "Epoch: 0766 cost= 0.013194192\n",
            "Epoch: 0771 cost= 0.012460294\n",
            "Epoch: 0776 cost= 0.013350530\n",
            "Epoch: 0781 cost= 0.012832724\n",
            "Epoch: 0786 cost= 0.013273761\n",
            "Epoch: 0791 cost= 0.013420443\n",
            "Epoch: 0796 cost= 0.013425568\n",
            "Epoch: 0801 cost= 0.013915227\n",
            "Epoch: 0806 cost= 0.013125844\n",
            "Epoch: 0811 cost= 0.013263592\n",
            "Epoch: 0816 cost= 0.013349690\n",
            "Epoch: 0821 cost= 0.013326487\n",
            "Epoch: 0826 cost= 0.013017262\n",
            "Epoch: 0831 cost= 0.012594221\n",
            "Epoch: 0836 cost= 0.013100351\n",
            "Epoch: 0841 cost= 0.012870133\n",
            "Epoch: 0846 cost= 0.013486423\n",
            "Epoch: 0851 cost= 0.013370233\n",
            "Epoch: 0856 cost= 0.013991048\n",
            "Epoch: 0861 cost= 0.013365289\n",
            "Epoch: 0866 cost= 0.013546781\n",
            "Epoch: 0871 cost= 0.013043826\n",
            "Epoch: 0876 cost= 0.013324511\n",
            "Epoch: 0881 cost= 0.012995898\n",
            "Epoch: 0886 cost= 0.013276742\n",
            "Epoch: 0891 cost= 0.013502741\n",
            "Epoch: 0896 cost= 0.013675697\n",
            "Epoch: 0901 cost= 0.013569956\n",
            "Epoch: 0906 cost= 0.013949506\n",
            "Epoch: 0911 cost= 0.012767737\n",
            "Epoch: 0916 cost= 0.013708288\n",
            "Epoch: 0921 cost= 0.012360498\n",
            "Epoch: 0926 cost= 0.012842448\n",
            "Epoch: 0931 cost= 0.012694962\n",
            "Epoch: 0936 cost= 0.012888127\n",
            "Epoch: 0941 cost= 0.013750683\n",
            "Epoch: 0946 cost= 0.012816126\n",
            "Epoch: 0951 cost= 0.012919813\n",
            "Epoch: 0956 cost= 0.012309678\n",
            "Epoch: 0961 cost= 0.013321834\n",
            "Epoch: 0966 cost= 0.013330144\n",
            "Epoch: 0971 cost= 0.012842879\n",
            "Epoch: 0976 cost= 0.013131336\n",
            "Epoch: 0981 cost= 0.012689552\n",
            "Epoch: 0986 cost= 0.013637125\n",
            "Epoch: 0991 cost= 0.013102265\n",
            "Epoch: 0996 cost= 0.013375316\n",
            "Epoch: 1001 cost= 0.013179976\n",
            "SNR= 0 BER: 0.285605\n",
            "SNR= 5 BER: 0.16214377\n",
            "SNR= 10 BER: 0.059461236\n",
            "SNR= 15 BER: 0.016075015\n",
            "SNR= 20 BER: 0.0042612553\n",
            "SNR= 25 BER: 0.0012249947\n",
            "SNR= 30 BER: 0.0003812313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAYaklEQVR4nO3df5BdZZ3n8ffXBDZpwgSBQLGGdMNA\nqQgkQMuPciSdlAoqLLO7riPbww4o28vWMutqlcJMZlfcmSi647ozwKrNT9lqyQgqggMDaOyAu4wT\nookjRNHFTggoP0KRITTsQPjuH/d20mnSp3+d2/f26ferKpV7nnvOuc83J+lPznnOfU5kJpIkjeYN\nze6AJKm1GRSSpEIGhSSpkEEhSSpkUEiSCs1tdgca4dBDD82Ojo5Jbfviiy9ywAEHlNuhJqlKLVWp\nA6ylVVWllqnWsWHDhmczc9HI9koGRUdHBw899NCktu3v76erq6vcDjVJVWqpSh1gLa2qKrVMtY6I\n2LKvdi89SZIKGRSSpEIGhSSpUCXHKCS1nldeeYVt27bx8ssvN7srr7Nw4UI2b97c7G5M2XjrmDdv\nHosXL2a//fYb134NCknTYtu2bRx44IF0dHQQEc3uzl5eeOEFDjzwwGZ3Y8rGU0dmsn37drZt28ZR\nRx01rv166amurw86OmDlyuV0dNSWJZXn5Zdf5pBDDmm5kJhtIoJDDjlkQmd2nlFQC4WeHhgcBAi2\nbKktA3R3N7NnUrUYEq1hosehUmcUEXFuRPTu2LFjQtutWjUUEnsMDtbaJWm2q1RQZOadmdmzcOHC\nCW23devE2iXNTHPmzGHZsmW87W1vY+nSpXzhC1/gtddeA2pfVjvnnHPGva+BgQGOP/74Mdf52te+\nNun+3nTTTTz55JO7ly+++GIeeeSRSe9vsioVFJO1ZMnE2iU13tC44RveQGnjhvPnz2fjxo08/PDD\n3Hfffdx99918+tOfnvqOR1F2UFx33XUcd9xxZXRtQgwKYPVqaGvbu62trdYuafoNjRtu2QKZ7B43\nLPMmk8MOO4ze3l6uvvpqxvukzw0bNrB06VKWLl3KNddcs7t9165dfOITn+Dtb387J554Il/5ylcA\nuPzyy3nggQdYtmwZX/ziF0ddD+Bzn/scJ5xwAkuXLuXyyy/ntttu46GHHqK7u5tly5bx0ksv0dXV\ntXt6oltuuYUTTjiB448/nssuu2z3fhYsWMCqVatYunQpp59+Ok899dSU/6wMCmoD1r290N4OEUl7\ne23ZgWypOaZr3PDoo49m165dPPPMM+Na/6KLLuKqq65i06ZNe7Vff/31LFy4kPXr17N+/XquvfZa\nfvWrX3HllVfyzne+k40bN/Kxj31s1PXuvvtuvv3tb/PDH/6QTZs28clPfpIPfOADdHZ20tfXx8aN\nG5k/f/7uz3vyySe57LLLWLt2LRs3bmT9+vXcfvvtQG1iwNNPP51NmzZx5plncu211075z8mgqOvu\nhoEBWLt2HQMDhoTUTK04bvj888/z/PPPc+aZZwJwwQUX7H7v3nvv5eabb2bZsmWcdtppbN++nV/8\n4hev28do6333u9/loosuoq1+aePggw8u7Mv69evp6upi0aJFzJ07l+7ubu6//34A9t9//91jLaec\ncgoDAwNTrt3bYyW1nCVLapeb9tVepscee4w5c+awaNEiHn/88UnvJzO56qqrOOuss/Zq7+/vH9d6\n99xzz6Q/e6T99ttv9+2vc+bM4dVXX53yPj2jkNRypmPc8JlnnuGSSy7h0ksvHdf3Cg466CAOOugg\nfvCDHwDQN2zA5KyzzuJLX/oSr7zyCgCPPvooL774IgceeCAvvPDCmOu9+93v5sYbb2Swfr3tueee\nA3jd9kNOPfVU1q1bx7PPPsuuXbu45ZZbWL58+ST/JMbmGYWkljN06XfVqtrlpiVLaiEx1UvCL730\nEsuWLeOVV15h7ty5XHDBBXz84x/nxRdfBOB73/seixcv3r3+rbfeyhlnnLF7+cYbb+TDH/4wEcF7\n3vOe3e0XX3wxAwMDnHzyyWQmixYt4vbbb+fEE09kzpw5LF26lAsvvJCPfvSj+1zv7LPPZuPGjXR2\ndrL//vvzvve9j8985jNceOGFXHLJJcyfP58HH3xw9+cdccQRXHnllaxYsYLM5P3vfz/nnXfePkOl\nDDHe0f6ZpLOzM31wUXVqqUodMLtr2bx5M29961sb16EpmE1zPQ3Z1/GIiA2Z2TlyXS89SZIKGRSS\npEKVCorJzvUkaXpU8VL3TDTR41CpoJjsXE+SGm/evHls377dsGiyoedRzJs3b9zbeNeTpGmxePFi\ntm3bNu5vQU+nl19+eUI/OFvVeOsYesLdeBkUFdTXN3Rb4fLSbiuUpmq//fYb9xPVplt/fz8nnXRS\ns7sxZY2qw6CoGB/CJKlslRqjkA9hklQ+g6JiWnEyNUkzm0FRMT6ESVLZDIqK8SFMkspmUFSMD2GS\nVDaDooJ8CJOkMhkUkqRCBoUkqZBBIUkqZFBIkgoZFJKkQgaFJKlQywdFRBwdEddHxG3N7oskzUYN\nDYqIuCEino6In45oPzsifh4Rv4yIy4v2kZmPZeZHGtlPSdLoGj3N+E3A1cDNQw0RMQe4Bng3sA1Y\nHxF3AHOAz47Y/sOZ+XSD+yhJKtDQoMjM+yOiY0TzqcAvM/MxgIhYA5yXmZ8FzmlkfyRJExeNfn5t\nPSi+k5nH15c/AJydmRfXly8ATsvMS0fZ/hBgNbUzkOvqgbKv9XqAHoDDDz/8lDVr1kyqvzt37mTB\nggWT2rbVVKWWqtQB1tKqqlLLVOtYsWLFhszsHNne8k+4y8ztwCXjWK8X6AXo7OzMrq6uSX1ef38/\nk9221VSllqrUAdbSqqpSS6PqaMZdT08ARw5bXlxvkyS1oGYExXrg2Ig4KiL2Bz4E3FHGjiPi3Ijo\n3bFjRxm7kyTR+NtjbwEeBN4cEdsi4iOZ+SpwKXAPsBn4emY+XMbnZeadmdmzcOHCMnYnSaLxdz2d\nP0r7XcBdjfxsSVI5Wv6b2RPhpSdJKl+lgsJLT5JUvkoFhSSpfAaFJKlQpYLCMQpJKl+lgsIxCkkq\nX6WCQtXS1wcdHbBy5XI6OmrLkqZfy8/1pNmprw96emBwECDYsqW2DNDd3cyeSbOPZxRqSatWDYXE\nHoODtXZJ06tSQeFgdnVs3TqxdkmNU6mgcDC7OpYsmVi7pMapVFCoOlavhra2vdva2mrtkqaXQaGW\n1N0Nvb3Q3g4RSXt7bdmBbGn6GRRqWd3dMDAAa9euY2DAkJCapVJB4WC2JJWvUkHhYLYkla9SQSFJ\nKp9BIUkqZFBIkgoZFJKkQgaFJKlQpYLC22MlqXyVCgpvj5Wk8lUqKCRJ5TMoJEmFDApJUiGDQpJU\nyKCQJBUyKCRJhQwKSVKhSgWFX7iTpPJVKij8wp0kla9SQSFJKp9BIUkqZFBIkgoZFJKkQgaFJKmQ\nQSFJKmRQSJIKGRSSpEIGhSSpkEEhSSpUqaBwridJKl+lgsK5niSpfJUKCklS+QwKaRr09UFHB6xc\nuZyOjtqyNFPMbXYHpKrr64OeHhgcBAi2bKktA3R3N7Nn0vh4RiE12KpVQyGxx+BgrV2aCQwKqcG2\nbp1Yu9RqDAqpwZYsmVi71GoMCqnBVq+Gtra929raau3STGBQSA3W3Q29vdDeDhFJe3tt2YFszRQG\nhTQNurthYADWrl3HwIAhoZnFoJAkFZpUUETEQRHhzX2SNAsUBkVEHBkRvRHxnYi4OCIOiIgvAI8C\nh01PFyVJzTTWN7NvBtYB3wDOBh4CNgInZuZvGtw3SVILGCsoDs7MK+qv74mIfwV0Z+Zrje2WJKlV\njDnXU0S8EYj64nZgYUQEQGY+18C+SZJawFhBsRDYwJ6gAPhR/fcEjm5Ep4aLiN8F3g/8FnB9Zt7b\n6M+UJO1RGBSZ2TGVnUfEDcA5wNOZefyw9rOBvwDmANdl5pUFfbgduL1+ZvPngEEhSdNorLuefn/Y\n63eMeO/Scez/JmqD4MO3mwNcA7wXOA44PyKOi4gT6ndXDf81/M6qP6lvJ0maRpGZo78Z8aPMPHnk\n630tF+yjA/jO0BlFRJwBXJGZZ9WX/wggMz87yvYBXAncl5nfLficHqAH4PDDDz9lzZo1Y3Vtn3bu\n3MmCBQsmtW2rqUotVakDrKVVVaWWqdaxYsWKDZnZObJ9rDGKGOX1vpbH603A48OWtwGnFaz/h8C7\nqA2iH5OZX97XSpnZC/QCdHZ2ZldX16Q619/fz2S3bTVVqaUqdYC1tKqq1NKoOsYKihzl9b6WGyIz\n/xL4y+n4LEnS640VFG+JiJ9QO3v47fpr6suTvePpCeDIYcuL621TFhHnAucec8wxZexOksTYQfHW\nBnzmeuDYiDiKWkB8CPjXZew4M+8E7uzs7Py3ZexPkjT27bFbRrZFxKHA9iwaBd+z7i1AF3BoRGwD\nPpWZ19fvmLqH2u2xN2Tmw5PpvCSp8QqDIiJOp3bH0XPAnwL/CzgUeENE/JvM/Jui7TPz/FHa7wLu\nmlSPJUnTaqxLT1cDf0ztG9prgfdm5t9GxFuAW4DCoJhujlFIUvnGeh7F3My8NzNvBX6TmX8LkJk/\na3zXJi4z78zMnoULFza7K5JUGWMFxfBZYl8a8d603B4rSWqusS49LY2If6B2O+z8+mvqy/Ma2jNJ\nUksY666nOdPVkTI4RiFJ5ZvUM7NblWMUklS+SgWFJKl8BoUkqZBBIUkqVKmgiIhzI6J3x44dze6K\nJFVGpYLCwWxJKl+lgkKSVD6DQpJUyKCQJBWqVFA4mC1J5atUUDiYLUnlq1RQSGq8vj7o6ICVK5fT\n0VFbVrWNNXusJO3W1wc9PTA4CBBs2VJbBujubmbP1EieUUgat1WrhkJij8HBWruqy6CQNG5bt06s\nXdVgUEgatyVLJtauaqhUUHh7rNRYq1dDW9vebW1ttXZVV6WCwttjpcbq7obeXmhvh4ikvb227EB2\ntVUqKCQ1Xnc3DAzA2rXrGBgwJGYDg0KSVMigkCQVMigkSYUMCklSIYNCklSoUkHh9ygkqXyVCgq/\nRyFJ5atUUEiSymdQSJIKGRSSpEIGhSSpkEEhSSpkUEiSChkUkqRCBoUkqZBBIUkqZFBIkgpVKiic\n60mSylepoHCuJ0kqX6WCQpJUPoNCklTIoJAkFTIoJEmFDApJUiGDQpJUyKCQJBUyKCRJhQwKSVIh\ng0KSVMigkDRr9fVBRwesXLmcjo7asl5vbrM7IEnN0NcHPT0wOAgQbNlSWwbo7m5mz1qPZxSSZqVV\nq4ZCYo/BwVq79mZQSJqVtm6dWPtsZlBImpWWLJlY+2xmUEialVavhra2vdva2mrt2lvLB0VEvDUi\nvhwRt0XEv292fyRVQ3c39PZCeztEJO3ttWUHsl+voUERETdExNMR8dMR7WdHxM8j4pcRcXnRPjJz\nc2ZeAnwQeEcj+ytpdunuhoEBWLt2HQMDhsRoGn1GcRNw9vCGiJgDXAO8FzgOOD8ijouIEyLiOyN+\nHVbf5p8Bfw3c1eD+SpJGiMxs7AdEdADfyczj68tnAFdk5ln15T8CyMzPjmNff52Z7x/lvR6gB+Dw\nww8/Zc2aNZPq786dO1mwYMGktm01VamlKnWAtbSqqtQy1TpWrFixITM7R7Y34wt3bwIeH7a8DTht\ntJUjogv4F8A/oeCMIjN7gV6Azs7O7OrqmlTn+vv7mey2raYqtVSlDrCWVlWVWhpVR8t/Mzsz+4H+\nJndDkmatZtz19ARw5LDlxfW2KYuIcyOid8eOHWXsTpJEc4JiPXBsRBwVEfsDHwLuKGPHmXlnZvYs\nXLiwjN1Jkmj87bG3AA8Cb46IbRHxkcx8FbgUuAfYDHw9Mx9uZD8kSZPX0DGKzDx/lPa78FZXSZoR\nWv6b2RPhGIUkla9SQeEYhSSVr1JBIUkqn0EhSSpUqaBwjEKSylepoHCMQpLKV6mgkCSVz6CQJBWq\nVFA4RiFJ5atUUDhGIUnlq1RQSJLKZ1BIkgoZFJKkQgaFJKlQpYLCu54kqXyVCgrvepKk8lUqKCRJ\n5TMoJEmFDApJUiGDQpJmuL4+6OiAlSuX09FRWy7T3HJ311wRcS5w7jHHHNPsrkjStOjrg54eGBwE\nCLZsqS0DdHeX8xmVOqPwridJs82qVUMhscfgYK29LJUKCkmabbZunVj7ZBgUkjSDLVkysfbJMCgk\naQZbvRra2vZua2urtZfFoJCkGay7G3p7ob0dIpL29tpyWQPZYFBI0ozX3Q0DA7B27ToGBsoNCTAo\nJEljMCgkSYUqFRROMy5J5atUUPiFO0kqX6WCQpJUvsjMZvehdBHxDLBlkpsfCjxbYneaqSq1VKUO\nsJZWVZVaplpHe2YuGtlYyaCYioh4KDM7m92PMlSllqrUAdbSqqpSS6Pq8NKTJKmQQSFJKmRQvF5v\nsztQoqrUUpU6wFpaVVVqaUgdjlFIkgp5RiFJKmRQSJIKGRTDRMTZEfHziPhlRFze7P5MVkQMRMTf\nR8TGiHio2f2ZiIi4ISKejoifDms7OCLui4hf1H9/YzP7OF6j1HJFRDxRPzYbI+J9zezjeETEkRHx\n/Yh4JCIejoiP1ttn3HEpqGUmHpd5EfF3EbGpXsun6+1HRcQP6z/H/ioi9p/yZzlGURMRc4BHgXcD\n24D1wPmZ+UhTOzYJETEAdGbmjPsCUUScCewEbs7M4+ttnweey8wr6wH+xsy8rJn9HI9RarkC2JmZ\nf97Mvk1ERBwBHJGZP4qIA4ENwO8CFzLDjktBLR9k5h2XAA7IzJ0RsR/wA+CjwMeBb2bmmoj4MrAp\nM780lc/yjGKPU4FfZuZjmfmPwBrgvCb3adbJzPuB50Y0nwd8tf76q9T+Ybe8UWqZcTLz15n5o/rr\nF4DNwJuYgceloJYZJ2t21hf3q/9KYCVwW729lONiUOzxJuDxYcvbmKF/gaj9Zbk3IjZERE+zO1OC\nwzPz1/XXvwEOb2ZnSnBpRPykfmmq5S/XDBcRHcBJwA+Z4cdlRC0wA49LRMyJiI3A08B9wP8Fns/M\nV+urlPJzzKCopt/JzJOB9wL/oX4JpBKydq10Jl8v/RLw28Ay4NfAF5rbnfGLiAXAN4D/lJn/MPy9\nmXZc9lHLjDwumbkrM5cBi6ldFXlLIz7HoNjjCeDIYcuL620zTmY+Uf/9aeBb1P4CzWRP1a8tD11j\nfrrJ/Zm0zHyq/o/7NeBaZsixqV8D/wbQl5nfrDfPyOOyr1pm6nEZkpnPA98HzgAOioi59bdK+Tlm\nUOyxHji2fsfA/sCHgDua3KcJi4gD6oN0RMQBwHuAnxZv1fLuAP6g/voPgG83sS9TMvSDte6fMwOO\nTX3Q9Hpgc2b+92FvzbjjMlotM/S4LIqIg+qv51O7EWcztcD4QH21Uo6Ldz0NU78l7n8Ac4AbMnN1\nk7s0YRFxNLWzCIC5wNdmUh0RcQvQRW265KeATwG3A18HllCbPv6Dmdnyg8Sj1NJF7fJGAgPAvxt2\nnb8lRcTvAA8Afw+8Vm/+Y2rX9mfUcSmo5Xxm3nE5kdpg9Rxq/+n/emb+1/rPgDXAwcCPgd/PzP83\npc8yKCRJRbz0JEkqZFBIkgoZFJKkQgaFJKmQQSFJKmRQaNaLiFX12Td/Up859LR6e//w2XcjojMi\n+uuvuyJiR339n0XEPieTG+96UiszKDSrRcQZwDnAyZl5IvAu9p7z67CIeO8omz9Qnz7hJOCciHjH\nFNeTWpJBodnuCODZoS8kZeazmfnksPf/G7CqaAeZ+RKwkTEmXxu5XkScGhEPRsSPI+L/RMSb6+0X\nRsQ3I+Jv6s96+PzQPiLiIxHxaP05BNdGxNX19kUR8Y2IWF//ZRipNAaFZrt7gSPrP3z/Z0QsH/H+\ng8A/RsSK0XZQn2n0WOD+og/ax3o/A96ZmScB/wX4zLDVlwG/B5wA/F7UHrjzT4H/DJwOvIO9J4D7\nC+CLmfl24F8C1xX1RZoIg0KzWn0+/1OAHuAZ4K8i4sIRq/0Z8Cf72PydEbGJ2qRr92Tmb0b5mNHW\nWwjcGrUn4H0ReNuwbb6XmTsy82XgEaCd2kR16zLzucx8Bbh12PrvAq6uTzl9B/Bb9RlSpSkzKDTr\n1WcN7c/MTwGXUvsf+fD31wLzqf1PfrgHMnMptR/wH4mIZaN8xGjr/Snw/frT784F5g3bZvjcPLuo\nzdtV5A3A6Zm5rP7rTcMeaiNNiUGhWS0i3hwRxw5rWkZtgruR/gz45L72kZm/Aq4ECh8Duo/1FrJn\nCugLx9Hd9cDyiHhjfRrp4YF2L/CHQwsFoSVNmEGh2W4B8NWIeCQifgIcB1wxcqXMvIvapanRfBk4\ns/7UtCLD1/s88NmI+DFjnzEMPWfkM8DfAf+b2iynO+pv/0egs36L7yPAJWPtTxovZ4+VZpCIWJCZ\nO+tnFN+iNh3+t8baTpoKzyikmeWK+oD1T4FfUXtWh9RQnlFIkgp5RiFJKmRQSJIKGRSSpEIGhSSp\nkEEhSSr0/wHn3tq8fppHbgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}