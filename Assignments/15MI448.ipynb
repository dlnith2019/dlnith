{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gSTv-pHAnVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voay5z4kBEj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9f305636-b8b4-43ab-ea19-f98652ae2eb2"
      },
      "source": [
        "X = []\n",
        "Y = []\n",
        "X = [((x*10)/100) for x in range(100)]\n",
        "Y = [(y * 5) for y in X]\n",
        "\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3.0, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5.0, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6.0, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 6.9, 7.0, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9, 8.0, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 9.0, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9]\n",
            "[0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0, 10.5, 11.0, 11.5, 12.0, 12.5, 13.0, 13.5, 14.0, 14.5, 15.0, 15.5, 16.0, 16.5, 17.0, 17.5, 18.0, 18.5, 19.0, 19.5, 20.0, 20.5, 21.0, 21.5, 22.0, 22.5, 23.0, 23.5, 24.0, 24.5, 25.0, 25.5, 26.0, 26.5, 27.0, 27.5, 28.0, 28.5, 29.0, 29.5, 30.0, 30.5, 31.0, 31.5, 32.0, 32.5, 33.0, 33.5, 34.0, 34.5, 35.0, 35.5, 36.0, 36.5, 37.0, 37.5, 38.0, 38.5, 39.0, 39.5, 40.0, 40.5, 41.0, 41.5, 42.0, 42.5, 43.0, 43.5, 44.0, 44.5, 45.0, 45.5, 46.0, 46.5, 47.0, 47.5, 48.0, 48.5, 49.0, 49.5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5E0zkCQBrtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.array(X,dtype=float)\n",
        "y = np.array(Y,dtype=float)\n",
        "\n",
        "x = np.array(x).reshape(100, 1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft3RJf5NB5i2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD_wpUX5B-Lh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "45d80835-00ec-4d2f-e5e0-78419c529ca1"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "print(model.summary())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 1, 50)             10400     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 30,651\n",
            "Trainable params: 30,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTtz1rwBCByn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f070e0ae-4a78-42bd-f2e9-8a477a1d621e"
      },
      "source": [
        "history = model.fit(x_train,y_train,epochs=2000,validation_data=(x_test,y_test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/2000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "80/80 [==============================] - 2s 22ms/step - loss: 874.2234 - val_loss: 610.9879\n",
            "Epoch 2/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 872.6268 - val_loss: 609.9562\n",
            "Epoch 3/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 871.2326 - val_loss: 608.9764\n",
            "Epoch 4/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 869.8892 - val_loss: 607.9666\n",
            "Epoch 5/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 868.4423 - val_loss: 606.9171\n",
            "Epoch 6/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 866.9388 - val_loss: 605.8525\n",
            "Epoch 7/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 865.4244 - val_loss: 604.6712\n",
            "Epoch 8/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 863.6723 - val_loss: 603.3163\n",
            "Epoch 9/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 861.7856 - val_loss: 601.7250\n",
            "Epoch 10/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 859.3725 - val_loss: 599.8211\n",
            "Epoch 11/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 856.6130 - val_loss: 597.5029\n",
            "Epoch 12/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 853.1782 - val_loss: 594.7115\n",
            "Epoch 13/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 849.1451 - val_loss: 591.3279\n",
            "Epoch 14/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 844.2957 - val_loss: 587.2174\n",
            "Epoch 15/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 838.1112 - val_loss: 582.1923\n",
            "Epoch 16/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 830.5311 - val_loss: 575.9573\n",
            "Epoch 17/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 820.8458 - val_loss: 568.2151\n",
            "Epoch 18/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 810.3290 - val_loss: 558.5008\n",
            "Epoch 19/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 795.4803 - val_loss: 546.4400\n",
            "Epoch 20/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 778.5135 - val_loss: 531.2435\n",
            "Epoch 21/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 755.7490 - val_loss: 512.3284\n",
            "Epoch 22/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 728.6304 - val_loss: 489.5118\n",
            "Epoch 23/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 694.5978 - val_loss: 462.9376\n",
            "Epoch 24/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 653.8109 - val_loss: 434.2670\n",
            "Epoch 25/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 608.4365 - val_loss: 403.5668\n",
            "Epoch 26/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 555.8413 - val_loss: 370.7339\n",
            "Epoch 27/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 503.3829 - val_loss: 337.0891\n",
            "Epoch 28/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 450.8399 - val_loss: 303.1167\n",
            "Epoch 29/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 398.4701 - val_loss: 268.2570\n",
            "Epoch 30/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 345.2940 - val_loss: 233.4124\n",
            "Epoch 31/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 294.7231 - val_loss: 198.9798\n",
            "Epoch 32/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 248.2318 - val_loss: 165.7831\n",
            "Epoch 33/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 202.1958 - val_loss: 134.9919\n",
            "Epoch 34/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 161.2070 - val_loss: 107.0594\n",
            "Epoch 35/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 124.2332 - val_loss: 82.5821\n",
            "Epoch 36/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 91.4875 - val_loss: 62.2814\n",
            "Epoch 37/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 64.0977 - val_loss: 46.2490\n",
            "Epoch 38/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 44.0155 - val_loss: 34.3063\n",
            "Epoch 39/2000\n",
            "80/80 [==============================] - 0s 249us/step - loss: 28.5022 - val_loss: 26.3744\n",
            "Epoch 40/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 19.4940 - val_loss: 21.7414\n",
            "Epoch 41/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 14.1012 - val_loss: 19.6772\n",
            "Epoch 42/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 12.5238 - val_loss: 19.1812\n",
            "Epoch 43/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 12.2551 - val_loss: 19.3341\n",
            "Epoch 44/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 13.1130 - val_loss: 19.5365\n",
            "Epoch 45/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 13.5476 - val_loss: 19.4694\n",
            "Epoch 46/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 13.6785 - val_loss: 19.1651\n",
            "Epoch 47/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 13.3804 - val_loss: 18.6682\n",
            "Epoch 48/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 12.8007 - val_loss: 18.0914\n",
            "Epoch 49/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 12.1912 - val_loss: 17.5300\n",
            "Epoch 50/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 11.4036 - val_loss: 17.0835\n",
            "Epoch 51/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 10.9465 - val_loss: 16.7236\n",
            "Epoch 52/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 10.6100 - val_loss: 16.4478\n",
            "Epoch 53/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 10.3503 - val_loss: 16.2277\n",
            "Epoch 54/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 10.1944 - val_loss: 16.0422\n",
            "Epoch 55/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 10.1066 - val_loss: 15.8671\n",
            "Epoch 56/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 9.9567 - val_loss: 15.6716\n",
            "Epoch 57/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 9.8261 - val_loss: 15.4663\n",
            "Epoch 58/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 9.6953 - val_loss: 15.2452\n",
            "Epoch 59/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 9.5455 - val_loss: 15.0225\n",
            "Epoch 60/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 9.3902 - val_loss: 14.7904\n",
            "Epoch 61/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 9.2438 - val_loss: 14.5631\n",
            "Epoch 62/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 9.0799 - val_loss: 14.3511\n",
            "Epoch 63/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 8.9417 - val_loss: 14.1431\n",
            "Epoch 64/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 8.8213 - val_loss: 13.9365\n",
            "Epoch 65/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 8.6955 - val_loss: 13.7358\n",
            "Epoch 66/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 8.5842 - val_loss: 13.5404\n",
            "Epoch 67/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 8.4395 - val_loss: 13.3547\n",
            "Epoch 68/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 8.3241 - val_loss: 13.1682\n",
            "Epoch 69/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 8.1963 - val_loss: 12.9875\n",
            "Epoch 70/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 8.0809 - val_loss: 12.8097\n",
            "Epoch 71/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 7.9554 - val_loss: 12.6360\n",
            "Epoch 72/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 7.8360 - val_loss: 12.4589\n",
            "Epoch 73/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 7.7182 - val_loss: 12.2850\n",
            "Epoch 74/2000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 7.6032 - val_loss: 12.1122\n",
            "Epoch 75/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 7.4929 - val_loss: 11.9406\n",
            "Epoch 76/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 7.3820 - val_loss: 11.7751\n",
            "Epoch 77/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 7.2680 - val_loss: 11.6129\n",
            "Epoch 78/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 7.1580 - val_loss: 11.4464\n",
            "Epoch 79/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 7.0396 - val_loss: 11.2835\n",
            "Epoch 80/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 6.9322 - val_loss: 11.1181\n",
            "Epoch 81/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 6.8278 - val_loss: 10.9508\n",
            "Epoch 82/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 6.7186 - val_loss: 10.7880\n",
            "Epoch 83/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 6.6071 - val_loss: 10.6263\n",
            "Epoch 84/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 6.5143 - val_loss: 10.4589\n",
            "Epoch 85/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 6.4010 - val_loss: 10.2986\n",
            "Epoch 86/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 6.2979 - val_loss: 10.1432\n",
            "Epoch 87/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 6.1936 - val_loss: 9.9904\n",
            "Epoch 88/2000\n",
            "80/80 [==============================] - 0s 253us/step - loss: 6.0926 - val_loss: 9.8370\n",
            "Epoch 89/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 5.9996 - val_loss: 9.6882\n",
            "Epoch 90/2000\n",
            "80/80 [==============================] - 0s 249us/step - loss: 5.8929 - val_loss: 9.5396\n",
            "Epoch 91/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 5.8016 - val_loss: 9.3918\n",
            "Epoch 92/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 5.7093 - val_loss: 9.2440\n",
            "Epoch 93/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 5.6157 - val_loss: 9.1014\n",
            "Epoch 94/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 5.5203 - val_loss: 8.9566\n",
            "Epoch 95/2000\n",
            "80/80 [==============================] - 0s 397us/step - loss: 5.4246 - val_loss: 8.8062\n",
            "Epoch 96/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 5.3340 - val_loss: 8.6544\n",
            "Epoch 97/2000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 5.2411 - val_loss: 8.5070\n",
            "Epoch 98/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 5.1470 - val_loss: 8.3651\n",
            "Epoch 99/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 5.0622 - val_loss: 8.2239\n",
            "Epoch 100/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 4.9678 - val_loss: 8.0891\n",
            "Epoch 101/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 4.8793 - val_loss: 7.9558\n",
            "Epoch 102/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 4.7970 - val_loss: 7.8204\n",
            "Epoch 103/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 4.7197 - val_loss: 7.6817\n",
            "Epoch 104/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 4.6224 - val_loss: 7.5541\n",
            "Epoch 105/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 4.5436 - val_loss: 7.4278\n",
            "Epoch 106/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 4.4593 - val_loss: 7.3039\n",
            "Epoch 107/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 4.3821 - val_loss: 7.1735\n",
            "Epoch 108/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 4.2997 - val_loss: 7.0479\n",
            "Epoch 109/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 4.2208 - val_loss: 6.9152\n",
            "Epoch 110/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 4.1370 - val_loss: 6.7899\n",
            "Epoch 111/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 4.0587 - val_loss: 6.6634\n",
            "Epoch 112/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 3.9784 - val_loss: 6.5431\n",
            "Epoch 113/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 3.9050 - val_loss: 6.4178\n",
            "Epoch 114/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 3.8256 - val_loss: 6.2988\n",
            "Epoch 115/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 3.7503 - val_loss: 6.1760\n",
            "Epoch 116/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 3.6780 - val_loss: 6.0508\n",
            "Epoch 117/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 3.6011 - val_loss: 5.9302\n",
            "Epoch 118/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 3.5338 - val_loss: 5.8113\n",
            "Epoch 119/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 3.4563 - val_loss: 5.6993\n",
            "Epoch 120/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 3.3848 - val_loss: 5.5880\n",
            "Epoch 121/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 3.3162 - val_loss: 5.4760\n",
            "Epoch 122/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 3.2399 - val_loss: 5.3649\n",
            "Epoch 123/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 3.1688 - val_loss: 5.2538\n",
            "Epoch 124/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 3.1036 - val_loss: 5.1424\n",
            "Epoch 125/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 3.0318 - val_loss: 5.0199\n",
            "Epoch 126/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 2.9575 - val_loss: 4.9038\n",
            "Epoch 127/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 2.8974 - val_loss: 4.7868\n",
            "Epoch 128/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 2.8235 - val_loss: 4.6823\n",
            "Epoch 129/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 2.7562 - val_loss: 4.5846\n",
            "Epoch 130/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 2.6923 - val_loss: 4.4856\n",
            "Epoch 131/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 2.6265 - val_loss: 4.3859\n",
            "Epoch 132/2000\n",
            "80/80 [==============================] - 0s 194us/step - loss: 2.5593 - val_loss: 4.2811\n",
            "Epoch 133/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 2.4962 - val_loss: 4.1691\n",
            "Epoch 134/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 2.4330 - val_loss: 4.0603\n",
            "Epoch 135/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 2.3700 - val_loss: 3.9508\n",
            "Epoch 136/2000\n",
            "80/80 [==============================] - 0s 249us/step - loss: 2.3126 - val_loss: 3.8503\n",
            "Epoch 137/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 2.2473 - val_loss: 3.7610\n",
            "Epoch 138/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 2.1859 - val_loss: 3.6722\n",
            "Epoch 139/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 2.1272 - val_loss: 3.5758\n",
            "Epoch 140/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 2.0705 - val_loss: 3.4747\n",
            "Epoch 141/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 2.0113 - val_loss: 3.3766\n",
            "Epoch 142/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 1.9517 - val_loss: 3.2832\n",
            "Epoch 143/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 1.8977 - val_loss: 3.1884\n",
            "Epoch 144/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 1.8406 - val_loss: 3.1027\n",
            "Epoch 145/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 1.7866 - val_loss: 3.0152\n",
            "Epoch 146/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 1.7347 - val_loss: 2.9374\n",
            "Epoch 147/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 1.6826 - val_loss: 2.8496\n",
            "Epoch 148/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 1.6335 - val_loss: 2.7657\n",
            "Epoch 149/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 1.5795 - val_loss: 2.6878\n",
            "Epoch 150/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 1.5316 - val_loss: 2.6088\n",
            "Epoch 151/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 1.4806 - val_loss: 2.5295\n",
            "Epoch 152/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 1.4352 - val_loss: 2.4471\n",
            "Epoch 153/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 1.3892 - val_loss: 2.3627\n",
            "Epoch 154/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 1.3410 - val_loss: 2.2932\n",
            "Epoch 155/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 1.2957 - val_loss: 2.2285\n",
            "Epoch 156/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 1.2540 - val_loss: 2.1615\n",
            "Epoch 157/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 1.2131 - val_loss: 2.0856\n",
            "Epoch 158/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 1.1705 - val_loss: 2.0164\n",
            "Epoch 159/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 1.1307 - val_loss: 1.9523\n",
            "Epoch 160/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 1.0905 - val_loss: 1.8854\n",
            "Epoch 161/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 1.0516 - val_loss: 1.8228\n",
            "Epoch 162/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 1.0143 - val_loss: 1.7565\n",
            "Epoch 163/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.9765 - val_loss: 1.6905\n",
            "Epoch 164/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.9444 - val_loss: 1.6223\n",
            "Epoch 165/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.9071 - val_loss: 1.5702\n",
            "Epoch 166/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.8718 - val_loss: 1.5244\n",
            "Epoch 167/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.8410 - val_loss: 1.4720\n",
            "Epoch 168/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.8105 - val_loss: 1.4183\n",
            "Epoch 169/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.7810 - val_loss: 1.3584\n",
            "Epoch 170/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.7505 - val_loss: 1.3052\n",
            "Epoch 171/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.7209 - val_loss: 1.2584\n",
            "Epoch 172/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.6947 - val_loss: 1.2119\n",
            "Epoch 173/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.6716 - val_loss: 1.1666\n",
            "Epoch 174/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.6457 - val_loss: 1.1312\n",
            "Epoch 175/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.6205 - val_loss: 1.0928\n",
            "Epoch 176/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.5988 - val_loss: 1.0530\n",
            "Epoch 177/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.5756 - val_loss: 1.0102\n",
            "Epoch 178/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.5555 - val_loss: 0.9662\n",
            "Epoch 179/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.5344 - val_loss: 0.9328\n",
            "Epoch 180/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.5131 - val_loss: 0.8984\n",
            "Epoch 181/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.4962 - val_loss: 0.8651\n",
            "Epoch 182/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.4779 - val_loss: 0.8362\n",
            "Epoch 183/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.4603 - val_loss: 0.8088\n",
            "Epoch 184/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.4451 - val_loss: 0.7787\n",
            "Epoch 185/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.4289 - val_loss: 0.7489\n",
            "Epoch 186/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.4143 - val_loss: 0.7205\n",
            "Epoch 187/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 0.4010 - val_loss: 0.6943\n",
            "Epoch 188/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.3872 - val_loss: 0.6738\n",
            "Epoch 189/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 0.3750 - val_loss: 0.6540\n",
            "Epoch 190/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.3625 - val_loss: 0.6295\n",
            "Epoch 191/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 0.3508 - val_loss: 0.6056\n",
            "Epoch 192/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.3402 - val_loss: 0.5816\n",
            "Epoch 193/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.3308 - val_loss: 0.5609\n",
            "Epoch 194/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.3202 - val_loss: 0.5451\n",
            "Epoch 195/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.3113 - val_loss: 0.5293\n",
            "Epoch 196/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.3031 - val_loss: 0.5134\n",
            "Epoch 197/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.2955 - val_loss: 0.4959\n",
            "Epoch 198/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.2879 - val_loss: 0.4806\n",
            "Epoch 199/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.2805 - val_loss: 0.4663\n",
            "Epoch 200/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.2745 - val_loss: 0.4528\n",
            "Epoch 201/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.2685 - val_loss: 0.4393\n",
            "Epoch 202/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.2632 - val_loss: 0.4270\n",
            "Epoch 203/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 0.2586 - val_loss: 0.4157\n",
            "Epoch 204/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.2529 - val_loss: 0.4075\n",
            "Epoch 205/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.2489 - val_loss: 0.3997\n",
            "Epoch 206/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.2454 - val_loss: 0.3907\n",
            "Epoch 207/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.2417 - val_loss: 0.3800\n",
            "Epoch 208/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.2380 - val_loss: 0.3713\n",
            "Epoch 209/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.2345 - val_loss: 0.3642\n",
            "Epoch 210/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.2316 - val_loss: 0.3576\n",
            "Epoch 211/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.2294 - val_loss: 0.3516\n",
            "Epoch 212/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.2263 - val_loss: 0.3437\n",
            "Epoch 213/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 0.2236 - val_loss: 0.3377\n",
            "Epoch 214/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.2213 - val_loss: 0.3327\n",
            "Epoch 215/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.2192 - val_loss: 0.3277\n",
            "Epoch 216/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.2172 - val_loss: 0.3224\n",
            "Epoch 217/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.2155 - val_loss: 0.3172\n",
            "Epoch 218/2000\n",
            "80/80 [==============================] - 0s 253us/step - loss: 0.2136 - val_loss: 0.3127\n",
            "Epoch 219/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.2119 - val_loss: 0.3086\n",
            "Epoch 220/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.2108 - val_loss: 0.3041\n",
            "Epoch 221/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.2093 - val_loss: 0.3001\n",
            "Epoch 222/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.2083 - val_loss: 0.2969\n",
            "Epoch 223/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.2071 - val_loss: 0.2942\n",
            "Epoch 224/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.2058 - val_loss: 0.2904\n",
            "Epoch 225/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.2049 - val_loss: 0.2871\n",
            "Epoch 226/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.2037 - val_loss: 0.2844\n",
            "Epoch 227/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.2027 - val_loss: 0.2821\n",
            "Epoch 228/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.2023 - val_loss: 0.2798\n",
            "Epoch 229/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.2011 - val_loss: 0.2775\n",
            "Epoch 230/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.2005 - val_loss: 0.2750\n",
            "Epoch 231/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.1997 - val_loss: 0.2725\n",
            "Epoch 232/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.1994 - val_loss: 0.2700\n",
            "Epoch 233/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.1987 - val_loss: 0.2684\n",
            "Epoch 234/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.1981 - val_loss: 0.2664\n",
            "Epoch 235/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.1975 - val_loss: 0.2642\n",
            "Epoch 236/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.1969 - val_loss: 0.2625\n",
            "Epoch 237/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.1961 - val_loss: 0.2610\n",
            "Epoch 238/2000\n",
            "80/80 [==============================] - 0s 249us/step - loss: 0.1958 - val_loss: 0.2598\n",
            "Epoch 239/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.1957 - val_loss: 0.2579\n",
            "Epoch 240/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.1948 - val_loss: 0.2563\n",
            "Epoch 241/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.1949 - val_loss: 0.2549\n",
            "Epoch 242/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.1942 - val_loss: 0.2537\n",
            "Epoch 243/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.1937 - val_loss: 0.2530\n",
            "Epoch 244/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.1936 - val_loss: 0.2520\n",
            "Epoch 245/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.1937 - val_loss: 0.2503\n",
            "Epoch 246/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.1931 - val_loss: 0.2490\n",
            "Epoch 247/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.1923 - val_loss: 0.2479\n",
            "Epoch 248/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.1919 - val_loss: 0.2469\n",
            "Epoch 249/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.1916 - val_loss: 0.2461\n",
            "Epoch 250/2000\n",
            "80/80 [==============================] - 0s 249us/step - loss: 0.1913 - val_loss: 0.2456\n",
            "Epoch 251/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.1914 - val_loss: 0.2449\n",
            "Epoch 252/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.1910 - val_loss: 0.2441\n",
            "Epoch 253/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.1908 - val_loss: 0.2434\n",
            "Epoch 254/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.1905 - val_loss: 0.2427\n",
            "Epoch 255/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.1899 - val_loss: 0.2420\n",
            "Epoch 256/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.1896 - val_loss: 0.2415\n",
            "Epoch 257/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.1905 - val_loss: 0.2409\n",
            "Epoch 258/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.1893 - val_loss: 0.2397\n",
            "Epoch 259/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.1887 - val_loss: 0.2389\n",
            "Epoch 260/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.1893 - val_loss: 0.2380\n",
            "Epoch 261/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.1890 - val_loss: 0.2369\n",
            "Epoch 262/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.1879 - val_loss: 0.2360\n",
            "Epoch 263/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.1876 - val_loss: 0.2352\n",
            "Epoch 264/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.1883 - val_loss: 0.2346\n",
            "Epoch 265/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.1877 - val_loss: 0.2337\n",
            "Epoch 266/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.1871 - val_loss: 0.2334\n",
            "Epoch 267/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.1871 - val_loss: 0.2330\n",
            "Epoch 268/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.1866 - val_loss: 0.2324\n",
            "Epoch 269/2000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 0.1863 - val_loss: 0.2321\n",
            "Epoch 270/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.1862 - val_loss: 0.2319\n",
            "Epoch 271/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.1863 - val_loss: 0.2314\n",
            "Epoch 272/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.1857 - val_loss: 0.2309\n",
            "Epoch 273/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.1856 - val_loss: 0.2304\n",
            "Epoch 274/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.1858 - val_loss: 0.2295\n",
            "Epoch 275/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 0.1850 - val_loss: 0.2288\n",
            "Epoch 276/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.1851 - val_loss: 0.2283\n",
            "Epoch 277/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.1848 - val_loss: 0.2279\n",
            "Epoch 278/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.1842 - val_loss: 0.2278\n",
            "Epoch 279/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.1843 - val_loss: 0.2275\n",
            "Epoch 280/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.1840 - val_loss: 0.2272\n",
            "Epoch 281/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.1837 - val_loss: 0.2268\n",
            "Epoch 282/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.1834 - val_loss: 0.2262\n",
            "Epoch 283/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.1833 - val_loss: 0.2257\n",
            "Epoch 284/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.1829 - val_loss: 0.2252\n",
            "Epoch 285/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.1829 - val_loss: 0.2249\n",
            "Epoch 286/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 0.1826 - val_loss: 0.2242\n",
            "Epoch 287/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 0.1824 - val_loss: 0.2238\n",
            "Epoch 288/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.1822 - val_loss: 0.2234\n",
            "Epoch 289/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.1820 - val_loss: 0.2230\n",
            "Epoch 290/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.1817 - val_loss: 0.2228\n",
            "Epoch 291/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.1817 - val_loss: 0.2225\n",
            "Epoch 292/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.1814 - val_loss: 0.2221\n",
            "Epoch 293/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.1811 - val_loss: 0.2218\n",
            "Epoch 294/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.1809 - val_loss: 0.2215\n",
            "Epoch 295/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 0.1808 - val_loss: 0.2209\n",
            "Epoch 296/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.1805 - val_loss: 0.2205\n",
            "Epoch 297/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.1804 - val_loss: 0.2200\n",
            "Epoch 298/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.1801 - val_loss: 0.2195\n",
            "Epoch 299/2000\n",
            "80/80 [==============================] - 0s 359us/step - loss: 0.1803 - val_loss: 0.2191\n",
            "Epoch 300/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.1797 - val_loss: 0.2187\n",
            "Epoch 301/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.1795 - val_loss: 0.2186\n",
            "Epoch 302/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.1793 - val_loss: 0.2182\n",
            "Epoch 303/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.1791 - val_loss: 0.2177\n",
            "Epoch 304/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.1786 - val_loss: 0.2171\n",
            "Epoch 305/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.1785 - val_loss: 0.2165\n",
            "Epoch 306/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.1783 - val_loss: 0.2162\n",
            "Epoch 307/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.1782 - val_loss: 0.2160\n",
            "Epoch 308/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.1779 - val_loss: 0.2157\n",
            "Epoch 309/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.1780 - val_loss: 0.2156\n",
            "Epoch 310/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.1780 - val_loss: 0.2153\n",
            "Epoch 311/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.1774 - val_loss: 0.2148\n",
            "Epoch 312/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.1773 - val_loss: 0.2146\n",
            "Epoch 313/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.1769 - val_loss: 0.2145\n",
            "Epoch 314/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.1765 - val_loss: 0.2144\n",
            "Epoch 315/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.1768 - val_loss: 0.2144\n",
            "Epoch 316/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.1769 - val_loss: 0.2143\n",
            "Epoch 317/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.1765 - val_loss: 0.2140\n",
            "Epoch 318/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 0.1762 - val_loss: 0.2138\n",
            "Epoch 319/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.1758 - val_loss: 0.2134\n",
            "Epoch 320/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.1755 - val_loss: 0.2130\n",
            "Epoch 321/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 0.1754 - val_loss: 0.2126\n",
            "Epoch 322/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.1755 - val_loss: 0.2123\n",
            "Epoch 323/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.1753 - val_loss: 0.2119\n",
            "Epoch 324/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.1747 - val_loss: 0.2116\n",
            "Epoch 325/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.1750 - val_loss: 0.2116\n",
            "Epoch 326/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 0.1752 - val_loss: 0.2109\n",
            "Epoch 327/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.1742 - val_loss: 0.2103\n",
            "Epoch 328/2000\n",
            "80/80 [==============================] - 0s 249us/step - loss: 0.1741 - val_loss: 0.2100\n",
            "Epoch 329/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.1741 - val_loss: 0.2096\n",
            "Epoch 330/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.1736 - val_loss: 0.2095\n",
            "Epoch 331/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.1738 - val_loss: 0.2094\n",
            "Epoch 332/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.1737 - val_loss: 0.2087\n",
            "Epoch 333/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.1730 - val_loss: 0.2082\n",
            "Epoch 334/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.1729 - val_loss: 0.2076\n",
            "Epoch 335/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 0.1731 - val_loss: 0.2072\n",
            "Epoch 336/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.1725 - val_loss: 0.2069\n",
            "Epoch 337/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.1724 - val_loss: 0.2068\n",
            "Epoch 338/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.1726 - val_loss: 0.2064\n",
            "Epoch 339/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.1725 - val_loss: 0.2058\n",
            "Epoch 340/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.1722 - val_loss: 0.2056\n",
            "Epoch 341/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.1717 - val_loss: 0.2051\n",
            "Epoch 342/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 0.1714 - val_loss: 0.2048\n",
            "Epoch 343/2000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.1713 - val_loss: 0.2045\n",
            "Epoch 344/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.1713 - val_loss: 0.2041\n",
            "Epoch 345/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.1707 - val_loss: 0.2039\n",
            "Epoch 346/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.1705 - val_loss: 0.2036\n",
            "Epoch 347/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.1705 - val_loss: 0.2032\n",
            "Epoch 348/2000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.1702 - val_loss: 0.2029\n",
            "Epoch 349/2000\n",
            "80/80 [==============================] - 0s 390us/step - loss: 0.1700 - val_loss: 0.2026\n",
            "Epoch 350/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.1697 - val_loss: 0.2020\n",
            "Epoch 351/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.1696 - val_loss: 0.2018\n",
            "Epoch 352/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.1696 - val_loss: 0.2017\n",
            "Epoch 353/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.1693 - val_loss: 0.2017\n",
            "Epoch 354/2000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.1690 - val_loss: 0.2019\n",
            "Epoch 355/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.1691 - val_loss: 0.2016\n",
            "Epoch 356/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.1687 - val_loss: 0.2011\n",
            "Epoch 357/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.1684 - val_loss: 0.2006\n",
            "Epoch 358/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.1687 - val_loss: 0.2003\n",
            "Epoch 359/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.1682 - val_loss: 0.2002\n",
            "Epoch 360/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.1679 - val_loss: 0.2003\n",
            "Epoch 361/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.1679 - val_loss: 0.2000\n",
            "Epoch 362/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.1678 - val_loss: 0.1995\n",
            "Epoch 363/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.1675 - val_loss: 0.1995\n",
            "Epoch 364/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.1675 - val_loss: 0.1997\n",
            "Epoch 365/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.1672 - val_loss: 0.1992\n",
            "Epoch 366/2000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.1668 - val_loss: 0.1988\n",
            "Epoch 367/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.1667 - val_loss: 0.1985\n",
            "Epoch 368/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.1666 - val_loss: 0.1984\n",
            "Epoch 369/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.1664 - val_loss: 0.1980\n",
            "Epoch 370/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.1663 - val_loss: 0.1976\n",
            "Epoch 371/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.1660 - val_loss: 0.1976\n",
            "Epoch 372/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.1659 - val_loss: 0.1977\n",
            "Epoch 373/2000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.1658 - val_loss: 0.1978\n",
            "Epoch 374/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 0.1657 - val_loss: 0.1973\n",
            "Epoch 375/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.1653 - val_loss: 0.1967\n",
            "Epoch 376/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.1652 - val_loss: 0.1965\n",
            "Epoch 377/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.1649 - val_loss: 0.1964\n",
            "Epoch 378/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.1648 - val_loss: 0.1963\n",
            "Epoch 379/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.1648 - val_loss: 0.1963\n",
            "Epoch 380/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.1644 - val_loss: 0.1959\n",
            "Epoch 381/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.1643 - val_loss: 0.1956\n",
            "Epoch 382/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.1641 - val_loss: 0.1956\n",
            "Epoch 383/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.1640 - val_loss: 0.1955\n",
            "Epoch 384/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.1641 - val_loss: 0.1956\n",
            "Epoch 385/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.1639 - val_loss: 0.1945\n",
            "Epoch 386/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.1634 - val_loss: 0.1937\n",
            "Epoch 387/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.1633 - val_loss: 0.1935\n",
            "Epoch 388/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.1631 - val_loss: 0.1936\n",
            "Epoch 389/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.1635 - val_loss: 0.1942\n",
            "Epoch 390/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.1629 - val_loss: 0.1932\n",
            "Epoch 391/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.1625 - val_loss: 0.1928\n",
            "Epoch 392/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.1626 - val_loss: 0.1926\n",
            "Epoch 393/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.1623 - val_loss: 0.1930\n",
            "Epoch 394/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.1621 - val_loss: 0.1929\n",
            "Epoch 395/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.1621 - val_loss: 0.1920\n",
            "Epoch 396/2000\n",
            "80/80 [==============================] - 0s 253us/step - loss: 0.1616 - val_loss: 0.1912\n",
            "Epoch 397/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.1617 - val_loss: 0.1905\n",
            "Epoch 398/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.1615 - val_loss: 0.1906\n",
            "Epoch 399/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.1610 - val_loss: 0.1916\n",
            "Epoch 400/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.1614 - val_loss: 0.1913\n",
            "Epoch 401/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.1609 - val_loss: 0.1902\n",
            "Epoch 402/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 0.1610 - val_loss: 0.1897\n",
            "Epoch 403/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.1606 - val_loss: 0.1904\n",
            "Epoch 404/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.1601 - val_loss: 0.1911\n",
            "Epoch 405/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.1605 - val_loss: 0.1909\n",
            "Epoch 406/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.1604 - val_loss: 0.1898\n",
            "Epoch 407/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.1597 - val_loss: 0.1895\n",
            "Epoch 408/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.1596 - val_loss: 0.1892\n",
            "Epoch 409/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.1594 - val_loss: 0.1893\n",
            "Epoch 410/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.1593 - val_loss: 0.1891\n",
            "Epoch 411/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.1591 - val_loss: 0.1888\n",
            "Epoch 412/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.1589 - val_loss: 0.1886\n",
            "Epoch 413/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.1589 - val_loss: 0.1884\n",
            "Epoch 414/2000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.1588 - val_loss: 0.1882\n",
            "Epoch 415/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.1585 - val_loss: 0.1879\n",
            "Epoch 416/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.1584 - val_loss: 0.1882\n",
            "Epoch 417/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.1581 - val_loss: 0.1878\n",
            "Epoch 418/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 0.1582 - val_loss: 0.1869\n",
            "Epoch 419/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.1578 - val_loss: 0.1874\n",
            "Epoch 420/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.1576 - val_loss: 0.1876\n",
            "Epoch 421/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.1575 - val_loss: 0.1871\n",
            "Epoch 422/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 0.1572 - val_loss: 0.1863\n",
            "Epoch 423/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.1572 - val_loss: 0.1863\n",
            "Epoch 424/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.1569 - val_loss: 0.1864\n",
            "Epoch 425/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.1567 - val_loss: 0.1869\n",
            "Epoch 426/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.1566 - val_loss: 0.1871\n",
            "Epoch 427/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.1564 - val_loss: 0.1872\n",
            "Epoch 428/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.1562 - val_loss: 0.1868\n",
            "Epoch 429/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.1563 - val_loss: 0.1876\n",
            "Epoch 430/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.1558 - val_loss: 0.1869\n",
            "Epoch 431/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.1557 - val_loss: 0.1865\n",
            "Epoch 432/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.1556 - val_loss: 0.1872\n",
            "Epoch 433/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.1554 - val_loss: 0.1873\n",
            "Epoch 434/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.1552 - val_loss: 0.1867\n",
            "Epoch 435/2000\n",
            "80/80 [==============================] - 0s 425us/step - loss: 0.1551 - val_loss: 0.1865\n",
            "Epoch 436/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.1551 - val_loss: 0.1870\n",
            "Epoch 437/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.1547 - val_loss: 0.1874\n",
            "Epoch 438/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.1546 - val_loss: 0.1878\n",
            "Epoch 439/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.1545 - val_loss: 0.1870\n",
            "Epoch 440/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 0.1543 - val_loss: 0.1860\n",
            "Epoch 441/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.1543 - val_loss: 0.1860\n",
            "Epoch 442/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.1541 - val_loss: 0.1855\n",
            "Epoch 443/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.1540 - val_loss: 0.1858\n",
            "Epoch 444/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.1537 - val_loss: 0.1848\n",
            "Epoch 445/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.1538 - val_loss: 0.1840\n",
            "Epoch 446/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.1537 - val_loss: 0.1842\n",
            "Epoch 447/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.1533 - val_loss: 0.1835\n",
            "Epoch 448/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.1532 - val_loss: 0.1834\n",
            "Epoch 449/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.1532 - val_loss: 0.1843\n",
            "Epoch 450/2000\n",
            "80/80 [==============================] - 0s 362us/step - loss: 0.1529 - val_loss: 0.1832\n",
            "Epoch 451/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.1528 - val_loss: 0.1829\n",
            "Epoch 452/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.1526 - val_loss: 0.1837\n",
            "Epoch 453/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.1526 - val_loss: 0.1827\n",
            "Epoch 454/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.1523 - val_loss: 0.1808\n",
            "Epoch 455/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.1526 - val_loss: 0.1815\n",
            "Epoch 456/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.1520 - val_loss: 0.1828\n",
            "Epoch 457/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.1524 - val_loss: 0.1834\n",
            "Epoch 458/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.1520 - val_loss: 0.1802\n",
            "Epoch 459/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 0.1518 - val_loss: 0.1803\n",
            "Epoch 460/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.1516 - val_loss: 0.1817\n",
            "Epoch 461/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.1513 - val_loss: 0.1816\n",
            "Epoch 462/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.1512 - val_loss: 0.1817\n",
            "Epoch 463/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.1511 - val_loss: 0.1815\n",
            "Epoch 464/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.1508 - val_loss: 0.1814\n",
            "Epoch 465/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.1508 - val_loss: 0.1810\n",
            "Epoch 466/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.1506 - val_loss: 0.1800\n",
            "Epoch 467/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 0.1505 - val_loss: 0.1800\n",
            "Epoch 468/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.1503 - val_loss: 0.1804\n",
            "Epoch 469/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.1502 - val_loss: 0.1801\n",
            "Epoch 470/2000\n",
            "80/80 [==============================] - 0s 249us/step - loss: 0.1503 - val_loss: 0.1794\n",
            "Epoch 471/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.1499 - val_loss: 0.1772\n",
            "Epoch 472/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.1501 - val_loss: 0.1773\n",
            "Epoch 473/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.1496 - val_loss: 0.1784\n",
            "Epoch 474/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.1500 - val_loss: 0.1783\n",
            "Epoch 475/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.1498 - val_loss: 0.1762\n",
            "Epoch 476/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.1494 - val_loss: 0.1766\n",
            "Epoch 477/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.1491 - val_loss: 0.1763\n",
            "Epoch 478/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.1490 - val_loss: 0.1762\n",
            "Epoch 479/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.1489 - val_loss: 0.1768\n",
            "Epoch 480/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.1487 - val_loss: 0.1757\n",
            "Epoch 481/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.1487 - val_loss: 0.1744\n",
            "Epoch 482/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.1490 - val_loss: 0.1751\n",
            "Epoch 483/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.1484 - val_loss: 0.1753\n",
            "Epoch 484/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.1482 - val_loss: 0.1746\n",
            "Epoch 485/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.1480 - val_loss: 0.1745\n",
            "Epoch 486/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.1479 - val_loss: 0.1749\n",
            "Epoch 487/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.1479 - val_loss: 0.1749\n",
            "Epoch 488/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.1478 - val_loss: 0.1741\n",
            "Epoch 489/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.1475 - val_loss: 0.1737\n",
            "Epoch 490/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.1475 - val_loss: 0.1742\n",
            "Epoch 491/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.1473 - val_loss: 0.1754\n",
            "Epoch 492/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 0.1475 - val_loss: 0.1743\n",
            "Epoch 493/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.1470 - val_loss: 0.1740\n",
            "Epoch 494/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.1469 - val_loss: 0.1742\n",
            "Epoch 495/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.1467 - val_loss: 0.1736\n",
            "Epoch 496/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.1466 - val_loss: 0.1738\n",
            "Epoch 497/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 0.1469 - val_loss: 0.1742\n",
            "Epoch 498/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.1462 - val_loss: 0.1721\n",
            "Epoch 499/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.1466 - val_loss: 0.1718\n",
            "Epoch 500/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.1464 - val_loss: 0.1734\n",
            "Epoch 501/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.1462 - val_loss: 0.1738\n",
            "Epoch 502/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.1458 - val_loss: 0.1721\n",
            "Epoch 503/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.1457 - val_loss: 0.1713\n",
            "Epoch 504/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.1457 - val_loss: 0.1717\n",
            "Epoch 505/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.1457 - val_loss: 0.1725\n",
            "Epoch 506/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.1453 - val_loss: 0.1707\n",
            "Epoch 507/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.1455 - val_loss: 0.1699\n",
            "Epoch 508/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.1452 - val_loss: 0.1716\n",
            "Epoch 509/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.1453 - val_loss: 0.1723\n",
            "Epoch 510/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.1450 - val_loss: 0.1707\n",
            "Epoch 511/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.1448 - val_loss: 0.1695\n",
            "Epoch 512/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.1447 - val_loss: 0.1708\n",
            "Epoch 513/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 0.1445 - val_loss: 0.1714\n",
            "Epoch 514/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.1445 - val_loss: 0.1701\n",
            "Epoch 515/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.1442 - val_loss: 0.1697\n",
            "Epoch 516/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.1441 - val_loss: 0.1697\n",
            "Epoch 517/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.1440 - val_loss: 0.1696\n",
            "Epoch 518/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.1439 - val_loss: 0.1691\n",
            "Epoch 519/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.1439 - val_loss: 0.1701\n",
            "Epoch 520/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.1436 - val_loss: 0.1691\n",
            "Epoch 521/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.1435 - val_loss: 0.1688\n",
            "Epoch 522/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.1434 - val_loss: 0.1695\n",
            "Epoch 523/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.1432 - val_loss: 0.1707\n",
            "Epoch 524/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.1433 - val_loss: 0.1702\n",
            "Epoch 525/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.1430 - val_loss: 0.1687\n",
            "Epoch 526/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.1430 - val_loss: 0.1691\n",
            "Epoch 527/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.1428 - val_loss: 0.1698\n",
            "Epoch 528/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.1427 - val_loss: 0.1702\n",
            "Epoch 529/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.1426 - val_loss: 0.1695\n",
            "Epoch 530/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.1424 - val_loss: 0.1689\n",
            "Epoch 531/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.1423 - val_loss: 0.1690\n",
            "Epoch 532/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.1421 - val_loss: 0.1682\n",
            "Epoch 533/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.1420 - val_loss: 0.1683\n",
            "Epoch 534/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.1419 - val_loss: 0.1679\n",
            "Epoch 535/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.1418 - val_loss: 0.1678\n",
            "Epoch 536/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.1416 - val_loss: 0.1675\n",
            "Epoch 537/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.1415 - val_loss: 0.1673\n",
            "Epoch 538/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.1414 - val_loss: 0.1668\n",
            "Epoch 539/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.1415 - val_loss: 0.1662\n",
            "Epoch 540/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.1411 - val_loss: 0.1676\n",
            "Epoch 541/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.1412 - val_loss: 0.1677\n",
            "Epoch 542/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.1409 - val_loss: 0.1659\n",
            "Epoch 543/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.1411 - val_loss: 0.1650\n",
            "Epoch 544/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.1412 - val_loss: 0.1665\n",
            "Epoch 545/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.1406 - val_loss: 0.1660\n",
            "Epoch 546/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.1404 - val_loss: 0.1652\n",
            "Epoch 547/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.1404 - val_loss: 0.1644\n",
            "Epoch 548/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.1404 - val_loss: 0.1649\n",
            "Epoch 549/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 0.1401 - val_loss: 0.1665\n",
            "Epoch 550/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.1404 - val_loss: 0.1649\n",
            "Epoch 551/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.1398 - val_loss: 0.1641\n",
            "Epoch 552/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.1398 - val_loss: 0.1639\n",
            "Epoch 553/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.1396 - val_loss: 0.1643\n",
            "Epoch 554/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.1396 - val_loss: 0.1648\n",
            "Epoch 555/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.1394 - val_loss: 0.1637\n",
            "Epoch 556/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.1396 - val_loss: 0.1633\n",
            "Epoch 557/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.1391 - val_loss: 0.1648\n",
            "Epoch 558/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.1391 - val_loss: 0.1649\n",
            "Epoch 559/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.1389 - val_loss: 0.1638\n",
            "Epoch 560/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.1390 - val_loss: 0.1631\n",
            "Epoch 561/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.1387 - val_loss: 0.1646\n",
            "Epoch 562/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.1386 - val_loss: 0.1647\n",
            "Epoch 563/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.1384 - val_loss: 0.1630\n",
            "Epoch 564/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.1385 - val_loss: 0.1620\n",
            "Epoch 565/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.1384 - val_loss: 0.1632\n",
            "Epoch 566/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.1381 - val_loss: 0.1632\n",
            "Epoch 567/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.1379 - val_loss: 0.1619\n",
            "Epoch 568/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.1379 - val_loss: 0.1620\n",
            "Epoch 569/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.1377 - val_loss: 0.1629\n",
            "Epoch 570/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.1376 - val_loss: 0.1629\n",
            "Epoch 571/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.1374 - val_loss: 0.1620\n",
            "Epoch 572/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.1373 - val_loss: 0.1615\n",
            "Epoch 573/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.1372 - val_loss: 0.1620\n",
            "Epoch 574/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.1372 - val_loss: 0.1626\n",
            "Epoch 575/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.1371 - val_loss: 0.1612\n",
            "Epoch 576/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 0.1369 - val_loss: 0.1615\n",
            "Epoch 577/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.1369 - val_loss: 0.1623\n",
            "Epoch 578/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.1368 - val_loss: 0.1613\n",
            "Epoch 579/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.1365 - val_loss: 0.1618\n",
            "Epoch 580/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.1364 - val_loss: 0.1615\n",
            "Epoch 581/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.1363 - val_loss: 0.1615\n",
            "Epoch 582/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.1361 - val_loss: 0.1610\n",
            "Epoch 583/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.1360 - val_loss: 0.1606\n",
            "Epoch 584/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.1359 - val_loss: 0.1613\n",
            "Epoch 585/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.1358 - val_loss: 0.1617\n",
            "Epoch 586/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.1357 - val_loss: 0.1609\n",
            "Epoch 587/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.1357 - val_loss: 0.1602\n",
            "Epoch 588/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.1354 - val_loss: 0.1613\n",
            "Epoch 589/2000\n",
            "80/80 [==============================] - 0s 249us/step - loss: 0.1357 - val_loss: 0.1614\n",
            "Epoch 590/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.1353 - val_loss: 0.1589\n",
            "Epoch 591/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.1353 - val_loss: 0.1588\n",
            "Epoch 592/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.1350 - val_loss: 0.1600\n",
            "Epoch 593/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.1349 - val_loss: 0.1595\n",
            "Epoch 594/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.1347 - val_loss: 0.1590\n",
            "Epoch 595/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.1346 - val_loss: 0.1591\n",
            "Epoch 596/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.1345 - val_loss: 0.1587\n",
            "Epoch 597/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.1344 - val_loss: 0.1585\n",
            "Epoch 598/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.1343 - val_loss: 0.1593\n",
            "Epoch 599/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.1342 - val_loss: 0.1592\n",
            "Epoch 600/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.1340 - val_loss: 0.1584\n",
            "Epoch 601/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.1340 - val_loss: 0.1584\n",
            "Epoch 602/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.1339 - val_loss: 0.1591\n",
            "Epoch 603/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.1337 - val_loss: 0.1581\n",
            "Epoch 604/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.1336 - val_loss: 0.1583\n",
            "Epoch 605/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.1334 - val_loss: 0.1589\n",
            "Epoch 606/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.1334 - val_loss: 0.1588\n",
            "Epoch 607/2000\n",
            "80/80 [==============================] - 0s 253us/step - loss: 0.1333 - val_loss: 0.1582\n",
            "Epoch 608/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.1331 - val_loss: 0.1573\n",
            "Epoch 609/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.1330 - val_loss: 0.1579\n",
            "Epoch 610/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 0.1329 - val_loss: 0.1577\n",
            "Epoch 611/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.1328 - val_loss: 0.1565\n",
            "Epoch 612/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.1327 - val_loss: 0.1564\n",
            "Epoch 613/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.1326 - val_loss: 0.1567\n",
            "Epoch 614/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.1324 - val_loss: 0.1562\n",
            "Epoch 615/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.1323 - val_loss: 0.1563\n",
            "Epoch 616/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.1323 - val_loss: 0.1560\n",
            "Epoch 617/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 0.1321 - val_loss: 0.1562\n",
            "Epoch 618/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.1320 - val_loss: 0.1558\n",
            "Epoch 619/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.1319 - val_loss: 0.1561\n",
            "Epoch 620/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 0.1318 - val_loss: 0.1560\n",
            "Epoch 621/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.1317 - val_loss: 0.1554\n",
            "Epoch 622/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.1317 - val_loss: 0.1557\n",
            "Epoch 623/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.1316 - val_loss: 0.1550\n",
            "Epoch 624/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.1314 - val_loss: 0.1558\n",
            "Epoch 625/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.1313 - val_loss: 0.1555\n",
            "Epoch 626/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.1311 - val_loss: 0.1559\n",
            "Epoch 627/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.1311 - val_loss: 0.1556\n",
            "Epoch 628/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.1308 - val_loss: 0.1544\n",
            "Epoch 629/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.1309 - val_loss: 0.1547\n",
            "Epoch 630/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.1307 - val_loss: 0.1554\n",
            "Epoch 631/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.1307 - val_loss: 0.1550\n",
            "Epoch 632/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.1304 - val_loss: 0.1532\n",
            "Epoch 633/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.1306 - val_loss: 0.1538\n",
            "Epoch 634/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.1302 - val_loss: 0.1550\n",
            "Epoch 635/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.1304 - val_loss: 0.1543\n",
            "Epoch 636/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.1301 - val_loss: 0.1535\n",
            "Epoch 637/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.1299 - val_loss: 0.1540\n",
            "Epoch 638/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.1298 - val_loss: 0.1536\n",
            "Epoch 639/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.1296 - val_loss: 0.1542\n",
            "Epoch 640/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.1296 - val_loss: 0.1538\n",
            "Epoch 641/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.1294 - val_loss: 0.1547\n",
            "Epoch 642/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.1293 - val_loss: 0.1548\n",
            "Epoch 643/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.1292 - val_loss: 0.1540\n",
            "Epoch 644/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.1290 - val_loss: 0.1532\n",
            "Epoch 645/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.1290 - val_loss: 0.1537\n",
            "Epoch 646/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.1288 - val_loss: 0.1544\n",
            "Epoch 647/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.1289 - val_loss: 0.1541\n",
            "Epoch 648/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.1287 - val_loss: 0.1527\n",
            "Epoch 649/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.1286 - val_loss: 0.1533\n",
            "Epoch 650/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.1284 - val_loss: 0.1531\n",
            "Epoch 651/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.1282 - val_loss: 0.1527\n",
            "Epoch 652/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.1283 - val_loss: 0.1522\n",
            "Epoch 653/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.1282 - val_loss: 0.1532\n",
            "Epoch 654/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.1279 - val_loss: 0.1524\n",
            "Epoch 655/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.1278 - val_loss: 0.1515\n",
            "Epoch 656/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.1277 - val_loss: 0.1522\n",
            "Epoch 657/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.1276 - val_loss: 0.1520\n",
            "Epoch 658/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.1276 - val_loss: 0.1512\n",
            "Epoch 659/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.1273 - val_loss: 0.1499\n",
            "Epoch 660/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.1274 - val_loss: 0.1505\n",
            "Epoch 661/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.1273 - val_loss: 0.1512\n",
            "Epoch 662/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.1272 - val_loss: 0.1496\n",
            "Epoch 663/2000\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.1270 - val_loss: 0.1499\n",
            "Epoch 664/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.1267 - val_loss: 0.1505\n",
            "Epoch 665/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.1267 - val_loss: 0.1502\n",
            "Epoch 666/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.1266 - val_loss: 0.1497\n",
            "Epoch 667/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.1265 - val_loss: 0.1505\n",
            "Epoch 668/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.1264 - val_loss: 0.1497\n",
            "Epoch 669/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 0.1262 - val_loss: 0.1493\n",
            "Epoch 670/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 0.1261 - val_loss: 0.1496\n",
            "Epoch 671/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.1260 - val_loss: 0.1500\n",
            "Epoch 672/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.1260 - val_loss: 0.1493\n",
            "Epoch 673/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.1259 - val_loss: 0.1483\n",
            "Epoch 674/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.1258 - val_loss: 0.1491\n",
            "Epoch 675/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.1256 - val_loss: 0.1485\n",
            "Epoch 676/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.1255 - val_loss: 0.1478\n",
            "Epoch 677/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.1254 - val_loss: 0.1482\n",
            "Epoch 678/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.1253 - val_loss: 0.1480\n",
            "Epoch 679/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.1252 - val_loss: 0.1479\n",
            "Epoch 680/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.1250 - val_loss: 0.1486\n",
            "Epoch 681/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.1251 - val_loss: 0.1482\n",
            "Epoch 682/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.1249 - val_loss: 0.1475\n",
            "Epoch 683/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.1247 - val_loss: 0.1485\n",
            "Epoch 684/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.1247 - val_loss: 0.1493\n",
            "Epoch 685/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.1245 - val_loss: 0.1480\n",
            "Epoch 686/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.1244 - val_loss: 0.1479\n",
            "Epoch 687/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 0.1243 - val_loss: 0.1489\n",
            "Epoch 688/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.1243 - val_loss: 0.1493\n",
            "Epoch 689/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.1240 - val_loss: 0.1476\n",
            "Epoch 690/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.1241 - val_loss: 0.1475\n",
            "Epoch 691/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.1238 - val_loss: 0.1491\n",
            "Epoch 692/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 0.1239 - val_loss: 0.1480\n",
            "Epoch 693/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.1235 - val_loss: 0.1467\n",
            "Epoch 694/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.1235 - val_loss: 0.1472\n",
            "Epoch 695/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.1233 - val_loss: 0.1479\n",
            "Epoch 696/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.1232 - val_loss: 0.1472\n",
            "Epoch 697/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.1231 - val_loss: 0.1466\n",
            "Epoch 698/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.1230 - val_loss: 0.1466\n",
            "Epoch 699/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.1229 - val_loss: 0.1467\n",
            "Epoch 700/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.1228 - val_loss: 0.1466\n",
            "Epoch 701/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.1226 - val_loss: 0.1455\n",
            "Epoch 702/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.1226 - val_loss: 0.1454\n",
            "Epoch 703/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.1225 - val_loss: 0.1461\n",
            "Epoch 704/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.1224 - val_loss: 0.1450\n",
            "Epoch 705/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.1222 - val_loss: 0.1447\n",
            "Epoch 706/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.1221 - val_loss: 0.1455\n",
            "Epoch 707/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.1220 - val_loss: 0.1449\n",
            "Epoch 708/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.1218 - val_loss: 0.1444\n",
            "Epoch 709/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.1218 - val_loss: 0.1442\n",
            "Epoch 710/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.1217 - val_loss: 0.1443\n",
            "Epoch 711/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.1215 - val_loss: 0.1446\n",
            "Epoch 712/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.1215 - val_loss: 0.1447\n",
            "Epoch 713/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.1213 - val_loss: 0.1435\n",
            "Epoch 714/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.1213 - val_loss: 0.1433\n",
            "Epoch 715/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.1211 - val_loss: 0.1445\n",
            "Epoch 716/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.1211 - val_loss: 0.1442\n",
            "Epoch 717/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.1208 - val_loss: 0.1432\n",
            "Epoch 718/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.1208 - val_loss: 0.1437\n",
            "Epoch 719/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.1206 - val_loss: 0.1441\n",
            "Epoch 720/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.1206 - val_loss: 0.1433\n",
            "Epoch 721/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.1205 - val_loss: 0.1426\n",
            "Epoch 722/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.1204 - val_loss: 0.1440\n",
            "Epoch 723/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.1205 - val_loss: 0.1440\n",
            "Epoch 724/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.1202 - val_loss: 0.1426\n",
            "Epoch 725/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.1200 - val_loss: 0.1427\n",
            "Epoch 726/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.1199 - val_loss: 0.1433\n",
            "Epoch 727/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.1198 - val_loss: 0.1422\n",
            "Epoch 728/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.1196 - val_loss: 0.1414\n",
            "Epoch 729/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.1198 - val_loss: 0.1418\n",
            "Epoch 730/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.1195 - val_loss: 0.1428\n",
            "Epoch 731/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.1194 - val_loss: 0.1413\n",
            "Epoch 732/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.1193 - val_loss: 0.1415\n",
            "Epoch 733/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.1190 - val_loss: 0.1422\n",
            "Epoch 734/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.1191 - val_loss: 0.1422\n",
            "Epoch 735/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.1189 - val_loss: 0.1415\n",
            "Epoch 736/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.1188 - val_loss: 0.1419\n",
            "Epoch 737/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.1187 - val_loss: 0.1425\n",
            "Epoch 738/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.1185 - val_loss: 0.1412\n",
            "Epoch 739/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.1185 - val_loss: 0.1408\n",
            "Epoch 740/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.1184 - val_loss: 0.1413\n",
            "Epoch 741/2000\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.1181 - val_loss: 0.1414\n",
            "Epoch 742/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.1181 - val_loss: 0.1407\n",
            "Epoch 743/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.1179 - val_loss: 0.1405\n",
            "Epoch 744/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.1179 - val_loss: 0.1408\n",
            "Epoch 745/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.1179 - val_loss: 0.1412\n",
            "Epoch 746/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.1176 - val_loss: 0.1400\n",
            "Epoch 747/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.1177 - val_loss: 0.1405\n",
            "Epoch 748/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.1174 - val_loss: 0.1411\n",
            "Epoch 749/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.1173 - val_loss: 0.1414\n",
            "Epoch 750/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.1172 - val_loss: 0.1403\n",
            "Epoch 751/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.1170 - val_loss: 0.1400\n",
            "Epoch 752/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.1170 - val_loss: 0.1403\n",
            "Epoch 753/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.1168 - val_loss: 0.1413\n",
            "Epoch 754/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.1170 - val_loss: 0.1402\n",
            "Epoch 755/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.1166 - val_loss: 0.1393\n",
            "Epoch 756/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.1167 - val_loss: 0.1400\n",
            "Epoch 757/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.1164 - val_loss: 0.1414\n",
            "Epoch 758/2000\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.1165 - val_loss: 0.1398\n",
            "Epoch 759/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.1163 - val_loss: 0.1392\n",
            "Epoch 760/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.1161 - val_loss: 0.1402\n",
            "Epoch 761/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.1162 - val_loss: 0.1408\n",
            "Epoch 762/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.1166 - val_loss: 0.1389\n",
            "Epoch 763/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.1158 - val_loss: 0.1403\n",
            "Epoch 764/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.1157 - val_loss: 0.1408\n",
            "Epoch 765/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.1155 - val_loss: 0.1394\n",
            "Epoch 766/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.1157 - val_loss: 0.1391\n",
            "Epoch 767/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.1153 - val_loss: 0.1410\n",
            "Epoch 768/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.1156 - val_loss: 0.1406\n",
            "Epoch 769/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.1150 - val_loss: 0.1389\n",
            "Epoch 770/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.1154 - val_loss: 0.1391\n",
            "Epoch 771/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.1148 - val_loss: 0.1402\n",
            "Epoch 772/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.1149 - val_loss: 0.1395\n",
            "Epoch 773/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.1147 - val_loss: 0.1383\n",
            "Epoch 774/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.1146 - val_loss: 0.1389\n",
            "Epoch 775/2000\n",
            "80/80 [==============================] - 0s 249us/step - loss: 0.1143 - val_loss: 0.1388\n",
            "Epoch 776/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.1143 - val_loss: 0.1387\n",
            "Epoch 777/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.1141 - val_loss: 0.1385\n",
            "Epoch 778/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.1140 - val_loss: 0.1384\n",
            "Epoch 779/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.1139 - val_loss: 0.1384\n",
            "Epoch 780/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 0.1138 - val_loss: 0.1387\n",
            "Epoch 781/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.1137 - val_loss: 0.1379\n",
            "Epoch 782/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.1135 - val_loss: 0.1380\n",
            "Epoch 783/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.1134 - val_loss: 0.1383\n",
            "Epoch 784/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.1134 - val_loss: 0.1381\n",
            "Epoch 785/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 0.1132 - val_loss: 0.1376\n",
            "Epoch 786/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.1131 - val_loss: 0.1378\n",
            "Epoch 787/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.1130 - val_loss: 0.1378\n",
            "Epoch 788/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.1129 - val_loss: 0.1375\n",
            "Epoch 789/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 0.1128 - val_loss: 0.1371\n",
            "Epoch 790/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.1127 - val_loss: 0.1367\n",
            "Epoch 791/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.1127 - val_loss: 0.1366\n",
            "Epoch 792/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.1124 - val_loss: 0.1372\n",
            "Epoch 793/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.1125 - val_loss: 0.1367\n",
            "Epoch 794/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.1124 - val_loss: 0.1359\n",
            "Epoch 795/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.1122 - val_loss: 0.1362\n",
            "Epoch 796/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 0.1121 - val_loss: 0.1367\n",
            "Epoch 797/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.1121 - val_loss: 0.1357\n",
            "Epoch 798/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.1120 - val_loss: 0.1356\n",
            "Epoch 799/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.1118 - val_loss: 0.1365\n",
            "Epoch 800/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.1117 - val_loss: 0.1359\n",
            "Epoch 801/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.1115 - val_loss: 0.1357\n",
            "Epoch 802/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 0.1115 - val_loss: 0.1361\n",
            "Epoch 803/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.1113 - val_loss: 0.1358\n",
            "Epoch 804/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 0.1112 - val_loss: 0.1353\n",
            "Epoch 805/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.1113 - val_loss: 0.1348\n",
            "Epoch 806/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.1110 - val_loss: 0.1357\n",
            "Epoch 807/2000\n",
            "80/80 [==============================] - 0s 370us/step - loss: 0.1109 - val_loss: 0.1348\n",
            "Epoch 808/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.1108 - val_loss: 0.1348\n",
            "Epoch 809/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.1107 - val_loss: 0.1353\n",
            "Epoch 810/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.1107 - val_loss: 0.1346\n",
            "Epoch 811/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.1104 - val_loss: 0.1337\n",
            "Epoch 812/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.1104 - val_loss: 0.1342\n",
            "Epoch 813/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.1102 - val_loss: 0.1342\n",
            "Epoch 814/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 0.1101 - val_loss: 0.1337\n",
            "Epoch 815/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.1100 - val_loss: 0.1336\n",
            "Epoch 816/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.1099 - val_loss: 0.1334\n",
            "Epoch 817/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 0.1098 - val_loss: 0.1330\n",
            "Epoch 818/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.1097 - val_loss: 0.1332\n",
            "Epoch 819/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.1096 - val_loss: 0.1331\n",
            "Epoch 820/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.1094 - val_loss: 0.1334\n",
            "Epoch 821/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.1094 - val_loss: 0.1337\n",
            "Epoch 822/2000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.1093 - val_loss: 0.1329\n",
            "Epoch 823/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.1091 - val_loss: 0.1331\n",
            "Epoch 824/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.1090 - val_loss: 0.1331\n",
            "Epoch 825/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.1089 - val_loss: 0.1328\n",
            "Epoch 826/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.1088 - val_loss: 0.1326\n",
            "Epoch 827/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.1087 - val_loss: 0.1324\n",
            "Epoch 828/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.1086 - val_loss: 0.1328\n",
            "Epoch 829/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.1085 - val_loss: 0.1323\n",
            "Epoch 830/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.1084 - val_loss: 0.1317\n",
            "Epoch 831/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.1083 - val_loss: 0.1321\n",
            "Epoch 832/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.1083 - val_loss: 0.1320\n",
            "Epoch 833/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.1082 - val_loss: 0.1314\n",
            "Epoch 834/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 0.1081 - val_loss: 0.1328\n",
            "Epoch 835/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.1079 - val_loss: 0.1319\n",
            "Epoch 836/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.1078 - val_loss: 0.1312\n",
            "Epoch 837/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.1078 - val_loss: 0.1317\n",
            "Epoch 838/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.1075 - val_loss: 0.1318\n",
            "Epoch 839/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.1074 - val_loss: 0.1313\n",
            "Epoch 840/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.1074 - val_loss: 0.1310\n",
            "Epoch 841/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.1073 - val_loss: 0.1317\n",
            "Epoch 842/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.1071 - val_loss: 0.1306\n",
            "Epoch 843/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.1070 - val_loss: 0.1307\n",
            "Epoch 844/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.1070 - val_loss: 0.1311\n",
            "Epoch 845/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.1067 - val_loss: 0.1302\n",
            "Epoch 846/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 0.1069 - val_loss: 0.1306\n",
            "Epoch 847/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.1067 - val_loss: 0.1318\n",
            "Epoch 848/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.1066 - val_loss: 0.1307\n",
            "Epoch 849/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.1065 - val_loss: 0.1307\n",
            "Epoch 850/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.1063 - val_loss: 0.1318\n",
            "Epoch 851/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.1064 - val_loss: 0.1306\n",
            "Epoch 852/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.1061 - val_loss: 0.1305\n",
            "Epoch 853/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.1059 - val_loss: 0.1309\n",
            "Epoch 854/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.1058 - val_loss: 0.1309\n",
            "Epoch 855/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.1058 - val_loss: 0.1304\n",
            "Epoch 856/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.1056 - val_loss: 0.1306\n",
            "Epoch 857/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.1056 - val_loss: 0.1306\n",
            "Epoch 858/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.1054 - val_loss: 0.1298\n",
            "Epoch 859/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 0.1054 - val_loss: 0.1299\n",
            "Epoch 860/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.1052 - val_loss: 0.1305\n",
            "Epoch 861/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.1052 - val_loss: 0.1298\n",
            "Epoch 862/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.1049 - val_loss: 0.1299\n",
            "Epoch 863/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.1049 - val_loss: 0.1296\n",
            "Epoch 864/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.1048 - val_loss: 0.1291\n",
            "Epoch 865/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.1047 - val_loss: 0.1292\n",
            "Epoch 866/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.1046 - val_loss: 0.1286\n",
            "Epoch 867/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.1044 - val_loss: 0.1285\n",
            "Epoch 868/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.1043 - val_loss: 0.1283\n",
            "Epoch 869/2000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 0.1043 - val_loss: 0.1277\n",
            "Epoch 870/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.1041 - val_loss: 0.1274\n",
            "Epoch 871/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.1041 - val_loss: 0.1274\n",
            "Epoch 872/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.1040 - val_loss: 0.1276\n",
            "Epoch 873/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 0.1039 - val_loss: 0.1267\n",
            "Epoch 874/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.1039 - val_loss: 0.1266\n",
            "Epoch 875/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.1037 - val_loss: 0.1272\n",
            "Epoch 876/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.1036 - val_loss: 0.1265\n",
            "Epoch 877/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.1034 - val_loss: 0.1261\n",
            "Epoch 878/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.1034 - val_loss: 0.1259\n",
            "Epoch 879/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.1033 - val_loss: 0.1262\n",
            "Epoch 880/2000\n",
            "80/80 [==============================] - 0s 253us/step - loss: 0.1032 - val_loss: 0.1259\n",
            "Epoch 881/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.1031 - val_loss: 0.1254\n",
            "Epoch 882/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.1030 - val_loss: 0.1252\n",
            "Epoch 883/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.1029 - val_loss: 0.1251\n",
            "Epoch 884/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.1028 - val_loss: 0.1250\n",
            "Epoch 885/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.1027 - val_loss: 0.1248\n",
            "Epoch 886/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.1026 - val_loss: 0.1245\n",
            "Epoch 887/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.1025 - val_loss: 0.1246\n",
            "Epoch 888/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.1024 - val_loss: 0.1246\n",
            "Epoch 889/2000\n",
            "80/80 [==============================] - 0s 253us/step - loss: 0.1023 - val_loss: 0.1245\n",
            "Epoch 890/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.1023 - val_loss: 0.1241\n",
            "Epoch 891/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.1022 - val_loss: 0.1246\n",
            "Epoch 892/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.1020 - val_loss: 0.1241\n",
            "Epoch 893/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.1020 - val_loss: 0.1242\n",
            "Epoch 894/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.1018 - val_loss: 0.1245\n",
            "Epoch 895/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.1018 - val_loss: 0.1240\n",
            "Epoch 896/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.1018 - val_loss: 0.1238\n",
            "Epoch 897/2000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.1016 - val_loss: 0.1243\n",
            "Epoch 898/2000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.1016 - val_loss: 0.1238\n",
            "Epoch 899/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.1013 - val_loss: 0.1248\n",
            "Epoch 900/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.1015 - val_loss: 0.1244\n",
            "Epoch 901/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.1013 - val_loss: 0.1241\n",
            "Epoch 902/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.1010 - val_loss: 0.1250\n",
            "Epoch 903/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.1011 - val_loss: 0.1241\n",
            "Epoch 904/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.1008 - val_loss: 0.1237\n",
            "Epoch 905/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.1007 - val_loss: 0.1238\n",
            "Epoch 906/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.1006 - val_loss: 0.1240\n",
            "Epoch 907/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.1006 - val_loss: 0.1235\n",
            "Epoch 908/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.1004 - val_loss: 0.1232\n",
            "Epoch 909/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.1004 - val_loss: 0.1229\n",
            "Epoch 910/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.1003 - val_loss: 0.1226\n",
            "Epoch 911/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.1001 - val_loss: 0.1228\n",
            "Epoch 912/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.1001 - val_loss: 0.1221\n",
            "Epoch 913/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.1000 - val_loss: 0.1219\n",
            "Epoch 914/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.1000 - val_loss: 0.1220\n",
            "Epoch 915/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.0998 - val_loss: 0.1218\n",
            "Epoch 916/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.0997 - val_loss: 0.1223\n",
            "Epoch 917/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.0996 - val_loss: 0.1221\n",
            "Epoch 918/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.0995 - val_loss: 0.1217\n",
            "Epoch 919/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 0.0994 - val_loss: 0.1218\n",
            "Epoch 920/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.0993 - val_loss: 0.1216\n",
            "Epoch 921/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.0992 - val_loss: 0.1212\n",
            "Epoch 922/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.0991 - val_loss: 0.1213\n",
            "Epoch 923/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0991 - val_loss: 0.1213\n",
            "Epoch 924/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.0989 - val_loss: 0.1208\n",
            "Epoch 925/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0990 - val_loss: 0.1210\n",
            "Epoch 926/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0987 - val_loss: 0.1209\n",
            "Epoch 927/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0986 - val_loss: 0.1203\n",
            "Epoch 928/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0985 - val_loss: 0.1205\n",
            "Epoch 929/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0984 - val_loss: 0.1205\n",
            "Epoch 930/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0983 - val_loss: 0.1200\n",
            "Epoch 931/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0982 - val_loss: 0.1199\n",
            "Epoch 932/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.0981 - val_loss: 0.1198\n",
            "Epoch 933/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0980 - val_loss: 0.1194\n",
            "Epoch 934/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0979 - val_loss: 0.1193\n",
            "Epoch 935/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0978 - val_loss: 0.1193\n",
            "Epoch 936/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0977 - val_loss: 0.1190\n",
            "Epoch 937/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.0976 - val_loss: 0.1192\n",
            "Epoch 938/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.0976 - val_loss: 0.1195\n",
            "Epoch 939/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 0.0974 - val_loss: 0.1191\n",
            "Epoch 940/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.0974 - val_loss: 0.1190\n",
            "Epoch 941/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0972 - val_loss: 0.1194\n",
            "Epoch 942/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.0972 - val_loss: 0.1189\n",
            "Epoch 943/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0971 - val_loss: 0.1187\n",
            "Epoch 944/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0970 - val_loss: 0.1187\n",
            "Epoch 945/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.0968 - val_loss: 0.1183\n",
            "Epoch 946/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.0968 - val_loss: 0.1178\n",
            "Epoch 947/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0967 - val_loss: 0.1177\n",
            "Epoch 948/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0966 - val_loss: 0.1176\n",
            "Epoch 949/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.0964 - val_loss: 0.1179\n",
            "Epoch 950/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.0965 - val_loss: 0.1179\n",
            "Epoch 951/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0963 - val_loss: 0.1177\n",
            "Epoch 952/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0962 - val_loss: 0.1183\n",
            "Epoch 953/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0962 - val_loss: 0.1175\n",
            "Epoch 954/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.0960 - val_loss: 0.1174\n",
            "Epoch 955/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0958 - val_loss: 0.1171\n",
            "Epoch 956/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.0957 - val_loss: 0.1167\n",
            "Epoch 957/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0957 - val_loss: 0.1166\n",
            "Epoch 958/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0957 - val_loss: 0.1168\n",
            "Epoch 959/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.0956 - val_loss: 0.1163\n",
            "Epoch 960/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0954 - val_loss: 0.1166\n",
            "Epoch 961/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.0954 - val_loss: 0.1162\n",
            "Epoch 962/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0952 - val_loss: 0.1161\n",
            "Epoch 963/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0951 - val_loss: 0.1163\n",
            "Epoch 964/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0950 - val_loss: 0.1162\n",
            "Epoch 965/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0949 - val_loss: 0.1162\n",
            "Epoch 966/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0949 - val_loss: 0.1162\n",
            "Epoch 967/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.0947 - val_loss: 0.1165\n",
            "Epoch 968/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0947 - val_loss: 0.1159\n",
            "Epoch 969/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.0946 - val_loss: 0.1160\n",
            "Epoch 970/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.0945 - val_loss: 0.1160\n",
            "Epoch 971/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0943 - val_loss: 0.1154\n",
            "Epoch 972/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0943 - val_loss: 0.1154\n",
            "Epoch 973/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0941 - val_loss: 0.1153\n",
            "Epoch 974/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.0941 - val_loss: 0.1149\n",
            "Epoch 975/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0940 - val_loss: 0.1148\n",
            "Epoch 976/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0939 - val_loss: 0.1148\n",
            "Epoch 977/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0938 - val_loss: 0.1146\n",
            "Epoch 978/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0937 - val_loss: 0.1148\n",
            "Epoch 979/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0936 - val_loss: 0.1144\n",
            "Epoch 980/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0935 - val_loss: 0.1144\n",
            "Epoch 981/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.0934 - val_loss: 0.1144\n",
            "Epoch 982/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0933 - val_loss: 0.1142\n",
            "Epoch 983/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.0932 - val_loss: 0.1140\n",
            "Epoch 984/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0931 - val_loss: 0.1141\n",
            "Epoch 985/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0930 - val_loss: 0.1138\n",
            "Epoch 986/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0930 - val_loss: 0.1137\n",
            "Epoch 987/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.0928 - val_loss: 0.1142\n",
            "Epoch 988/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.0928 - val_loss: 0.1136\n",
            "Epoch 989/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0927 - val_loss: 0.1134\n",
            "Epoch 990/2000\n",
            "80/80 [==============================] - 0s 376us/step - loss: 0.0925 - val_loss: 0.1137\n",
            "Epoch 991/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.0925 - val_loss: 0.1131\n",
            "Epoch 992/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.0924 - val_loss: 0.1131\n",
            "Epoch 993/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0923 - val_loss: 0.1133\n",
            "Epoch 994/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0922 - val_loss: 0.1126\n",
            "Epoch 995/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.0921 - val_loss: 0.1126\n",
            "Epoch 996/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0920 - val_loss: 0.1122\n",
            "Epoch 997/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.0919 - val_loss: 0.1120\n",
            "Epoch 998/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0918 - val_loss: 0.1120\n",
            "Epoch 999/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.0917 - val_loss: 0.1121\n",
            "Epoch 1000/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0916 - val_loss: 0.1118\n",
            "Epoch 1001/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0915 - val_loss: 0.1121\n",
            "Epoch 1002/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.0916 - val_loss: 0.1118\n",
            "Epoch 1003/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0914 - val_loss: 0.1111\n",
            "Epoch 1004/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.0913 - val_loss: 0.1112\n",
            "Epoch 1005/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.0913 - val_loss: 0.1105\n",
            "Epoch 1006/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0911 - val_loss: 0.1104\n",
            "Epoch 1007/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.0910 - val_loss: 0.1105\n",
            "Epoch 1008/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0909 - val_loss: 0.1103\n",
            "Epoch 1009/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 0.0908 - val_loss: 0.1103\n",
            "Epoch 1010/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.0907 - val_loss: 0.1106\n",
            "Epoch 1011/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.0907 - val_loss: 0.1101\n",
            "Epoch 1012/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 0.0906 - val_loss: 0.1102\n",
            "Epoch 1013/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0904 - val_loss: 0.1100\n",
            "Epoch 1014/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0903 - val_loss: 0.1102\n",
            "Epoch 1015/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.0903 - val_loss: 0.1097\n",
            "Epoch 1016/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.0901 - val_loss: 0.1098\n",
            "Epoch 1017/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.0901 - val_loss: 0.1099\n",
            "Epoch 1018/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.0899 - val_loss: 0.1095\n",
            "Epoch 1019/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0899 - val_loss: 0.1094\n",
            "Epoch 1020/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0897 - val_loss: 0.1091\n",
            "Epoch 1021/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.0896 - val_loss: 0.1089\n",
            "Epoch 1022/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.0897 - val_loss: 0.1087\n",
            "Epoch 1023/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.0894 - val_loss: 0.1089\n",
            "Epoch 1024/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0894 - val_loss: 0.1084\n",
            "Epoch 1025/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.0893 - val_loss: 0.1084\n",
            "Epoch 1026/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0893 - val_loss: 0.1085\n",
            "Epoch 1027/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0892 - val_loss: 0.1083\n",
            "Epoch 1028/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.0890 - val_loss: 0.1089\n",
            "Epoch 1029/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.0891 - val_loss: 0.1080\n",
            "Epoch 1030/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0890 - val_loss: 0.1078\n",
            "Epoch 1031/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0888 - val_loss: 0.1080\n",
            "Epoch 1032/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.0887 - val_loss: 0.1075\n",
            "Epoch 1033/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0886 - val_loss: 0.1079\n",
            "Epoch 1034/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0884 - val_loss: 0.1072\n",
            "Epoch 1035/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.0883 - val_loss: 0.1072\n",
            "Epoch 1036/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.0882 - val_loss: 0.1072\n",
            "Epoch 1037/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.0881 - val_loss: 0.1069\n",
            "Epoch 1038/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.0880 - val_loss: 0.1067\n",
            "Epoch 1039/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.0879 - val_loss: 0.1065\n",
            "Epoch 1040/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0878 - val_loss: 0.1064\n",
            "Epoch 1041/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.0877 - val_loss: 0.1061\n",
            "Epoch 1042/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0877 - val_loss: 0.1061\n",
            "Epoch 1043/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0875 - val_loss: 0.1064\n",
            "Epoch 1044/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0874 - val_loss: 0.1062\n",
            "Epoch 1045/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0875 - val_loss: 0.1062\n",
            "Epoch 1046/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 0.0871 - val_loss: 0.1070\n",
            "Epoch 1047/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0873 - val_loss: 0.1065\n",
            "Epoch 1048/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.0871 - val_loss: 0.1067\n",
            "Epoch 1049/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0870 - val_loss: 0.1066\n",
            "Epoch 1050/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.0869 - val_loss: 0.1062\n",
            "Epoch 1051/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0868 - val_loss: 0.1056\n",
            "Epoch 1052/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.0867 - val_loss: 0.1056\n",
            "Epoch 1053/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.0866 - val_loss: 0.1051\n",
            "Epoch 1054/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0865 - val_loss: 0.1049\n",
            "Epoch 1055/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0864 - val_loss: 0.1048\n",
            "Epoch 1056/2000\n",
            "80/80 [==============================] - 0s 376us/step - loss: 0.0863 - val_loss: 0.1046\n",
            "Epoch 1057/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.0863 - val_loss: 0.1045\n",
            "Epoch 1058/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0861 - val_loss: 0.1044\n",
            "Epoch 1059/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.0860 - val_loss: 0.1044\n",
            "Epoch 1060/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.0859 - val_loss: 0.1043\n",
            "Epoch 1061/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0858 - val_loss: 0.1045\n",
            "Epoch 1062/2000\n",
            "80/80 [==============================] - 0s 352us/step - loss: 0.0857 - val_loss: 0.1043\n",
            "Epoch 1063/2000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.0856 - val_loss: 0.1044\n",
            "Epoch 1064/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0856 - val_loss: 0.1044\n",
            "Epoch 1065/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.0855 - val_loss: 0.1042\n",
            "Epoch 1066/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 0.0854 - val_loss: 0.1043\n",
            "Epoch 1067/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.0853 - val_loss: 0.1038\n",
            "Epoch 1068/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0851 - val_loss: 0.1035\n",
            "Epoch 1069/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0851 - val_loss: 0.1034\n",
            "Epoch 1070/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0850 - val_loss: 0.1031\n",
            "Epoch 1071/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.0849 - val_loss: 0.1030\n",
            "Epoch 1072/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.0848 - val_loss: 0.1028\n",
            "Epoch 1073/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0847 - val_loss: 0.1026\n",
            "Epoch 1074/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0846 - val_loss: 0.1026\n",
            "Epoch 1075/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 0.0846 - val_loss: 0.1026\n",
            "Epoch 1076/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.0844 - val_loss: 0.1022\n",
            "Epoch 1077/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.0844 - val_loss: 0.1025\n",
            "Epoch 1078/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.0843 - val_loss: 0.1021\n",
            "Epoch 1079/2000\n",
            "80/80 [==============================] - 0s 253us/step - loss: 0.0841 - val_loss: 0.1019\n",
            "Epoch 1080/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.0840 - val_loss: 0.1018\n",
            "Epoch 1081/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.0840 - val_loss: 0.1016\n",
            "Epoch 1082/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.0838 - val_loss: 0.1015\n",
            "Epoch 1083/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.0838 - val_loss: 0.1015\n",
            "Epoch 1084/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.0837 - val_loss: 0.1014\n",
            "Epoch 1085/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.0836 - val_loss: 0.1012\n",
            "Epoch 1086/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 0.0835 - val_loss: 0.1015\n",
            "Epoch 1087/2000\n",
            "80/80 [==============================] - 0s 249us/step - loss: 0.0835 - val_loss: 0.1012\n",
            "Epoch 1088/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.0833 - val_loss: 0.1013\n",
            "Epoch 1089/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.0832 - val_loss: 0.1014\n",
            "Epoch 1090/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0832 - val_loss: 0.1010\n",
            "Epoch 1091/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 0.0831 - val_loss: 0.1009\n",
            "Epoch 1092/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.0830 - val_loss: 0.1008\n",
            "Epoch 1093/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.0829 - val_loss: 0.1007\n",
            "Epoch 1094/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 0.0828 - val_loss: 0.1008\n",
            "Epoch 1095/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.0828 - val_loss: 0.1009\n",
            "Epoch 1096/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0826 - val_loss: 0.1007\n",
            "Epoch 1097/2000\n",
            "80/80 [==============================] - 0s 249us/step - loss: 0.0826 - val_loss: 0.1005\n",
            "Epoch 1098/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0824 - val_loss: 0.1003\n",
            "Epoch 1099/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.0823 - val_loss: 0.1003\n",
            "Epoch 1100/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0822 - val_loss: 0.1000\n",
            "Epoch 1101/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0822 - val_loss: 0.1000\n",
            "Epoch 1102/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0821 - val_loss: 0.0999\n",
            "Epoch 1103/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0820 - val_loss: 0.0998\n",
            "Epoch 1104/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0819 - val_loss: 0.1001\n",
            "Epoch 1105/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.0820 - val_loss: 0.0996\n",
            "Epoch 1106/2000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.0817 - val_loss: 0.0995\n",
            "Epoch 1107/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0816 - val_loss: 0.0997\n",
            "Epoch 1108/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.0816 - val_loss: 0.0993\n",
            "Epoch 1109/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0815 - val_loss: 0.0994\n",
            "Epoch 1110/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.0814 - val_loss: 0.0992\n",
            "Epoch 1111/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0813 - val_loss: 0.0994\n",
            "Epoch 1112/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.0812 - val_loss: 0.0992\n",
            "Epoch 1113/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 0.0811 - val_loss: 0.0992\n",
            "Epoch 1114/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0811 - val_loss: 0.0991\n",
            "Epoch 1115/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 0.0810 - val_loss: 0.0989\n",
            "Epoch 1116/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0809 - val_loss: 0.0988\n",
            "Epoch 1117/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0808 - val_loss: 0.0984\n",
            "Epoch 1118/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0807 - val_loss: 0.0981\n",
            "Epoch 1119/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 0.0806 - val_loss: 0.0977\n",
            "Epoch 1120/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0805 - val_loss: 0.0976\n",
            "Epoch 1121/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0805 - val_loss: 0.0976\n",
            "Epoch 1122/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0804 - val_loss: 0.0976\n",
            "Epoch 1123/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.0803 - val_loss: 0.0975\n",
            "Epoch 1124/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0802 - val_loss: 0.0979\n",
            "Epoch 1125/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0801 - val_loss: 0.0978\n",
            "Epoch 1126/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0800 - val_loss: 0.0980\n",
            "Epoch 1127/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0799 - val_loss: 0.0979\n",
            "Epoch 1128/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.0799 - val_loss: 0.0978\n",
            "Epoch 1129/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0797 - val_loss: 0.0974\n",
            "Epoch 1130/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0796 - val_loss: 0.0969\n",
            "Epoch 1131/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0797 - val_loss: 0.0966\n",
            "Epoch 1132/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0797 - val_loss: 0.0961\n",
            "Epoch 1133/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0796 - val_loss: 0.0961\n",
            "Epoch 1134/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.0795 - val_loss: 0.0962\n",
            "Epoch 1135/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0793 - val_loss: 0.0959\n",
            "Epoch 1136/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0793 - val_loss: 0.0959\n",
            "Epoch 1137/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0792 - val_loss: 0.0956\n",
            "Epoch 1138/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0791 - val_loss: 0.0956\n",
            "Epoch 1139/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0790 - val_loss: 0.0954\n",
            "Epoch 1140/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0789 - val_loss: 0.0954\n",
            "Epoch 1141/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0788 - val_loss: 0.0957\n",
            "Epoch 1142/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0787 - val_loss: 0.0956\n",
            "Epoch 1143/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0787 - val_loss: 0.0958\n",
            "Epoch 1144/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0786 - val_loss: 0.0956\n",
            "Epoch 1145/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0784 - val_loss: 0.0957\n",
            "Epoch 1146/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.0784 - val_loss: 0.0956\n",
            "Epoch 1147/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.0782 - val_loss: 0.0954\n",
            "Epoch 1148/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.0782 - val_loss: 0.0953\n",
            "Epoch 1149/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0781 - val_loss: 0.0952\n",
            "Epoch 1150/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0780 - val_loss: 0.0951\n",
            "Epoch 1151/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 0.0779 - val_loss: 0.0950\n",
            "Epoch 1152/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0778 - val_loss: 0.0948\n",
            "Epoch 1153/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0777 - val_loss: 0.0946\n",
            "Epoch 1154/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.0777 - val_loss: 0.0946\n",
            "Epoch 1155/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0776 - val_loss: 0.0944\n",
            "Epoch 1156/2000\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.0776 - val_loss: 0.0944\n",
            "Epoch 1157/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0774 - val_loss: 0.0943\n",
            "Epoch 1158/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0773 - val_loss: 0.0943\n",
            "Epoch 1159/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0772 - val_loss: 0.0939\n",
            "Epoch 1160/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0772 - val_loss: 0.0939\n",
            "Epoch 1161/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 0.0772 - val_loss: 0.0936\n",
            "Epoch 1162/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.0770 - val_loss: 0.0937\n",
            "Epoch 1163/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0769 - val_loss: 0.0937\n",
            "Epoch 1164/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0770 - val_loss: 0.0937\n",
            "Epoch 1165/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.0768 - val_loss: 0.0939\n",
            "Epoch 1166/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.0767 - val_loss: 0.0937\n",
            "Epoch 1167/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.0766 - val_loss: 0.0935\n",
            "Epoch 1168/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 0.0765 - val_loss: 0.0932\n",
            "Epoch 1169/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0765 - val_loss: 0.0931\n",
            "Epoch 1170/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0763 - val_loss: 0.0926\n",
            "Epoch 1171/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.0763 - val_loss: 0.0922\n",
            "Epoch 1172/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0762 - val_loss: 0.0921\n",
            "Epoch 1173/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0761 - val_loss: 0.0919\n",
            "Epoch 1174/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.0761 - val_loss: 0.0920\n",
            "Epoch 1175/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0760 - val_loss: 0.0920\n",
            "Epoch 1176/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.0759 - val_loss: 0.0917\n",
            "Epoch 1177/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0758 - val_loss: 0.0916\n",
            "Epoch 1178/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0758 - val_loss: 0.0916\n",
            "Epoch 1179/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0757 - val_loss: 0.0918\n",
            "Epoch 1180/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0756 - val_loss: 0.0917\n",
            "Epoch 1181/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0755 - val_loss: 0.0917\n",
            "Epoch 1182/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.0755 - val_loss: 0.0918\n",
            "Epoch 1183/2000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0754 - val_loss: 0.0916\n",
            "Epoch 1184/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.0752 - val_loss: 0.0914\n",
            "Epoch 1185/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0752 - val_loss: 0.0913\n",
            "Epoch 1186/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.0751 - val_loss: 0.0908\n",
            "Epoch 1187/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0752 - val_loss: 0.0904\n",
            "Epoch 1188/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0750 - val_loss: 0.0900\n",
            "Epoch 1189/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.0749 - val_loss: 0.0897\n",
            "Epoch 1190/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0748 - val_loss: 0.0898\n",
            "Epoch 1191/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.0748 - val_loss: 0.0898\n",
            "Epoch 1192/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0747 - val_loss: 0.0899\n",
            "Epoch 1193/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0746 - val_loss: 0.0899\n",
            "Epoch 1194/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.0745 - val_loss: 0.0900\n",
            "Epoch 1195/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.0745 - val_loss: 0.0901\n",
            "Epoch 1196/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.0743 - val_loss: 0.0899\n",
            "Epoch 1197/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0742 - val_loss: 0.0898\n",
            "Epoch 1198/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0742 - val_loss: 0.0895\n",
            "Epoch 1199/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0741 - val_loss: 0.0895\n",
            "Epoch 1200/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.0740 - val_loss: 0.0893\n",
            "Epoch 1201/2000\n",
            "80/80 [==============================] - 0s 249us/step - loss: 0.0739 - val_loss: 0.0891\n",
            "Epoch 1202/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 0.0738 - val_loss: 0.0893\n",
            "Epoch 1203/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0737 - val_loss: 0.0893\n",
            "Epoch 1204/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0737 - val_loss: 0.0893\n",
            "Epoch 1205/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.0736 - val_loss: 0.0891\n",
            "Epoch 1206/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0735 - val_loss: 0.0889\n",
            "Epoch 1207/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0735 - val_loss: 0.0885\n",
            "Epoch 1208/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0734 - val_loss: 0.0881\n",
            "Epoch 1209/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.0733 - val_loss: 0.0877\n",
            "Epoch 1210/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0733 - val_loss: 0.0873\n",
            "Epoch 1211/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0731 - val_loss: 0.0870\n",
            "Epoch 1212/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0733 - val_loss: 0.0869\n",
            "Epoch 1213/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.0731 - val_loss: 0.0868\n",
            "Epoch 1214/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0730 - val_loss: 0.0867\n",
            "Epoch 1215/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0728 - val_loss: 0.0870\n",
            "Epoch 1216/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.0728 - val_loss: 0.0872\n",
            "Epoch 1217/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0726 - val_loss: 0.0872\n",
            "Epoch 1218/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0726 - val_loss: 0.0869\n",
            "Epoch 1219/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.0726 - val_loss: 0.0868\n",
            "Epoch 1220/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0725 - val_loss: 0.0866\n",
            "Epoch 1221/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0723 - val_loss: 0.0864\n",
            "Epoch 1222/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.0722 - val_loss: 0.0864\n",
            "Epoch 1223/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0721 - val_loss: 0.0862\n",
            "Epoch 1224/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0720 - val_loss: 0.0860\n",
            "Epoch 1225/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.0720 - val_loss: 0.0858\n",
            "Epoch 1226/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0720 - val_loss: 0.0855\n",
            "Epoch 1227/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0719 - val_loss: 0.0855\n",
            "Epoch 1228/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0718 - val_loss: 0.0856\n",
            "Epoch 1229/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0717 - val_loss: 0.0857\n",
            "Epoch 1230/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.0717 - val_loss: 0.0860\n",
            "Epoch 1231/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0716 - val_loss: 0.0858\n",
            "Epoch 1232/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.0715 - val_loss: 0.0858\n",
            "Epoch 1233/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0714 - val_loss: 0.0857\n",
            "Epoch 1234/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0714 - val_loss: 0.0857\n",
            "Epoch 1235/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0713 - val_loss: 0.0856\n",
            "Epoch 1236/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0711 - val_loss: 0.0856\n",
            "Epoch 1237/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.0711 - val_loss: 0.0857\n",
            "Epoch 1238/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0710 - val_loss: 0.0857\n",
            "Epoch 1239/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.0709 - val_loss: 0.0857\n",
            "Epoch 1240/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0709 - val_loss: 0.0858\n",
            "Epoch 1241/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0708 - val_loss: 0.0856\n",
            "Epoch 1242/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.0707 - val_loss: 0.0853\n",
            "Epoch 1243/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.0706 - val_loss: 0.0850\n",
            "Epoch 1244/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0705 - val_loss: 0.0847\n",
            "Epoch 1245/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.0705 - val_loss: 0.0843\n",
            "Epoch 1246/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0703 - val_loss: 0.0841\n",
            "Epoch 1247/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.0703 - val_loss: 0.0841\n",
            "Epoch 1248/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.0702 - val_loss: 0.0839\n",
            "Epoch 1249/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.0701 - val_loss: 0.0837\n",
            "Epoch 1250/2000\n",
            "80/80 [==============================] - 0s 253us/step - loss: 0.0701 - val_loss: 0.0834\n",
            "Epoch 1251/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.0700 - val_loss: 0.0835\n",
            "Epoch 1252/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0699 - val_loss: 0.0835\n",
            "Epoch 1253/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.0698 - val_loss: 0.0835\n",
            "Epoch 1254/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.0697 - val_loss: 0.0834\n",
            "Epoch 1255/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.0697 - val_loss: 0.0833\n",
            "Epoch 1256/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.0697 - val_loss: 0.0834\n",
            "Epoch 1257/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.0696 - val_loss: 0.0833\n",
            "Epoch 1258/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0695 - val_loss: 0.0831\n",
            "Epoch 1259/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.0694 - val_loss: 0.0829\n",
            "Epoch 1260/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.0693 - val_loss: 0.0829\n",
            "Epoch 1261/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.0692 - val_loss: 0.0825\n",
            "Epoch 1262/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0691 - val_loss: 0.0826\n",
            "Epoch 1263/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0693 - val_loss: 0.0821\n",
            "Epoch 1264/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0692 - val_loss: 0.0821\n",
            "Epoch 1265/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.0691 - val_loss: 0.0821\n",
            "Epoch 1266/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.0690 - val_loss: 0.0821\n",
            "Epoch 1267/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0690 - val_loss: 0.0822\n",
            "Epoch 1268/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0687 - val_loss: 0.0822\n",
            "Epoch 1269/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0687 - val_loss: 0.0822\n",
            "Epoch 1270/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.0686 - val_loss: 0.0821\n",
            "Epoch 1271/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.0685 - val_loss: 0.0820\n",
            "Epoch 1272/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0686 - val_loss: 0.0814\n",
            "Epoch 1273/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.0683 - val_loss: 0.0815\n",
            "Epoch 1274/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0683 - val_loss: 0.0813\n",
            "Epoch 1275/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0683 - val_loss: 0.0813\n",
            "Epoch 1276/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0682 - val_loss: 0.0812\n",
            "Epoch 1277/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0680 - val_loss: 0.0809\n",
            "Epoch 1278/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.0679 - val_loss: 0.0808\n",
            "Epoch 1279/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0679 - val_loss: 0.0804\n",
            "Epoch 1280/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0678 - val_loss: 0.0804\n",
            "Epoch 1281/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.0677 - val_loss: 0.0803\n",
            "Epoch 1282/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0676 - val_loss: 0.0803\n",
            "Epoch 1283/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0676 - val_loss: 0.0803\n",
            "Epoch 1284/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0676 - val_loss: 0.0804\n",
            "Epoch 1285/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.0674 - val_loss: 0.0802\n",
            "Epoch 1286/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0673 - val_loss: 0.0801\n",
            "Epoch 1287/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.0672 - val_loss: 0.0798\n",
            "Epoch 1288/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0672 - val_loss: 0.0797\n",
            "Epoch 1289/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.0671 - val_loss: 0.0793\n",
            "Epoch 1290/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.0670 - val_loss: 0.0791\n",
            "Epoch 1291/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.0669 - val_loss: 0.0789\n",
            "Epoch 1292/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0669 - val_loss: 0.0788\n",
            "Epoch 1293/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.0668 - val_loss: 0.0788\n",
            "Epoch 1294/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.0667 - val_loss: 0.0788\n",
            "Epoch 1295/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.0667 - val_loss: 0.0789\n",
            "Epoch 1296/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0666 - val_loss: 0.0786\n",
            "Epoch 1297/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 0.0665 - val_loss: 0.0783\n",
            "Epoch 1298/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.0664 - val_loss: 0.0783\n",
            "Epoch 1299/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.0663 - val_loss: 0.0784\n",
            "Epoch 1300/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.0663 - val_loss: 0.0786\n",
            "Epoch 1301/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0664 - val_loss: 0.0786\n",
            "Epoch 1302/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0665 - val_loss: 0.0783\n",
            "Epoch 1303/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.0662 - val_loss: 0.0780\n",
            "Epoch 1304/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0660 - val_loss: 0.0777\n",
            "Epoch 1305/2000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.0659 - val_loss: 0.0774\n",
            "Epoch 1306/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.0658 - val_loss: 0.0771\n",
            "Epoch 1307/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.0658 - val_loss: 0.0766\n",
            "Epoch 1308/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.0657 - val_loss: 0.0765\n",
            "Epoch 1309/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.0657 - val_loss: 0.0765\n",
            "Epoch 1310/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.0656 - val_loss: 0.0766\n",
            "Epoch 1311/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 0.0654 - val_loss: 0.0764\n",
            "Epoch 1312/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.0654 - val_loss: 0.0763\n",
            "Epoch 1313/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0653 - val_loss: 0.0762\n",
            "Epoch 1314/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0653 - val_loss: 0.0761\n",
            "Epoch 1315/2000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0651 - val_loss: 0.0759\n",
            "Epoch 1316/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0650 - val_loss: 0.0757\n",
            "Epoch 1317/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0650 - val_loss: 0.0755\n",
            "Epoch 1318/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.0649 - val_loss: 0.0753\n",
            "Epoch 1319/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.0648 - val_loss: 0.0750\n",
            "Epoch 1320/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0647 - val_loss: 0.0749\n",
            "Epoch 1321/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0647 - val_loss: 0.0749\n",
            "Epoch 1322/2000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0646 - val_loss: 0.0749\n",
            "Epoch 1323/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.0645 - val_loss: 0.0748\n",
            "Epoch 1324/2000\n",
            "80/80 [==============================] - 0s 249us/step - loss: 0.0644 - val_loss: 0.0748\n",
            "Epoch 1325/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.0643 - val_loss: 0.0747\n",
            "Epoch 1326/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0643 - val_loss: 0.0746\n",
            "Epoch 1327/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.0642 - val_loss: 0.0746\n",
            "Epoch 1328/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.0642 - val_loss: 0.0745\n",
            "Epoch 1329/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.0642 - val_loss: 0.0745\n",
            "Epoch 1330/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0641 - val_loss: 0.0745\n",
            "Epoch 1331/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.0641 - val_loss: 0.0746\n",
            "Epoch 1332/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.0640 - val_loss: 0.0746\n",
            "Epoch 1333/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0638 - val_loss: 0.0743\n",
            "Epoch 1334/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0637 - val_loss: 0.0738\n",
            "Epoch 1335/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0636 - val_loss: 0.0734\n",
            "Epoch 1336/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0635 - val_loss: 0.0732\n",
            "Epoch 1337/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.0635 - val_loss: 0.0732\n",
            "Epoch 1338/2000\n",
            "80/80 [==============================] - 0s 249us/step - loss: 0.0634 - val_loss: 0.0732\n",
            "Epoch 1339/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0634 - val_loss: 0.0731\n",
            "Epoch 1340/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.0633 - val_loss: 0.0731\n",
            "Epoch 1341/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0632 - val_loss: 0.0729\n",
            "Epoch 1342/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0631 - val_loss: 0.0728\n",
            "Epoch 1343/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0631 - val_loss: 0.0725\n",
            "Epoch 1344/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.0630 - val_loss: 0.0722\n",
            "Epoch 1345/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0629 - val_loss: 0.0722\n",
            "Epoch 1346/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.0629 - val_loss: 0.0723\n",
            "Epoch 1347/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0627 - val_loss: 0.0723\n",
            "Epoch 1348/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.0626 - val_loss: 0.0721\n",
            "Epoch 1349/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.0627 - val_loss: 0.0719\n",
            "Epoch 1350/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0626 - val_loss: 0.0717\n",
            "Epoch 1351/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0626 - val_loss: 0.0717\n",
            "Epoch 1352/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.0625 - val_loss: 0.0718\n",
            "Epoch 1353/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0624 - val_loss: 0.0717\n",
            "Epoch 1354/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.0622 - val_loss: 0.0716\n",
            "Epoch 1355/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.0621 - val_loss: 0.0715\n",
            "Epoch 1356/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.0620 - val_loss: 0.0714\n",
            "Epoch 1357/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0620 - val_loss: 0.0715\n",
            "Epoch 1358/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0619 - val_loss: 0.0714\n",
            "Epoch 1359/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.0617 - val_loss: 0.0714\n",
            "Epoch 1360/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0617 - val_loss: 0.0713\n",
            "Epoch 1361/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0616 - val_loss: 0.0713\n",
            "Epoch 1362/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.0615 - val_loss: 0.0712\n",
            "Epoch 1363/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0614 - val_loss: 0.0711\n",
            "Epoch 1364/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0614 - val_loss: 0.0710\n",
            "Epoch 1365/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.0613 - val_loss: 0.0709\n",
            "Epoch 1366/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0613 - val_loss: 0.0708\n",
            "Epoch 1367/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.0613 - val_loss: 0.0705\n",
            "Epoch 1368/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.0611 - val_loss: 0.0703\n",
            "Epoch 1369/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0611 - val_loss: 0.0702\n",
            "Epoch 1370/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0609 - val_loss: 0.0703\n",
            "Epoch 1371/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0608 - val_loss: 0.0703\n",
            "Epoch 1372/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0608 - val_loss: 0.0703\n",
            "Epoch 1373/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0607 - val_loss: 0.0703\n",
            "Epoch 1374/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0606 - val_loss: 0.0702\n",
            "Epoch 1375/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0606 - val_loss: 0.0700\n",
            "Epoch 1376/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0604 - val_loss: 0.0700\n",
            "Epoch 1377/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0604 - val_loss: 0.0699\n",
            "Epoch 1378/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.0604 - val_loss: 0.0699\n",
            "Epoch 1379/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.0603 - val_loss: 0.0698\n",
            "Epoch 1380/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0602 - val_loss: 0.0696\n",
            "Epoch 1381/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0601 - val_loss: 0.0693\n",
            "Epoch 1382/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.0600 - val_loss: 0.0692\n",
            "Epoch 1383/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0599 - val_loss: 0.0691\n",
            "Epoch 1384/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.0599 - val_loss: 0.0690\n",
            "Epoch 1385/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.0598 - val_loss: 0.0689\n",
            "Epoch 1386/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0597 - val_loss: 0.0687\n",
            "Epoch 1387/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.0596 - val_loss: 0.0685\n",
            "Epoch 1388/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0596 - val_loss: 0.0685\n",
            "Epoch 1389/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0595 - val_loss: 0.0684\n",
            "Epoch 1390/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.0595 - val_loss: 0.0684\n",
            "Epoch 1391/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0594 - val_loss: 0.0683\n",
            "Epoch 1392/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 0.0593 - val_loss: 0.0683\n",
            "Epoch 1393/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.0593 - val_loss: 0.0680\n",
            "Epoch 1394/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 0.0593 - val_loss: 0.0678\n",
            "Epoch 1395/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.0593 - val_loss: 0.0677\n",
            "Epoch 1396/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0591 - val_loss: 0.0677\n",
            "Epoch 1397/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.0590 - val_loss: 0.0677\n",
            "Epoch 1398/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0589 - val_loss: 0.0673\n",
            "Epoch 1399/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0588 - val_loss: 0.0672\n",
            "Epoch 1400/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.0587 - val_loss: 0.0670\n",
            "Epoch 1401/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0587 - val_loss: 0.0667\n",
            "Epoch 1402/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0586 - val_loss: 0.0665\n",
            "Epoch 1403/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.0586 - val_loss: 0.0664\n",
            "Epoch 1404/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0585 - val_loss: 0.0664\n",
            "Epoch 1405/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.0584 - val_loss: 0.0664\n",
            "Epoch 1406/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.0584 - val_loss: 0.0666\n",
            "Epoch 1407/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0585 - val_loss: 0.0664\n",
            "Epoch 1408/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0583 - val_loss: 0.0664\n",
            "Epoch 1409/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0582 - val_loss: 0.0664\n",
            "Epoch 1410/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0581 - val_loss: 0.0662\n",
            "Epoch 1411/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.0581 - val_loss: 0.0658\n",
            "Epoch 1412/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0579 - val_loss: 0.0656\n",
            "Epoch 1413/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.0579 - val_loss: 0.0654\n",
            "Epoch 1414/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0578 - val_loss: 0.0654\n",
            "Epoch 1415/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 0.0578 - val_loss: 0.0653\n",
            "Epoch 1416/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.0577 - val_loss: 0.0653\n",
            "Epoch 1417/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 0.0576 - val_loss: 0.0652\n",
            "Epoch 1418/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0576 - val_loss: 0.0652\n",
            "Epoch 1419/2000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0575 - val_loss: 0.0651\n",
            "Epoch 1420/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0575 - val_loss: 0.0652\n",
            "Epoch 1421/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.0574 - val_loss: 0.0649\n",
            "Epoch 1422/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.0573 - val_loss: 0.0648\n",
            "Epoch 1423/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.0572 - val_loss: 0.0648\n",
            "Epoch 1424/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.0571 - val_loss: 0.0647\n",
            "Epoch 1425/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0571 - val_loss: 0.0647\n",
            "Epoch 1426/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0570 - val_loss: 0.0646\n",
            "Epoch 1427/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.0569 - val_loss: 0.0644\n",
            "Epoch 1428/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0569 - val_loss: 0.0641\n",
            "Epoch 1429/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0568 - val_loss: 0.0640\n",
            "Epoch 1430/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.0568 - val_loss: 0.0641\n",
            "Epoch 1431/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.0567 - val_loss: 0.0642\n",
            "Epoch 1432/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0566 - val_loss: 0.0641\n",
            "Epoch 1433/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 0.0566 - val_loss: 0.0641\n",
            "Epoch 1434/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.0565 - val_loss: 0.0637\n",
            "Epoch 1435/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0564 - val_loss: 0.0637\n",
            "Epoch 1436/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0564 - val_loss: 0.0637\n",
            "Epoch 1437/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 0.0566 - val_loss: 0.0637\n",
            "Epoch 1438/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0563 - val_loss: 0.0634\n",
            "Epoch 1439/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0563 - val_loss: 0.0634\n",
            "Epoch 1440/2000\n",
            "80/80 [==============================] - 0s 511us/step - loss: 0.0562 - val_loss: 0.0631\n",
            "Epoch 1441/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 0.0561 - val_loss: 0.0631\n",
            "Epoch 1442/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.0560 - val_loss: 0.0630\n",
            "Epoch 1443/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.0559 - val_loss: 0.0629\n",
            "Epoch 1444/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.0558 - val_loss: 0.0628\n",
            "Epoch 1445/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.0557 - val_loss: 0.0628\n",
            "Epoch 1446/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.0558 - val_loss: 0.0629\n",
            "Epoch 1447/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.0557 - val_loss: 0.0627\n",
            "Epoch 1448/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0555 - val_loss: 0.0627\n",
            "Epoch 1449/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.0555 - val_loss: 0.0625\n",
            "Epoch 1450/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0554 - val_loss: 0.0625\n",
            "Epoch 1451/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.0554 - val_loss: 0.0625\n",
            "Epoch 1452/2000\n",
            "80/80 [==============================] - 0s 249us/step - loss: 0.0554 - val_loss: 0.0622\n",
            "Epoch 1453/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.0552 - val_loss: 0.0622\n",
            "Epoch 1454/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.0552 - val_loss: 0.0622\n",
            "Epoch 1455/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0551 - val_loss: 0.0623\n",
            "Epoch 1456/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0551 - val_loss: 0.0622\n",
            "Epoch 1457/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.0549 - val_loss: 0.0618\n",
            "Epoch 1458/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0549 - val_loss: 0.0617\n",
            "Epoch 1459/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0548 - val_loss: 0.0615\n",
            "Epoch 1460/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.0547 - val_loss: 0.0611\n",
            "Epoch 1461/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0547 - val_loss: 0.0610\n",
            "Epoch 1462/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.0548 - val_loss: 0.0607\n",
            "Epoch 1463/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.0547 - val_loss: 0.0605\n",
            "Epoch 1464/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.0546 - val_loss: 0.0604\n",
            "Epoch 1465/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.0545 - val_loss: 0.0604\n",
            "Epoch 1466/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0545 - val_loss: 0.0604\n",
            "Epoch 1467/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.0545 - val_loss: 0.0609\n",
            "Epoch 1468/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0545 - val_loss: 0.0609\n",
            "Epoch 1469/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0546 - val_loss: 0.0615\n",
            "Epoch 1470/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0547 - val_loss: 0.0608\n",
            "Epoch 1471/2000\n",
            "80/80 [==============================] - 0s 420us/step - loss: 0.0545 - val_loss: 0.0605\n",
            "Epoch 1472/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.0541 - val_loss: 0.0603\n",
            "Epoch 1473/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.0542 - val_loss: 0.0605\n",
            "Epoch 1474/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.0541 - val_loss: 0.0602\n",
            "Epoch 1475/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0540 - val_loss: 0.0605\n",
            "Epoch 1476/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0540 - val_loss: 0.0601\n",
            "Epoch 1477/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0540 - val_loss: 0.0598\n",
            "Epoch 1478/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.0538 - val_loss: 0.0596\n",
            "Epoch 1479/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0538 - val_loss: 0.0593\n",
            "Epoch 1480/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0536 - val_loss: 0.0590\n",
            "Epoch 1481/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0535 - val_loss: 0.0593\n",
            "Epoch 1482/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0536 - val_loss: 0.0589\n",
            "Epoch 1483/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0535 - val_loss: 0.0589\n",
            "Epoch 1484/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0532 - val_loss: 0.0591\n",
            "Epoch 1485/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.0535 - val_loss: 0.0595\n",
            "Epoch 1486/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0532 - val_loss: 0.0593\n",
            "Epoch 1487/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.0533 - val_loss: 0.0594\n",
            "Epoch 1488/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0533 - val_loss: 0.0586\n",
            "Epoch 1489/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0530 - val_loss: 0.0586\n",
            "Epoch 1490/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.0529 - val_loss: 0.0582\n",
            "Epoch 1491/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0528 - val_loss: 0.0579\n",
            "Epoch 1492/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0528 - val_loss: 0.0579\n",
            "Epoch 1493/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0528 - val_loss: 0.0578\n",
            "Epoch 1494/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.0526 - val_loss: 0.0578\n",
            "Epoch 1495/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0525 - val_loss: 0.0577\n",
            "Epoch 1496/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0524 - val_loss: 0.0576\n",
            "Epoch 1497/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0524 - val_loss: 0.0575\n",
            "Epoch 1498/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0524 - val_loss: 0.0578\n",
            "Epoch 1499/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0524 - val_loss: 0.0577\n",
            "Epoch 1500/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.0523 - val_loss: 0.0579\n",
            "Epoch 1501/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0522 - val_loss: 0.0576\n",
            "Epoch 1502/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0521 - val_loss: 0.0575\n",
            "Epoch 1503/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0520 - val_loss: 0.0573\n",
            "Epoch 1504/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0519 - val_loss: 0.0572\n",
            "Epoch 1505/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0519 - val_loss: 0.0571\n",
            "Epoch 1506/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.0517 - val_loss: 0.0571\n",
            "Epoch 1507/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.0517 - val_loss: 0.0572\n",
            "Epoch 1508/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.0517 - val_loss: 0.0573\n",
            "Epoch 1509/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.0516 - val_loss: 0.0572\n",
            "Epoch 1510/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.0515 - val_loss: 0.0570\n",
            "Epoch 1511/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.0515 - val_loss: 0.0566\n",
            "Epoch 1512/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0514 - val_loss: 0.0564\n",
            "Epoch 1513/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0513 - val_loss: 0.0562\n",
            "Epoch 1514/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0512 - val_loss: 0.0561\n",
            "Epoch 1515/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0512 - val_loss: 0.0560\n",
            "Epoch 1516/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0511 - val_loss: 0.0560\n",
            "Epoch 1517/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 0.0511 - val_loss: 0.0561\n",
            "Epoch 1518/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.0510 - val_loss: 0.0560\n",
            "Epoch 1519/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.0509 - val_loss: 0.0559\n",
            "Epoch 1520/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.0509 - val_loss: 0.0555\n",
            "Epoch 1521/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0508 - val_loss: 0.0555\n",
            "Epoch 1522/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0507 - val_loss: 0.0554\n",
            "Epoch 1523/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0507 - val_loss: 0.0555\n",
            "Epoch 1524/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0506 - val_loss: 0.0552\n",
            "Epoch 1525/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0505 - val_loss: 0.0552\n",
            "Epoch 1526/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0505 - val_loss: 0.0551\n",
            "Epoch 1527/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0504 - val_loss: 0.0550\n",
            "Epoch 1528/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.0503 - val_loss: 0.0550\n",
            "Epoch 1529/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0503 - val_loss: 0.0550\n",
            "Epoch 1530/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0502 - val_loss: 0.0549\n",
            "Epoch 1531/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0501 - val_loss: 0.0548\n",
            "Epoch 1532/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0500 - val_loss: 0.0548\n",
            "Epoch 1533/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0500 - val_loss: 0.0546\n",
            "Epoch 1534/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0500 - val_loss: 0.0546\n",
            "Epoch 1535/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.0499 - val_loss: 0.0543\n",
            "Epoch 1536/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0498 - val_loss: 0.0541\n",
            "Epoch 1537/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.0498 - val_loss: 0.0542\n",
            "Epoch 1538/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0497 - val_loss: 0.0542\n",
            "Epoch 1539/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0496 - val_loss: 0.0541\n",
            "Epoch 1540/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.0500 - val_loss: 0.0542\n",
            "Epoch 1541/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0496 - val_loss: 0.0539\n",
            "Epoch 1542/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0496 - val_loss: 0.0540\n",
            "Epoch 1543/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.0496 - val_loss: 0.0536\n",
            "Epoch 1544/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 0.0494 - val_loss: 0.0536\n",
            "Epoch 1545/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0495 - val_loss: 0.0535\n",
            "Epoch 1546/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0498 - val_loss: 0.0532\n",
            "Epoch 1547/2000\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.0495 - val_loss: 0.0528\n",
            "Epoch 1548/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0492 - val_loss: 0.0529\n",
            "Epoch 1549/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0491 - val_loss: 0.0528\n",
            "Epoch 1550/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 0.0491 - val_loss: 0.0530\n",
            "Epoch 1551/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0490 - val_loss: 0.0528\n",
            "Epoch 1552/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.0491 - val_loss: 0.0527\n",
            "Epoch 1553/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0490 - val_loss: 0.0528\n",
            "Epoch 1554/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.0489 - val_loss: 0.0525\n",
            "Epoch 1555/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0491 - val_loss: 0.0524\n",
            "Epoch 1556/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.0489 - val_loss: 0.0519\n",
            "Epoch 1557/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0488 - val_loss: 0.0519\n",
            "Epoch 1558/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0486 - val_loss: 0.0518\n",
            "Epoch 1559/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.0486 - val_loss: 0.0518\n",
            "Epoch 1560/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0487 - val_loss: 0.0522\n",
            "Epoch 1561/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0489 - val_loss: 0.0523\n",
            "Epoch 1562/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0492 - val_loss: 0.0517\n",
            "Epoch 1563/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0483 - val_loss: 0.0514\n",
            "Epoch 1564/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0483 - val_loss: 0.0513\n",
            "Epoch 1565/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.0483 - val_loss: 0.0514\n",
            "Epoch 1566/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0483 - val_loss: 0.0512\n",
            "Epoch 1567/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0482 - val_loss: 0.0512\n",
            "Epoch 1568/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.0481 - val_loss: 0.0508\n",
            "Epoch 1569/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 0.0482 - val_loss: 0.0508\n",
            "Epoch 1570/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.0480 - val_loss: 0.0508\n",
            "Epoch 1571/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0479 - val_loss: 0.0511\n",
            "Epoch 1572/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0482 - val_loss: 0.0510\n",
            "Epoch 1573/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0480 - val_loss: 0.0509\n",
            "Epoch 1574/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0479 - val_loss: 0.0506\n",
            "Epoch 1575/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0479 - val_loss: 0.0508\n",
            "Epoch 1576/2000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0478 - val_loss: 0.0504\n",
            "Epoch 1577/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0476 - val_loss: 0.0503\n",
            "Epoch 1578/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0475 - val_loss: 0.0502\n",
            "Epoch 1579/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 0.0474 - val_loss: 0.0501\n",
            "Epoch 1580/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 0.0475 - val_loss: 0.0499\n",
            "Epoch 1581/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.0474 - val_loss: 0.0498\n",
            "Epoch 1582/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 0.0473 - val_loss: 0.0500\n",
            "Epoch 1583/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0473 - val_loss: 0.0499\n",
            "Epoch 1584/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0471 - val_loss: 0.0499\n",
            "Epoch 1585/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.0470 - val_loss: 0.0497\n",
            "Epoch 1586/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.0470 - val_loss: 0.0497\n",
            "Epoch 1587/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0470 - val_loss: 0.0496\n",
            "Epoch 1588/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0469 - val_loss: 0.0495\n",
            "Epoch 1589/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0468 - val_loss: 0.0493\n",
            "Epoch 1590/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0468 - val_loss: 0.0491\n",
            "Epoch 1591/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.0467 - val_loss: 0.0489\n",
            "Epoch 1592/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0467 - val_loss: 0.0487\n",
            "Epoch 1593/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.0466 - val_loss: 0.0486\n",
            "Epoch 1594/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.0466 - val_loss: 0.0486\n",
            "Epoch 1595/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0465 - val_loss: 0.0484\n",
            "Epoch 1596/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0464 - val_loss: 0.0484\n",
            "Epoch 1597/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0464 - val_loss: 0.0485\n",
            "Epoch 1598/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0464 - val_loss: 0.0482\n",
            "Epoch 1599/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0463 - val_loss: 0.0481\n",
            "Epoch 1600/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0462 - val_loss: 0.0479\n",
            "Epoch 1601/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.0461 - val_loss: 0.0479\n",
            "Epoch 1602/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0461 - val_loss: 0.0479\n",
            "Epoch 1603/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.0462 - val_loss: 0.0482\n",
            "Epoch 1604/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0463 - val_loss: 0.0479\n",
            "Epoch 1605/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0461 - val_loss: 0.0479\n",
            "Epoch 1606/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.0459 - val_loss: 0.0476\n",
            "Epoch 1607/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0459 - val_loss: 0.0476\n",
            "Epoch 1608/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.0458 - val_loss: 0.0475\n",
            "Epoch 1609/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.0459 - val_loss: 0.0477\n",
            "Epoch 1610/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.0458 - val_loss: 0.0474\n",
            "Epoch 1611/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.0457 - val_loss: 0.0473\n",
            "Epoch 1612/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0456 - val_loss: 0.0469\n",
            "Epoch 1613/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.0456 - val_loss: 0.0468\n",
            "Epoch 1614/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0455 - val_loss: 0.0467\n",
            "Epoch 1615/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.0455 - val_loss: 0.0468\n",
            "Epoch 1616/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.0453 - val_loss: 0.0468\n",
            "Epoch 1617/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.0453 - val_loss: 0.0470\n",
            "Epoch 1618/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0453 - val_loss: 0.0469\n",
            "Epoch 1619/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0453 - val_loss: 0.0470\n",
            "Epoch 1620/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0453 - val_loss: 0.0464\n",
            "Epoch 1621/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0451 - val_loss: 0.0462\n",
            "Epoch 1622/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0452 - val_loss: 0.0461\n",
            "Epoch 1623/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0449 - val_loss: 0.0460\n",
            "Epoch 1624/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0449 - val_loss: 0.0458\n",
            "Epoch 1625/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.0448 - val_loss: 0.0458\n",
            "Epoch 1626/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0448 - val_loss: 0.0456\n",
            "Epoch 1627/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.0448 - val_loss: 0.0455\n",
            "Epoch 1628/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.0447 - val_loss: 0.0454\n",
            "Epoch 1629/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0448 - val_loss: 0.0459\n",
            "Epoch 1630/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.0451 - val_loss: 0.0452\n",
            "Epoch 1631/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0448 - val_loss: 0.0450\n",
            "Epoch 1632/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.0446 - val_loss: 0.0447\n",
            "Epoch 1633/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.0447 - val_loss: 0.0452\n",
            "Epoch 1634/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0448 - val_loss: 0.0449\n",
            "Epoch 1635/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.0448 - val_loss: 0.0449\n",
            "Epoch 1636/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0444 - val_loss: 0.0448\n",
            "Epoch 1637/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.0445 - val_loss: 0.0451\n",
            "Epoch 1638/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.0445 - val_loss: 0.0446\n",
            "Epoch 1639/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0447 - val_loss: 0.0443\n",
            "Epoch 1640/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0443 - val_loss: 0.0443\n",
            "Epoch 1641/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0444 - val_loss: 0.0442\n",
            "Epoch 1642/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0441 - val_loss: 0.0443\n",
            "Epoch 1643/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.0441 - val_loss: 0.0440\n",
            "Epoch 1644/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0440 - val_loss: 0.0438\n",
            "Epoch 1645/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.0438 - val_loss: 0.0436\n",
            "Epoch 1646/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0437 - val_loss: 0.0436\n",
            "Epoch 1647/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0437 - val_loss: 0.0435\n",
            "Epoch 1648/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0436 - val_loss: 0.0434\n",
            "Epoch 1649/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 0.0436 - val_loss: 0.0435\n",
            "Epoch 1650/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.0435 - val_loss: 0.0434\n",
            "Epoch 1651/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0435 - val_loss: 0.0434\n",
            "Epoch 1652/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0435 - val_loss: 0.0432\n",
            "Epoch 1653/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0434 - val_loss: 0.0433\n",
            "Epoch 1654/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.0435 - val_loss: 0.0429\n",
            "Epoch 1655/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.0433 - val_loss: 0.0430\n",
            "Epoch 1656/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0433 - val_loss: 0.0428\n",
            "Epoch 1657/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0434 - val_loss: 0.0429\n",
            "Epoch 1658/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0432 - val_loss: 0.0426\n",
            "Epoch 1659/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0431 - val_loss: 0.0427\n",
            "Epoch 1660/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0431 - val_loss: 0.0426\n",
            "Epoch 1661/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0430 - val_loss: 0.0427\n",
            "Epoch 1662/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.0429 - val_loss: 0.0426\n",
            "Epoch 1663/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 0.0430 - val_loss: 0.0427\n",
            "Epoch 1664/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.0428 - val_loss: 0.0425\n",
            "Epoch 1665/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0427 - val_loss: 0.0424\n",
            "Epoch 1666/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0427 - val_loss: 0.0423\n",
            "Epoch 1667/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.0426 - val_loss: 0.0421\n",
            "Epoch 1668/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.0427 - val_loss: 0.0424\n",
            "Epoch 1669/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.0428 - val_loss: 0.0419\n",
            "Epoch 1670/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.0425 - val_loss: 0.0420\n",
            "Epoch 1671/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.0425 - val_loss: 0.0417\n",
            "Epoch 1672/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.0424 - val_loss: 0.0418\n",
            "Epoch 1673/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0424 - val_loss: 0.0417\n",
            "Epoch 1674/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.0423 - val_loss: 0.0414\n",
            "Epoch 1675/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0424 - val_loss: 0.0418\n",
            "Epoch 1676/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.0427 - val_loss: 0.0415\n",
            "Epoch 1677/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0427 - val_loss: 0.0416\n",
            "Epoch 1678/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0424 - val_loss: 0.0416\n",
            "Epoch 1679/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.0431 - val_loss: 0.0431\n",
            "Epoch 1680/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0432 - val_loss: 0.0425\n",
            "Epoch 1681/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.0432 - val_loss: 0.0430\n",
            "Epoch 1682/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.0431 - val_loss: 0.0422\n",
            "Epoch 1683/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.0426 - val_loss: 0.0429\n",
            "Epoch 1684/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0430 - val_loss: 0.0423\n",
            "Epoch 1685/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.0430 - val_loss: 0.0427\n",
            "Epoch 1686/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0433 - val_loss: 0.0415\n",
            "Epoch 1687/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0424 - val_loss: 0.0415\n",
            "Epoch 1688/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.0422 - val_loss: 0.0421\n",
            "Epoch 1689/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0433 - val_loss: 0.0421\n",
            "Epoch 1690/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0429 - val_loss: 0.0427\n",
            "Epoch 1691/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0432 - val_loss: 0.0430\n",
            "Epoch 1692/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.0430 - val_loss: 0.0419\n",
            "Epoch 1693/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0430 - val_loss: 0.0426\n",
            "Epoch 1694/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.0430 - val_loss: 0.0409\n",
            "Epoch 1695/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0426 - val_loss: 0.0409\n",
            "Epoch 1696/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.0418 - val_loss: 0.0398\n",
            "Epoch 1697/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0413 - val_loss: 0.0403\n",
            "Epoch 1698/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 0.0415 - val_loss: 0.0396\n",
            "Epoch 1699/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.0411 - val_loss: 0.0397\n",
            "Epoch 1700/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.0413 - val_loss: 0.0390\n",
            "Epoch 1701/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.0411 - val_loss: 0.0389\n",
            "Epoch 1702/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.0410 - val_loss: 0.0387\n",
            "Epoch 1703/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.0409 - val_loss: 0.0388\n",
            "Epoch 1704/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0408 - val_loss: 0.0389\n",
            "Epoch 1705/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0408 - val_loss: 0.0394\n",
            "Epoch 1706/2000\n",
            "80/80 [==============================] - 0s 249us/step - loss: 0.0408 - val_loss: 0.0391\n",
            "Epoch 1707/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.0407 - val_loss: 0.0392\n",
            "Epoch 1708/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0407 - val_loss: 0.0387\n",
            "Epoch 1709/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.0407 - val_loss: 0.0384\n",
            "Epoch 1710/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.0405 - val_loss: 0.0384\n",
            "Epoch 1711/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.0404 - val_loss: 0.0382\n",
            "Epoch 1712/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.0403 - val_loss: 0.0382\n",
            "Epoch 1713/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0404 - val_loss: 0.0381\n",
            "Epoch 1714/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0405 - val_loss: 0.0383\n",
            "Epoch 1715/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0405 - val_loss: 0.0380\n",
            "Epoch 1716/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.0403 - val_loss: 0.0382\n",
            "Epoch 1717/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.0402 - val_loss: 0.0379\n",
            "Epoch 1718/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.0400 - val_loss: 0.0379\n",
            "Epoch 1719/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.0400 - val_loss: 0.0376\n",
            "Epoch 1720/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0399 - val_loss: 0.0376\n",
            "Epoch 1721/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.0399 - val_loss: 0.0374\n",
            "Epoch 1722/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0398 - val_loss: 0.0374\n",
            "Epoch 1723/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0397 - val_loss: 0.0373\n",
            "Epoch 1724/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.0398 - val_loss: 0.0372\n",
            "Epoch 1725/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.0397 - val_loss: 0.0372\n",
            "Epoch 1726/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0396 - val_loss: 0.0370\n",
            "Epoch 1727/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.0396 - val_loss: 0.0370\n",
            "Epoch 1728/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0396 - val_loss: 0.0369\n",
            "Epoch 1729/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.0395 - val_loss: 0.0370\n",
            "Epoch 1730/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.0395 - val_loss: 0.0365\n",
            "Epoch 1731/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0394 - val_loss: 0.0364\n",
            "Epoch 1732/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.0393 - val_loss: 0.0362\n",
            "Epoch 1733/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0393 - val_loss: 0.0363\n",
            "Epoch 1734/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.0392 - val_loss: 0.0362\n",
            "Epoch 1735/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.0392 - val_loss: 0.0361\n",
            "Epoch 1736/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.0391 - val_loss: 0.0360\n",
            "Epoch 1737/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.0391 - val_loss: 0.0360\n",
            "Epoch 1738/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.0390 - val_loss: 0.0358\n",
            "Epoch 1739/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.0390 - val_loss: 0.0357\n",
            "Epoch 1740/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0390 - val_loss: 0.0355\n",
            "Epoch 1741/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0390 - val_loss: 0.0358\n",
            "Epoch 1742/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.0390 - val_loss: 0.0354\n",
            "Epoch 1743/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0388 - val_loss: 0.0353\n",
            "Epoch 1744/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0387 - val_loss: 0.0351\n",
            "Epoch 1745/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.0387 - val_loss: 0.0352\n",
            "Epoch 1746/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0386 - val_loss: 0.0351\n",
            "Epoch 1747/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.0387 - val_loss: 0.0356\n",
            "Epoch 1748/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0388 - val_loss: 0.0350\n",
            "Epoch 1749/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0385 - val_loss: 0.0350\n",
            "Epoch 1750/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.0385 - val_loss: 0.0347\n",
            "Epoch 1751/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0384 - val_loss: 0.0347\n",
            "Epoch 1752/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.0383 - val_loss: 0.0345\n",
            "Epoch 1753/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0383 - val_loss: 0.0346\n",
            "Epoch 1754/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0383 - val_loss: 0.0344\n",
            "Epoch 1755/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0382 - val_loss: 0.0347\n",
            "Epoch 1756/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.0383 - val_loss: 0.0344\n",
            "Epoch 1757/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.0382 - val_loss: 0.0348\n",
            "Epoch 1758/2000\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.0385 - val_loss: 0.0344\n",
            "Epoch 1759/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.0383 - val_loss: 0.0346\n",
            "Epoch 1760/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.0380 - val_loss: 0.0344\n",
            "Epoch 1761/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.0381 - val_loss: 0.0347\n",
            "Epoch 1762/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0382 - val_loss: 0.0341\n",
            "Epoch 1763/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0379 - val_loss: 0.0340\n",
            "Epoch 1764/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.0377 - val_loss: 0.0338\n",
            "Epoch 1765/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0377 - val_loss: 0.0339\n",
            "Epoch 1766/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0377 - val_loss: 0.0337\n",
            "Epoch 1767/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0376 - val_loss: 0.0338\n",
            "Epoch 1768/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 0.0375 - val_loss: 0.0336\n",
            "Epoch 1769/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0375 - val_loss: 0.0336\n",
            "Epoch 1770/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.0375 - val_loss: 0.0336\n",
            "Epoch 1771/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0374 - val_loss: 0.0335\n",
            "Epoch 1772/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.0375 - val_loss: 0.0338\n",
            "Epoch 1773/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.0374 - val_loss: 0.0334\n",
            "Epoch 1774/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0374 - val_loss: 0.0337\n",
            "Epoch 1775/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0374 - val_loss: 0.0331\n",
            "Epoch 1776/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.0371 - val_loss: 0.0333\n",
            "Epoch 1777/2000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0372 - val_loss: 0.0330\n",
            "Epoch 1778/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.0372 - val_loss: 0.0328\n",
            "Epoch 1779/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0371 - val_loss: 0.0328\n",
            "Epoch 1780/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0369 - val_loss: 0.0329\n",
            "Epoch 1781/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.0368 - val_loss: 0.0330\n",
            "Epoch 1782/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0368 - val_loss: 0.0331\n",
            "Epoch 1783/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.0368 - val_loss: 0.0329\n",
            "Epoch 1784/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.0369 - val_loss: 0.0326\n",
            "Epoch 1785/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0366 - val_loss: 0.0327\n",
            "Epoch 1786/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0366 - val_loss: 0.0324\n",
            "Epoch 1787/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0365 - val_loss: 0.0324\n",
            "Epoch 1788/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.0364 - val_loss: 0.0323\n",
            "Epoch 1789/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.0364 - val_loss: 0.0323\n",
            "Epoch 1790/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0363 - val_loss: 0.0323\n",
            "Epoch 1791/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0363 - val_loss: 0.0321\n",
            "Epoch 1792/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0363 - val_loss: 0.0322\n",
            "Epoch 1793/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0362 - val_loss: 0.0322\n",
            "Epoch 1794/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0363 - val_loss: 0.0324\n",
            "Epoch 1795/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.0363 - val_loss: 0.0319\n",
            "Epoch 1796/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 0.0361 - val_loss: 0.0319\n",
            "Epoch 1797/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0361 - val_loss: 0.0317\n",
            "Epoch 1798/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.0361 - val_loss: 0.0320\n",
            "Epoch 1799/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0361 - val_loss: 0.0316\n",
            "Epoch 1800/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.0359 - val_loss: 0.0321\n",
            "Epoch 1801/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0360 - val_loss: 0.0316\n",
            "Epoch 1802/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0358 - val_loss: 0.0317\n",
            "Epoch 1803/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.0358 - val_loss: 0.0313\n",
            "Epoch 1804/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0356 - val_loss: 0.0312\n",
            "Epoch 1805/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.0356 - val_loss: 0.0312\n",
            "Epoch 1806/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0356 - val_loss: 0.0310\n",
            "Epoch 1807/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0355 - val_loss: 0.0309\n",
            "Epoch 1808/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0355 - val_loss: 0.0307\n",
            "Epoch 1809/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0354 - val_loss: 0.0306\n",
            "Epoch 1810/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0353 - val_loss: 0.0306\n",
            "Epoch 1811/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 0.0353 - val_loss: 0.0306\n",
            "Epoch 1812/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0353 - val_loss: 0.0308\n",
            "Epoch 1813/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0352 - val_loss: 0.0306\n",
            "Epoch 1814/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0352 - val_loss: 0.0311\n",
            "Epoch 1815/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0352 - val_loss: 0.0307\n",
            "Epoch 1816/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0355 - val_loss: 0.0305\n",
            "Epoch 1817/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0350 - val_loss: 0.0303\n",
            "Epoch 1818/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.0351 - val_loss: 0.0302\n",
            "Epoch 1819/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0350 - val_loss: 0.0301\n",
            "Epoch 1820/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0349 - val_loss: 0.0300\n",
            "Epoch 1821/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0349 - val_loss: 0.0300\n",
            "Epoch 1822/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0347 - val_loss: 0.0299\n",
            "Epoch 1823/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.0347 - val_loss: 0.0299\n",
            "Epoch 1824/2000\n",
            "80/80 [==============================] - 0s 249us/step - loss: 0.0346 - val_loss: 0.0299\n",
            "Epoch 1825/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.0348 - val_loss: 0.0298\n",
            "Epoch 1826/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.0345 - val_loss: 0.0296\n",
            "Epoch 1827/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.0346 - val_loss: 0.0298\n",
            "Epoch 1828/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.0345 - val_loss: 0.0296\n",
            "Epoch 1829/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.0345 - val_loss: 0.0295\n",
            "Epoch 1830/2000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0344 - val_loss: 0.0295\n",
            "Epoch 1831/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0343 - val_loss: 0.0293\n",
            "Epoch 1832/2000\n",
            "80/80 [==============================] - 0s 249us/step - loss: 0.0344 - val_loss: 0.0294\n",
            "Epoch 1833/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.0342 - val_loss: 0.0291\n",
            "Epoch 1834/2000\n",
            "80/80 [==============================] - 0s 253us/step - loss: 0.0342 - val_loss: 0.0294\n",
            "Epoch 1835/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.0342 - val_loss: 0.0291\n",
            "Epoch 1836/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.0341 - val_loss: 0.0292\n",
            "Epoch 1837/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0341 - val_loss: 0.0289\n",
            "Epoch 1838/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.0340 - val_loss: 0.0290\n",
            "Epoch 1839/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.0340 - val_loss: 0.0287\n",
            "Epoch 1840/2000\n",
            "80/80 [==============================] - 0s 253us/step - loss: 0.0341 - val_loss: 0.0287\n",
            "Epoch 1841/2000\n",
            "80/80 [==============================] - 0s 253us/step - loss: 0.0339 - val_loss: 0.0286\n",
            "Epoch 1842/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 0.0338 - val_loss: 0.0285\n",
            "Epoch 1843/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0338 - val_loss: 0.0284\n",
            "Epoch 1844/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0337 - val_loss: 0.0284\n",
            "Epoch 1845/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0336 - val_loss: 0.0284\n",
            "Epoch 1846/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.0336 - val_loss: 0.0284\n",
            "Epoch 1847/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0335 - val_loss: 0.0283\n",
            "Epoch 1848/2000\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.0335 - val_loss: 0.0283\n",
            "Epoch 1849/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0335 - val_loss: 0.0282\n",
            "Epoch 1850/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.0334 - val_loss: 0.0280\n",
            "Epoch 1851/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0334 - val_loss: 0.0282\n",
            "Epoch 1852/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0334 - val_loss: 0.0279\n",
            "Epoch 1853/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0333 - val_loss: 0.0278\n",
            "Epoch 1854/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.0332 - val_loss: 0.0277\n",
            "Epoch 1855/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0332 - val_loss: 0.0279\n",
            "Epoch 1856/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.0332 - val_loss: 0.0276\n",
            "Epoch 1857/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0331 - val_loss: 0.0278\n",
            "Epoch 1858/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.0331 - val_loss: 0.0276\n",
            "Epoch 1859/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.0330 - val_loss: 0.0274\n",
            "Epoch 1860/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0330 - val_loss: 0.0275\n",
            "Epoch 1861/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0330 - val_loss: 0.0274\n",
            "Epoch 1862/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0332 - val_loss: 0.0282\n",
            "Epoch 1863/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0333 - val_loss: 0.0273\n",
            "Epoch 1864/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0328 - val_loss: 0.0275\n",
            "Epoch 1865/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.0328 - val_loss: 0.0271\n",
            "Epoch 1866/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0328 - val_loss: 0.0270\n",
            "Epoch 1867/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.0328 - val_loss: 0.0271\n",
            "Epoch 1868/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0326 - val_loss: 0.0269\n",
            "Epoch 1869/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.0326 - val_loss: 0.0270\n",
            "Epoch 1870/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.0325 - val_loss: 0.0268\n",
            "Epoch 1871/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0325 - val_loss: 0.0275\n",
            "Epoch 1872/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0327 - val_loss: 0.0272\n",
            "Epoch 1873/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.0329 - val_loss: 0.0275\n",
            "Epoch 1874/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0327 - val_loss: 0.0267\n",
            "Epoch 1875/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0326 - val_loss: 0.0266\n",
            "Epoch 1876/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0324 - val_loss: 0.0265\n",
            "Epoch 1877/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0323 - val_loss: 0.0265\n",
            "Epoch 1878/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0325 - val_loss: 0.0272\n",
            "Epoch 1879/2000\n",
            "80/80 [==============================] - 0s 253us/step - loss: 0.0324 - val_loss: 0.0265\n",
            "Epoch 1880/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0323 - val_loss: 0.0270\n",
            "Epoch 1881/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0323 - val_loss: 0.0264\n",
            "Epoch 1882/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0322 - val_loss: 0.0267\n",
            "Epoch 1883/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0321 - val_loss: 0.0262\n",
            "Epoch 1884/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.0322 - val_loss: 0.0261\n",
            "Epoch 1885/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0322 - val_loss: 0.0265\n",
            "Epoch 1886/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.0322 - val_loss: 0.0261\n",
            "Epoch 1887/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0318 - val_loss: 0.0262\n",
            "Epoch 1888/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.0318 - val_loss: 0.0259\n",
            "Epoch 1889/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.0317 - val_loss: 0.0259\n",
            "Epoch 1890/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0317 - val_loss: 0.0257\n",
            "Epoch 1891/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 0.0316 - val_loss: 0.0259\n",
            "Epoch 1892/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0316 - val_loss: 0.0257\n",
            "Epoch 1893/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0316 - val_loss: 0.0257\n",
            "Epoch 1894/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0315 - val_loss: 0.0256\n",
            "Epoch 1895/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 0.0315 - val_loss: 0.0255\n",
            "Epoch 1896/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0315 - val_loss: 0.0256\n",
            "Epoch 1897/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0314 - val_loss: 0.0255\n",
            "Epoch 1898/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0313 - val_loss: 0.0256\n",
            "Epoch 1899/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0313 - val_loss: 0.0254\n",
            "Epoch 1900/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0312 - val_loss: 0.0252\n",
            "Epoch 1901/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0312 - val_loss: 0.0253\n",
            "Epoch 1902/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.0311 - val_loss: 0.0252\n",
            "Epoch 1903/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.0313 - val_loss: 0.0253\n",
            "Epoch 1904/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0311 - val_loss: 0.0253\n",
            "Epoch 1905/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0311 - val_loss: 0.0251\n",
            "Epoch 1906/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.0311 - val_loss: 0.0251\n",
            "Epoch 1907/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0309 - val_loss: 0.0251\n",
            "Epoch 1908/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.0310 - val_loss: 0.0251\n",
            "Epoch 1909/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0312 - val_loss: 0.0260\n",
            "Epoch 1910/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0315 - val_loss: 0.0252\n",
            "Epoch 1911/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.0314 - val_loss: 0.0250\n",
            "Epoch 1912/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0310 - val_loss: 0.0247\n",
            "Epoch 1913/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0311 - val_loss: 0.0249\n",
            "Epoch 1914/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0314 - val_loss: 0.0261\n",
            "Epoch 1915/2000\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.0315 - val_loss: 0.0250\n",
            "Epoch 1916/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0312 - val_loss: 0.0254\n",
            "Epoch 1917/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0311 - val_loss: 0.0243\n",
            "Epoch 1918/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0308 - val_loss: 0.0243\n",
            "Epoch 1919/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0306 - val_loss: 0.0244\n",
            "Epoch 1920/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0305 - val_loss: 0.0244\n",
            "Epoch 1921/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0305 - val_loss: 0.0243\n",
            "Epoch 1922/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.0304 - val_loss: 0.0242\n",
            "Epoch 1923/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.0303 - val_loss: 0.0240\n",
            "Epoch 1924/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0303 - val_loss: 0.0241\n",
            "Epoch 1925/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0303 - val_loss: 0.0239\n",
            "Epoch 1926/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0303 - val_loss: 0.0238\n",
            "Epoch 1927/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.0302 - val_loss: 0.0241\n",
            "Epoch 1928/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.0302 - val_loss: 0.0237\n",
            "Epoch 1929/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0301 - val_loss: 0.0241\n",
            "Epoch 1930/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0301 - val_loss: 0.0237\n",
            "Epoch 1931/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.0301 - val_loss: 0.0241\n",
            "Epoch 1932/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0301 - val_loss: 0.0236\n",
            "Epoch 1933/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0302 - val_loss: 0.0235\n",
            "Epoch 1934/2000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.0301 - val_loss: 0.0237\n",
            "Epoch 1935/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.0300 - val_loss: 0.0234\n",
            "Epoch 1936/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0300 - val_loss: 0.0240\n",
            "Epoch 1937/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0300 - val_loss: 0.0234\n",
            "Epoch 1938/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.0301 - val_loss: 0.0238\n",
            "Epoch 1939/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0299 - val_loss: 0.0233\n",
            "Epoch 1940/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.0298 - val_loss: 0.0232\n",
            "Epoch 1941/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0300 - val_loss: 0.0245\n",
            "Epoch 1942/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.0304 - val_loss: 0.0237\n",
            "Epoch 1943/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0304 - val_loss: 0.0244\n",
            "Epoch 1944/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.0308 - val_loss: 0.0233\n",
            "Epoch 1945/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.0308 - val_loss: 0.0238\n",
            "Epoch 1946/2000\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.0308 - val_loss: 0.0243\n",
            "Epoch 1947/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 0.0301 - val_loss: 0.0235\n",
            "Epoch 1948/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0301 - val_loss: 0.0236\n",
            "Epoch 1949/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0297 - val_loss: 0.0228\n",
            "Epoch 1950/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.0294 - val_loss: 0.0230\n",
            "Epoch 1951/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0295 - val_loss: 0.0228\n",
            "Epoch 1952/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0294 - val_loss: 0.0227\n",
            "Epoch 1953/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 0.0295 - val_loss: 0.0233\n",
            "Epoch 1954/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0294 - val_loss: 0.0228\n",
            "Epoch 1955/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0296 - val_loss: 0.0232\n",
            "Epoch 1956/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0295 - val_loss: 0.0225\n",
            "Epoch 1957/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0295 - val_loss: 0.0226\n",
            "Epoch 1958/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.0296 - val_loss: 0.0233\n",
            "Epoch 1959/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0297 - val_loss: 0.0226\n",
            "Epoch 1960/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0293 - val_loss: 0.0242\n",
            "Epoch 1961/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.0297 - val_loss: 0.0230\n",
            "Epoch 1962/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0296 - val_loss: 0.0242\n",
            "Epoch 1963/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0297 - val_loss: 0.0228\n",
            "Epoch 1964/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0295 - val_loss: 0.0233\n",
            "Epoch 1965/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0294 - val_loss: 0.0222\n",
            "Epoch 1966/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0296 - val_loss: 0.0220\n",
            "Epoch 1967/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.0297 - val_loss: 0.0226\n",
            "Epoch 1968/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.0291 - val_loss: 0.0220\n",
            "Epoch 1969/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.0289 - val_loss: 0.0227\n",
            "Epoch 1970/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0290 - val_loss: 0.0219\n",
            "Epoch 1971/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0289 - val_loss: 0.0222\n",
            "Epoch 1972/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0286 - val_loss: 0.0219\n",
            "Epoch 1973/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.0287 - val_loss: 0.0218\n",
            "Epoch 1974/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0288 - val_loss: 0.0224\n",
            "Epoch 1975/2000\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0288 - val_loss: 0.0218\n",
            "Epoch 1976/2000\n",
            "80/80 [==============================] - 0s 237us/step - loss: 0.0287 - val_loss: 0.0218\n",
            "Epoch 1977/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0284 - val_loss: 0.0217\n",
            "Epoch 1978/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0283 - val_loss: 0.0216\n",
            "Epoch 1979/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0282 - val_loss: 0.0216\n",
            "Epoch 1980/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0282 - val_loss: 0.0216\n",
            "Epoch 1981/2000\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.0282 - val_loss: 0.0215\n",
            "Epoch 1982/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.0282 - val_loss: 0.0216\n",
            "Epoch 1983/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0281 - val_loss: 0.0214\n",
            "Epoch 1984/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0281 - val_loss: 0.0214\n",
            "Epoch 1985/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.0280 - val_loss: 0.0214\n",
            "Epoch 1986/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.0280 - val_loss: 0.0214\n",
            "Epoch 1987/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 0.0280 - val_loss: 0.0212\n",
            "Epoch 1988/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.0279 - val_loss: 0.0213\n",
            "Epoch 1989/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 0.0279 - val_loss: 0.0211\n",
            "Epoch 1990/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.0280 - val_loss: 0.0212\n",
            "Epoch 1991/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.0279 - val_loss: 0.0212\n",
            "Epoch 1992/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.0279 - val_loss: 0.0212\n",
            "Epoch 1993/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.0281 - val_loss: 0.0224\n",
            "Epoch 1994/2000\n",
            "80/80 [==============================] - 0s 247us/step - loss: 0.0283 - val_loss: 0.0210\n",
            "Epoch 1995/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.0279 - val_loss: 0.0211\n",
            "Epoch 1996/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 0.0277 - val_loss: 0.0209\n",
            "Epoch 1997/2000\n",
            "80/80 [==============================] - 0s 245us/step - loss: 0.0277 - val_loss: 0.0208\n",
            "Epoch 1998/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0276 - val_loss: 0.0208\n",
            "Epoch 1999/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.0275 - val_loss: 0.0207\n",
            "Epoch 2000/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.0275 - val_loss: 0.0207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJrPNKhgCIEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xf06QLHCRCM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "bbaa9218-9664-48dc-f16a-82315f6c8694"
      },
      "source": [
        "plt.scatter(range(20),results,c='r')\n",
        "plt.scatter(range(20),y_test,c='g')\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD8CAYAAACSCdTiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAQrPssYDsq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
