{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_15MI413.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK48I_mdPVIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "505cc8e7-2acd-49ec-ca89-3f0225181d91"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,LSTM\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaCEYdX3PX64",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "bf3b691e-d2a3-4501-aa84-cb3d4a222675"
      },
      "source": [
        "X = []\n",
        "Y = []\n",
        "X = [((x+1)/100) for x in range(100)]\n",
        "Y = [(y * 15) for y in X]\n",
        "\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0]\n",
            "[0.15, 0.3, 0.44999999999999996, 0.6, 0.75, 0.8999999999999999, 1.05, 1.2, 1.3499999999999999, 1.5, 1.65, 1.7999999999999998, 1.9500000000000002, 2.1, 2.25, 2.4, 2.5500000000000003, 2.6999999999999997, 2.85, 3.0, 3.15, 3.3, 3.45, 3.5999999999999996, 3.75, 3.9000000000000004, 4.050000000000001, 4.2, 4.35, 4.5, 4.65, 4.8, 4.95, 5.1000000000000005, 5.25, 5.3999999999999995, 5.55, 5.7, 5.8500000000000005, 6.0, 6.1499999999999995, 6.3, 6.45, 6.6, 6.75, 6.9, 7.05, 7.199999999999999, 7.35, 7.5, 7.65, 7.800000000000001, 7.95, 8.100000000000001, 8.25, 8.4, 8.549999999999999, 8.7, 8.85, 9.0, 9.15, 9.3, 9.45, 9.6, 9.75, 9.9, 10.05, 10.200000000000001, 10.35, 10.5, 10.649999999999999, 10.799999999999999, 10.95, 11.1, 11.25, 11.4, 11.55, 11.700000000000001, 11.850000000000001, 12.0, 12.15, 12.299999999999999, 12.45, 12.6, 12.75, 12.9, 13.05, 13.2, 13.35, 13.5, 13.65, 13.8, 13.950000000000001, 14.1, 14.25, 14.399999999999999, 14.549999999999999, 14.7, 14.85, 15.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTIIM8eYPm1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.array(X,dtype=float)\n",
        "y = np.array(Y,dtype=float)\n",
        "\n",
        "x = np.array(x).reshape(100, 1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIkyh3ASPt3L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5323612-e78a-490d-cd76-15628a86e59a"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 1, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPK_ACaPQfh_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e0a4b19-4887-4f01-be24-3eb93c28f9fa"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqRkq6nnQg2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhmFq0z4QlHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "6e44aae5-47fc-4a59-c538-d98e9aeca2d0"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "print(model.summary())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 1, 50)             10400     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 30,651\n",
            "Trainable params: 30,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahMQSvCtRXry",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "704e5ac7-65d1-4455-cf59-1612fe3eda53"
      },
      "source": [
        "history = model.fit(x_train,y_train,epochs=2000,validation_data=(x_test,y_test))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/2000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "80/80 [==============================] - 2s 30ms/step - loss: 80.8598 - val_loss: 56.7296\n",
            "Epoch 2/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 80.7326 - val_loss: 56.6311\n",
            "Epoch 3/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 80.6047 - val_loss: 56.5319\n",
            "Epoch 4/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 80.4747 - val_loss: 56.4289\n",
            "Epoch 5/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 80.3426 - val_loss: 56.3205\n",
            "Epoch 6/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 80.1939 - val_loss: 56.2064\n",
            "Epoch 7/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 80.0461 - val_loss: 56.0836\n",
            "Epoch 8/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 79.8848 - val_loss: 55.9522\n",
            "Epoch 9/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 79.7044 - val_loss: 55.8117\n",
            "Epoch 10/2000\n",
            "80/80 [==============================] - 0s 360us/step - loss: 79.5221 - val_loss: 55.6581\n",
            "Epoch 11/2000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 79.3130 - val_loss: 55.4900\n",
            "Epoch 12/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 79.0929 - val_loss: 55.3067\n",
            "Epoch 13/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 78.8402 - val_loss: 55.1095\n",
            "Epoch 14/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 78.5781 - val_loss: 54.8940\n",
            "Epoch 15/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 78.2895 - val_loss: 54.6592\n",
            "Epoch 16/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 77.9791 - val_loss: 54.4040\n",
            "Epoch 17/2000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 77.6278 - val_loss: 54.1281\n",
            "Epoch 18/2000\n",
            "80/80 [==============================] - 0s 403us/step - loss: 77.2611 - val_loss: 53.8266\n",
            "Epoch 19/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 76.8374 - val_loss: 53.4993\n",
            "Epoch 20/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 76.3951 - val_loss: 53.1398\n",
            "Epoch 21/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 75.9069 - val_loss: 52.7464\n",
            "Epoch 22/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 75.3582 - val_loss: 52.3172\n",
            "Epoch 23/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 74.7898 - val_loss: 51.8451\n",
            "Epoch 24/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 74.1221 - val_loss: 51.3323\n",
            "Epoch 25/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 73.4416 - val_loss: 50.7689\n",
            "Epoch 26/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 72.6790 - val_loss: 50.1575\n",
            "Epoch 27/2000\n",
            "80/80 [==============================] - 0s 494us/step - loss: 71.8102 - val_loss: 49.4937\n",
            "Epoch 28/2000\n",
            "80/80 [==============================] - 0s 451us/step - loss: 70.8844 - val_loss: 48.7659\n",
            "Epoch 29/2000\n",
            "80/80 [==============================] - 0s 390us/step - loss: 69.8785 - val_loss: 47.9694\n",
            "Epoch 30/2000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 68.7894 - val_loss: 47.1006\n",
            "Epoch 31/2000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 67.5749 - val_loss: 46.1555\n",
            "Epoch 32/2000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 66.2862 - val_loss: 45.1225\n",
            "Epoch 33/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 64.8211 - val_loss: 44.0066\n",
            "Epoch 34/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 63.3121 - val_loss: 42.7873\n",
            "Epoch 35/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 61.5662 - val_loss: 41.4735\n",
            "Epoch 36/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 59.7454 - val_loss: 40.0389\n",
            "Epoch 37/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 57.7423 - val_loss: 38.4857\n",
            "Epoch 38/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 55.4373 - val_loss: 36.8242\n",
            "Epoch 39/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 53.1747 - val_loss: 35.0212\n",
            "Epoch 40/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 50.5699 - val_loss: 33.0885\n",
            "Epoch 41/2000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 47.9091 - val_loss: 31.0205\n",
            "Epoch 42/2000\n",
            "80/80 [==============================] - 0s 411us/step - loss: 44.8739 - val_loss: 28.8445\n",
            "Epoch 43/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 41.9084 - val_loss: 26.5345\n",
            "Epoch 44/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 38.5955 - val_loss: 24.1409\n",
            "Epoch 45/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 35.1630 - val_loss: 21.6701\n",
            "Epoch 46/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 31.6232 - val_loss: 19.1476\n",
            "Epoch 47/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 27.8595 - val_loss: 16.6215\n",
            "Epoch 48/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 24.2681 - val_loss: 14.0980\n",
            "Epoch 49/2000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 20.6208 - val_loss: 11.6487\n",
            "Epoch 50/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 16.9800 - val_loss: 9.3573\n",
            "Epoch 51/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 13.6705 - val_loss: 7.2675\n",
            "Epoch 52/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 10.4817 - val_loss: 5.4692\n",
            "Epoch 53/2000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 7.8961 - val_loss: 4.0079\n",
            "Epoch 54/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 5.6557 - val_loss: 2.9593\n",
            "Epoch 55/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 3.9026 - val_loss: 2.3364\n",
            "Epoch 56/2000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 2.6432 - val_loss: 2.0943\n",
            "Epoch 57/2000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 2.0751 - val_loss: 2.1366\n",
            "Epoch 58/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 1.8692 - val_loss: 2.3445\n",
            "Epoch 59/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 1.8591 - val_loss: 2.5772\n",
            "Epoch 60/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 1.9745 - val_loss: 2.7466\n",
            "Epoch 61/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 2.0688 - val_loss: 2.8098\n",
            "Epoch 62/2000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 2.0919 - val_loss: 2.7648\n",
            "Epoch 63/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 2.0422 - val_loss: 2.6437\n",
            "Epoch 64/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 1.9526 - val_loss: 2.4908\n",
            "Epoch 65/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 1.8681 - val_loss: 2.3400\n",
            "Epoch 66/2000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 1.7841 - val_loss: 2.2182\n",
            "Epoch 67/2000\n",
            "80/80 [==============================] - 0s 360us/step - loss: 1.7362 - val_loss: 2.1204\n",
            "Epoch 68/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 1.7078 - val_loss: 2.0469\n",
            "Epoch 69/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 1.6978 - val_loss: 1.9922\n",
            "Epoch 70/2000\n",
            "80/80 [==============================] - 0s 378us/step - loss: 1.6858 - val_loss: 1.9555\n",
            "Epoch 71/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 1.6777 - val_loss: 1.9291\n",
            "Epoch 72/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 1.6690 - val_loss: 1.9100\n",
            "Epoch 73/2000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 1.6502 - val_loss: 1.9009\n",
            "Epoch 74/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 1.6329 - val_loss: 1.8973\n",
            "Epoch 75/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 1.6143 - val_loss: 1.8928\n",
            "Epoch 76/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 1.5972 - val_loss: 1.8893\n",
            "Epoch 77/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 1.5819 - val_loss: 1.8836\n",
            "Epoch 78/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 1.5681 - val_loss: 1.8770\n",
            "Epoch 79/2000\n",
            "80/80 [==============================] - 0s 436us/step - loss: 1.5550 - val_loss: 1.8672\n",
            "Epoch 80/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 1.5421 - val_loss: 1.8504\n",
            "Epoch 81/2000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 1.5283 - val_loss: 1.8356\n",
            "Epoch 82/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 1.5154 - val_loss: 1.8197\n",
            "Epoch 83/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 1.5028 - val_loss: 1.8014\n",
            "Epoch 84/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 1.4900 - val_loss: 1.7822\n",
            "Epoch 85/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 1.4774 - val_loss: 1.7602\n",
            "Epoch 86/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 1.4652 - val_loss: 1.7399\n",
            "Epoch 87/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 1.4518 - val_loss: 1.7243\n",
            "Epoch 88/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 1.4408 - val_loss: 1.7060\n",
            "Epoch 89/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 1.4272 - val_loss: 1.6890\n",
            "Epoch 90/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 1.4164 - val_loss: 1.6698\n",
            "Epoch 91/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 1.4038 - val_loss: 1.6533\n",
            "Epoch 92/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 1.3927 - val_loss: 1.6356\n",
            "Epoch 93/2000\n",
            "80/80 [==============================] - 0s 370us/step - loss: 1.3817 - val_loss: 1.6182\n",
            "Epoch 94/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 1.3691 - val_loss: 1.6036\n",
            "Epoch 95/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 1.3585 - val_loss: 1.5892\n",
            "Epoch 96/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 1.3467 - val_loss: 1.5777\n",
            "Epoch 97/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 1.3362 - val_loss: 1.5673\n",
            "Epoch 98/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 1.3250 - val_loss: 1.5584\n",
            "Epoch 99/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 1.3148 - val_loss: 1.5467\n",
            "Epoch 100/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 1.3047 - val_loss: 1.5328\n",
            "Epoch 101/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 1.2940 - val_loss: 1.5215\n",
            "Epoch 102/2000\n",
            "80/80 [==============================] - 0s 387us/step - loss: 1.2844 - val_loss: 1.5075\n",
            "Epoch 103/2000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 1.2732 - val_loss: 1.4961\n",
            "Epoch 104/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 1.2637 - val_loss: 1.4825\n",
            "Epoch 105/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 1.2537 - val_loss: 1.4675\n",
            "Epoch 106/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 1.2435 - val_loss: 1.4512\n",
            "Epoch 107/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 1.2344 - val_loss: 1.4332\n",
            "Epoch 108/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 1.2246 - val_loss: 1.4193\n",
            "Epoch 109/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 1.2158 - val_loss: 1.4029\n",
            "Epoch 110/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 1.2060 - val_loss: 1.3907\n",
            "Epoch 111/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 1.1970 - val_loss: 1.3796\n",
            "Epoch 112/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 1.1889 - val_loss: 1.3690\n",
            "Epoch 113/2000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 1.1791 - val_loss: 1.3643\n",
            "Epoch 114/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 1.1707 - val_loss: 1.3577\n",
            "Epoch 115/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 1.1623 - val_loss: 1.3484\n",
            "Epoch 116/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 1.1539 - val_loss: 1.3380\n",
            "Epoch 117/2000\n",
            "80/80 [==============================] - 0s 349us/step - loss: 1.1452 - val_loss: 1.3272\n",
            "Epoch 118/2000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 1.1376 - val_loss: 1.3179\n",
            "Epoch 119/2000\n",
            "80/80 [==============================] - 0s 461us/step - loss: 1.1292 - val_loss: 1.3091\n",
            "Epoch 120/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 1.1222 - val_loss: 1.3003\n",
            "Epoch 121/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 1.1141 - val_loss: 1.2931\n",
            "Epoch 122/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 1.1069 - val_loss: 1.2847\n",
            "Epoch 123/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 1.0993 - val_loss: 1.2766\n",
            "Epoch 124/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 1.0924 - val_loss: 1.2673\n",
            "Epoch 125/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 1.0850 - val_loss: 1.2557\n",
            "Epoch 126/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 1.0777 - val_loss: 1.2442\n",
            "Epoch 127/2000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 1.0703 - val_loss: 1.2319\n",
            "Epoch 128/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 1.0642 - val_loss: 1.2180\n",
            "Epoch 129/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 1.0563 - val_loss: 1.2091\n",
            "Epoch 130/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 1.0494 - val_loss: 1.2007\n",
            "Epoch 131/2000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 1.0437 - val_loss: 1.1907\n",
            "Epoch 132/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 1.0366 - val_loss: 1.1800\n",
            "Epoch 133/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 1.0301 - val_loss: 1.1700\n",
            "Epoch 134/2000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 1.0236 - val_loss: 1.1628\n",
            "Epoch 135/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 1.0179 - val_loss: 1.1548\n",
            "Epoch 136/2000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 1.0109 - val_loss: 1.1488\n",
            "Epoch 137/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 1.0054 - val_loss: 1.1398\n",
            "Epoch 138/2000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.9992 - val_loss: 1.1322\n",
            "Epoch 139/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.9937 - val_loss: 1.1275\n",
            "Epoch 140/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.9876 - val_loss: 1.1276\n",
            "Epoch 141/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.9827 - val_loss: 1.1289\n",
            "Epoch 142/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.9770 - val_loss: 1.1242\n",
            "Epoch 143/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.9717 - val_loss: 1.1130\n",
            "Epoch 144/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.9656 - val_loss: 1.0974\n",
            "Epoch 145/2000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.9612 - val_loss: 1.0828\n",
            "Epoch 146/2000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.9546 - val_loss: 1.0716\n",
            "Epoch 147/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.9503 - val_loss: 1.0612\n",
            "Epoch 148/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.9450 - val_loss: 1.0548\n",
            "Epoch 149/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.9409 - val_loss: 1.0498\n",
            "Epoch 150/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.9354 - val_loss: 1.0504\n",
            "Epoch 151/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.9301 - val_loss: 1.0524\n",
            "Epoch 152/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.9262 - val_loss: 1.0527\n",
            "Epoch 153/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.9219 - val_loss: 1.0491\n",
            "Epoch 154/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.9171 - val_loss: 1.0393\n",
            "Epoch 155/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.9119 - val_loss: 1.0265\n",
            "Epoch 156/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.9078 - val_loss: 1.0148\n",
            "Epoch 157/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.9035 - val_loss: 1.0063\n",
            "Epoch 158/2000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.8995 - val_loss: 0.9999\n",
            "Epoch 159/2000\n",
            "80/80 [==============================] - 0s 353us/step - loss: 0.8958 - val_loss: 0.9917\n",
            "Epoch 160/2000\n",
            "80/80 [==============================] - 0s 353us/step - loss: 0.8918 - val_loss: 0.9898\n",
            "Epoch 161/2000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.8877 - val_loss: 0.9876\n",
            "Epoch 162/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.8840 - val_loss: 0.9853\n",
            "Epoch 163/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.8799 - val_loss: 0.9809\n",
            "Epoch 164/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.8772 - val_loss: 0.9739\n",
            "Epoch 165/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.8726 - val_loss: 0.9744\n",
            "Epoch 166/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.8694 - val_loss: 0.9785\n",
            "Epoch 167/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.8657 - val_loss: 0.9840\n",
            "Epoch 168/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.8640 - val_loss: 0.9876\n",
            "Epoch 169/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.8605 - val_loss: 0.9834\n",
            "Epoch 170/2000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.8574 - val_loss: 0.9782\n",
            "Epoch 171/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.8543 - val_loss: 0.9733\n",
            "Epoch 172/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.8507 - val_loss: 0.9654\n",
            "Epoch 173/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.8468 - val_loss: 0.9515\n",
            "Epoch 174/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.8445 - val_loss: 0.9383\n",
            "Epoch 175/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.8414 - val_loss: 0.9299\n",
            "Epoch 176/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.8395 - val_loss: 0.9238\n",
            "Epoch 177/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.8367 - val_loss: 0.9218\n",
            "Epoch 178/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.8336 - val_loss: 0.9235\n",
            "Epoch 179/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.8305 - val_loss: 0.9243\n",
            "Epoch 180/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.8274 - val_loss: 0.9251\n",
            "Epoch 181/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.8249 - val_loss: 0.9224\n",
            "Epoch 182/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.8222 - val_loss: 0.9246\n",
            "Epoch 183/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.8194 - val_loss: 0.9215\n",
            "Epoch 184/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.8175 - val_loss: 0.9189\n",
            "Epoch 185/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.8152 - val_loss: 0.9162\n",
            "Epoch 186/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.8122 - val_loss: 0.9185\n",
            "Epoch 187/2000\n",
            "80/80 [==============================] - 0s 352us/step - loss: 0.8106 - val_loss: 0.9188\n",
            "Epoch 188/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.8084 - val_loss: 0.9149\n",
            "Epoch 189/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.8057 - val_loss: 0.9120\n",
            "Epoch 190/2000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.8042 - val_loss: 0.9110\n",
            "Epoch 191/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.8018 - val_loss: 0.9079\n",
            "Epoch 192/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.8001 - val_loss: 0.9004\n",
            "Epoch 193/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.7978 - val_loss: 0.8942\n",
            "Epoch 194/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.7959 - val_loss: 0.8908\n",
            "Epoch 195/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.7939 - val_loss: 0.8883\n",
            "Epoch 196/2000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.7920 - val_loss: 0.8879\n",
            "Epoch 197/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.7901 - val_loss: 0.8885\n",
            "Epoch 198/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.7889 - val_loss: 0.8911\n",
            "Epoch 199/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.7875 - val_loss: 0.8944\n",
            "Epoch 200/2000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.7857 - val_loss: 0.8904\n",
            "Epoch 201/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.7840 - val_loss: 0.8855\n",
            "Epoch 202/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.7817 - val_loss: 0.8766\n",
            "Epoch 203/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.7806 - val_loss: 0.8669\n",
            "Epoch 204/2000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.7789 - val_loss: 0.8628\n",
            "Epoch 205/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.7777 - val_loss: 0.8601\n",
            "Epoch 206/2000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.7764 - val_loss: 0.8610\n",
            "Epoch 207/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.7746 - val_loss: 0.8600\n",
            "Epoch 208/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.7729 - val_loss: 0.8589\n",
            "Epoch 209/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.7715 - val_loss: 0.8598\n",
            "Epoch 210/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.7701 - val_loss: 0.8608\n",
            "Epoch 211/2000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.7683 - val_loss: 0.8654\n",
            "Epoch 212/2000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.7677 - val_loss: 0.8706\n",
            "Epoch 213/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.7662 - val_loss: 0.8714\n",
            "Epoch 214/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.7651 - val_loss: 0.8665\n",
            "Epoch 215/2000\n",
            "80/80 [==============================] - 0s 362us/step - loss: 0.7633 - val_loss: 0.8647\n",
            "Epoch 216/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.7620 - val_loss: 0.8636\n",
            "Epoch 217/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.7611 - val_loss: 0.8600\n",
            "Epoch 218/2000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.7596 - val_loss: 0.8565\n",
            "Epoch 219/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.7590 - val_loss: 0.8541\n",
            "Epoch 220/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.7574 - val_loss: 0.8461\n",
            "Epoch 221/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.7566 - val_loss: 0.8417\n",
            "Epoch 222/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.7554 - val_loss: 0.8416\n",
            "Epoch 223/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.7542 - val_loss: 0.8456\n",
            "Epoch 224/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.7545 - val_loss: 0.8512\n",
            "Epoch 225/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.7520 - val_loss: 0.8482\n",
            "Epoch 226/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.7508 - val_loss: 0.8458\n",
            "Epoch 227/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.7504 - val_loss: 0.8436\n",
            "Epoch 228/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.7494 - val_loss: 0.8412\n",
            "Epoch 229/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.7487 - val_loss: 0.8349\n",
            "Epoch 230/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.7478 - val_loss: 0.8325\n",
            "Epoch 231/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.7493 - val_loss: 0.8305\n",
            "Epoch 232/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.7465 - val_loss: 0.8393\n",
            "Epoch 233/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.7453 - val_loss: 0.8438\n",
            "Epoch 234/2000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.7446 - val_loss: 0.8456\n",
            "Epoch 235/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.7439 - val_loss: 0.8414\n",
            "Epoch 236/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.7448 - val_loss: 0.8332\n",
            "Epoch 237/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.7426 - val_loss: 0.8333\n",
            "Epoch 238/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.7416 - val_loss: 0.8364\n",
            "Epoch 239/2000\n",
            "80/80 [==============================] - 0s 372us/step - loss: 0.7410 - val_loss: 0.8401\n",
            "Epoch 240/2000\n",
            "80/80 [==============================] - 0s 349us/step - loss: 0.7401 - val_loss: 0.8443\n",
            "Epoch 241/2000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.7400 - val_loss: 0.8500\n",
            "Epoch 242/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.7406 - val_loss: 0.8533\n",
            "Epoch 243/2000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.7394 - val_loss: 0.8503\n",
            "Epoch 244/2000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.7393 - val_loss: 0.8421\n",
            "Epoch 245/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.7379 - val_loss: 0.8368\n",
            "Epoch 246/2000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.7376 - val_loss: 0.8363\n",
            "Epoch 247/2000\n",
            "80/80 [==============================] - 0s 360us/step - loss: 0.7362 - val_loss: 0.8397\n",
            "Epoch 248/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.7358 - val_loss: 0.8404\n",
            "Epoch 249/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.7356 - val_loss: 0.8352\n",
            "Epoch 250/2000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.7346 - val_loss: 0.8307\n",
            "Epoch 251/2000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.7345 - val_loss: 0.8277\n",
            "Epoch 252/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.7338 - val_loss: 0.8176\n",
            "Epoch 253/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.7361 - val_loss: 0.8035\n",
            "Epoch 254/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.7350 - val_loss: 0.8034\n",
            "Epoch 255/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.7353 - val_loss: 0.8080\n",
            "Epoch 256/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.7331 - val_loss: 0.8083\n",
            "Epoch 257/2000\n",
            "80/80 [==============================] - 0s 407us/step - loss: 0.7324 - val_loss: 0.8132\n",
            "Epoch 258/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.7315 - val_loss: 0.8179\n",
            "Epoch 259/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.7296 - val_loss: 0.8195\n",
            "Epoch 260/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.7286 - val_loss: 0.8233\n",
            "Epoch 261/2000\n",
            "80/80 [==============================] - 0s 354us/step - loss: 0.7284 - val_loss: 0.8301\n",
            "Epoch 262/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.7277 - val_loss: 0.8324\n",
            "Epoch 263/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.7275 - val_loss: 0.8333\n",
            "Epoch 264/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.7275 - val_loss: 0.8349\n",
            "Epoch 265/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.7263 - val_loss: 0.8285\n",
            "Epoch 266/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.7260 - val_loss: 0.8227\n",
            "Epoch 267/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.7284 - val_loss: 0.8083\n",
            "Epoch 268/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.7258 - val_loss: 0.8063\n",
            "Epoch 269/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.7252 - val_loss: 0.8124\n",
            "Epoch 270/2000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.7242 - val_loss: 0.8145\n",
            "Epoch 271/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.7243 - val_loss: 0.8225\n",
            "Epoch 272/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.7231 - val_loss: 0.8227\n",
            "Epoch 273/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.7229 - val_loss: 0.8178\n",
            "Epoch 274/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.7230 - val_loss: 0.8195\n",
            "Epoch 275/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.7215 - val_loss: 0.8123\n",
            "Epoch 276/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.7224 - val_loss: 0.8007\n",
            "Epoch 277/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.7227 - val_loss: 0.7993\n",
            "Epoch 278/2000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.7223 - val_loss: 0.7971\n",
            "Epoch 279/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.7212 - val_loss: 0.8015\n",
            "Epoch 280/2000\n",
            "80/80 [==============================] - 0s 441us/step - loss: 0.7201 - val_loss: 0.8106\n",
            "Epoch 281/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.7186 - val_loss: 0.8178\n",
            "Epoch 282/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.7195 - val_loss: 0.8274\n",
            "Epoch 283/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.7186 - val_loss: 0.8270\n",
            "Epoch 284/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.7181 - val_loss: 0.8218\n",
            "Epoch 285/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.7177 - val_loss: 0.8087\n",
            "Epoch 286/2000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.7174 - val_loss: 0.8014\n",
            "Epoch 287/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.7170 - val_loss: 0.7969\n",
            "Epoch 288/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.7172 - val_loss: 0.7937\n",
            "Epoch 289/2000\n",
            "80/80 [==============================] - 0s 349us/step - loss: 0.7174 - val_loss: 0.7920\n",
            "Epoch 290/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.7167 - val_loss: 0.7975\n",
            "Epoch 291/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.7154 - val_loss: 0.8071\n",
            "Epoch 292/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.7142 - val_loss: 0.8155\n",
            "Epoch 293/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.7158 - val_loss: 0.8220\n",
            "Epoch 294/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.7141 - val_loss: 0.8162\n",
            "Epoch 295/2000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.7136 - val_loss: 0.8162\n",
            "Epoch 296/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.7131 - val_loss: 0.8159\n",
            "Epoch 297/2000\n",
            "80/80 [==============================] - 0s 387us/step - loss: 0.7126 - val_loss: 0.8174\n",
            "Epoch 298/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.7129 - val_loss: 0.8252\n",
            "Epoch 299/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.7124 - val_loss: 0.8282\n",
            "Epoch 300/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.7130 - val_loss: 0.8318\n",
            "Epoch 301/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.7123 - val_loss: 0.8420\n",
            "Epoch 302/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.7137 - val_loss: 0.8445\n",
            "Epoch 303/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.7152 - val_loss: 0.8432\n",
            "Epoch 304/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.7119 - val_loss: 0.8255\n",
            "Epoch 305/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.7094 - val_loss: 0.8060\n",
            "Epoch 306/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.7099 - val_loss: 0.7933\n",
            "Epoch 307/2000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.7107 - val_loss: 0.7909\n",
            "Epoch 308/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.7093 - val_loss: 0.7979\n",
            "Epoch 309/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.7097 - val_loss: 0.8130\n",
            "Epoch 310/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.7094 - val_loss: 0.8250\n",
            "Epoch 311/2000\n",
            "80/80 [==============================] - 0s 366us/step - loss: 0.7093 - val_loss: 0.8200\n",
            "Epoch 312/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.7078 - val_loss: 0.8166\n",
            "Epoch 313/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.7078 - val_loss: 0.8104\n",
            "Epoch 314/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.7067 - val_loss: 0.8100\n",
            "Epoch 315/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.7069 - val_loss: 0.8110\n",
            "Epoch 316/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.7065 - val_loss: 0.8061\n",
            "Epoch 317/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.7066 - val_loss: 0.7919\n",
            "Epoch 318/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.7059 - val_loss: 0.7884\n",
            "Epoch 319/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.7060 - val_loss: 0.7876\n",
            "Epoch 320/2000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.7061 - val_loss: 0.7929\n",
            "Epoch 321/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.7046 - val_loss: 0.7978\n",
            "Epoch 322/2000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.7040 - val_loss: 0.8028\n",
            "Epoch 323/2000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.7035 - val_loss: 0.8048\n",
            "Epoch 324/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.7032 - val_loss: 0.8043\n",
            "Epoch 325/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.7028 - val_loss: 0.8073\n",
            "Epoch 326/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.7038 - val_loss: 0.8071\n",
            "Epoch 327/2000\n",
            "80/80 [==============================] - 0s 379us/step - loss: 0.7023 - val_loss: 0.7946\n",
            "Epoch 328/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.7018 - val_loss: 0.7897\n",
            "Epoch 329/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.7033 - val_loss: 0.7868\n",
            "Epoch 330/2000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.7020 - val_loss: 0.7927\n",
            "Epoch 331/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.7019 - val_loss: 0.7956\n",
            "Epoch 332/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.7003 - val_loss: 0.7909\n",
            "Epoch 333/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.7002 - val_loss: 0.7902\n",
            "Epoch 334/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.6997 - val_loss: 0.7927\n",
            "Epoch 335/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.6997 - val_loss: 0.8002\n",
            "Epoch 336/2000\n",
            "80/80 [==============================] - 0s 354us/step - loss: 0.7021 - val_loss: 0.8089\n",
            "Epoch 337/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.6985 - val_loss: 0.8013\n",
            "Epoch 338/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.6988 - val_loss: 0.7895\n",
            "Epoch 339/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.6989 - val_loss: 0.7844\n",
            "Epoch 340/2000\n",
            "80/80 [==============================] - 0s 365us/step - loss: 0.6982 - val_loss: 0.7859\n",
            "Epoch 341/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.6979 - val_loss: 0.7886\n",
            "Epoch 342/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.6976 - val_loss: 0.7862\n",
            "Epoch 343/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.6968 - val_loss: 0.7887\n",
            "Epoch 344/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 0.6963 - val_loss: 0.7968\n",
            "Epoch 345/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.6957 - val_loss: 0.8002\n",
            "Epoch 346/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.6959 - val_loss: 0.8012\n",
            "Epoch 347/2000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.6953 - val_loss: 0.8036\n",
            "Epoch 348/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.6957 - val_loss: 0.7982\n",
            "Epoch 349/2000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.6947 - val_loss: 0.7995\n",
            "Epoch 350/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.6938 - val_loss: 0.8033\n",
            "Epoch 351/2000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.6961 - val_loss: 0.8095\n",
            "Epoch 352/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.6939 - val_loss: 0.8018\n",
            "Epoch 353/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.6946 - val_loss: 0.7884\n",
            "Epoch 354/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.6931 - val_loss: 0.7887\n",
            "Epoch 355/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.6924 - val_loss: 0.7838\n",
            "Epoch 356/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.6922 - val_loss: 0.7843\n",
            "Epoch 357/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.6916 - val_loss: 0.7882\n",
            "Epoch 358/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.6910 - val_loss: 0.7949\n",
            "Epoch 359/2000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.6907 - val_loss: 0.7985\n",
            "Epoch 360/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.6908 - val_loss: 0.8008\n",
            "Epoch 361/2000\n",
            "80/80 [==============================] - 0s 382us/step - loss: 0.6913 - val_loss: 0.8083\n",
            "Epoch 362/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.6915 - val_loss: 0.8063\n",
            "Epoch 363/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.6902 - val_loss: 0.7992\n",
            "Epoch 364/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.6892 - val_loss: 0.7910\n",
            "Epoch 365/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.6886 - val_loss: 0.7844\n",
            "Epoch 366/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.6885 - val_loss: 0.7796\n",
            "Epoch 367/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.6887 - val_loss: 0.7786\n",
            "Epoch 368/2000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.6894 - val_loss: 0.7767\n",
            "Epoch 369/2000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.6879 - val_loss: 0.7854\n",
            "Epoch 370/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.6888 - val_loss: 0.7907\n",
            "Epoch 371/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.6870 - val_loss: 0.7846\n",
            "Epoch 372/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.6880 - val_loss: 0.7693\n",
            "Epoch 373/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.6876 - val_loss: 0.7674\n",
            "Epoch 374/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.6867 - val_loss: 0.7725\n",
            "Epoch 375/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.6862 - val_loss: 0.7825\n",
            "Epoch 376/2000\n",
            "80/80 [==============================] - 0s 393us/step - loss: 0.6849 - val_loss: 0.7896\n",
            "Epoch 377/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.6858 - val_loss: 0.8023\n",
            "Epoch 378/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.6859 - val_loss: 0.8024\n",
            "Epoch 379/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.6848 - val_loss: 0.7931\n",
            "Epoch 380/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.6833 - val_loss: 0.7845\n",
            "Epoch 381/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.6841 - val_loss: 0.7728\n",
            "Epoch 382/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 0.6837 - val_loss: 0.7691\n",
            "Epoch 383/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.6830 - val_loss: 0.7743\n",
            "Epoch 384/2000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.6822 - val_loss: 0.7793\n",
            "Epoch 385/2000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.6822 - val_loss: 0.7847\n",
            "Epoch 386/2000\n",
            "80/80 [==============================] - 0s 379us/step - loss: 0.6815 - val_loss: 0.7814\n",
            "Epoch 387/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.6814 - val_loss: 0.7845\n",
            "Epoch 388/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.6813 - val_loss: 0.7812\n",
            "Epoch 389/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.6821 - val_loss: 0.7889\n",
            "Epoch 390/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.6818 - val_loss: 0.7902\n",
            "Epoch 391/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.6797 - val_loss: 0.7823\n",
            "Epoch 392/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.6794 - val_loss: 0.7724\n",
            "Epoch 393/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.6788 - val_loss: 0.7680\n",
            "Epoch 394/2000\n",
            "80/80 [==============================] - 0s 404us/step - loss: 0.6791 - val_loss: 0.7609\n",
            "Epoch 395/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.6801 - val_loss: 0.7645\n",
            "Epoch 396/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.6783 - val_loss: 0.7625\n",
            "Epoch 397/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.6783 - val_loss: 0.7654\n",
            "Epoch 398/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.6781 - val_loss: 0.7703\n",
            "Epoch 399/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.6769 - val_loss: 0.7675\n",
            "Epoch 400/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.6771 - val_loss: 0.7659\n",
            "Epoch 401/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.6763 - val_loss: 0.7736\n",
            "Epoch 402/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.6753 - val_loss: 0.7783\n",
            "Epoch 403/2000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.6759 - val_loss: 0.7812\n",
            "Epoch 404/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.6747 - val_loss: 0.7815\n",
            "Epoch 405/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.6747 - val_loss: 0.7808\n",
            "Epoch 406/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.6740 - val_loss: 0.7771\n",
            "Epoch 407/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.6748 - val_loss: 0.7650\n",
            "Epoch 408/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.6735 - val_loss: 0.7635\n",
            "Epoch 409/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.6738 - val_loss: 0.7658\n",
            "Epoch 410/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.6726 - val_loss: 0.7604\n",
            "Epoch 411/2000\n",
            "80/80 [==============================] - 0s 370us/step - loss: 0.6730 - val_loss: 0.7583\n",
            "Epoch 412/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.6728 - val_loss: 0.7545\n",
            "Epoch 413/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.6728 - val_loss: 0.7627\n",
            "Epoch 414/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.6711 - val_loss: 0.7665\n",
            "Epoch 415/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.6705 - val_loss: 0.7655\n",
            "Epoch 416/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.6699 - val_loss: 0.7685\n",
            "Epoch 417/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.6692 - val_loss: 0.7736\n",
            "Epoch 418/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.6691 - val_loss: 0.7796\n",
            "Epoch 419/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.6698 - val_loss: 0.7784\n",
            "Epoch 420/2000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.6689 - val_loss: 0.7833\n",
            "Epoch 421/2000\n",
            "80/80 [==============================] - 0s 360us/step - loss: 0.6697 - val_loss: 0.7840\n",
            "Epoch 422/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.6688 - val_loss: 0.7717\n",
            "Epoch 423/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.6674 - val_loss: 0.7553\n",
            "Epoch 424/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 0.6687 - val_loss: 0.7447\n",
            "Epoch 425/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.6687 - val_loss: 0.7464\n",
            "Epoch 426/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.6676 - val_loss: 0.7568\n",
            "Epoch 427/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.6657 - val_loss: 0.7662\n",
            "Epoch 428/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.6661 - val_loss: 0.7819\n",
            "Epoch 429/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.6658 - val_loss: 0.7883\n",
            "Epoch 430/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.6665 - val_loss: 0.7858\n",
            "Epoch 431/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.6653 - val_loss: 0.7756\n",
            "Epoch 432/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.6637 - val_loss: 0.7586\n",
            "Epoch 433/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.6634 - val_loss: 0.7470\n",
            "Epoch 434/2000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.6638 - val_loss: 0.7447\n",
            "Epoch 435/2000\n",
            "80/80 [==============================] - 0s 386us/step - loss: 0.6642 - val_loss: 0.7486\n",
            "Epoch 436/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.6631 - val_loss: 0.7475\n",
            "Epoch 437/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.6619 - val_loss: 0.7546\n",
            "Epoch 438/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.6606 - val_loss: 0.7643\n",
            "Epoch 439/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.6603 - val_loss: 0.7738\n",
            "Epoch 440/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.6617 - val_loss: 0.7828\n",
            "Epoch 441/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.6628 - val_loss: 0.7899\n",
            "Epoch 442/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.6627 - val_loss: 0.7782\n",
            "Epoch 443/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.6641 - val_loss: 0.7550\n",
            "Epoch 444/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.6610 - val_loss: 0.7440\n",
            "Epoch 445/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.6589 - val_loss: 0.7470\n",
            "Epoch 446/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.6584 - val_loss: 0.7548\n",
            "Epoch 447/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.6581 - val_loss: 0.7564\n",
            "Epoch 448/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.6588 - val_loss: 0.7668\n",
            "Epoch 449/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.6574 - val_loss: 0.7626\n",
            "Epoch 450/2000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.6566 - val_loss: 0.7516\n",
            "Epoch 451/2000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.6560 - val_loss: 0.7441\n",
            "Epoch 452/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.6559 - val_loss: 0.7402\n",
            "Epoch 453/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.6576 - val_loss: 0.7421\n",
            "Epoch 454/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.6554 - val_loss: 0.7350\n",
            "Epoch 455/2000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 0.6562 - val_loss: 0.7388\n",
            "Epoch 456/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.6550 - val_loss: 0.7403\n",
            "Epoch 457/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.6563 - val_loss: 0.7441\n",
            "Epoch 458/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.6528 - val_loss: 0.7368\n",
            "Epoch 459/2000\n",
            "80/80 [==============================] - 0s 369us/step - loss: 0.6531 - val_loss: 0.7328\n",
            "Epoch 460/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.6533 - val_loss: 0.7331\n",
            "Epoch 461/2000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.6534 - val_loss: 0.7389\n",
            "Epoch 462/2000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.6520 - val_loss: 0.7413\n",
            "Epoch 463/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.6524 - val_loss: 0.7385\n",
            "Epoch 464/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.6532 - val_loss: 0.7516\n",
            "Epoch 465/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 0.6507 - val_loss: 0.7562\n",
            "Epoch 466/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.6504 - val_loss: 0.7565\n",
            "Epoch 467/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.6535 - val_loss: 0.7466\n",
            "Epoch 468/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.6486 - val_loss: 0.7546\n",
            "Epoch 469/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.6502 - val_loss: 0.7592\n",
            "Epoch 470/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.6495 - val_loss: 0.7482\n",
            "Epoch 471/2000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.6512 - val_loss: 0.7390\n",
            "Epoch 472/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.6471 - val_loss: 0.7455\n",
            "Epoch 473/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.6487 - val_loss: 0.7540\n",
            "Epoch 474/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.6468 - val_loss: 0.7473\n",
            "Epoch 475/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.6462 - val_loss: 0.7415\n",
            "Epoch 476/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.6460 - val_loss: 0.7345\n",
            "Epoch 477/2000\n",
            "80/80 [==============================] - 0s 354us/step - loss: 0.6450 - val_loss: 0.7360\n",
            "Epoch 478/2000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.6449 - val_loss: 0.7385\n",
            "Epoch 479/2000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.6445 - val_loss: 0.7385\n",
            "Epoch 480/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.6440 - val_loss: 0.7406\n",
            "Epoch 481/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.6451 - val_loss: 0.7415\n",
            "Epoch 482/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.6439 - val_loss: 0.7392\n",
            "Epoch 483/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.6414 - val_loss: 0.7264\n",
            "Epoch 484/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.6416 - val_loss: 0.7126\n",
            "Epoch 485/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.6454 - val_loss: 0.7068\n",
            "Epoch 486/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.6450 - val_loss: 0.7140\n",
            "Epoch 487/2000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.6440 - val_loss: 0.7281\n",
            "Epoch 488/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.6401 - val_loss: 0.7351\n",
            "Epoch 489/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.6397 - val_loss: 0.7397\n",
            "Epoch 490/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.6413 - val_loss: 0.7467\n",
            "Epoch 491/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.6394 - val_loss: 0.7404\n",
            "Epoch 492/2000\n",
            "80/80 [==============================] - 0s 386us/step - loss: 0.6384 - val_loss: 0.7327\n",
            "Epoch 493/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.6383 - val_loss: 0.7198\n",
            "Epoch 494/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.6390 - val_loss: 0.7160\n",
            "Epoch 495/2000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.6394 - val_loss: 0.7121\n",
            "Epoch 496/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.6389 - val_loss: 0.7122\n",
            "Epoch 497/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.6373 - val_loss: 0.7179\n",
            "Epoch 498/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.6360 - val_loss: 0.7297\n",
            "Epoch 499/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.6365 - val_loss: 0.7409\n",
            "Epoch 500/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 0.6371 - val_loss: 0.7444\n",
            "Epoch 501/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.6350 - val_loss: 0.7390\n",
            "Epoch 502/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.6338 - val_loss: 0.7299\n",
            "Epoch 503/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.6335 - val_loss: 0.7199\n",
            "Epoch 504/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.6335 - val_loss: 0.7167\n",
            "Epoch 505/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.6328 - val_loss: 0.7226\n",
            "Epoch 506/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.6325 - val_loss: 0.7263\n",
            "Epoch 507/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.6314 - val_loss: 0.7244\n",
            "Epoch 508/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.6312 - val_loss: 0.7224\n",
            "Epoch 509/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.6310 - val_loss: 0.7216\n",
            "Epoch 510/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.6314 - val_loss: 0.7235\n",
            "Epoch 511/2000\n",
            "80/80 [==============================] - 0s 370us/step - loss: 0.6301 - val_loss: 0.7269\n",
            "Epoch 512/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.6298 - val_loss: 0.7227\n",
            "Epoch 513/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.6289 - val_loss: 0.7240\n",
            "Epoch 514/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.6288 - val_loss: 0.7283\n",
            "Epoch 515/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.6304 - val_loss: 0.7436\n",
            "Epoch 516/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.6291 - val_loss: 0.7398\n",
            "Epoch 517/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.6286 - val_loss: 0.7278\n",
            "Epoch 518/2000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.6280 - val_loss: 0.7204\n",
            "Epoch 519/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.6270 - val_loss: 0.7260\n",
            "Epoch 520/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.6257 - val_loss: 0.7233\n",
            "Epoch 521/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.6252 - val_loss: 0.7218\n",
            "Epoch 522/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.6252 - val_loss: 0.7151\n",
            "Epoch 523/2000\n",
            "80/80 [==============================] - 0s 411us/step - loss: 0.6242 - val_loss: 0.7158\n",
            "Epoch 524/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.6236 - val_loss: 0.7199\n",
            "Epoch 525/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.6228 - val_loss: 0.7272\n",
            "Epoch 526/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.6235 - val_loss: 0.7331\n",
            "Epoch 527/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.6238 - val_loss: 0.7276\n",
            "Epoch 528/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.6226 - val_loss: 0.7252\n",
            "Epoch 529/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.6220 - val_loss: 0.7187\n",
            "Epoch 530/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.6240 - val_loss: 0.7008\n",
            "Epoch 531/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.6221 - val_loss: 0.7010\n",
            "Epoch 532/2000\n",
            "80/80 [==============================] - 0s 416us/step - loss: 0.6204 - val_loss: 0.6961\n",
            "Epoch 533/2000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.6205 - val_loss: 0.6918\n",
            "Epoch 534/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.6208 - val_loss: 0.6912\n",
            "Epoch 535/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.6202 - val_loss: 0.6956\n",
            "Epoch 536/2000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.6233 - val_loss: 0.7079\n",
            "Epoch 537/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.6179 - val_loss: 0.7076\n",
            "Epoch 538/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.6172 - val_loss: 0.7019\n",
            "Epoch 539/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.6170 - val_loss: 0.7004\n",
            "Epoch 540/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.6163 - val_loss: 0.7023\n",
            "Epoch 541/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.6160 - val_loss: 0.7058\n",
            "Epoch 542/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.6149 - val_loss: 0.7070\n",
            "Epoch 543/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.6144 - val_loss: 0.7098\n",
            "Epoch 544/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.6152 - val_loss: 0.7111\n",
            "Epoch 545/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.6136 - val_loss: 0.7163\n",
            "Epoch 546/2000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.6137 - val_loss: 0.7179\n",
            "Epoch 547/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.6135 - val_loss: 0.7165\n",
            "Epoch 548/2000\n",
            "80/80 [==============================] - 0s 388us/step - loss: 0.6132 - val_loss: 0.7167\n",
            "Epoch 549/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.6137 - val_loss: 0.7149\n",
            "Epoch 550/2000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.6120 - val_loss: 0.7083\n",
            "Epoch 551/2000\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.6109 - val_loss: 0.7065\n",
            "Epoch 552/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.6112 - val_loss: 0.7052\n",
            "Epoch 553/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.6098 - val_loss: 0.7103\n",
            "Epoch 554/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.6098 - val_loss: 0.7101\n",
            "Epoch 555/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.6093 - val_loss: 0.7031\n",
            "Epoch 556/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.6092 - val_loss: 0.6954\n",
            "Epoch 557/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.6099 - val_loss: 0.6841\n",
            "Epoch 558/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.6082 - val_loss: 0.6895\n",
            "Epoch 559/2000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.6071 - val_loss: 0.6966\n",
            "Epoch 560/2000\n",
            "80/80 [==============================] - 0s 375us/step - loss: 0.6060 - val_loss: 0.7102\n",
            "Epoch 561/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.6065 - val_loss: 0.7152\n",
            "Epoch 562/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.6070 - val_loss: 0.7110\n",
            "Epoch 563/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.6050 - val_loss: 0.6919\n",
            "Epoch 564/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.6041 - val_loss: 0.6758\n",
            "Epoch 565/2000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.6082 - val_loss: 0.6690\n",
            "Epoch 566/2000\n",
            "80/80 [==============================] - 0s 362us/step - loss: 0.6065 - val_loss: 0.6773\n",
            "Epoch 567/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.6058 - val_loss: 0.7034\n",
            "Epoch 568/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.6044 - val_loss: 0.7214\n",
            "Epoch 569/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.6063 - val_loss: 0.7242\n",
            "Epoch 570/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.6076 - val_loss: 0.7133\n",
            "Epoch 571/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.6024 - val_loss: 0.7045\n",
            "Epoch 572/2000\n",
            "80/80 [==============================] - 0s 406us/step - loss: 0.6022 - val_loss: 0.6924\n",
            "Epoch 573/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.6001 - val_loss: 0.6869\n",
            "Epoch 574/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.5991 - val_loss: 0.6819\n",
            "Epoch 575/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.6033 - val_loss: 0.6716\n",
            "Epoch 576/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.5995 - val_loss: 0.6798\n",
            "Epoch 577/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.5970 - val_loss: 0.6990\n",
            "Epoch 578/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.5981 - val_loss: 0.7110\n",
            "Epoch 579/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.6022 - val_loss: 0.7087\n",
            "Epoch 580/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.5966 - val_loss: 0.6801\n",
            "Epoch 581/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.5982 - val_loss: 0.6624\n",
            "Epoch 582/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.5983 - val_loss: 0.6597\n",
            "Epoch 583/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.5975 - val_loss: 0.6663\n",
            "Epoch 584/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.5960 - val_loss: 0.6813\n",
            "Epoch 585/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.5944 - val_loss: 0.6960\n",
            "Epoch 586/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.5942 - val_loss: 0.6972\n",
            "Epoch 587/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.5933 - val_loss: 0.6887\n",
            "Epoch 588/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.5925 - val_loss: 0.6791\n",
            "Epoch 589/2000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.5921 - val_loss: 0.6702\n",
            "Epoch 590/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.5916 - val_loss: 0.6669\n",
            "Epoch 591/2000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.5927 - val_loss: 0.6686\n",
            "Epoch 592/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.5900 - val_loss: 0.6850\n",
            "Epoch 593/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.5894 - val_loss: 0.7001\n",
            "Epoch 594/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.5912 - val_loss: 0.7012\n",
            "Epoch 595/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.5908 - val_loss: 0.6923\n",
            "Epoch 596/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.5890 - val_loss: 0.6849\n",
            "Epoch 597/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.5877 - val_loss: 0.6737\n",
            "Epoch 598/2000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.5868 - val_loss: 0.6698\n",
            "Epoch 599/2000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.5868 - val_loss: 0.6632\n",
            "Epoch 600/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.5872 - val_loss: 0.6630\n",
            "Epoch 601/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.5850 - val_loss: 0.6757\n",
            "Epoch 602/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.5868 - val_loss: 0.6890\n",
            "Epoch 603/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 0.5862 - val_loss: 0.6823\n",
            "Epoch 604/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.5845 - val_loss: 0.6812\n",
            "Epoch 605/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.5847 - val_loss: 0.6687\n",
            "Epoch 606/2000\n",
            "80/80 [==============================] - 0s 360us/step - loss: 0.5833 - val_loss: 0.6597\n",
            "Epoch 607/2000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.5858 - val_loss: 0.6606\n",
            "Epoch 608/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.5823 - val_loss: 0.6467\n",
            "Epoch 609/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.5835 - val_loss: 0.6431\n",
            "Epoch 610/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.5841 - val_loss: 0.6473\n",
            "Epoch 611/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.5811 - val_loss: 0.6565\n",
            "Epoch 612/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.5797 - val_loss: 0.6710\n",
            "Epoch 613/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.5800 - val_loss: 0.6806\n",
            "Epoch 614/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.5799 - val_loss: 0.6730\n",
            "Epoch 615/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.5778 - val_loss: 0.6639\n",
            "Epoch 616/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.5778 - val_loss: 0.6490\n",
            "Epoch 617/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.5778 - val_loss: 0.6488\n",
            "Epoch 618/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.5769 - val_loss: 0.6488\n",
            "Epoch 619/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.5762 - val_loss: 0.6498\n",
            "Epoch 620/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.5764 - val_loss: 0.6561\n",
            "Epoch 621/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.5749 - val_loss: 0.6538\n",
            "Epoch 622/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.5737 - val_loss: 0.6599\n",
            "Epoch 623/2000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.5734 - val_loss: 0.6626\n",
            "Epoch 624/2000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 0.5740 - val_loss: 0.6711\n",
            "Epoch 625/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.5745 - val_loss: 0.6616\n",
            "Epoch 626/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.5730 - val_loss: 0.6636\n",
            "Epoch 627/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.5715 - val_loss: 0.6635\n",
            "Epoch 628/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.5712 - val_loss: 0.6620\n",
            "Epoch 629/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.5724 - val_loss: 0.6492\n",
            "Epoch 630/2000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.5696 - val_loss: 0.6520\n",
            "Epoch 631/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.5697 - val_loss: 0.6571\n",
            "Epoch 632/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.5695 - val_loss: 0.6574\n",
            "Epoch 633/2000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.5676 - val_loss: 0.6509\n",
            "Epoch 634/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.5671 - val_loss: 0.6455\n",
            "Epoch 635/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.5680 - val_loss: 0.6353\n",
            "Epoch 636/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.5680 - val_loss: 0.6379\n",
            "Epoch 637/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.5685 - val_loss: 0.6570\n",
            "Epoch 638/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.5649 - val_loss: 0.6631\n",
            "Epoch 639/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.5656 - val_loss: 0.6640\n",
            "Epoch 640/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.5654 - val_loss: 0.6687\n",
            "Epoch 641/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.5664 - val_loss: 0.6684\n",
            "Epoch 642/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.5646 - val_loss: 0.6596\n",
            "Epoch 643/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.5624 - val_loss: 0.6392\n",
            "Epoch 644/2000\n",
            "80/80 [==============================] - 0s 400us/step - loss: 0.5616 - val_loss: 0.6301\n",
            "Epoch 645/2000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.5625 - val_loss: 0.6283\n",
            "Epoch 646/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.5615 - val_loss: 0.6338\n",
            "Epoch 647/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.5594 - val_loss: 0.6444\n",
            "Epoch 648/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.5602 - val_loss: 0.6593\n",
            "Epoch 649/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.5601 - val_loss: 0.6619\n",
            "Epoch 650/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.5606 - val_loss: 0.6587\n",
            "Epoch 651/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.5590 - val_loss: 0.6573\n",
            "Epoch 652/2000\n",
            "80/80 [==============================] - 0s 396us/step - loss: 0.5582 - val_loss: 0.6544\n",
            "Epoch 653/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.5591 - val_loss: 0.6438\n",
            "Epoch 654/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.5562 - val_loss: 0.6385\n",
            "Epoch 655/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.5554 - val_loss: 0.6348\n",
            "Epoch 656/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.5545 - val_loss: 0.6278\n",
            "Epoch 657/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.5552 - val_loss: 0.6179\n",
            "Epoch 658/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.5563 - val_loss: 0.6152\n",
            "Epoch 659/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.5557 - val_loss: 0.6204\n",
            "Epoch 660/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.5548 - val_loss: 0.6416\n",
            "Epoch 661/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.5519 - val_loss: 0.6497\n",
            "Epoch 662/2000\n",
            "80/80 [==============================] - 0s 425us/step - loss: 0.5528 - val_loss: 0.6479\n",
            "Epoch 663/2000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.5510 - val_loss: 0.6362\n",
            "Epoch 664/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.5501 - val_loss: 0.6156\n",
            "Epoch 665/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.5516 - val_loss: 0.6047\n",
            "Epoch 666/2000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.5560 - val_loss: 0.6038\n",
            "Epoch 667/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.5538 - val_loss: 0.6211\n",
            "Epoch 668/2000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.5476 - val_loss: 0.6387\n",
            "Epoch 669/2000\n",
            "80/80 [==============================] - 0s 552us/step - loss: 0.5476 - val_loss: 0.6467\n",
            "Epoch 670/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.5480 - val_loss: 0.6432\n",
            "Epoch 671/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.5474 - val_loss: 0.6364\n",
            "Epoch 672/2000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.5495 - val_loss: 0.6140\n",
            "Epoch 673/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.5477 - val_loss: 0.6080\n",
            "Epoch 674/2000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.5461 - val_loss: 0.6138\n",
            "Epoch 675/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.5435 - val_loss: 0.6236\n",
            "Epoch 676/2000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.5421 - val_loss: 0.6354\n",
            "Epoch 677/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.5428 - val_loss: 0.6449\n",
            "Epoch 678/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.5440 - val_loss: 0.6418\n",
            "Epoch 679/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.5428 - val_loss: 0.6346\n",
            "Epoch 680/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.5418 - val_loss: 0.6238\n",
            "Epoch 681/2000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.5401 - val_loss: 0.6194\n",
            "Epoch 682/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.5448 - val_loss: 0.6092\n",
            "Epoch 683/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.5385 - val_loss: 0.6189\n",
            "Epoch 684/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.5379 - val_loss: 0.6302\n",
            "Epoch 685/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.5393 - val_loss: 0.6383\n",
            "Epoch 686/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.5392 - val_loss: 0.6318\n",
            "Epoch 687/2000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.5365 - val_loss: 0.6145\n",
            "Epoch 688/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.5348 - val_loss: 0.6011\n",
            "Epoch 689/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.5362 - val_loss: 0.5935\n",
            "Epoch 690/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.5381 - val_loss: 0.5900\n",
            "Epoch 691/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.5382 - val_loss: 0.5966\n",
            "Epoch 692/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.5331 - val_loss: 0.6142\n",
            "Epoch 693/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.5314 - val_loss: 0.6324\n",
            "Epoch 694/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.5366 - val_loss: 0.6448\n",
            "Epoch 695/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.5376 - val_loss: 0.6287\n",
            "Epoch 696/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.5326 - val_loss: 0.6131\n",
            "Epoch 697/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.5319 - val_loss: 0.6014\n",
            "Epoch 698/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.5303 - val_loss: 0.6000\n",
            "Epoch 699/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.5308 - val_loss: 0.5990\n",
            "Epoch 700/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.5294 - val_loss: 0.6063\n",
            "Epoch 701/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.5282 - val_loss: 0.6094\n",
            "Epoch 702/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.5277 - val_loss: 0.6079\n",
            "Epoch 703/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.5285 - val_loss: 0.6107\n",
            "Epoch 704/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.5259 - val_loss: 0.6013\n",
            "Epoch 705/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 0.5257 - val_loss: 0.5908\n",
            "Epoch 706/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.5264 - val_loss: 0.5909\n",
            "Epoch 707/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.5259 - val_loss: 0.5951\n",
            "Epoch 708/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.5245 - val_loss: 0.6004\n",
            "Epoch 709/2000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.5229 - val_loss: 0.6062\n",
            "Epoch 710/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.5241 - val_loss: 0.6156\n",
            "Epoch 711/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.5243 - val_loss: 0.6073\n",
            "Epoch 712/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.5238 - val_loss: 0.6085\n",
            "Epoch 713/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.5206 - val_loss: 0.5966\n",
            "Epoch 714/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.5202 - val_loss: 0.5801\n",
            "Epoch 715/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.5231 - val_loss: 0.5748\n",
            "Epoch 716/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.5210 - val_loss: 0.5838\n",
            "Epoch 717/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.5206 - val_loss: 0.6007\n",
            "Epoch 718/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.5187 - val_loss: 0.6068\n",
            "Epoch 719/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.5178 - val_loss: 0.6001\n",
            "Epoch 720/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.5198 - val_loss: 0.5865\n",
            "Epoch 721/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.5168 - val_loss: 0.5854\n",
            "Epoch 722/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.5165 - val_loss: 0.5776\n",
            "Epoch 723/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.5176 - val_loss: 0.5858\n",
            "Epoch 724/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.5140 - val_loss: 0.5865\n",
            "Epoch 725/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.5133 - val_loss: 0.5907\n",
            "Epoch 726/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.5129 - val_loss: 0.5924\n",
            "Epoch 727/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 0.5121 - val_loss: 0.5887\n",
            "Epoch 728/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.5134 - val_loss: 0.5838\n",
            "Epoch 729/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.5110 - val_loss: 0.5939\n",
            "Epoch 730/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.5108 - val_loss: 0.5975\n",
            "Epoch 731/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.5112 - val_loss: 0.5920\n",
            "Epoch 732/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.5094 - val_loss: 0.5920\n",
            "Epoch 733/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.5100 - val_loss: 0.5855\n",
            "Epoch 734/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.5084 - val_loss: 0.5870\n",
            "Epoch 735/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.5076 - val_loss: 0.5849\n",
            "Epoch 736/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.5066 - val_loss: 0.5881\n",
            "Epoch 737/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.5074 - val_loss: 0.5879\n",
            "Epoch 738/2000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.5058 - val_loss: 0.5923\n",
            "Epoch 739/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.5058 - val_loss: 0.5923\n",
            "Epoch 740/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.5062 - val_loss: 0.5909\n",
            "Epoch 741/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.5030 - val_loss: 0.5755\n",
            "Epoch 742/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.5034 - val_loss: 0.5613\n",
            "Epoch 743/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.5053 - val_loss: 0.5535\n",
            "Epoch 744/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.5052 - val_loss: 0.5567\n",
            "Epoch 745/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.5021 - val_loss: 0.5696\n",
            "Epoch 746/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.4996 - val_loss: 0.5848\n",
            "Epoch 747/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.5011 - val_loss: 0.5927\n",
            "Epoch 748/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.5010 - val_loss: 0.5831\n",
            "Epoch 749/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.4988 - val_loss: 0.5701\n",
            "Epoch 750/2000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.4975 - val_loss: 0.5637\n",
            "Epoch 751/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.4975 - val_loss: 0.5571\n",
            "Epoch 752/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.4980 - val_loss: 0.5603\n",
            "Epoch 753/2000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.4948 - val_loss: 0.5751\n",
            "Epoch 754/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.4946 - val_loss: 0.5842\n",
            "Epoch 755/2000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.4963 - val_loss: 0.5827\n",
            "Epoch 756/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.4951 - val_loss: 0.5829\n",
            "Epoch 757/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.4948 - val_loss: 0.5755\n",
            "Epoch 758/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.4929 - val_loss: 0.5623\n",
            "Epoch 759/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.4916 - val_loss: 0.5562\n",
            "Epoch 760/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.4923 - val_loss: 0.5537\n",
            "Epoch 761/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.4908 - val_loss: 0.5648\n",
            "Epoch 762/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.4896 - val_loss: 0.5714\n",
            "Epoch 763/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.4896 - val_loss: 0.5707\n",
            "Epoch 764/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.4897 - val_loss: 0.5716\n",
            "Epoch 765/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.4881 - val_loss: 0.5656\n",
            "Epoch 766/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.4872 - val_loss: 0.5589\n",
            "Epoch 767/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.4877 - val_loss: 0.5449\n",
            "Epoch 768/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.4875 - val_loss: 0.5438\n",
            "Epoch 769/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.4860 - val_loss: 0.5461\n",
            "Epoch 770/2000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.4845 - val_loss: 0.5525\n",
            "Epoch 771/2000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.4862 - val_loss: 0.5651\n",
            "Epoch 772/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.4867 - val_loss: 0.5683\n",
            "Epoch 773/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.4882 - val_loss: 0.5460\n",
            "Epoch 774/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.4824 - val_loss: 0.5412\n",
            "Epoch 775/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.4818 - val_loss: 0.5437\n",
            "Epoch 776/2000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.4802 - val_loss: 0.5499\n",
            "Epoch 777/2000\n",
            "80/80 [==============================] - 0s 379us/step - loss: 0.4788 - val_loss: 0.5591\n",
            "Epoch 778/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.4795 - val_loss: 0.5742\n",
            "Epoch 779/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.4816 - val_loss: 0.5781\n",
            "Epoch 780/2000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.4825 - val_loss: 0.5673\n",
            "Epoch 781/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.4792 - val_loss: 0.5579\n",
            "Epoch 782/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.4776 - val_loss: 0.5532\n",
            "Epoch 783/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.4757 - val_loss: 0.5450\n",
            "Epoch 784/2000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.4746 - val_loss: 0.5409\n",
            "Epoch 785/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.4742 - val_loss: 0.5388\n",
            "Epoch 786/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.4743 - val_loss: 0.5402\n",
            "Epoch 787/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.4751 - val_loss: 0.5336\n",
            "Epoch 788/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.4733 - val_loss: 0.5412\n",
            "Epoch 789/2000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.4725 - val_loss: 0.5445\n",
            "Epoch 790/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.4710 - val_loss: 0.5455\n",
            "Epoch 791/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.4711 - val_loss: 0.5377\n",
            "Epoch 792/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.4701 - val_loss: 0.5355\n",
            "Epoch 793/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.4714 - val_loss: 0.5425\n",
            "Epoch 794/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.4694 - val_loss: 0.5314\n",
            "Epoch 795/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.4675 - val_loss: 0.5299\n",
            "Epoch 796/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.4681 - val_loss: 0.5292\n",
            "Epoch 797/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.4657 - val_loss: 0.5418\n",
            "Epoch 798/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.4652 - val_loss: 0.5487\n",
            "Epoch 799/2000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.4679 - val_loss: 0.5516\n",
            "Epoch 800/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.4651 - val_loss: 0.5352\n",
            "Epoch 801/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.4618 - val_loss: 0.5184\n",
            "Epoch 802/2000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.4651 - val_loss: 0.5059\n",
            "Epoch 803/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.4675 - val_loss: 0.5068\n",
            "Epoch 804/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.4677 - val_loss: 0.5195\n",
            "Epoch 805/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.4611 - val_loss: 0.5254\n",
            "Epoch 806/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.4601 - val_loss: 0.5265\n",
            "Epoch 807/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.4600 - val_loss: 0.5327\n",
            "Epoch 808/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.4590 - val_loss: 0.5358\n",
            "Epoch 809/2000\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.4585 - val_loss: 0.5337\n",
            "Epoch 810/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.4604 - val_loss: 0.5209\n",
            "Epoch 811/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.4569 - val_loss: 0.5203\n",
            "Epoch 812/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.4555 - val_loss: 0.5267\n",
            "Epoch 813/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.4555 - val_loss: 0.5282\n",
            "Epoch 814/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.4546 - val_loss: 0.5295\n",
            "Epoch 815/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.4539 - val_loss: 0.5292\n",
            "Epoch 816/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.4536 - val_loss: 0.5242\n",
            "Epoch 817/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.4522 - val_loss: 0.5218\n",
            "Epoch 818/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.4529 - val_loss: 0.5155\n",
            "Epoch 819/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.4512 - val_loss: 0.5172\n",
            "Epoch 820/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.4500 - val_loss: 0.5118\n",
            "Epoch 821/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.4497 - val_loss: 0.5124\n",
            "Epoch 822/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.4487 - val_loss: 0.5111\n",
            "Epoch 823/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.4484 - val_loss: 0.5137\n",
            "Epoch 824/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.4478 - val_loss: 0.5082\n",
            "Epoch 825/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.4466 - val_loss: 0.5053\n",
            "Epoch 826/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.4460 - val_loss: 0.5066\n",
            "Epoch 827/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.4453 - val_loss: 0.5114\n",
            "Epoch 828/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.4438 - val_loss: 0.5216\n",
            "Epoch 829/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.4445 - val_loss: 0.5262\n",
            "Epoch 830/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.4450 - val_loss: 0.5206\n",
            "Epoch 831/2000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.4445 - val_loss: 0.5165\n",
            "Epoch 832/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.4412 - val_loss: 0.4986\n",
            "Epoch 833/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.4441 - val_loss: 0.4881\n",
            "Epoch 834/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.4428 - val_loss: 0.4925\n",
            "Epoch 835/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.4400 - val_loss: 0.5099\n",
            "Epoch 836/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.4412 - val_loss: 0.5220\n",
            "Epoch 837/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.4409 - val_loss: 0.5138\n",
            "Epoch 838/2000\n",
            "80/80 [==============================] - 0s 380us/step - loss: 0.4389 - val_loss: 0.5065\n",
            "Epoch 839/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.4380 - val_loss: 0.5004\n",
            "Epoch 840/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.4364 - val_loss: 0.5019\n",
            "Epoch 841/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.4353 - val_loss: 0.5001\n",
            "Epoch 842/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.4351 - val_loss: 0.4952\n",
            "Epoch 843/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.4330 - val_loss: 0.4843\n",
            "Epoch 844/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.4353 - val_loss: 0.4787\n",
            "Epoch 845/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.4348 - val_loss: 0.4867\n",
            "Epoch 846/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 0.4323 - val_loss: 0.4926\n",
            "Epoch 847/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.4310 - val_loss: 0.5106\n",
            "Epoch 848/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.4326 - val_loss: 0.5109\n",
            "Epoch 849/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.4324 - val_loss: 0.5115\n",
            "Epoch 850/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.4304 - val_loss: 0.4932\n",
            "Epoch 851/2000\n",
            "80/80 [==============================] - 0s 396us/step - loss: 0.4291 - val_loss: 0.4787\n",
            "Epoch 852/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.4287 - val_loss: 0.4798\n",
            "Epoch 853/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.4272 - val_loss: 0.4800\n",
            "Epoch 854/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.4274 - val_loss: 0.4839\n",
            "Epoch 855/2000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.4254 - val_loss: 0.4852\n",
            "Epoch 856/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.4243 - val_loss: 0.4868\n",
            "Epoch 857/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.4247 - val_loss: 0.4831\n",
            "Epoch 858/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.4230 - val_loss: 0.4883\n",
            "Epoch 859/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.4223 - val_loss: 0.4882\n",
            "Epoch 860/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.4216 - val_loss: 0.4827\n",
            "Epoch 861/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.4224 - val_loss: 0.4711\n",
            "Epoch 862/2000\n",
            "80/80 [==============================] - 0s 362us/step - loss: 0.4211 - val_loss: 0.4730\n",
            "Epoch 863/2000\n",
            "80/80 [==============================] - 0s 349us/step - loss: 0.4195 - val_loss: 0.4827\n",
            "Epoch 864/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.4192 - val_loss: 0.4880\n",
            "Epoch 865/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.4188 - val_loss: 0.4854\n",
            "Epoch 866/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.4182 - val_loss: 0.4826\n",
            "Epoch 867/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.4169 - val_loss: 0.4830\n",
            "Epoch 868/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.4156 - val_loss: 0.4764\n",
            "Epoch 869/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.4167 - val_loss: 0.4658\n",
            "Epoch 870/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.4152 - val_loss: 0.4676\n",
            "Epoch 871/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.4134 - val_loss: 0.4733\n",
            "Epoch 872/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.4123 - val_loss: 0.4799\n",
            "Epoch 873/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.4171 - val_loss: 0.4878\n",
            "Epoch 874/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.4116 - val_loss: 0.4730\n",
            "Epoch 875/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.4089 - val_loss: 0.4586\n",
            "Epoch 876/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.4129 - val_loss: 0.4479\n",
            "Epoch 877/2000\n",
            "80/80 [==============================] - 0s 356us/step - loss: 0.4160 - val_loss: 0.4453\n",
            "Epoch 878/2000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.4142 - val_loss: 0.4603\n",
            "Epoch 879/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.4097 - val_loss: 0.4758\n",
            "Epoch 880/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.4090 - val_loss: 0.4772\n",
            "Epoch 881/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.4073 - val_loss: 0.4612\n",
            "Epoch 882/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.4054 - val_loss: 0.4500\n",
            "Epoch 883/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.4087 - val_loss: 0.4457\n",
            "Epoch 884/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.4064 - val_loss: 0.4533\n",
            "Epoch 885/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.4053 - val_loss: 0.4720\n",
            "Epoch 886/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.4093 - val_loss: 0.4758\n",
            "Epoch 887/2000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.4038 - val_loss: 0.4520\n",
            "Epoch 888/2000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.4018 - val_loss: 0.4432\n",
            "Epoch 889/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.4028 - val_loss: 0.4431\n",
            "Epoch 890/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.4018 - val_loss: 0.4475\n",
            "Epoch 891/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.4004 - val_loss: 0.4597\n",
            "Epoch 892/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.3982 - val_loss: 0.4657\n",
            "Epoch 893/2000\n",
            "80/80 [==============================] - 0s 349us/step - loss: 0.3987 - val_loss: 0.4696\n",
            "Epoch 894/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.3979 - val_loss: 0.4613\n",
            "Epoch 895/2000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.3971 - val_loss: 0.4526\n",
            "Epoch 896/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.3953 - val_loss: 0.4527\n",
            "Epoch 897/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.3945 - val_loss: 0.4556\n",
            "Epoch 898/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.3941 - val_loss: 0.4595\n",
            "Epoch 899/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.3933 - val_loss: 0.4545\n",
            "Epoch 900/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.3920 - val_loss: 0.4431\n",
            "Epoch 901/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.3920 - val_loss: 0.4339\n",
            "Epoch 902/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.3934 - val_loss: 0.4323\n",
            "Epoch 903/2000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.3913 - val_loss: 0.4408\n",
            "Epoch 904/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.3907 - val_loss: 0.4557\n",
            "Epoch 905/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.3894 - val_loss: 0.4586\n",
            "Epoch 906/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.3889 - val_loss: 0.4516\n",
            "Epoch 907/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.3894 - val_loss: 0.4389\n",
            "Epoch 908/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.3871 - val_loss: 0.4363\n",
            "Epoch 909/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.3863 - val_loss: 0.4348\n",
            "Epoch 910/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.3877 - val_loss: 0.4439\n",
            "Epoch 911/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.3854 - val_loss: 0.4391\n",
            "Epoch 912/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.3833 - val_loss: 0.4443\n",
            "Epoch 913/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.3824 - val_loss: 0.4493\n",
            "Epoch 914/2000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.3832 - val_loss: 0.4504\n",
            "Epoch 915/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.3824 - val_loss: 0.4409\n",
            "Epoch 916/2000\n",
            "80/80 [==============================] - 0s 380us/step - loss: 0.3810 - val_loss: 0.4219\n",
            "Epoch 917/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.3821 - val_loss: 0.4176\n",
            "Epoch 918/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.3816 - val_loss: 0.4235\n",
            "Epoch 919/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.3777 - val_loss: 0.4369\n",
            "Epoch 920/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.3782 - val_loss: 0.4500\n",
            "Epoch 921/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.3790 - val_loss: 0.4448\n",
            "Epoch 922/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.3770 - val_loss: 0.4354\n",
            "Epoch 923/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.3767 - val_loss: 0.4165\n",
            "Epoch 924/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.3764 - val_loss: 0.4108\n",
            "Epoch 925/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.3771 - val_loss: 0.4147\n",
            "Epoch 926/2000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.3744 - val_loss: 0.4231\n",
            "Epoch 927/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.3740 - val_loss: 0.4276\n",
            "Epoch 928/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.3732 - val_loss: 0.4196\n",
            "Epoch 929/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.3718 - val_loss: 0.4252\n",
            "Epoch 930/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.3700 - val_loss: 0.4235\n",
            "Epoch 931/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.3687 - val_loss: 0.4201\n",
            "Epoch 932/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.3685 - val_loss: 0.4185\n",
            "Epoch 933/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.3682 - val_loss: 0.4231\n",
            "Epoch 934/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.3668 - val_loss: 0.4182\n",
            "Epoch 935/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.3665 - val_loss: 0.4185\n",
            "Epoch 936/2000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.3648 - val_loss: 0.4135\n",
            "Epoch 937/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.3644 - val_loss: 0.4111\n",
            "Epoch 938/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.3650 - val_loss: 0.4097\n",
            "Epoch 939/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.3634 - val_loss: 0.4024\n",
            "Epoch 940/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.3638 - val_loss: 0.4038\n",
            "Epoch 941/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.3633 - val_loss: 0.4061\n",
            "Epoch 942/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.3602 - val_loss: 0.4196\n",
            "Epoch 943/2000\n",
            "80/80 [==============================] - 0s 359us/step - loss: 0.3609 - val_loss: 0.4268\n",
            "Epoch 944/2000\n",
            "80/80 [==============================] - 0s 360us/step - loss: 0.3610 - val_loss: 0.4242\n",
            "Epoch 945/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.3594 - val_loss: 0.4151\n",
            "Epoch 946/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.3574 - val_loss: 0.4045\n",
            "Epoch 947/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.3564 - val_loss: 0.3978\n",
            "Epoch 948/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.3576 - val_loss: 0.3943\n",
            "Epoch 949/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.3572 - val_loss: 0.3988\n",
            "Epoch 950/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.3545 - val_loss: 0.4066\n",
            "Epoch 951/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.3539 - val_loss: 0.4124\n",
            "Epoch 952/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.3572 - val_loss: 0.4155\n",
            "Epoch 953/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.3539 - val_loss: 0.4007\n",
            "Epoch 954/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.3558 - val_loss: 0.3929\n",
            "Epoch 955/2000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.3544 - val_loss: 0.4022\n",
            "Epoch 956/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.3507 - val_loss: 0.3967\n",
            "Epoch 957/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.3489 - val_loss: 0.3987\n",
            "Epoch 958/2000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.3488 - val_loss: 0.4015\n",
            "Epoch 959/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.3474 - val_loss: 0.3963\n",
            "Epoch 960/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.3468 - val_loss: 0.3918\n",
            "Epoch 961/2000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.3460 - val_loss: 0.3924\n",
            "Epoch 962/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.3459 - val_loss: 0.3950\n",
            "Epoch 963/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.3443 - val_loss: 0.3924\n",
            "Epoch 964/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.3436 - val_loss: 0.3915\n",
            "Epoch 965/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.3432 - val_loss: 0.3898\n",
            "Epoch 966/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.3428 - val_loss: 0.3830\n",
            "Epoch 967/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.3423 - val_loss: 0.3828\n",
            "Epoch 968/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.3406 - val_loss: 0.3895\n",
            "Epoch 969/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.3412 - val_loss: 0.3983\n",
            "Epoch 970/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.3399 - val_loss: 0.3928\n",
            "Epoch 971/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.3384 - val_loss: 0.3875\n",
            "Epoch 972/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.3371 - val_loss: 0.3820\n",
            "Epoch 973/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.3369 - val_loss: 0.3771\n",
            "Epoch 974/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.3366 - val_loss: 0.3779\n",
            "Epoch 975/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.3354 - val_loss: 0.3846\n",
            "Epoch 976/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.3344 - val_loss: 0.3874\n",
            "Epoch 977/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.3350 - val_loss: 0.3911\n",
            "Epoch 978/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.3342 - val_loss: 0.3815\n",
            "Epoch 979/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.3329 - val_loss: 0.3785\n",
            "Epoch 980/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.3311 - val_loss: 0.3681\n",
            "Epoch 981/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.3346 - val_loss: 0.3648\n",
            "Epoch 982/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.3335 - val_loss: 0.3577\n",
            "Epoch 983/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.3371 - val_loss: 0.3597\n",
            "Epoch 984/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.3340 - val_loss: 0.3783\n",
            "Epoch 985/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.3301 - val_loss: 0.3873\n",
            "Epoch 986/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.3288 - val_loss: 0.3811\n",
            "Epoch 987/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.3275 - val_loss: 0.3654\n",
            "Epoch 988/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.3262 - val_loss: 0.3624\n",
            "Epoch 989/2000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.3251 - val_loss: 0.3666\n",
            "Epoch 990/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.3238 - val_loss: 0.3721\n",
            "Epoch 991/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.3232 - val_loss: 0.3722\n",
            "Epoch 992/2000\n",
            "80/80 [==============================] - 0s 397us/step - loss: 0.3217 - val_loss: 0.3660\n",
            "Epoch 993/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.3211 - val_loss: 0.3587\n",
            "Epoch 994/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.3222 - val_loss: 0.3561\n",
            "Epoch 995/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.3206 - val_loss: 0.3630\n",
            "Epoch 996/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.3192 - val_loss: 0.3716\n",
            "Epoch 997/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.3188 - val_loss: 0.3708\n",
            "Epoch 998/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.3180 - val_loss: 0.3658\n",
            "Epoch 999/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.3169 - val_loss: 0.3605\n",
            "Epoch 1000/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.3158 - val_loss: 0.3595\n",
            "Epoch 1001/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.3154 - val_loss: 0.3571\n",
            "Epoch 1002/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.3146 - val_loss: 0.3586\n",
            "Epoch 1003/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.3137 - val_loss: 0.3551\n",
            "Epoch 1004/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.3129 - val_loss: 0.3531\n",
            "Epoch 1005/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.3124 - val_loss: 0.3506\n",
            "Epoch 1006/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.3121 - val_loss: 0.3541\n",
            "Epoch 1007/2000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.3109 - val_loss: 0.3526\n",
            "Epoch 1008/2000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.3096 - val_loss: 0.3497\n",
            "Epoch 1009/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.3097 - val_loss: 0.3473\n",
            "Epoch 1010/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.3083 - val_loss: 0.3509\n",
            "Epoch 1011/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.3096 - val_loss: 0.3609\n",
            "Epoch 1012/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.3079 - val_loss: 0.3561\n",
            "Epoch 1013/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.3064 - val_loss: 0.3441\n",
            "Epoch 1014/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.3055 - val_loss: 0.3410\n",
            "Epoch 1015/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.3051 - val_loss: 0.3436\n",
            "Epoch 1016/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.3039 - val_loss: 0.3488\n",
            "Epoch 1017/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.3031 - val_loss: 0.3541\n",
            "Epoch 1018/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.3034 - val_loss: 0.3515\n",
            "Epoch 1019/2000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.3029 - val_loss: 0.3447\n",
            "Epoch 1020/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.3017 - val_loss: 0.3464\n",
            "Epoch 1021/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.2998 - val_loss: 0.3464\n",
            "Epoch 1022/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.2990 - val_loss: 0.3436\n",
            "Epoch 1023/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.2984 - val_loss: 0.3398\n",
            "Epoch 1024/2000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.3005 - val_loss: 0.3304\n",
            "Epoch 1025/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.2982 - val_loss: 0.3328\n",
            "Epoch 1026/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.2967 - val_loss: 0.3381\n",
            "Epoch 1027/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.2954 - val_loss: 0.3401\n",
            "Epoch 1028/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.2968 - val_loss: 0.3413\n",
            "Epoch 1029/2000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.2938 - val_loss: 0.3313\n",
            "Epoch 1030/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.2928 - val_loss: 0.3253\n",
            "Epoch 1031/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.2933 - val_loss: 0.3255\n",
            "Epoch 1032/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.2923 - val_loss: 0.3307\n",
            "Epoch 1033/2000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.2905 - val_loss: 0.3334\n",
            "Epoch 1034/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.2893 - val_loss: 0.3383\n",
            "Epoch 1035/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.2911 - val_loss: 0.3398\n",
            "Epoch 1036/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.2887 - val_loss: 0.3285\n",
            "Epoch 1037/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.2874 - val_loss: 0.3225\n",
            "Epoch 1038/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.2871 - val_loss: 0.3227\n",
            "Epoch 1039/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.2854 - val_loss: 0.3278\n",
            "Epoch 1040/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.2843 - val_loss: 0.3361\n",
            "Epoch 1041/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.2870 - val_loss: 0.3386\n",
            "Epoch 1042/2000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.2847 - val_loss: 0.3279\n",
            "Epoch 1043/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.2815 - val_loss: 0.3185\n",
            "Epoch 1044/2000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.2826 - val_loss: 0.3103\n",
            "Epoch 1045/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.2845 - val_loss: 0.3105\n",
            "Epoch 1046/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.2806 - val_loss: 0.3196\n",
            "Epoch 1047/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 0.2774 - val_loss: 0.3363\n",
            "Epoch 1048/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.2824 - val_loss: 0.3441\n",
            "Epoch 1049/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.2844 - val_loss: 0.3331\n",
            "Epoch 1050/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.2787 - val_loss: 0.3190\n",
            "Epoch 1051/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.2758 - val_loss: 0.3063\n",
            "Epoch 1052/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.2779 - val_loss: 0.3032\n",
            "Epoch 1053/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.2778 - val_loss: 0.3076\n",
            "Epoch 1054/2000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.2742 - val_loss: 0.3131\n",
            "Epoch 1055/2000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.2729 - val_loss: 0.3182\n",
            "Epoch 1056/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.2740 - val_loss: 0.3196\n",
            "Epoch 1057/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.2720 - val_loss: 0.3112\n",
            "Epoch 1058/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.2714 - val_loss: 0.3026\n",
            "Epoch 1059/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.2711 - val_loss: 0.3024\n",
            "Epoch 1060/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.2699 - val_loss: 0.3044\n",
            "Epoch 1061/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.2694 - val_loss: 0.3085\n",
            "Epoch 1062/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.2692 - val_loss: 0.3065\n",
            "Epoch 1063/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.2660 - val_loss: 0.2983\n",
            "Epoch 1064/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.2672 - val_loss: 0.2935\n",
            "Epoch 1065/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.2682 - val_loss: 0.2948\n",
            "Epoch 1066/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.2660 - val_loss: 0.2999\n",
            "Epoch 1067/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.2638 - val_loss: 0.3030\n",
            "Epoch 1068/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.2651 - val_loss: 0.3108\n",
            "Epoch 1069/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.2635 - val_loss: 0.3051\n",
            "Epoch 1070/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.2613 - val_loss: 0.2966\n",
            "Epoch 1071/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.2625 - val_loss: 0.2865\n",
            "Epoch 1072/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.2626 - val_loss: 0.2880\n",
            "Epoch 1073/2000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.2612 - val_loss: 0.2951\n",
            "Epoch 1074/2000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.2588 - val_loss: 0.2987\n",
            "Epoch 1075/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.2581 - val_loss: 0.2961\n",
            "Epoch 1076/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.2578 - val_loss: 0.2897\n",
            "Epoch 1077/2000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.2567 - val_loss: 0.2903\n",
            "Epoch 1078/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.2555 - val_loss: 0.2870\n",
            "Epoch 1079/2000\n",
            "80/80 [==============================] - 0s 369us/step - loss: 0.2551 - val_loss: 0.2846\n",
            "Epoch 1080/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.2546 - val_loss: 0.2884\n",
            "Epoch 1081/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.2528 - val_loss: 0.2922\n",
            "Epoch 1082/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.2527 - val_loss: 0.2958\n",
            "Epoch 1083/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.2542 - val_loss: 0.2947\n",
            "Epoch 1084/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.2519 - val_loss: 0.2833\n",
            "Epoch 1085/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.2501 - val_loss: 0.2800\n",
            "Epoch 1086/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.2496 - val_loss: 0.2808\n",
            "Epoch 1087/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.2485 - val_loss: 0.2850\n",
            "Epoch 1088/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.2480 - val_loss: 0.2855\n",
            "Epoch 1089/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.2473 - val_loss: 0.2871\n",
            "Epoch 1090/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.2468 - val_loss: 0.2850\n",
            "Epoch 1091/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.2474 - val_loss: 0.2793\n",
            "Epoch 1092/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.2455 - val_loss: 0.2817\n",
            "Epoch 1093/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.2438 - val_loss: 0.2773\n",
            "Epoch 1094/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.2452 - val_loss: 0.2710\n",
            "Epoch 1095/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.2436 - val_loss: 0.2736\n",
            "Epoch 1096/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.2416 - val_loss: 0.2747\n",
            "Epoch 1097/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.2417 - val_loss: 0.2776\n",
            "Epoch 1098/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.2400 - val_loss: 0.2738\n",
            "Epoch 1099/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.2405 - val_loss: 0.2676\n",
            "Epoch 1100/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.2395 - val_loss: 0.2669\n",
            "Epoch 1101/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.2377 - val_loss: 0.2716\n",
            "Epoch 1102/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.2385 - val_loss: 0.2773\n",
            "Epoch 1103/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.2392 - val_loss: 0.2781\n",
            "Epoch 1104/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.2378 - val_loss: 0.2687\n",
            "Epoch 1105/2000\n",
            "80/80 [==============================] - 0s 392us/step - loss: 0.2356 - val_loss: 0.2645\n",
            "Epoch 1106/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.2337 - val_loss: 0.2662\n",
            "Epoch 1107/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.2339 - val_loss: 0.2692\n",
            "Epoch 1108/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.2328 - val_loss: 0.2640\n",
            "Epoch 1109/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.2321 - val_loss: 0.2566\n",
            "Epoch 1110/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.2320 - val_loss: 0.2568\n",
            "Epoch 1111/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.2309 - val_loss: 0.2588\n",
            "Epoch 1112/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.2294 - val_loss: 0.2603\n",
            "Epoch 1113/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.2284 - val_loss: 0.2600\n",
            "Epoch 1114/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.2277 - val_loss: 0.2607\n",
            "Epoch 1115/2000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.2274 - val_loss: 0.2615\n",
            "Epoch 1116/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.2263 - val_loss: 0.2592\n",
            "Epoch 1117/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.2254 - val_loss: 0.2563\n",
            "Epoch 1118/2000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.2244 - val_loss: 0.2518\n",
            "Epoch 1119/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.2243 - val_loss: 0.2487\n",
            "Epoch 1120/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.2240 - val_loss: 0.2489\n",
            "Epoch 1121/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.2227 - val_loss: 0.2527\n",
            "Epoch 1122/2000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.2221 - val_loss: 0.2583\n",
            "Epoch 1123/2000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.2217 - val_loss: 0.2563\n",
            "Epoch 1124/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.2208 - val_loss: 0.2517\n",
            "Epoch 1125/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.2199 - val_loss: 0.2449\n",
            "Epoch 1126/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.2193 - val_loss: 0.2441\n",
            "Epoch 1127/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.2184 - val_loss: 0.2453\n",
            "Epoch 1128/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.2171 - val_loss: 0.2486\n",
            "Epoch 1129/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.2169 - val_loss: 0.2487\n",
            "Epoch 1130/2000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.2153 - val_loss: 0.2433\n",
            "Epoch 1131/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.2164 - val_loss: 0.2373\n",
            "Epoch 1132/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.2161 - val_loss: 0.2379\n",
            "Epoch 1133/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.2126 - val_loss: 0.2461\n",
            "Epoch 1134/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.2171 - val_loss: 0.2544\n",
            "Epoch 1135/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.2139 - val_loss: 0.2440\n",
            "Epoch 1136/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.2111 - val_loss: 0.2327\n",
            "Epoch 1137/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.2119 - val_loss: 0.2304\n",
            "Epoch 1138/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.2122 - val_loss: 0.2314\n",
            "Epoch 1139/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.2093 - val_loss: 0.2360\n",
            "Epoch 1140/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.2089 - val_loss: 0.2448\n",
            "Epoch 1141/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.2103 - val_loss: 0.2459\n",
            "Epoch 1142/2000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.2082 - val_loss: 0.2339\n",
            "Epoch 1143/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.2056 - val_loss: 0.2277\n",
            "Epoch 1144/2000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.2066 - val_loss: 0.2254\n",
            "Epoch 1145/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.2059 - val_loss: 0.2290\n",
            "Epoch 1146/2000\n",
            "80/80 [==============================] - 0s 262us/step - loss: 0.2045 - val_loss: 0.2361\n",
            "Epoch 1147/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.2041 - val_loss: 0.2356\n",
            "Epoch 1148/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.2030 - val_loss: 0.2312\n",
            "Epoch 1149/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.2020 - val_loss: 0.2244\n",
            "Epoch 1150/2000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.2013 - val_loss: 0.2236\n",
            "Epoch 1151/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.2002 - val_loss: 0.2258\n",
            "Epoch 1152/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.1992 - val_loss: 0.2290\n",
            "Epoch 1153/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.1999 - val_loss: 0.2298\n",
            "Epoch 1154/2000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.1981 - val_loss: 0.2238\n",
            "Epoch 1155/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.1965 - val_loss: 0.2181\n",
            "Epoch 1156/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.1992 - val_loss: 0.2148\n",
            "Epoch 1157/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.1978 - val_loss: 0.2209\n",
            "Epoch 1158/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.1956 - val_loss: 0.2267\n",
            "Epoch 1159/2000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.1964 - val_loss: 0.2261\n",
            "Epoch 1160/2000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 0.1948 - val_loss: 0.2190\n",
            "Epoch 1161/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.1935 - val_loss: 0.2173\n",
            "Epoch 1162/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.1926 - val_loss: 0.2177\n",
            "Epoch 1163/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.1926 - val_loss: 0.2136\n",
            "Epoch 1164/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.1908 - val_loss: 0.2155\n",
            "Epoch 1165/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.1900 - val_loss: 0.2168\n",
            "Epoch 1166/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.1896 - val_loss: 0.2159\n",
            "Epoch 1167/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.1889 - val_loss: 0.2162\n",
            "Epoch 1168/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.1881 - val_loss: 0.2137\n",
            "Epoch 1169/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.1868 - val_loss: 0.2091\n",
            "Epoch 1170/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.1870 - val_loss: 0.2060\n",
            "Epoch 1171/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.1863 - val_loss: 0.2080\n",
            "Epoch 1172/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.1860 - val_loss: 0.2116\n",
            "Epoch 1173/2000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.1846 - val_loss: 0.2088\n",
            "Epoch 1174/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.1839 - val_loss: 0.2053\n",
            "Epoch 1175/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.1831 - val_loss: 0.2055\n",
            "Epoch 1176/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.1820 - val_loss: 0.2078\n",
            "Epoch 1177/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.1824 - val_loss: 0.2111\n",
            "Epoch 1178/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.1814 - val_loss: 0.2058\n",
            "Epoch 1179/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.1810 - val_loss: 0.2013\n",
            "Epoch 1180/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.1793 - val_loss: 0.2026\n",
            "Epoch 1181/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.1785 - val_loss: 0.2045\n",
            "Epoch 1182/2000\n",
            "80/80 [==============================] - 0s 382us/step - loss: 0.1779 - val_loss: 0.2069\n",
            "Epoch 1183/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.1779 - val_loss: 0.2074\n",
            "Epoch 1184/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.1778 - val_loss: 0.2041\n",
            "Epoch 1185/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.1764 - val_loss: 0.1958\n",
            "Epoch 1186/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.1761 - val_loss: 0.1927\n",
            "Epoch 1187/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.1758 - val_loss: 0.1935\n",
            "Epoch 1188/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.1740 - val_loss: 0.1969\n",
            "Epoch 1189/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.1745 - val_loss: 0.1995\n",
            "Epoch 1190/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.1723 - val_loss: 0.1946\n",
            "Epoch 1191/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.1723 - val_loss: 0.1894\n",
            "Epoch 1192/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.1719 - val_loss: 0.1899\n",
            "Epoch 1193/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.1709 - val_loss: 0.1909\n",
            "Epoch 1194/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.1696 - val_loss: 0.1927\n",
            "Epoch 1195/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.1695 - val_loss: 0.1926\n",
            "Epoch 1196/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.1686 - val_loss: 0.1947\n",
            "Epoch 1197/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.1679 - val_loss: 0.1906\n",
            "Epoch 1198/2000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.1662 - val_loss: 0.1846\n",
            "Epoch 1199/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.1670 - val_loss: 0.1827\n",
            "Epoch 1200/2000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.1667 - val_loss: 0.1843\n",
            "Epoch 1201/2000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.1640 - val_loss: 0.1901\n",
            "Epoch 1202/2000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.1644 - val_loss: 0.1932\n",
            "Epoch 1203/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.1650 - val_loss: 0.1896\n",
            "Epoch 1204/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.1632 - val_loss: 0.1847\n",
            "Epoch 1205/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.1620 - val_loss: 0.1806\n",
            "Epoch 1206/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.1622 - val_loss: 0.1778\n",
            "Epoch 1207/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.1615 - val_loss: 0.1790\n",
            "Epoch 1208/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.1604 - val_loss: 0.1804\n",
            "Epoch 1209/2000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.1592 - val_loss: 0.1790\n",
            "Epoch 1210/2000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.1585 - val_loss: 0.1788\n",
            "Epoch 1211/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.1583 - val_loss: 0.1786\n",
            "Epoch 1212/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.1585 - val_loss: 0.1749\n",
            "Epoch 1213/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.1571 - val_loss: 0.1757\n",
            "Epoch 1214/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.1562 - val_loss: 0.1806\n",
            "Epoch 1215/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.1559 - val_loss: 0.1787\n",
            "Epoch 1216/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.1555 - val_loss: 0.1755\n",
            "Epoch 1217/2000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.1539 - val_loss: 0.1747\n",
            "Epoch 1218/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.1533 - val_loss: 0.1737\n",
            "Epoch 1219/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.1529 - val_loss: 0.1740\n",
            "Epoch 1220/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.1545 - val_loss: 0.1735\n",
            "Epoch 1221/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.1511 - val_loss: 0.1671\n",
            "Epoch 1222/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.1530 - val_loss: 0.1647\n",
            "Epoch 1223/2000\n",
            "80/80 [==============================] - 0s 354us/step - loss: 0.1508 - val_loss: 0.1670\n",
            "Epoch 1224/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.1485 - val_loss: 0.1712\n",
            "Epoch 1225/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.1488 - val_loss: 0.1752\n",
            "Epoch 1226/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.1510 - val_loss: 0.1765\n",
            "Epoch 1227/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.1498 - val_loss: 0.1680\n",
            "Epoch 1228/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.1481 - val_loss: 0.1616\n",
            "Epoch 1229/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.1468 - val_loss: 0.1616\n",
            "Epoch 1230/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.1456 - val_loss: 0.1617\n",
            "Epoch 1231/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.1448 - val_loss: 0.1626\n",
            "Epoch 1232/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.1439 - val_loss: 0.1634\n",
            "Epoch 1233/2000\n",
            "80/80 [==============================] - 0s 376us/step - loss: 0.1436 - val_loss: 0.1631\n",
            "Epoch 1234/2000\n",
            "80/80 [==============================] - 0s 409us/step - loss: 0.1429 - val_loss: 0.1602\n",
            "Epoch 1235/2000\n",
            "80/80 [==============================] - 0s 425us/step - loss: 0.1420 - val_loss: 0.1580\n",
            "Epoch 1236/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.1418 - val_loss: 0.1572\n",
            "Epoch 1237/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.1408 - val_loss: 0.1577\n",
            "Epoch 1238/2000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.1404 - val_loss: 0.1589\n",
            "Epoch 1239/2000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.1400 - val_loss: 0.1579\n",
            "Epoch 1240/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.1389 - val_loss: 0.1563\n",
            "Epoch 1241/2000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.1384 - val_loss: 0.1547\n",
            "Epoch 1242/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.1376 - val_loss: 0.1541\n",
            "Epoch 1243/2000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.1373 - val_loss: 0.1543\n",
            "Epoch 1244/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.1366 - val_loss: 0.1528\n",
            "Epoch 1245/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.1357 - val_loss: 0.1529\n",
            "Epoch 1246/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.1352 - val_loss: 0.1524\n",
            "Epoch 1247/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.1345 - val_loss: 0.1530\n",
            "Epoch 1248/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.1346 - val_loss: 0.1545\n",
            "Epoch 1249/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.1348 - val_loss: 0.1520\n",
            "Epoch 1250/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.1335 - val_loss: 0.1482\n",
            "Epoch 1251/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.1320 - val_loss: 0.1474\n",
            "Epoch 1252/2000\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.1315 - val_loss: 0.1470\n",
            "Epoch 1253/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.1316 - val_loss: 0.1462\n",
            "Epoch 1254/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.1311 - val_loss: 0.1427\n",
            "Epoch 1255/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.1303 - val_loss: 0.1432\n",
            "Epoch 1256/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.1292 - val_loss: 0.1457\n",
            "Epoch 1257/2000\n",
            "80/80 [==============================] - 0s 354us/step - loss: 0.1292 - val_loss: 0.1468\n",
            "Epoch 1258/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.1285 - val_loss: 0.1440\n",
            "Epoch 1259/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.1280 - val_loss: 0.1413\n",
            "Epoch 1260/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.1268 - val_loss: 0.1409\n",
            "Epoch 1261/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.1260 - val_loss: 0.1390\n",
            "Epoch 1262/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.1254 - val_loss: 0.1375\n",
            "Epoch 1263/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.1251 - val_loss: 0.1379\n",
            "Epoch 1264/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.1242 - val_loss: 0.1402\n",
            "Epoch 1265/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.1237 - val_loss: 0.1403\n",
            "Epoch 1266/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.1234 - val_loss: 0.1400\n",
            "Epoch 1267/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.1225 - val_loss: 0.1371\n",
            "Epoch 1268/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.1215 - val_loss: 0.1337\n",
            "Epoch 1269/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.1221 - val_loss: 0.1317\n",
            "Epoch 1270/2000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.1212 - val_loss: 0.1330\n",
            "Epoch 1271/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.1205 - val_loss: 0.1375\n",
            "Epoch 1272/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.1201 - val_loss: 0.1372\n",
            "Epoch 1273/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.1194 - val_loss: 0.1332\n",
            "Epoch 1274/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.1188 - val_loss: 0.1292\n",
            "Epoch 1275/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.1179 - val_loss: 0.1290\n",
            "Epoch 1276/2000\n",
            "80/80 [==============================] - 0s 363us/step - loss: 0.1170 - val_loss: 0.1300\n",
            "Epoch 1277/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.1160 - val_loss: 0.1318\n",
            "Epoch 1278/2000\n",
            "80/80 [==============================] - 0s 396us/step - loss: 0.1161 - val_loss: 0.1319\n",
            "Epoch 1279/2000\n",
            "80/80 [==============================] - 0s 358us/step - loss: 0.1158 - val_loss: 0.1292\n",
            "Epoch 1280/2000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.1146 - val_loss: 0.1253\n",
            "Epoch 1281/2000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.1144 - val_loss: 0.1249\n",
            "Epoch 1282/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.1136 - val_loss: 0.1256\n",
            "Epoch 1283/2000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.1133 - val_loss: 0.1283\n",
            "Epoch 1284/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.1128 - val_loss: 0.1280\n",
            "Epoch 1285/2000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.1114 - val_loss: 0.1244\n",
            "Epoch 1286/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.1109 - val_loss: 0.1216\n",
            "Epoch 1287/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.1112 - val_loss: 0.1208\n",
            "Epoch 1288/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.1104 - val_loss: 0.1219\n",
            "Epoch 1289/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.1093 - val_loss: 0.1247\n",
            "Epoch 1290/2000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.1094 - val_loss: 0.1252\n",
            "Epoch 1291/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.1088 - val_loss: 0.1216\n",
            "Epoch 1292/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.1079 - val_loss: 0.1191\n",
            "Epoch 1293/2000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.1069 - val_loss: 0.1194\n",
            "Epoch 1294/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.1062 - val_loss: 0.1203\n",
            "Epoch 1295/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.1069 - val_loss: 0.1218\n",
            "Epoch 1296/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.1059 - val_loss: 0.1178\n",
            "Epoch 1297/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.1046 - val_loss: 0.1157\n",
            "Epoch 1298/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.1040 - val_loss: 0.1138\n",
            "Epoch 1299/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.1045 - val_loss: 0.1131\n",
            "Epoch 1300/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.1039 - val_loss: 0.1132\n",
            "Epoch 1301/2000\n",
            "80/80 [==============================] - 0s 384us/step - loss: 0.1026 - val_loss: 0.1132\n",
            "Epoch 1302/2000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.1020 - val_loss: 0.1147\n",
            "Epoch 1303/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.1014 - val_loss: 0.1139\n",
            "Epoch 1304/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.1008 - val_loss: 0.1121\n",
            "Epoch 1305/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.1005 - val_loss: 0.1108\n",
            "Epoch 1306/2000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0994 - val_loss: 0.1115\n",
            "Epoch 1307/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.1003 - val_loss: 0.1128\n",
            "Epoch 1308/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0990 - val_loss: 0.1103\n",
            "Epoch 1309/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0980 - val_loss: 0.1080\n",
            "Epoch 1310/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0980 - val_loss: 0.1068\n",
            "Epoch 1311/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0970 - val_loss: 0.1076\n",
            "Epoch 1312/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0965 - val_loss: 0.1078\n",
            "Epoch 1313/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0958 - val_loss: 0.1063\n",
            "Epoch 1314/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0955 - val_loss: 0.1048\n",
            "Epoch 1315/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0949 - val_loss: 0.1049\n",
            "Epoch 1316/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0943 - val_loss: 0.1044\n",
            "Epoch 1317/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0940 - val_loss: 0.1035\n",
            "Epoch 1318/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0931 - val_loss: 0.1039\n",
            "Epoch 1319/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0925 - val_loss: 0.1033\n",
            "Epoch 1320/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0920 - val_loss: 0.1025\n",
            "Epoch 1321/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0915 - val_loss: 0.1017\n",
            "Epoch 1322/2000\n",
            "80/80 [==============================] - 0s 440us/step - loss: 0.0915 - val_loss: 0.1007\n",
            "Epoch 1323/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0907 - val_loss: 0.1015\n",
            "Epoch 1324/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0900 - val_loss: 0.1007\n",
            "Epoch 1325/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.0898 - val_loss: 0.0997\n",
            "Epoch 1326/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0894 - val_loss: 0.1000\n",
            "Epoch 1327/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0883 - val_loss: 0.0975\n",
            "Epoch 1328/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0880 - val_loss: 0.0959\n",
            "Epoch 1329/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0878 - val_loss: 0.0958\n",
            "Epoch 1330/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0871 - val_loss: 0.0973\n",
            "Epoch 1331/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0867 - val_loss: 0.0968\n",
            "Epoch 1332/2000\n",
            "80/80 [==============================] - 0s 383us/step - loss: 0.0861 - val_loss: 0.0965\n",
            "Epoch 1333/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0857 - val_loss: 0.0956\n",
            "Epoch 1334/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0848 - val_loss: 0.0934\n",
            "Epoch 1335/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0845 - val_loss: 0.0914\n",
            "Epoch 1336/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.0847 - val_loss: 0.0911\n",
            "Epoch 1337/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0838 - val_loss: 0.0920\n",
            "Epoch 1338/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.0829 - val_loss: 0.0937\n",
            "Epoch 1339/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0830 - val_loss: 0.0932\n",
            "Epoch 1340/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0832 - val_loss: 0.0899\n",
            "Epoch 1341/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0817 - val_loss: 0.0898\n",
            "Epoch 1342/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0808 - val_loss: 0.0889\n",
            "Epoch 1343/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0807 - val_loss: 0.0880\n",
            "Epoch 1344/2000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0809 - val_loss: 0.0866\n",
            "Epoch 1345/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0800 - val_loss: 0.0871\n",
            "Epoch 1346/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0789 - val_loss: 0.0890\n",
            "Epoch 1347/2000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.0789 - val_loss: 0.0889\n",
            "Epoch 1348/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.0785 - val_loss: 0.0866\n",
            "Epoch 1349/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0770 - val_loss: 0.0840\n",
            "Epoch 1350/2000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0780 - val_loss: 0.0831\n",
            "Epoch 1351/2000\n",
            "80/80 [==============================] - 0s 358us/step - loss: 0.0773 - val_loss: 0.0838\n",
            "Epoch 1352/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0768 - val_loss: 0.0861\n",
            "Epoch 1353/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.0764 - val_loss: 0.0848\n",
            "Epoch 1354/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0752 - val_loss: 0.0819\n",
            "Epoch 1355/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0754 - val_loss: 0.0807\n",
            "Epoch 1356/2000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.0747 - val_loss: 0.0809\n",
            "Epoch 1357/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0742 - val_loss: 0.0820\n",
            "Epoch 1358/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.0736 - val_loss: 0.0812\n",
            "Epoch 1359/2000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0726 - val_loss: 0.0793\n",
            "Epoch 1360/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0731 - val_loss: 0.0782\n",
            "Epoch 1361/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0725 - val_loss: 0.0785\n",
            "Epoch 1362/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0726 - val_loss: 0.0802\n",
            "Epoch 1363/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0718 - val_loss: 0.0788\n",
            "Epoch 1364/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0710 - val_loss: 0.0761\n",
            "Epoch 1365/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0707 - val_loss: 0.0756\n",
            "Epoch 1366/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0704 - val_loss: 0.0752\n",
            "Epoch 1367/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0694 - val_loss: 0.0753\n",
            "Epoch 1368/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0686 - val_loss: 0.0759\n",
            "Epoch 1369/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0682 - val_loss: 0.0756\n",
            "Epoch 1370/2000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0681 - val_loss: 0.0748\n",
            "Epoch 1371/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0677 - val_loss: 0.0746\n",
            "Epoch 1372/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0671 - val_loss: 0.0727\n",
            "Epoch 1373/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0667 - val_loss: 0.0719\n",
            "Epoch 1374/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0664 - val_loss: 0.0719\n",
            "Epoch 1375/2000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.0657 - val_loss: 0.0712\n",
            "Epoch 1376/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0654 - val_loss: 0.0707\n",
            "Epoch 1377/2000\n",
            "80/80 [==============================] - 0s 365us/step - loss: 0.0648 - val_loss: 0.0707\n",
            "Epoch 1378/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0645 - val_loss: 0.0705\n",
            "Epoch 1379/2000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0642 - val_loss: 0.0706\n",
            "Epoch 1380/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0637 - val_loss: 0.0694\n",
            "Epoch 1381/2000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0631 - val_loss: 0.0687\n",
            "Epoch 1382/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.0627 - val_loss: 0.0680\n",
            "Epoch 1383/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0623 - val_loss: 0.0677\n",
            "Epoch 1384/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0619 - val_loss: 0.0674\n",
            "Epoch 1385/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0616 - val_loss: 0.0674\n",
            "Epoch 1386/2000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0613 - val_loss: 0.0669\n",
            "Epoch 1387/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0606 - val_loss: 0.0655\n",
            "Epoch 1388/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0607 - val_loss: 0.0646\n",
            "Epoch 1389/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0603 - val_loss: 0.0646\n",
            "Epoch 1390/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0597 - val_loss: 0.0654\n",
            "Epoch 1391/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0590 - val_loss: 0.0649\n",
            "Epoch 1392/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0586 - val_loss: 0.0640\n",
            "Epoch 1393/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0583 - val_loss: 0.0633\n",
            "Epoch 1394/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0579 - val_loss: 0.0630\n",
            "Epoch 1395/2000\n",
            "80/80 [==============================] - 0s 370us/step - loss: 0.0576 - val_loss: 0.0626\n",
            "Epoch 1396/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0572 - val_loss: 0.0616\n",
            "Epoch 1397/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0570 - val_loss: 0.0612\n",
            "Epoch 1398/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0565 - val_loss: 0.0610\n",
            "Epoch 1399/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0557 - val_loss: 0.0611\n",
            "Epoch 1400/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0554 - val_loss: 0.0609\n",
            "Epoch 1401/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0551 - val_loss: 0.0603\n",
            "Epoch 1402/2000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0546 - val_loss: 0.0597\n",
            "Epoch 1403/2000\n",
            "80/80 [==============================] - 0s 399us/step - loss: 0.0543 - val_loss: 0.0593\n",
            "Epoch 1404/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0539 - val_loss: 0.0586\n",
            "Epoch 1405/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.0535 - val_loss: 0.0585\n",
            "Epoch 1406/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0530 - val_loss: 0.0587\n",
            "Epoch 1407/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0537 - val_loss: 0.0586\n",
            "Epoch 1408/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0522 - val_loss: 0.0567\n",
            "Epoch 1409/2000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.0524 - val_loss: 0.0562\n",
            "Epoch 1410/2000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.0529 - val_loss: 0.0557\n",
            "Epoch 1411/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0515 - val_loss: 0.0556\n",
            "Epoch 1412/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0514 - val_loss: 0.0561\n",
            "Epoch 1413/2000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0507 - val_loss: 0.0549\n",
            "Epoch 1414/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0511 - val_loss: 0.0538\n",
            "Epoch 1415/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0503 - val_loss: 0.0536\n",
            "Epoch 1416/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0501 - val_loss: 0.0548\n",
            "Epoch 1417/2000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0502 - val_loss: 0.0538\n",
            "Epoch 1418/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0487 - val_loss: 0.0521\n",
            "Epoch 1419/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0491 - val_loss: 0.0517\n",
            "Epoch 1420/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0484 - val_loss: 0.0519\n",
            "Epoch 1421/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0479 - val_loss: 0.0523\n",
            "Epoch 1422/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0477 - val_loss: 0.0512\n",
            "Epoch 1423/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.0472 - val_loss: 0.0503\n",
            "Epoch 1424/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0469 - val_loss: 0.0499\n",
            "Epoch 1425/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0465 - val_loss: 0.0500\n",
            "Epoch 1426/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0461 - val_loss: 0.0499\n",
            "Epoch 1427/2000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.0458 - val_loss: 0.0491\n",
            "Epoch 1428/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.0453 - val_loss: 0.0488\n",
            "Epoch 1429/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0450 - val_loss: 0.0484\n",
            "Epoch 1430/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0446 - val_loss: 0.0481\n",
            "Epoch 1431/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0444 - val_loss: 0.0479\n",
            "Epoch 1432/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0443 - val_loss: 0.0474\n",
            "Epoch 1433/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0436 - val_loss: 0.0470\n",
            "Epoch 1434/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0437 - val_loss: 0.0467\n",
            "Epoch 1435/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0432 - val_loss: 0.0460\n",
            "Epoch 1436/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0429 - val_loss: 0.0457\n",
            "Epoch 1437/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.0428 - val_loss: 0.0457\n",
            "Epoch 1438/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0420 - val_loss: 0.0450\n",
            "Epoch 1439/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0420 - val_loss: 0.0445\n",
            "Epoch 1440/2000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0415 - val_loss: 0.0444\n",
            "Epoch 1441/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0412 - val_loss: 0.0444\n",
            "Epoch 1442/2000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.0410 - val_loss: 0.0439\n",
            "Epoch 1443/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0405 - val_loss: 0.0433\n",
            "Epoch 1444/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0403 - val_loss: 0.0428\n",
            "Epoch 1445/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0404 - val_loss: 0.0426\n",
            "Epoch 1446/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0400 - val_loss: 0.0427\n",
            "Epoch 1447/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0393 - val_loss: 0.0424\n",
            "Epoch 1448/2000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0390 - val_loss: 0.0418\n",
            "Epoch 1449/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0388 - val_loss: 0.0414\n",
            "Epoch 1450/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.0385 - val_loss: 0.0412\n",
            "Epoch 1451/2000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.0381 - val_loss: 0.0410\n",
            "Epoch 1452/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0378 - val_loss: 0.0406\n",
            "Epoch 1453/2000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0374 - val_loss: 0.0401\n",
            "Epoch 1454/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0374 - val_loss: 0.0398\n",
            "Epoch 1455/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.0368 - val_loss: 0.0397\n",
            "Epoch 1456/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0367 - val_loss: 0.0400\n",
            "Epoch 1457/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.0369 - val_loss: 0.0394\n",
            "Epoch 1458/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0362 - val_loss: 0.0385\n",
            "Epoch 1459/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0360 - val_loss: 0.0382\n",
            "Epoch 1460/2000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.0356 - val_loss: 0.0379\n",
            "Epoch 1461/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0352 - val_loss: 0.0379\n",
            "Epoch 1462/2000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.0351 - val_loss: 0.0376\n",
            "Epoch 1463/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0348 - val_loss: 0.0371\n",
            "Epoch 1464/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0344 - val_loss: 0.0366\n",
            "Epoch 1465/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0341 - val_loss: 0.0363\n",
            "Epoch 1466/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0340 - val_loss: 0.0360\n",
            "Epoch 1467/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0336 - val_loss: 0.0358\n",
            "Epoch 1468/2000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0334 - val_loss: 0.0356\n",
            "Epoch 1469/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0331 - val_loss: 0.0351\n",
            "Epoch 1470/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0328 - val_loss: 0.0347\n",
            "Epoch 1471/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0325 - val_loss: 0.0344\n",
            "Epoch 1472/2000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.0323 - val_loss: 0.0341\n",
            "Epoch 1473/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0322 - val_loss: 0.0337\n",
            "Epoch 1474/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0318 - val_loss: 0.0334\n",
            "Epoch 1475/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0316 - val_loss: 0.0332\n",
            "Epoch 1476/2000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.0314 - val_loss: 0.0329\n",
            "Epoch 1477/2000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0311 - val_loss: 0.0326\n",
            "Epoch 1478/2000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0308 - val_loss: 0.0322\n",
            "Epoch 1479/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0305 - val_loss: 0.0320\n",
            "Epoch 1480/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0304 - val_loss: 0.0317\n",
            "Epoch 1481/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0301 - val_loss: 0.0315\n",
            "Epoch 1482/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0305 - val_loss: 0.0313\n",
            "Epoch 1483/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0296 - val_loss: 0.0312\n",
            "Epoch 1484/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0296 - val_loss: 0.0309\n",
            "Epoch 1485/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0290 - val_loss: 0.0307\n",
            "Epoch 1486/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0291 - val_loss: 0.0307\n",
            "Epoch 1487/2000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0289 - val_loss: 0.0301\n",
            "Epoch 1488/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0286 - val_loss: 0.0299\n",
            "Epoch 1489/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0282 - val_loss: 0.0297\n",
            "Epoch 1490/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0280 - val_loss: 0.0294\n",
            "Epoch 1491/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0282 - val_loss: 0.0291\n",
            "Epoch 1492/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0276 - val_loss: 0.0287\n",
            "Epoch 1493/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0272 - val_loss: 0.0285\n",
            "Epoch 1494/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0271 - val_loss: 0.0284\n",
            "Epoch 1495/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0270 - val_loss: 0.0280\n",
            "Epoch 1496/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0269 - val_loss: 0.0277\n",
            "Epoch 1497/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0264 - val_loss: 0.0274\n",
            "Epoch 1498/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0262 - val_loss: 0.0272\n",
            "Epoch 1499/2000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0262 - val_loss: 0.0270\n",
            "Epoch 1500/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0258 - val_loss: 0.0267\n",
            "Epoch 1501/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0257 - val_loss: 0.0267\n",
            "Epoch 1502/2000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0255 - val_loss: 0.0264\n",
            "Epoch 1503/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0253 - val_loss: 0.0261\n",
            "Epoch 1504/2000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.0250 - val_loss: 0.0259\n",
            "Epoch 1505/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0247 - val_loss: 0.0257\n",
            "Epoch 1506/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0245 - val_loss: 0.0256\n",
            "Epoch 1507/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0244 - val_loss: 0.0253\n",
            "Epoch 1508/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0242 - val_loss: 0.0251\n",
            "Epoch 1509/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0239 - val_loss: 0.0248\n",
            "Epoch 1510/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0237 - val_loss: 0.0246\n",
            "Epoch 1511/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0237 - val_loss: 0.0244\n",
            "Epoch 1512/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0232 - val_loss: 0.0244\n",
            "Epoch 1513/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0232 - val_loss: 0.0242\n",
            "Epoch 1514/2000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0232 - val_loss: 0.0238\n",
            "Epoch 1515/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0227 - val_loss: 0.0236\n",
            "Epoch 1516/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0225 - val_loss: 0.0234\n",
            "Epoch 1517/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0224 - val_loss: 0.0232\n",
            "Epoch 1518/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0222 - val_loss: 0.0229\n",
            "Epoch 1519/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0220 - val_loss: 0.0227\n",
            "Epoch 1520/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0218 - val_loss: 0.0225\n",
            "Epoch 1521/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0216 - val_loss: 0.0223\n",
            "Epoch 1522/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0214 - val_loss: 0.0220\n",
            "Epoch 1523/2000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.0213 - val_loss: 0.0218\n",
            "Epoch 1524/2000\n",
            "80/80 [==============================] - 0s 385us/step - loss: 0.0211 - val_loss: 0.0217\n",
            "Epoch 1525/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.0209 - val_loss: 0.0216\n",
            "Epoch 1526/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0207 - val_loss: 0.0215\n",
            "Epoch 1527/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0207 - val_loss: 0.0212\n",
            "Epoch 1528/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0204 - val_loss: 0.0209\n",
            "Epoch 1529/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0202 - val_loss: 0.0207\n",
            "Epoch 1530/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.0200 - val_loss: 0.0205\n",
            "Epoch 1531/2000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.0199 - val_loss: 0.0204\n",
            "Epoch 1532/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0196 - val_loss: 0.0202\n",
            "Epoch 1533/2000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.0195 - val_loss: 0.0200\n",
            "Epoch 1534/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0193 - val_loss: 0.0199\n",
            "Epoch 1535/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0191 - val_loss: 0.0197\n",
            "Epoch 1536/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0190 - val_loss: 0.0194\n",
            "Epoch 1537/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0188 - val_loss: 0.0192\n",
            "Epoch 1538/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0188 - val_loss: 0.0190\n",
            "Epoch 1539/2000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.0185 - val_loss: 0.0189\n",
            "Epoch 1540/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0183 - val_loss: 0.0191\n",
            "Epoch 1541/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.0184 - val_loss: 0.0187\n",
            "Epoch 1542/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0181 - val_loss: 0.0184\n",
            "Epoch 1543/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0179 - val_loss: 0.0181\n",
            "Epoch 1544/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0178 - val_loss: 0.0180\n",
            "Epoch 1545/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0176 - val_loss: 0.0180\n",
            "Epoch 1546/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0176 - val_loss: 0.0180\n",
            "Epoch 1547/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0174 - val_loss: 0.0175\n",
            "Epoch 1548/2000\n",
            "80/80 [==============================] - 0s 360us/step - loss: 0.0172 - val_loss: 0.0174\n",
            "Epoch 1549/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0171 - val_loss: 0.0173\n",
            "Epoch 1550/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0168 - val_loss: 0.0172\n",
            "Epoch 1551/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0167 - val_loss: 0.0170\n",
            "Epoch 1552/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0165 - val_loss: 0.0168\n",
            "Epoch 1553/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0164 - val_loss: 0.0166\n",
            "Epoch 1554/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0163 - val_loss: 0.0164\n",
            "Epoch 1555/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0161 - val_loss: 0.0163\n",
            "Epoch 1556/2000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.0160 - val_loss: 0.0164\n",
            "Epoch 1557/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0159 - val_loss: 0.0161\n",
            "Epoch 1558/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0157 - val_loss: 0.0158\n",
            "Epoch 1559/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.0156 - val_loss: 0.0157\n",
            "Epoch 1560/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0155 - val_loss: 0.0156\n",
            "Epoch 1561/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0153 - val_loss: 0.0156\n",
            "Epoch 1562/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0153 - val_loss: 0.0156\n",
            "Epoch 1563/2000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0152 - val_loss: 0.0152\n",
            "Epoch 1564/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0149 - val_loss: 0.0149\n",
            "Epoch 1565/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0149 - val_loss: 0.0148\n",
            "Epoch 1566/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0147 - val_loss: 0.0148\n",
            "Epoch 1567/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0148 - val_loss: 0.0151\n",
            "Epoch 1568/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0146 - val_loss: 0.0146\n",
            "Epoch 1569/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0144 - val_loss: 0.0143\n",
            "Epoch 1570/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0142 - val_loss: 0.0143\n",
            "Epoch 1571/2000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.0141 - val_loss: 0.0144\n",
            "Epoch 1572/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0140 - val_loss: 0.0142\n",
            "Epoch 1573/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0138 - val_loss: 0.0139\n",
            "Epoch 1574/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0137 - val_loss: 0.0137\n",
            "Epoch 1575/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0137 - val_loss: 0.0137\n",
            "Epoch 1576/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0135 - val_loss: 0.0137\n",
            "Epoch 1577/2000\n",
            "80/80 [==============================] - 0s 423us/step - loss: 0.0134 - val_loss: 0.0136\n",
            "Epoch 1578/2000\n",
            "80/80 [==============================] - 0s 359us/step - loss: 0.0132 - val_loss: 0.0133\n",
            "Epoch 1579/2000\n",
            "80/80 [==============================] - 0s 371us/step - loss: 0.0132 - val_loss: 0.0131\n",
            "Epoch 1580/2000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.0131 - val_loss: 0.0130\n",
            "Epoch 1581/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0129 - val_loss: 0.0131\n",
            "Epoch 1582/2000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0128 - val_loss: 0.0130\n",
            "Epoch 1583/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0128 - val_loss: 0.0129\n",
            "Epoch 1584/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0126 - val_loss: 0.0126\n",
            "Epoch 1585/2000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0126 - val_loss: 0.0123\n",
            "Epoch 1586/2000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.0125 - val_loss: 0.0122\n",
            "Epoch 1587/2000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.0124 - val_loss: 0.0125\n",
            "Epoch 1588/2000\n",
            "80/80 [==============================] - 0s 380us/step - loss: 0.0122 - val_loss: 0.0122\n",
            "Epoch 1589/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0121 - val_loss: 0.0119\n",
            "Epoch 1590/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0120 - val_loss: 0.0118\n",
            "Epoch 1591/2000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.0120 - val_loss: 0.0118\n",
            "Epoch 1592/2000\n",
            "80/80 [==============================] - 0s 361us/step - loss: 0.0118 - val_loss: 0.0116\n",
            "Epoch 1593/2000\n",
            "80/80 [==============================] - 0s 356us/step - loss: 0.0117 - val_loss: 0.0115\n",
            "Epoch 1594/2000\n",
            "80/80 [==============================] - 0s 363us/step - loss: 0.0116 - val_loss: 0.0115\n",
            "Epoch 1595/2000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.0116 - val_loss: 0.0117\n",
            "Epoch 1596/2000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.0115 - val_loss: 0.0113\n",
            "Epoch 1597/2000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0113 - val_loss: 0.0112\n",
            "Epoch 1598/2000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.0112 - val_loss: 0.0111\n",
            "Epoch 1599/2000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 0.0111 - val_loss: 0.0111\n",
            "Epoch 1600/2000\n",
            "80/80 [==============================] - 0s 363us/step - loss: 0.0110 - val_loss: 0.0110\n",
            "Epoch 1601/2000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.0109 - val_loss: 0.0107\n",
            "Epoch 1602/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0109 - val_loss: 0.0106\n",
            "Epoch 1603/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0108 - val_loss: 0.0109\n",
            "Epoch 1604/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0107 - val_loss: 0.0108\n",
            "Epoch 1605/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0106 - val_loss: 0.0104\n",
            "Epoch 1606/2000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0105 - val_loss: 0.0101\n",
            "Epoch 1607/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0105 - val_loss: 0.0101\n",
            "Epoch 1608/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.0104 - val_loss: 0.0103\n",
            "Epoch 1609/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0102 - val_loss: 0.0102\n",
            "Epoch 1610/2000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0102 - val_loss: 0.0100\n",
            "Epoch 1611/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0101 - val_loss: 0.0099\n",
            "Epoch 1612/2000\n",
            "80/80 [==============================] - 0s 387us/step - loss: 0.0100 - val_loss: 0.0098\n",
            "Epoch 1613/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0099 - val_loss: 0.0099\n",
            "Epoch 1614/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0098 - val_loss: 0.0098\n",
            "Epoch 1615/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0097 - val_loss: 0.0098\n",
            "Epoch 1616/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0097 - val_loss: 0.0099\n",
            "Epoch 1617/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0096 - val_loss: 0.0095\n",
            "Epoch 1618/2000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0095 - val_loss: 0.0092\n",
            "Epoch 1619/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0095 - val_loss: 0.0091\n",
            "Epoch 1620/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0094 - val_loss: 0.0093\n",
            "Epoch 1621/2000\n",
            "80/80 [==============================] - 0s 360us/step - loss: 0.0093 - val_loss: 0.0096\n",
            "Epoch 1622/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0093 - val_loss: 0.0093\n",
            "Epoch 1623/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0092 - val_loss: 0.0089\n",
            "Epoch 1624/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.0091 - val_loss: 0.0087\n",
            "Epoch 1625/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0091 - val_loss: 0.0089\n",
            "Epoch 1626/2000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0089 - val_loss: 0.0090\n",
            "Epoch 1627/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0089 - val_loss: 0.0088\n",
            "Epoch 1628/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0088 - val_loss: 0.0085\n",
            "Epoch 1629/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0087 - val_loss: 0.0086\n",
            "Epoch 1630/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0087 - val_loss: 0.0089\n",
            "Epoch 1631/2000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0086 - val_loss: 0.0086\n",
            "Epoch 1632/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0085 - val_loss: 0.0082\n",
            "Epoch 1633/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0085 - val_loss: 0.0081\n",
            "Epoch 1634/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0084 - val_loss: 0.0083\n",
            "Epoch 1635/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0083 - val_loss: 0.0085\n",
            "Epoch 1636/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0083 - val_loss: 0.0083\n",
            "Epoch 1637/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0083 - val_loss: 0.0079\n",
            "Epoch 1638/2000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.0081 - val_loss: 0.0079\n",
            "Epoch 1639/2000\n",
            "80/80 [==============================] - 0s 422us/step - loss: 0.0081 - val_loss: 0.0080\n",
            "Epoch 1640/2000\n",
            "80/80 [==============================] - 0s 467us/step - loss: 0.0080 - val_loss: 0.0080\n",
            "Epoch 1641/2000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.0080 - val_loss: 0.0078\n",
            "Epoch 1642/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0079 - val_loss: 0.0076\n",
            "Epoch 1643/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.0078 - val_loss: 0.0074\n",
            "Epoch 1644/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.0078 - val_loss: 0.0075\n",
            "Epoch 1645/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0077 - val_loss: 0.0075\n",
            "Epoch 1646/2000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0077 - val_loss: 0.0074\n",
            "Epoch 1647/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0076 - val_loss: 0.0075\n",
            "Epoch 1648/2000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0076 - val_loss: 0.0073\n",
            "Epoch 1649/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0075 - val_loss: 0.0074\n",
            "Epoch 1650/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0075 - val_loss: 0.0073\n",
            "Epoch 1651/2000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0074 - val_loss: 0.0071\n",
            "Epoch 1652/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0074 - val_loss: 0.0072\n",
            "Epoch 1653/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0073 - val_loss: 0.0070\n",
            "Epoch 1654/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0073 - val_loss: 0.0069\n",
            "Epoch 1655/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0073 - val_loss: 0.0071\n",
            "Epoch 1656/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0072 - val_loss: 0.0069\n",
            "Epoch 1657/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0071 - val_loss: 0.0067\n",
            "Epoch 1658/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0071 - val_loss: 0.0067\n",
            "Epoch 1659/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0070 - val_loss: 0.0068\n",
            "Epoch 1660/2000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0070 - val_loss: 0.0068\n",
            "Epoch 1661/2000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0069 - val_loss: 0.0067\n",
            "Epoch 1662/2000\n",
            "80/80 [==============================] - 0s 353us/step - loss: 0.0069 - val_loss: 0.0068\n",
            "Epoch 1663/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0069 - val_loss: 0.0068\n",
            "Epoch 1664/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0068 - val_loss: 0.0068\n",
            "Epoch 1665/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0068 - val_loss: 0.0066\n",
            "Epoch 1666/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 1667/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0066 - val_loss: 0.0067\n",
            "Epoch 1668/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0067 - val_loss: 0.0068\n",
            "Epoch 1669/2000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.0066 - val_loss: 0.0063\n",
            "Epoch 1670/2000\n",
            "80/80 [==============================] - 0s 377us/step - loss: 0.0065 - val_loss: 0.0063\n",
            "Epoch 1671/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0065 - val_loss: 0.0063\n",
            "Epoch 1672/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0064 - val_loss: 0.0065\n",
            "Epoch 1673/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0065 - val_loss: 0.0065\n",
            "Epoch 1674/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0063 - val_loss: 0.0059\n",
            "Epoch 1675/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0064 - val_loss: 0.0058\n",
            "Epoch 1676/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0063 - val_loss: 0.0064\n",
            "Epoch 1677/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0063 - val_loss: 0.0068\n",
            "Epoch 1678/2000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 0.0063 - val_loss: 0.0062\n",
            "Epoch 1679/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0062 - val_loss: 0.0058\n",
            "Epoch 1680/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0062 - val_loss: 0.0058\n",
            "Epoch 1681/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0061 - val_loss: 0.0062\n",
            "Epoch 1682/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0061 - val_loss: 0.0062\n",
            "Epoch 1683/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0060 - val_loss: 0.0056\n",
            "Epoch 1684/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0060 - val_loss: 0.0057\n",
            "Epoch 1685/2000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0060 - val_loss: 0.0058\n",
            "Epoch 1686/2000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0059 - val_loss: 0.0059\n",
            "Epoch 1687/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0059 - val_loss: 0.0060\n",
            "Epoch 1688/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0059 - val_loss: 0.0059\n",
            "Epoch 1689/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0058 - val_loss: 0.0056\n",
            "Epoch 1690/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0058 - val_loss: 0.0055\n",
            "Epoch 1691/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0057 - val_loss: 0.0058\n",
            "Epoch 1692/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0058 - val_loss: 0.0060\n",
            "Epoch 1693/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0057 - val_loss: 0.0054\n",
            "Epoch 1694/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0057 - val_loss: 0.0052\n",
            "Epoch 1695/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0057 - val_loss: 0.0057\n",
            "Epoch 1696/2000\n",
            "80/80 [==============================] - 0s 411us/step - loss: 0.0056 - val_loss: 0.0057\n",
            "Epoch 1697/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0055 - val_loss: 0.0058\n",
            "Epoch 1698/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0055 - val_loss: 0.0055\n",
            "Epoch 1699/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0055 - val_loss: 0.0054\n",
            "Epoch 1700/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0055 - val_loss: 0.0056\n",
            "Epoch 1701/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.0054 - val_loss: 0.0055\n",
            "Epoch 1702/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0054 - val_loss: 0.0054\n",
            "Epoch 1703/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0053 - val_loss: 0.0052\n",
            "Epoch 1704/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0053 - val_loss: 0.0053\n",
            "Epoch 1705/2000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.0053 - val_loss: 0.0053\n",
            "Epoch 1706/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0053 - val_loss: 0.0055\n",
            "Epoch 1707/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0052 - val_loss: 0.0051\n",
            "Epoch 1708/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0052 - val_loss: 0.0049\n",
            "Epoch 1709/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0052 - val_loss: 0.0052\n",
            "Epoch 1710/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0052 - val_loss: 0.0056\n",
            "Epoch 1711/2000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.0052 - val_loss: 0.0051\n",
            "Epoch 1712/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0051 - val_loss: 0.0050\n",
            "Epoch 1713/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0051 - val_loss: 0.0051\n",
            "Epoch 1714/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0051 - val_loss: 0.0053\n",
            "Epoch 1715/2000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.0050 - val_loss: 0.0050\n",
            "Epoch 1716/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0050 - val_loss: 0.0050\n",
            "Epoch 1717/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0050 - val_loss: 0.0053\n",
            "Epoch 1718/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0050 - val_loss: 0.0053\n",
            "Epoch 1719/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0050 - val_loss: 0.0051\n",
            "Epoch 1720/2000\n",
            "80/80 [==============================] - 0s 400us/step - loss: 0.0049 - val_loss: 0.0048\n",
            "Epoch 1721/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0049 - val_loss: 0.0046\n",
            "Epoch 1722/2000\n",
            "80/80 [==============================] - 0s 364us/step - loss: 0.0049 - val_loss: 0.0046\n",
            "Epoch 1723/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0049 - val_loss: 0.0052\n",
            "Epoch 1724/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0049 - val_loss: 0.0051\n",
            "Epoch 1725/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0048 - val_loss: 0.0047\n",
            "Epoch 1726/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0049 - val_loss: 0.0043\n",
            "Epoch 1727/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.0048 - val_loss: 0.0049\n",
            "Epoch 1728/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0048 - val_loss: 0.0053\n",
            "Epoch 1729/2000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0047 - val_loss: 0.0048\n",
            "Epoch 1730/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0048 - val_loss: 0.0043\n",
            "Epoch 1731/2000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.0047 - val_loss: 0.0047\n",
            "Epoch 1732/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0046 - val_loss: 0.0054\n",
            "Epoch 1733/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0047 - val_loss: 0.0050\n",
            "Epoch 1734/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0046 - val_loss: 0.0043\n",
            "Epoch 1735/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0046 - val_loss: 0.0044\n",
            "Epoch 1736/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0046 - val_loss: 0.0048\n",
            "Epoch 1737/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0046 - val_loss: 0.0048\n",
            "Epoch 1738/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0045 - val_loss: 0.0045\n",
            "Epoch 1739/2000\n",
            "80/80 [==============================] - 0s 372us/step - loss: 0.0045 - val_loss: 0.0046\n",
            "Epoch 1740/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0045 - val_loss: 0.0046\n",
            "Epoch 1741/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.0045 - val_loss: 0.0047\n",
            "Epoch 1742/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0045 - val_loss: 0.0047\n",
            "Epoch 1743/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0045 - val_loss: 0.0046\n",
            "Epoch 1744/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0044 - val_loss: 0.0048\n",
            "Epoch 1745/2000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0044 - val_loss: 0.0047\n",
            "Epoch 1746/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0044 - val_loss: 0.0045\n",
            "Epoch 1747/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0044 - val_loss: 0.0045\n",
            "Epoch 1748/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0044 - val_loss: 0.0048\n",
            "Epoch 1749/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0044 - val_loss: 0.0046\n",
            "Epoch 1750/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0043 - val_loss: 0.0042\n",
            "Epoch 1751/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0044 - val_loss: 0.0043\n",
            "Epoch 1752/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0043 - val_loss: 0.0043\n",
            "Epoch 1753/2000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.0043 - val_loss: 0.0045\n",
            "Epoch 1754/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0043 - val_loss: 0.0047\n",
            "Epoch 1755/2000\n",
            "80/80 [==============================] - 0s 349us/step - loss: 0.0043 - val_loss: 0.0045\n",
            "Epoch 1756/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0042 - val_loss: 0.0043\n",
            "Epoch 1757/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.0042 - val_loss: 0.0045\n",
            "Epoch 1758/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0042 - val_loss: 0.0045\n",
            "Epoch 1759/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0042 - val_loss: 0.0043\n",
            "Epoch 1760/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.0042 - val_loss: 0.0041\n",
            "Epoch 1761/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0042 - val_loss: 0.0044\n",
            "Epoch 1762/2000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0042 - val_loss: 0.0047\n",
            "Epoch 1763/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0041 - val_loss: 0.0042\n",
            "Epoch 1764/2000\n",
            "80/80 [==============================] - 0s 353us/step - loss: 0.0041 - val_loss: 0.0040\n",
            "Epoch 1765/2000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.0041 - val_loss: 0.0041\n",
            "Epoch 1766/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0041 - val_loss: 0.0044\n",
            "Epoch 1767/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0041 - val_loss: 0.0044\n",
            "Epoch 1768/2000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.0041 - val_loss: 0.0043\n",
            "Epoch 1769/2000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0041 - val_loss: 0.0041\n",
            "Epoch 1770/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0041 - val_loss: 0.0042\n",
            "Epoch 1771/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0040 - val_loss: 0.0042\n",
            "Epoch 1772/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0040 - val_loss: 0.0043\n",
            "Epoch 1773/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0040 - val_loss: 0.0046\n",
            "Epoch 1774/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.0040 - val_loss: 0.0043\n",
            "Epoch 1775/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0040 - val_loss: 0.0042\n",
            "Epoch 1776/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0040 - val_loss: 0.0046\n",
            "Epoch 1777/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0040 - val_loss: 0.0043\n",
            "Epoch 1778/2000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0040 - val_loss: 0.0038\n",
            "Epoch 1779/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0040 - val_loss: 0.0042\n",
            "Epoch 1780/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0040 - val_loss: 0.0045\n",
            "Epoch 1781/2000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0039 - val_loss: 0.0041\n",
            "Epoch 1782/2000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0039 - val_loss: 0.0039\n",
            "Epoch 1783/2000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.0040 - val_loss: 0.0042\n",
            "Epoch 1784/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0039 - val_loss: 0.0040\n",
            "Epoch 1785/2000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.0039 - val_loss: 0.0042\n",
            "Epoch 1786/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0039 - val_loss: 0.0041\n",
            "Epoch 1787/2000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0039 - val_loss: 0.0040\n",
            "Epoch 1788/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0039 - val_loss: 0.0043\n",
            "Epoch 1789/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0039 - val_loss: 0.0045\n",
            "Epoch 1790/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0039 - val_loss: 0.0043\n",
            "Epoch 1791/2000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.0039 - val_loss: 0.0041\n",
            "Epoch 1792/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0038 - val_loss: 0.0043\n",
            "Epoch 1793/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0038 - val_loss: 0.0045\n",
            "Epoch 1794/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0038 - val_loss: 0.0042\n",
            "Epoch 1795/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0038 - val_loss: 0.0040\n",
            "Epoch 1796/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0038 - val_loss: 0.0043\n",
            "Epoch 1797/2000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.0038 - val_loss: 0.0046\n",
            "Epoch 1798/2000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.0038 - val_loss: 0.0043\n",
            "Epoch 1799/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 1800/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 1801/2000\n",
            "80/80 [==============================] - 0s 362us/step - loss: 0.0038 - val_loss: 0.0042\n",
            "Epoch 1802/2000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0038 - val_loss: 0.0042\n",
            "Epoch 1803/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0037 - val_loss: 0.0040\n",
            "Epoch 1804/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0037 - val_loss: 0.0038\n",
            "Epoch 1805/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0038 - val_loss: 0.0040\n",
            "Epoch 1806/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0037 - val_loss: 0.0047\n",
            "Epoch 1807/2000\n",
            "80/80 [==============================] - 0s 362us/step - loss: 0.0038 - val_loss: 0.0044\n",
            "Epoch 1808/2000\n",
            "80/80 [==============================] - 0s 353us/step - loss: 0.0038 - val_loss: 0.0035\n",
            "Epoch 1809/2000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0038 - val_loss: 0.0038\n",
            "Epoch 1810/2000\n",
            "80/80 [==============================] - 0s 358us/step - loss: 0.0037 - val_loss: 0.0042\n",
            "Epoch 1811/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0037 - val_loss: 0.0044\n",
            "Epoch 1812/2000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 1813/2000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 1814/2000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.0037 - val_loss: 0.0046\n",
            "Epoch 1815/2000\n",
            "80/80 [==============================] - 0s 373us/step - loss: 0.0038 - val_loss: 0.0046\n",
            "Epoch 1816/2000\n",
            "80/80 [==============================] - 0s 358us/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 1817/2000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 1818/2000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0036 - val_loss: 0.0043\n",
            "Epoch 1819/2000\n",
            "80/80 [==============================] - 0s 380us/step - loss: 0.0037 - val_loss: 0.0045\n",
            "Epoch 1820/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0037 - val_loss: 0.0039\n",
            "Epoch 1821/2000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0037 - val_loss: 0.0039\n",
            "Epoch 1822/2000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0036 - val_loss: 0.0045\n",
            "Epoch 1823/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0036 - val_loss: 0.0042\n",
            "Epoch 1824/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0036 - val_loss: 0.0039\n",
            "Epoch 1825/2000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.0036 - val_loss: 0.0040\n",
            "Epoch 1826/2000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.0036 - val_loss: 0.0042\n",
            "Epoch 1827/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0036 - val_loss: 0.0040\n",
            "Epoch 1828/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.0036 - val_loss: 0.0040\n",
            "Epoch 1829/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0036 - val_loss: 0.0040\n",
            "Epoch 1830/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0036 - val_loss: 0.0039\n",
            "Epoch 1831/2000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0036 - val_loss: 0.0038\n",
            "Epoch 1832/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0036 - val_loss: 0.0039\n",
            "Epoch 1833/2000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0036 - val_loss: 0.0043\n",
            "Epoch 1834/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0036 - val_loss: 0.0038\n",
            "Epoch 1835/2000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0036 - val_loss: 0.0038\n",
            "Epoch 1836/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0036 - val_loss: 0.0045\n",
            "Epoch 1837/2000\n",
            "80/80 [==============================] - 0s 370us/step - loss: 0.0036 - val_loss: 0.0041\n",
            "Epoch 1838/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 1839/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0036 - val_loss: 0.0039\n",
            "Epoch 1840/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0035 - val_loss: 0.0042\n",
            "Epoch 1841/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0035 - val_loss: 0.0040\n",
            "Epoch 1842/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0035 - val_loss: 0.0039\n",
            "Epoch 1843/2000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0036 - val_loss: 0.0038\n",
            "Epoch 1844/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0036 - val_loss: 0.0045\n",
            "Epoch 1845/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0036 - val_loss: 0.0042\n",
            "Epoch 1846/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0035 - val_loss: 0.0036\n",
            "Epoch 1847/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0035 - val_loss: 0.0037\n",
            "Epoch 1848/2000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0035 - val_loss: 0.0044\n",
            "Epoch 1849/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0035 - val_loss: 0.0039\n",
            "Epoch 1850/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0035 - val_loss: 0.0039\n",
            "Epoch 1851/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0035 - val_loss: 0.0039\n",
            "Epoch 1852/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0035 - val_loss: 0.0038\n",
            "Epoch 1853/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0035 - val_loss: 0.0038\n",
            "Epoch 1854/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0035 - val_loss: 0.0043\n",
            "Epoch 1855/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0035 - val_loss: 0.0040\n",
            "Epoch 1856/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0035 - val_loss: 0.0039\n",
            "Epoch 1857/2000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0035 - val_loss: 0.0041\n",
            "Epoch 1858/2000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0035 - val_loss: 0.0039\n",
            "Epoch 1859/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0034 - val_loss: 0.0037\n",
            "Epoch 1860/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0035 - val_loss: 0.0038\n",
            "Epoch 1861/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0034 - val_loss: 0.0042\n",
            "Epoch 1862/2000\n",
            "80/80 [==============================] - 0s 398us/step - loss: 0.0035 - val_loss: 0.0040\n",
            "Epoch 1863/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 1864/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0035 - val_loss: 0.0039\n",
            "Epoch 1865/2000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0035 - val_loss: 0.0044\n",
            "Epoch 1866/2000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.0034 - val_loss: 0.0038\n",
            "Epoch 1867/2000\n",
            "80/80 [==============================] - 0s 352us/step - loss: 0.0034 - val_loss: 0.0035\n",
            "Epoch 1868/2000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.0034 - val_loss: 0.0042\n",
            "Epoch 1869/2000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.0034 - val_loss: 0.0044\n",
            "Epoch 1870/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0035 - val_loss: 0.0040\n",
            "Epoch 1871/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0035 - val_loss: 0.0035\n",
            "Epoch 1872/2000\n",
            "80/80 [==============================] - 0s 363us/step - loss: 0.0035 - val_loss: 0.0038\n",
            "Epoch 1873/2000\n",
            "80/80 [==============================] - 0s 368us/step - loss: 0.0034 - val_loss: 0.0039\n",
            "Epoch 1874/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0034 - val_loss: 0.0039\n",
            "Epoch 1875/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0034 - val_loss: 0.0038\n",
            "Epoch 1876/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0034 - val_loss: 0.0040\n",
            "Epoch 1877/2000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.0034 - val_loss: 0.0037\n",
            "Epoch 1878/2000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.0034 - val_loss: 0.0035\n",
            "Epoch 1879/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 1880/2000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0035 - val_loss: 0.0044\n",
            "Epoch 1881/2000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 1882/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0034 - val_loss: 0.0040\n",
            "Epoch 1883/2000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0034 - val_loss: 0.0043\n",
            "Epoch 1884/2000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.0034 - val_loss: 0.0042\n",
            "Epoch 1885/2000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0034 - val_loss: 0.0036\n",
            "Epoch 1886/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0034 - val_loss: 0.0040\n",
            "Epoch 1887/2000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0034 - val_loss: 0.0042\n",
            "Epoch 1888/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 1889/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0034 - val_loss: 0.0038\n",
            "Epoch 1890/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 1891/2000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 1892/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.0034 - val_loss: 0.0045\n",
            "Epoch 1893/2000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.0034 - val_loss: 0.0038\n",
            "Epoch 1894/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0033 - val_loss: 0.0038\n",
            "Epoch 1895/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0033 - val_loss: 0.0040\n",
            "Epoch 1896/2000\n",
            "80/80 [==============================] - 0s 352us/step - loss: 0.0034 - val_loss: 0.0039\n",
            "Epoch 1897/2000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0033 - val_loss: 0.0042\n",
            "Epoch 1898/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 1899/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0033 - val_loss: 0.0037\n",
            "Epoch 1900/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0034 - val_loss: 0.0040\n",
            "Epoch 1901/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.0033 - val_loss: 0.0037\n",
            "Epoch 1902/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0034 - val_loss: 0.0038\n",
            "Epoch 1903/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0033 - val_loss: 0.0037\n",
            "Epoch 1904/2000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0034 - val_loss: 0.0038\n",
            "Epoch 1905/2000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0033 - val_loss: 0.0034\n",
            "Epoch 1906/2000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0034 - val_loss: 0.0039\n",
            "Epoch 1907/2000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0033 - val_loss: 0.0042\n",
            "Epoch 1908/2000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 1909/2000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0033 - val_loss: 0.0034\n",
            "Epoch 1910/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0033 - val_loss: 0.0037\n",
            "Epoch 1911/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.0033 - val_loss: 0.0044\n",
            "Epoch 1912/2000\n",
            "80/80 [==============================] - 0s 352us/step - loss: 0.0033 - val_loss: 0.0038\n",
            "Epoch 1913/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0033 - val_loss: 0.0034\n",
            "Epoch 1914/2000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 1915/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0033 - val_loss: 0.0041\n",
            "Epoch 1916/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0033 - val_loss: 0.0042\n",
            "Epoch 1917/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0033 - val_loss: 0.0043\n",
            "Epoch 1918/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0033 - val_loss: 0.0040\n",
            "Epoch 1919/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0033 - val_loss: 0.0035\n",
            "Epoch 1920/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0033 - val_loss: 0.0037\n",
            "Epoch 1921/2000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0033 - val_loss: 0.0043\n",
            "Epoch 1922/2000\n",
            "80/80 [==============================] - 0s 395us/step - loss: 0.0033 - val_loss: 0.0038\n",
            "Epoch 1923/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0033 - val_loss: 0.0035\n",
            "Epoch 1924/2000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.0033 - val_loss: 0.0040\n",
            "Epoch 1925/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.0033 - val_loss: 0.0043\n",
            "Epoch 1926/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0033 - val_loss: 0.0041\n",
            "Epoch 1927/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0033 - val_loss: 0.0036\n",
            "Epoch 1928/2000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0033 - val_loss: 0.0040\n",
            "Epoch 1929/2000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.0033 - val_loss: 0.0039\n",
            "Epoch 1930/2000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.0033 - val_loss: 0.0040\n",
            "Epoch 1931/2000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 1932/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0033 - val_loss: 0.0035\n",
            "Epoch 1933/2000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0033 - val_loss: 0.0040\n",
            "Epoch 1934/2000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0033 - val_loss: 0.0044\n",
            "Epoch 1935/2000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0033 - val_loss: 0.0034\n",
            "Epoch 1936/2000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0033 - val_loss: 0.0038\n",
            "Epoch 1937/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0033 - val_loss: 0.0041\n",
            "Epoch 1938/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0033 - val_loss: 0.0034\n",
            "Epoch 1939/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0033 - val_loss: 0.0037\n",
            "Epoch 1940/2000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.0033 - val_loss: 0.0042\n",
            "Epoch 1941/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0033 - val_loss: 0.0045\n",
            "Epoch 1942/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0033 - val_loss: 0.0033\n",
            "Epoch 1943/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0033 - val_loss: 0.0035\n",
            "Epoch 1944/2000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0033 - val_loss: 0.0046\n",
            "Epoch 1945/2000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0033 - val_loss: 0.0039\n",
            "Epoch 1946/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0033 - val_loss: 0.0034\n",
            "Epoch 1947/2000\n",
            "80/80 [==============================] - 0s 356us/step - loss: 0.0033 - val_loss: 0.0041\n",
            "Epoch 1948/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0033 - val_loss: 0.0040\n",
            "Epoch 1949/2000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0033 - val_loss: 0.0034\n",
            "Epoch 1950/2000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0032 - val_loss: 0.0040\n",
            "Epoch 1951/2000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0033 - val_loss: 0.0042\n",
            "Epoch 1952/2000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0032 - val_loss: 0.0034\n",
            "Epoch 1953/2000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0033 - val_loss: 0.0035\n",
            "Epoch 1954/2000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0032 - val_loss: 0.0040\n",
            "Epoch 1955/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0032 - val_loss: 0.0044\n",
            "Epoch 1956/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0033 - val_loss: 0.0038\n",
            "Epoch 1957/2000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 1958/2000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 1959/2000\n",
            "80/80 [==============================] - 0s 386us/step - loss: 0.0032 - val_loss: 0.0038\n",
            "Epoch 1960/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0033 - val_loss: 0.0040\n",
            "Epoch 1961/2000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0032 - val_loss: 0.0034\n",
            "Epoch 1962/2000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0032 - val_loss: 0.0040\n",
            "Epoch 1963/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0032 - val_loss: 0.0042\n",
            "Epoch 1964/2000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 1965/2000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0033 - val_loss: 0.0035\n",
            "Epoch 1966/2000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0033 - val_loss: 0.0042\n",
            "Epoch 1967/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 1968/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 1969/2000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.0032 - val_loss: 0.0043\n",
            "Epoch 1970/2000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.0032 - val_loss: 0.0037\n",
            "Epoch 1971/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0032 - val_loss: 0.0031\n",
            "Epoch 1972/2000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0033 - val_loss: 0.0039\n",
            "Epoch 1973/2000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0032 - val_loss: 0.0049\n",
            "Epoch 1974/2000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0033 - val_loss: 0.0039\n",
            "Epoch 1975/2000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0032 - val_loss: 0.0033\n",
            "Epoch 1976/2000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.0032 - val_loss: 0.0038\n",
            "Epoch 1977/2000\n",
            "80/80 [==============================] - 0s 412us/step - loss: 0.0032 - val_loss: 0.0041\n",
            "Epoch 1978/2000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.0032 - val_loss: 0.0039\n",
            "Epoch 1979/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 1980/2000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.0032 - val_loss: 0.0037\n",
            "Epoch 1981/2000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0032 - val_loss: 0.0040\n",
            "Epoch 1982/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 1983/2000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 1984/2000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0033 - val_loss: 0.0034\n",
            "Epoch 1985/2000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0033 - val_loss: 0.0042\n",
            "Epoch 1986/2000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0032 - val_loss: 0.0040\n",
            "Epoch 1987/2000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0032 - val_loss: 0.0035\n",
            "Epoch 1988/2000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.0032 - val_loss: 0.0040\n",
            "Epoch 1989/2000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 1990/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0032 - val_loss: 0.0040\n",
            "Epoch 1991/2000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.0033 - val_loss: 0.0044\n",
            "Epoch 1992/2000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 1993/2000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.0032 - val_loss: 0.0034\n",
            "Epoch 1994/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0032 - val_loss: 0.0039\n",
            "Epoch 1995/2000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0031 - val_loss: 0.0043\n",
            "Epoch 1996/2000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0032 - val_loss: 0.0040\n",
            "Epoch 1997/2000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0031 - val_loss: 0.0033\n",
            "Epoch 1998/2000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0033 - val_loss: 0.0036\n",
            "Epoch 1999/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0031 - val_loss: 0.0041\n",
            "Epoch 2000/2000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0032 - val_loss: 0.0042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us2VwPPaRc6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDApJDEsRlRD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcb732b7-db11-4611-f834-86f975ddddd1"
      },
      "source": [
        "results.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGPjOP7xRo9l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40699c4f-9029-4b5f-d21a-844ee2107d2a"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7r1E6k-RsdM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "c904bdab-055d-4ce0-d903-e3e68cce6847"
      },
      "source": [
        "plt.scatter(range(20),results,c='r')\n",
        "plt.scatter(range(20),y_test,c='g')\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD8CAYAAACSCdTiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVGGGvCRVmCEvSRVmyEtShf0/Rm4AbZxv410AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahFGVDGLS1aC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}