{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15mi453.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUgRJd-JwE7b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e1b61699-95bd-4561-fbd0-e5c3d73a57e1"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN, LSTM , Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlDC4VYCBRHh",
        "colab_type": "code",
        "outputId": "cd9525be-4d5a-4748-90df-52bd02636394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "X = [[[(5**i)+j] for i in range (5)] for j in range(100)]\n",
        "print (X)\n",
        "Y = [(3125+5*i) for i in range(100)]\n",
        "print (Y)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[1], [5], [25], [125], [625]], [[2], [6], [26], [126], [626]], [[3], [7], [27], [127], [627]], [[4], [8], [28], [128], [628]], [[5], [9], [29], [129], [629]], [[6], [10], [30], [130], [630]], [[7], [11], [31], [131], [631]], [[8], [12], [32], [132], [632]], [[9], [13], [33], [133], [633]], [[10], [14], [34], [134], [634]], [[11], [15], [35], [135], [635]], [[12], [16], [36], [136], [636]], [[13], [17], [37], [137], [637]], [[14], [18], [38], [138], [638]], [[15], [19], [39], [139], [639]], [[16], [20], [40], [140], [640]], [[17], [21], [41], [141], [641]], [[18], [22], [42], [142], [642]], [[19], [23], [43], [143], [643]], [[20], [24], [44], [144], [644]], [[21], [25], [45], [145], [645]], [[22], [26], [46], [146], [646]], [[23], [27], [47], [147], [647]], [[24], [28], [48], [148], [648]], [[25], [29], [49], [149], [649]], [[26], [30], [50], [150], [650]], [[27], [31], [51], [151], [651]], [[28], [32], [52], [152], [652]], [[29], [33], [53], [153], [653]], [[30], [34], [54], [154], [654]], [[31], [35], [55], [155], [655]], [[32], [36], [56], [156], [656]], [[33], [37], [57], [157], [657]], [[34], [38], [58], [158], [658]], [[35], [39], [59], [159], [659]], [[36], [40], [60], [160], [660]], [[37], [41], [61], [161], [661]], [[38], [42], [62], [162], [662]], [[39], [43], [63], [163], [663]], [[40], [44], [64], [164], [664]], [[41], [45], [65], [165], [665]], [[42], [46], [66], [166], [666]], [[43], [47], [67], [167], [667]], [[44], [48], [68], [168], [668]], [[45], [49], [69], [169], [669]], [[46], [50], [70], [170], [670]], [[47], [51], [71], [171], [671]], [[48], [52], [72], [172], [672]], [[49], [53], [73], [173], [673]], [[50], [54], [74], [174], [674]], [[51], [55], [75], [175], [675]], [[52], [56], [76], [176], [676]], [[53], [57], [77], [177], [677]], [[54], [58], [78], [178], [678]], [[55], [59], [79], [179], [679]], [[56], [60], [80], [180], [680]], [[57], [61], [81], [181], [681]], [[58], [62], [82], [182], [682]], [[59], [63], [83], [183], [683]], [[60], [64], [84], [184], [684]], [[61], [65], [85], [185], [685]], [[62], [66], [86], [186], [686]], [[63], [67], [87], [187], [687]], [[64], [68], [88], [188], [688]], [[65], [69], [89], [189], [689]], [[66], [70], [90], [190], [690]], [[67], [71], [91], [191], [691]], [[68], [72], [92], [192], [692]], [[69], [73], [93], [193], [693]], [[70], [74], [94], [194], [694]], [[71], [75], [95], [195], [695]], [[72], [76], [96], [196], [696]], [[73], [77], [97], [197], [697]], [[74], [78], [98], [198], [698]], [[75], [79], [99], [199], [699]], [[76], [80], [100], [200], [700]], [[77], [81], [101], [201], [701]], [[78], [82], [102], [202], [702]], [[79], [83], [103], [203], [703]], [[80], [84], [104], [204], [704]], [[81], [85], [105], [205], [705]], [[82], [86], [106], [206], [706]], [[83], [87], [107], [207], [707]], [[84], [88], [108], [208], [708]], [[85], [89], [109], [209], [709]], [[86], [90], [110], [210], [710]], [[87], [91], [111], [211], [711]], [[88], [92], [112], [212], [712]], [[89], [93], [113], [213], [713]], [[90], [94], [114], [214], [714]], [[91], [95], [115], [215], [715]], [[92], [96], [116], [216], [716]], [[93], [97], [117], [217], [717]], [[94], [98], [118], [218], [718]], [[95], [99], [119], [219], [719]], [[96], [100], [120], [220], [720]], [[97], [101], [121], [221], [721]], [[98], [102], [122], [222], [722]], [[99], [103], [123], [223], [723]], [[100], [104], [124], [224], [724]]]\n",
            "[3125, 3130, 3135, 3140, 3145, 3150, 3155, 3160, 3165, 3170, 3175, 3180, 3185, 3190, 3195, 3200, 3205, 3210, 3215, 3220, 3225, 3230, 3235, 3240, 3245, 3250, 3255, 3260, 3265, 3270, 3275, 3280, 3285, 3290, 3295, 3300, 3305, 3310, 3315, 3320, 3325, 3330, 3335, 3340, 3345, 3350, 3355, 3360, 3365, 3370, 3375, 3380, 3385, 3390, 3395, 3400, 3405, 3410, 3415, 3420, 3425, 3430, 3435, 3440, 3445, 3450, 3455, 3460, 3465, 3470, 3475, 3480, 3485, 3490, 3495, 3500, 3505, 3510, 3515, 3520, 3525, 3530, 3535, 3540, 3545, 3550, 3555, 3560, 3565, 3570, 3575, 3580, 3585, 3590, 3595, 3600, 3605, 3610, 3615, 3620]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKAoQeqSzFwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(X, dtype=\"float32\")\n",
        "Y = np.array(Y, dtype=\"float32\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nujWp20Edh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X /= 500\n",
        "Y /= 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdO2WW63Ejxv",
        "colab_type": "code",
        "outputId": "899d5b8c-33f7-4165-9bc1-1c66527ecef5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaWPaPenEnV5",
        "colab_type": "code",
        "outputId": "3da4d108-e0c4-4257-be0c-5fd47a2b498d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hFVg98QErgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2, \n",
        "                                                random_state=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtU_BMZEEu8E",
        "colab_type": "code",
        "outputId": "294159f8-9756-4afe-fe79-37c8d4d0b86c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.19 ],\n",
              "        [0.198],\n",
              "        [0.238],\n",
              "        [0.438],\n",
              "        [1.438]],\n",
              "\n",
              "       [[0.114],\n",
              "        [0.122],\n",
              "        [0.162],\n",
              "        [0.362],\n",
              "        [1.362]],\n",
              "\n",
              "       [[0.046],\n",
              "        [0.054],\n",
              "        [0.094],\n",
              "        [0.294],\n",
              "        [1.294]],\n",
              "\n",
              "       [[0.08 ],\n",
              "        [0.088],\n",
              "        [0.128],\n",
              "        [0.328],\n",
              "        [1.328]],\n",
              "\n",
              "       [[0.05 ],\n",
              "        [0.058],\n",
              "        [0.098],\n",
              "        [0.298],\n",
              "        [1.298]],\n",
              "\n",
              "       [[0.028],\n",
              "        [0.036],\n",
              "        [0.076],\n",
              "        [0.276],\n",
              "        [1.276]],\n",
              "\n",
              "       [[0.128],\n",
              "        [0.136],\n",
              "        [0.176],\n",
              "        [0.376],\n",
              "        [1.376]],\n",
              "\n",
              "       [[0.144],\n",
              "        [0.152],\n",
              "        [0.192],\n",
              "        [0.392],\n",
              "        [1.392]],\n",
              "\n",
              "       [[0.112],\n",
              "        [0.12 ],\n",
              "        [0.16 ],\n",
              "        [0.36 ],\n",
              "        [1.36 ]],\n",
              "\n",
              "       [[0.176],\n",
              "        [0.184],\n",
              "        [0.224],\n",
              "        [0.424],\n",
              "        [1.424]],\n",
              "\n",
              "       [[0.014],\n",
              "        [0.022],\n",
              "        [0.062],\n",
              "        [0.262],\n",
              "        [1.262]],\n",
              "\n",
              "       [[0.178],\n",
              "        [0.186],\n",
              "        [0.226],\n",
              "        [0.426],\n",
              "        [1.426]],\n",
              "\n",
              "       [[0.13 ],\n",
              "        [0.138],\n",
              "        [0.178],\n",
              "        [0.378],\n",
              "        [1.378]],\n",
              "\n",
              "       [[0.054],\n",
              "        [0.062],\n",
              "        [0.102],\n",
              "        [0.302],\n",
              "        [1.302]],\n",
              "\n",
              "       [[0.098],\n",
              "        [0.106],\n",
              "        [0.146],\n",
              "        [0.346],\n",
              "        [1.346]],\n",
              "\n",
              "       [[0.102],\n",
              "        [0.11 ],\n",
              "        [0.15 ],\n",
              "        [0.35 ],\n",
              "        [1.35 ]],\n",
              "\n",
              "       [[0.146],\n",
              "        [0.154],\n",
              "        [0.194],\n",
              "        [0.394],\n",
              "        [1.394]],\n",
              "\n",
              "       [[0.11 ],\n",
              "        [0.118],\n",
              "        [0.158],\n",
              "        [0.358],\n",
              "        [1.358]],\n",
              "\n",
              "       [[0.044],\n",
              "        [0.052],\n",
              "        [0.092],\n",
              "        [0.292],\n",
              "        [1.292]],\n",
              "\n",
              "       [[0.052],\n",
              "        [0.06 ],\n",
              "        [0.1  ],\n",
              "        [0.3  ],\n",
              "        [1.3  ]],\n",
              "\n",
              "       [[0.068],\n",
              "        [0.076],\n",
              "        [0.116],\n",
              "        [0.316],\n",
              "        [1.316]],\n",
              "\n",
              "       [[0.06 ],\n",
              "        [0.068],\n",
              "        [0.108],\n",
              "        [0.308],\n",
              "        [1.308]],\n",
              "\n",
              "       [[0.106],\n",
              "        [0.114],\n",
              "        [0.154],\n",
              "        [0.354],\n",
              "        [1.354]],\n",
              "\n",
              "       [[0.03 ],\n",
              "        [0.038],\n",
              "        [0.078],\n",
              "        [0.278],\n",
              "        [1.278]],\n",
              "\n",
              "       [[0.172],\n",
              "        [0.18 ],\n",
              "        [0.22 ],\n",
              "        [0.42 ],\n",
              "        [1.42 ]],\n",
              "\n",
              "       [[0.16 ],\n",
              "        [0.168],\n",
              "        [0.208],\n",
              "        [0.408],\n",
              "        [1.408]],\n",
              "\n",
              "       [[0.192],\n",
              "        [0.2  ],\n",
              "        [0.24 ],\n",
              "        [0.44 ],\n",
              "        [1.44 ]],\n",
              "\n",
              "       [[0.008],\n",
              "        [0.016],\n",
              "        [0.056],\n",
              "        [0.256],\n",
              "        [1.256]],\n",
              "\n",
              "       [[0.088],\n",
              "        [0.096],\n",
              "        [0.136],\n",
              "        [0.336],\n",
              "        [1.336]],\n",
              "\n",
              "       [[0.024],\n",
              "        [0.032],\n",
              "        [0.072],\n",
              "        [0.272],\n",
              "        [1.272]],\n",
              "\n",
              "       [[0.198],\n",
              "        [0.206],\n",
              "        [0.246],\n",
              "        [0.446],\n",
              "        [1.446]],\n",
              "\n",
              "       [[0.092],\n",
              "        [0.1  ],\n",
              "        [0.14 ],\n",
              "        [0.34 ],\n",
              "        [1.34 ]],\n",
              "\n",
              "       [[0.168],\n",
              "        [0.176],\n",
              "        [0.216],\n",
              "        [0.416],\n",
              "        [1.416]],\n",
              "\n",
              "       [[0.136],\n",
              "        [0.144],\n",
              "        [0.184],\n",
              "        [0.384],\n",
              "        [1.384]],\n",
              "\n",
              "       [[0.18 ],\n",
              "        [0.188],\n",
              "        [0.228],\n",
              "        [0.428],\n",
              "        [1.428]],\n",
              "\n",
              "       [[0.174],\n",
              "        [0.182],\n",
              "        [0.222],\n",
              "        [0.422],\n",
              "        [1.422]],\n",
              "\n",
              "       [[0.1  ],\n",
              "        [0.108],\n",
              "        [0.148],\n",
              "        [0.348],\n",
              "        [1.348]],\n",
              "\n",
              "       [[0.166],\n",
              "        [0.174],\n",
              "        [0.214],\n",
              "        [0.414],\n",
              "        [1.414]],\n",
              "\n",
              "       [[0.12 ],\n",
              "        [0.128],\n",
              "        [0.168],\n",
              "        [0.368],\n",
              "        [1.368]],\n",
              "\n",
              "       [[0.04 ],\n",
              "        [0.048],\n",
              "        [0.088],\n",
              "        [0.288],\n",
              "        [1.288]],\n",
              "\n",
              "       [[0.164],\n",
              "        [0.172],\n",
              "        [0.212],\n",
              "        [0.412],\n",
              "        [1.412]],\n",
              "\n",
              "       [[0.078],\n",
              "        [0.086],\n",
              "        [0.126],\n",
              "        [0.326],\n",
              "        [1.326]],\n",
              "\n",
              "       [[0.138],\n",
              "        [0.146],\n",
              "        [0.186],\n",
              "        [0.386],\n",
              "        [1.386]],\n",
              "\n",
              "       [[0.006],\n",
              "        [0.014],\n",
              "        [0.054],\n",
              "        [0.254],\n",
              "        [1.254]],\n",
              "\n",
              "       [[0.064],\n",
              "        [0.072],\n",
              "        [0.112],\n",
              "        [0.312],\n",
              "        [1.312]],\n",
              "\n",
              "       [[0.17 ],\n",
              "        [0.178],\n",
              "        [0.218],\n",
              "        [0.418],\n",
              "        [1.418]],\n",
              "\n",
              "       [[0.104],\n",
              "        [0.112],\n",
              "        [0.152],\n",
              "        [0.352],\n",
              "        [1.352]],\n",
              "\n",
              "       [[0.074],\n",
              "        [0.082],\n",
              "        [0.122],\n",
              "        [0.322],\n",
              "        [1.322]],\n",
              "\n",
              "       [[0.01 ],\n",
              "        [0.018],\n",
              "        [0.058],\n",
              "        [0.258],\n",
              "        [1.258]],\n",
              "\n",
              "       [[0.002],\n",
              "        [0.01 ],\n",
              "        [0.05 ],\n",
              "        [0.25 ],\n",
              "        [1.25 ]],\n",
              "\n",
              "       [[0.118],\n",
              "        [0.126],\n",
              "        [0.166],\n",
              "        [0.366],\n",
              "        [1.366]],\n",
              "\n",
              "       [[0.012],\n",
              "        [0.02 ],\n",
              "        [0.06 ],\n",
              "        [0.26 ],\n",
              "        [1.26 ]],\n",
              "\n",
              "       [[0.194],\n",
              "        [0.202],\n",
              "        [0.242],\n",
              "        [0.442],\n",
              "        [1.442]],\n",
              "\n",
              "       [[0.004],\n",
              "        [0.012],\n",
              "        [0.052],\n",
              "        [0.252],\n",
              "        [1.252]],\n",
              "\n",
              "       [[0.188],\n",
              "        [0.196],\n",
              "        [0.236],\n",
              "        [0.436],\n",
              "        [1.436]],\n",
              "\n",
              "       [[0.084],\n",
              "        [0.092],\n",
              "        [0.132],\n",
              "        [0.332],\n",
              "        [1.332]],\n",
              "\n",
              "       [[0.02 ],\n",
              "        [0.028],\n",
              "        [0.068],\n",
              "        [0.268],\n",
              "        [1.268]],\n",
              "\n",
              "       [[0.038],\n",
              "        [0.046],\n",
              "        [0.086],\n",
              "        [0.286],\n",
              "        [1.286]],\n",
              "\n",
              "       [[0.184],\n",
              "        [0.192],\n",
              "        [0.232],\n",
              "        [0.432],\n",
              "        [1.432]],\n",
              "\n",
              "       [[0.096],\n",
              "        [0.104],\n",
              "        [0.144],\n",
              "        [0.344],\n",
              "        [1.344]],\n",
              "\n",
              "       [[0.132],\n",
              "        [0.14 ],\n",
              "        [0.18 ],\n",
              "        [0.38 ],\n",
              "        [1.38 ]],\n",
              "\n",
              "       [[0.152],\n",
              "        [0.16 ],\n",
              "        [0.2  ],\n",
              "        [0.4  ],\n",
              "        [1.4  ]],\n",
              "\n",
              "       [[0.156],\n",
              "        [0.164],\n",
              "        [0.204],\n",
              "        [0.404],\n",
              "        [1.404]],\n",
              "\n",
              "       [[0.09 ],\n",
              "        [0.098],\n",
              "        [0.138],\n",
              "        [0.338],\n",
              "        [1.338]],\n",
              "\n",
              "       [[0.186],\n",
              "        [0.194],\n",
              "        [0.234],\n",
              "        [0.434],\n",
              "        [1.434]],\n",
              "\n",
              "       [[0.182],\n",
              "        [0.19 ],\n",
              "        [0.23 ],\n",
              "        [0.43 ],\n",
              "        [1.43 ]],\n",
              "\n",
              "       [[0.108],\n",
              "        [0.116],\n",
              "        [0.156],\n",
              "        [0.356],\n",
              "        [1.356]],\n",
              "\n",
              "       [[0.032],\n",
              "        [0.04 ],\n",
              "        [0.08 ],\n",
              "        [0.28 ],\n",
              "        [1.28 ]],\n",
              "\n",
              "       [[0.154],\n",
              "        [0.162],\n",
              "        [0.202],\n",
              "        [0.402],\n",
              "        [1.402]],\n",
              "\n",
              "       [[0.016],\n",
              "        [0.024],\n",
              "        [0.064],\n",
              "        [0.264],\n",
              "        [1.264]],\n",
              "\n",
              "       [[0.162],\n",
              "        [0.17 ],\n",
              "        [0.21 ],\n",
              "        [0.41 ],\n",
              "        [1.41 ]],\n",
              "\n",
              "       [[0.062],\n",
              "        [0.07 ],\n",
              "        [0.11 ],\n",
              "        [0.31 ],\n",
              "        [1.31 ]],\n",
              "\n",
              "       [[0.056],\n",
              "        [0.064],\n",
              "        [0.104],\n",
              "        [0.304],\n",
              "        [1.304]],\n",
              "\n",
              "       [[0.126],\n",
              "        [0.134],\n",
              "        [0.174],\n",
              "        [0.374],\n",
              "        [1.374]],\n",
              "\n",
              "       [[0.018],\n",
              "        [0.026],\n",
              "        [0.066],\n",
              "        [0.266],\n",
              "        [1.266]],\n",
              "\n",
              "       [[0.148],\n",
              "        [0.156],\n",
              "        [0.196],\n",
              "        [0.396],\n",
              "        [1.396]],\n",
              "\n",
              "       [[0.034],\n",
              "        [0.042],\n",
              "        [0.082],\n",
              "        [0.282],\n",
              "        [1.282]],\n",
              "\n",
              "       [[0.124],\n",
              "        [0.132],\n",
              "        [0.172],\n",
              "        [0.372],\n",
              "        [1.372]],\n",
              "\n",
              "       [[0.158],\n",
              "        [0.166],\n",
              "        [0.206],\n",
              "        [0.406],\n",
              "        [1.406]],\n",
              "\n",
              "       [[0.2  ],\n",
              "        [0.208],\n",
              "        [0.248],\n",
              "        [0.448],\n",
              "        [1.448]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnZRd-9HEx43",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "bd3365f9-f68d-4d82-c4cb-44f20ad2569a"
      },
      "source": [
        "from keras.layers import SimpleRNN,LSTM,Flatten\n",
        "model = Sequential()\n",
        "model.add(LSTM((2),input_shape=(5,1),return_sequences=True))\n",
        "model.add(LSTM((3),input_shape=(5,1),return_sequences=True))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1,activation='relu'))\n",
        "#model.compile(optimizer='adam',loss='mae',metrics=['acc'])\n",
        "model.compile(optimizer='adam',loss='mae',metrics=['acc'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXNvNbarE3ll",
        "colab_type": "code",
        "outputId": "f46f02db-06ad-43aa-fc9a-94a3754bed7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 5, 2)              32        \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 5, 3)              72        \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 16        \n",
            "=================================================================\n",
            "Total params: 120\n",
            "Trainable params: 120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wuc_THFUE7JL",
        "colab_type": "code",
        "outputId": "1da7ee19-6e16-44f0-d2e5-3aba114c9df5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hist = model.fit(X_train, y_train, epochs=1000, batch_size=64, validation_data=(X_test, y_test))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "80/80 [==============================] - 2s 25ms/step - loss: 6.7595 - acc: 0.0000e+00 - val_loss: 6.6797 - val_acc: 0.0000e+00\n",
            "Epoch 2/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 6.7547 - acc: 0.0000e+00 - val_loss: 6.6747 - val_acc: 0.0000e+00\n",
            "Epoch 3/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 6.7497 - acc: 0.0000e+00 - val_loss: 6.6697 - val_acc: 0.0000e+00\n",
            "Epoch 4/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 6.7446 - acc: 0.0000e+00 - val_loss: 6.6648 - val_acc: 0.0000e+00\n",
            "Epoch 5/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 6.7396 - acc: 0.0000e+00 - val_loss: 6.6598 - val_acc: 0.0000e+00\n",
            "Epoch 6/1000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 6.7345 - acc: 0.0000e+00 - val_loss: 6.6547 - val_acc: 0.0000e+00\n",
            "Epoch 7/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 6.7294 - acc: 0.0000e+00 - val_loss: 6.6496 - val_acc: 0.0000e+00\n",
            "Epoch 8/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 6.7243 - acc: 0.0000e+00 - val_loss: 6.6444 - val_acc: 0.0000e+00\n",
            "Epoch 9/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 6.7190 - acc: 0.0000e+00 - val_loss: 6.6391 - val_acc: 0.0000e+00\n",
            "Epoch 10/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 6.7137 - acc: 0.0000e+00 - val_loss: 6.6338 - val_acc: 0.0000e+00\n",
            "Epoch 11/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 6.7083 - acc: 0.0000e+00 - val_loss: 6.6283 - val_acc: 0.0000e+00\n",
            "Epoch 12/1000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 6.7027 - acc: 0.0000e+00 - val_loss: 6.6227 - val_acc: 0.0000e+00\n",
            "Epoch 13/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 6.6971 - acc: 0.0000e+00 - val_loss: 6.6169 - val_acc: 0.0000e+00\n",
            "Epoch 14/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 6.6912 - acc: 0.0000e+00 - val_loss: 6.6109 - val_acc: 0.0000e+00\n",
            "Epoch 15/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 6.6852 - acc: 0.0000e+00 - val_loss: 6.6048 - val_acc: 0.0000e+00\n",
            "Epoch 16/1000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 6.6790 - acc: 0.0000e+00 - val_loss: 6.5985 - val_acc: 0.0000e+00\n",
            "Epoch 17/1000\n",
            "80/80 [==============================] - 0s 369us/step - loss: 6.6726 - acc: 0.0000e+00 - val_loss: 6.5919 - val_acc: 0.0000e+00\n",
            "Epoch 18/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 6.6660 - acc: 0.0000e+00 - val_loss: 6.5852 - val_acc: 0.0000e+00\n",
            "Epoch 19/1000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 6.6592 - acc: 0.0000e+00 - val_loss: 6.5782 - val_acc: 0.0000e+00\n",
            "Epoch 20/1000\n",
            "80/80 [==============================] - 0s 373us/step - loss: 6.6521 - acc: 0.0000e+00 - val_loss: 6.5709 - val_acc: 0.0000e+00\n",
            "Epoch 21/1000\n",
            "80/80 [==============================] - 0s 373us/step - loss: 6.6448 - acc: 0.0000e+00 - val_loss: 6.5634 - val_acc: 0.0000e+00\n",
            "Epoch 22/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 6.6372 - acc: 0.0000e+00 - val_loss: 6.5557 - val_acc: 0.0000e+00\n",
            "Epoch 23/1000\n",
            "80/80 [==============================] - 0s 398us/step - loss: 6.6294 - acc: 0.0000e+00 - val_loss: 6.5476 - val_acc: 0.0000e+00\n",
            "Epoch 24/1000\n",
            "80/80 [==============================] - 0s 361us/step - loss: 6.6212 - acc: 0.0000e+00 - val_loss: 6.5393 - val_acc: 0.0000e+00\n",
            "Epoch 25/1000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 6.6128 - acc: 0.0000e+00 - val_loss: 6.5307 - val_acc: 0.0000e+00\n",
            "Epoch 26/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 6.6041 - acc: 0.0000e+00 - val_loss: 6.5217 - val_acc: 0.0000e+00\n",
            "Epoch 27/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 6.5950 - acc: 0.0000e+00 - val_loss: 6.5124 - val_acc: 0.0000e+00\n",
            "Epoch 28/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 6.5856 - acc: 0.0000e+00 - val_loss: 6.5028 - val_acc: 0.0000e+00\n",
            "Epoch 29/1000\n",
            "80/80 [==============================] - 0s 387us/step - loss: 6.5759 - acc: 0.0000e+00 - val_loss: 6.4928 - val_acc: 0.0000e+00\n",
            "Epoch 30/1000\n",
            "80/80 [==============================] - 0s 377us/step - loss: 6.5658 - acc: 0.0000e+00 - val_loss: 6.4824 - val_acc: 0.0000e+00\n",
            "Epoch 31/1000\n",
            "80/80 [==============================] - 0s 376us/step - loss: 6.5553 - acc: 0.0000e+00 - val_loss: 6.4716 - val_acc: 0.0000e+00\n",
            "Epoch 32/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 6.5444 - acc: 0.0000e+00 - val_loss: 6.4605 - val_acc: 0.0000e+00\n",
            "Epoch 33/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 6.5332 - acc: 0.0000e+00 - val_loss: 6.4489 - val_acc: 0.0000e+00\n",
            "Epoch 34/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 6.5214 - acc: 0.0000e+00 - val_loss: 6.4369 - val_acc: 0.0000e+00\n",
            "Epoch 35/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 6.5093 - acc: 0.0000e+00 - val_loss: 6.4244 - val_acc: 0.0000e+00\n",
            "Epoch 36/1000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 6.4967 - acc: 0.0000e+00 - val_loss: 6.4115 - val_acc: 0.0000e+00\n",
            "Epoch 37/1000\n",
            "80/80 [==============================] - 0s 417us/step - loss: 6.4837 - acc: 0.0000e+00 - val_loss: 6.3981 - val_acc: 0.0000e+00\n",
            "Epoch 38/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 6.4701 - acc: 0.0000e+00 - val_loss: 6.3841 - val_acc: 0.0000e+00\n",
            "Epoch 39/1000\n",
            "80/80 [==============================] - 0s 394us/step - loss: 6.4560 - acc: 0.0000e+00 - val_loss: 6.3697 - val_acc: 0.0000e+00\n",
            "Epoch 40/1000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 6.4414 - acc: 0.0000e+00 - val_loss: 6.3547 - val_acc: 0.0000e+00\n",
            "Epoch 41/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 6.4263 - acc: 0.0000e+00 - val_loss: 6.3391 - val_acc: 0.0000e+00\n",
            "Epoch 42/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 6.4106 - acc: 0.0000e+00 - val_loss: 6.3230 - val_acc: 0.0000e+00\n",
            "Epoch 43/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 6.3943 - acc: 0.0000e+00 - val_loss: 6.3062 - val_acc: 0.0000e+00\n",
            "Epoch 44/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 6.3774 - acc: 0.0000e+00 - val_loss: 6.2889 - val_acc: 0.0000e+00\n",
            "Epoch 45/1000\n",
            "80/80 [==============================] - 0s 359us/step - loss: 6.3598 - acc: 0.0000e+00 - val_loss: 6.2709 - val_acc: 0.0000e+00\n",
            "Epoch 46/1000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 6.3416 - acc: 0.0000e+00 - val_loss: 6.2523 - val_acc: 0.0000e+00\n",
            "Epoch 47/1000\n",
            "80/80 [==============================] - 0s 364us/step - loss: 6.3228 - acc: 0.0000e+00 - val_loss: 6.2329 - val_acc: 0.0000e+00\n",
            "Epoch 48/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 6.3033 - acc: 0.0000e+00 - val_loss: 6.2129 - val_acc: 0.0000e+00\n",
            "Epoch 49/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 6.2831 - acc: 0.0000e+00 - val_loss: 6.1922 - val_acc: 0.0000e+00\n",
            "Epoch 50/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 6.2622 - acc: 0.0000e+00 - val_loss: 6.1706 - val_acc: 0.0000e+00\n",
            "Epoch 51/1000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 6.2404 - acc: 0.0000e+00 - val_loss: 6.1483 - val_acc: 0.0000e+00\n",
            "Epoch 52/1000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 6.2179 - acc: 0.0000e+00 - val_loss: 6.1252 - val_acc: 0.0000e+00\n",
            "Epoch 53/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 6.1946 - acc: 0.0000e+00 - val_loss: 6.1014 - val_acc: 0.0000e+00\n",
            "Epoch 54/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 6.1705 - acc: 0.0000e+00 - val_loss: 6.0767 - val_acc: 0.0000e+00\n",
            "Epoch 55/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 6.1457 - acc: 0.0000e+00 - val_loss: 6.0513 - val_acc: 0.0000e+00\n",
            "Epoch 56/1000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 6.1200 - acc: 0.0000e+00 - val_loss: 6.0250 - val_acc: 0.0000e+00\n",
            "Epoch 57/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 6.0935 - acc: 0.0000e+00 - val_loss: 5.9979 - val_acc: 0.0000e+00\n",
            "Epoch 58/1000\n",
            "80/80 [==============================] - 0s 468us/step - loss: 6.0662 - acc: 0.0000e+00 - val_loss: 5.9700 - val_acc: 0.0000e+00\n",
            "Epoch 59/1000\n",
            "80/80 [==============================] - 0s 367us/step - loss: 6.0380 - acc: 0.0000e+00 - val_loss: 5.9412 - val_acc: 0.0000e+00\n",
            "Epoch 60/1000\n",
            "80/80 [==============================] - 0s 356us/step - loss: 6.0090 - acc: 0.0000e+00 - val_loss: 5.9116 - val_acc: 0.0000e+00\n",
            "Epoch 61/1000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 5.9792 - acc: 0.0000e+00 - val_loss: 5.8811 - val_acc: 0.0000e+00\n",
            "Epoch 62/1000\n",
            "80/80 [==============================] - 0s 371us/step - loss: 5.9485 - acc: 0.0000e+00 - val_loss: 5.8498 - val_acc: 0.0000e+00\n",
            "Epoch 63/1000\n",
            "80/80 [==============================] - 0s 367us/step - loss: 5.9170 - acc: 0.0000e+00 - val_loss: 5.8176 - val_acc: 0.0000e+00\n",
            "Epoch 64/1000\n",
            "80/80 [==============================] - 0s 352us/step - loss: 5.8846 - acc: 0.0000e+00 - val_loss: 5.7846 - val_acc: 0.0000e+00\n",
            "Epoch 65/1000\n",
            "80/80 [==============================] - 0s 361us/step - loss: 5.8513 - acc: 0.0000e+00 - val_loss: 5.7507 - val_acc: 0.0000e+00\n",
            "Epoch 66/1000\n",
            "80/80 [==============================] - 0s 512us/step - loss: 5.8171 - acc: 0.0000e+00 - val_loss: 5.7159 - val_acc: 0.0000e+00\n",
            "Epoch 67/1000\n",
            "80/80 [==============================] - 0s 369us/step - loss: 5.7822 - acc: 0.0000e+00 - val_loss: 5.6803 - val_acc: 0.0000e+00\n",
            "Epoch 68/1000\n",
            "80/80 [==============================] - 0s 375us/step - loss: 5.7464 - acc: 0.0000e+00 - val_loss: 5.6438 - val_acc: 0.0000e+00\n",
            "Epoch 69/1000\n",
            "80/80 [==============================] - 0s 356us/step - loss: 5.7096 - acc: 0.0000e+00 - val_loss: 5.6065 - val_acc: 0.0000e+00\n",
            "Epoch 70/1000\n",
            "80/80 [==============================] - 0s 369us/step - loss: 5.6721 - acc: 0.0000e+00 - val_loss: 5.5684 - val_acc: 0.0000e+00\n",
            "Epoch 71/1000\n",
            "80/80 [==============================] - 0s 368us/step - loss: 5.6338 - acc: 0.0000e+00 - val_loss: 5.5294 - val_acc: 0.0000e+00\n",
            "Epoch 72/1000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 5.5946 - acc: 0.0000e+00 - val_loss: 5.4896 - val_acc: 0.0000e+00\n",
            "Epoch 73/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 5.5546 - acc: 0.0000e+00 - val_loss: 5.4490 - val_acc: 0.0000e+00\n",
            "Epoch 74/1000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 5.5138 - acc: 0.0000e+00 - val_loss: 5.4076 - val_acc: 0.0000e+00\n",
            "Epoch 75/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 5.4722 - acc: 0.0000e+00 - val_loss: 5.3655 - val_acc: 0.0000e+00\n",
            "Epoch 76/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 5.4299 - acc: 0.0000e+00 - val_loss: 5.3225 - val_acc: 0.0000e+00\n",
            "Epoch 77/1000\n",
            "80/80 [==============================] - 0s 409us/step - loss: 5.3868 - acc: 0.0000e+00 - val_loss: 5.2789 - val_acc: 0.0000e+00\n",
            "Epoch 78/1000\n",
            "80/80 [==============================] - 0s 416us/step - loss: 5.3430 - acc: 0.0000e+00 - val_loss: 5.2345 - val_acc: 0.0000e+00\n",
            "Epoch 79/1000\n",
            "80/80 [==============================] - 0s 375us/step - loss: 5.2984 - acc: 0.0000e+00 - val_loss: 5.1894 - val_acc: 0.0000e+00\n",
            "Epoch 80/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 5.2532 - acc: 0.0000e+00 - val_loss: 5.1436 - val_acc: 0.0000e+00\n",
            "Epoch 81/1000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 5.2072 - acc: 0.0000e+00 - val_loss: 5.0972 - val_acc: 0.0000e+00\n",
            "Epoch 82/1000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 5.1606 - acc: 0.0000e+00 - val_loss: 5.0501 - val_acc: 0.0000e+00\n",
            "Epoch 83/1000\n",
            "80/80 [==============================] - 0s 363us/step - loss: 5.1134 - acc: 0.0000e+00 - val_loss: 5.0024 - val_acc: 0.0000e+00\n",
            "Epoch 84/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 5.0656 - acc: 0.0000e+00 - val_loss: 4.9541 - val_acc: 0.0000e+00\n",
            "Epoch 85/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 5.0172 - acc: 0.0000e+00 - val_loss: 4.9052 - val_acc: 0.0000e+00\n",
            "Epoch 86/1000\n",
            "80/80 [==============================] - 0s 356us/step - loss: 4.9682 - acc: 0.0000e+00 - val_loss: 4.8558 - val_acc: 0.0000e+00\n",
            "Epoch 87/1000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 4.9186 - acc: 0.0000e+00 - val_loss: 4.8058 - val_acc: 0.0000e+00\n",
            "Epoch 88/1000\n",
            "80/80 [==============================] - 0s 386us/step - loss: 4.8685 - acc: 0.0000e+00 - val_loss: 4.7553 - val_acc: 0.0000e+00\n",
            "Epoch 89/1000\n",
            "80/80 [==============================] - 0s 387us/step - loss: 4.8180 - acc: 0.0000e+00 - val_loss: 4.7044 - val_acc: 0.0000e+00\n",
            "Epoch 90/1000\n",
            "80/80 [==============================] - 0s 384us/step - loss: 4.7669 - acc: 0.0000e+00 - val_loss: 4.6529 - val_acc: 0.0000e+00\n",
            "Epoch 91/1000\n",
            "80/80 [==============================] - 0s 364us/step - loss: 4.7153 - acc: 0.0000e+00 - val_loss: 4.6010 - val_acc: 0.0000e+00\n",
            "Epoch 92/1000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 4.6633 - acc: 0.0000e+00 - val_loss: 4.5486 - val_acc: 0.0000e+00\n",
            "Epoch 93/1000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 4.6109 - acc: 0.0000e+00 - val_loss: 4.4958 - val_acc: 0.0000e+00\n",
            "Epoch 94/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 4.5580 - acc: 0.0000e+00 - val_loss: 4.4427 - val_acc: 0.0000e+00\n",
            "Epoch 95/1000\n",
            "80/80 [==============================] - 0s 355us/step - loss: 4.5047 - acc: 0.0000e+00 - val_loss: 4.3891 - val_acc: 0.0000e+00\n",
            "Epoch 96/1000\n",
            "80/80 [==============================] - 0s 371us/step - loss: 4.4511 - acc: 0.0000e+00 - val_loss: 4.3351 - val_acc: 0.0000e+00\n",
            "Epoch 97/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 4.3970 - acc: 0.0000e+00 - val_loss: 4.2807 - val_acc: 0.0000e+00\n",
            "Epoch 98/1000\n",
            "80/80 [==============================] - 0s 487us/step - loss: 4.3426 - acc: 0.0000e+00 - val_loss: 4.2260 - val_acc: 0.0000e+00\n",
            "Epoch 99/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 4.2878 - acc: 0.0000e+00 - val_loss: 4.1709 - val_acc: 0.0000e+00\n",
            "Epoch 100/1000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 4.2327 - acc: 0.0000e+00 - val_loss: 4.1155 - val_acc: 0.0000e+00\n",
            "Epoch 101/1000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 4.1773 - acc: 0.0000e+00 - val_loss: 4.0599 - val_acc: 0.0000e+00\n",
            "Epoch 102/1000\n",
            "80/80 [==============================] - 0s 364us/step - loss: 4.1216 - acc: 0.0000e+00 - val_loss: 4.0041 - val_acc: 0.0000e+00\n",
            "Epoch 103/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 4.0657 - acc: 0.0000e+00 - val_loss: 3.9480 - val_acc: 0.0000e+00\n",
            "Epoch 104/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 4.0095 - acc: 0.0000e+00 - val_loss: 3.8915 - val_acc: 0.0000e+00\n",
            "Epoch 105/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 3.9530 - acc: 0.0000e+00 - val_loss: 3.8347 - val_acc: 0.0000e+00\n",
            "Epoch 106/1000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 3.8961 - acc: 0.0000e+00 - val_loss: 3.7775 - val_acc: 0.0000e+00\n",
            "Epoch 107/1000\n",
            "80/80 [==============================] - 0s 386us/step - loss: 3.8388 - acc: 0.0000e+00 - val_loss: 3.7200 - val_acc: 0.0000e+00\n",
            "Epoch 108/1000\n",
            "80/80 [==============================] - 0s 356us/step - loss: 3.7811 - acc: 0.0000e+00 - val_loss: 3.6620 - val_acc: 0.0000e+00\n",
            "Epoch 109/1000\n",
            "80/80 [==============================] - 0s 403us/step - loss: 3.7230 - acc: 0.0000e+00 - val_loss: 3.6036 - val_acc: 0.0000e+00\n",
            "Epoch 110/1000\n",
            "80/80 [==============================] - 0s 354us/step - loss: 3.6646 - acc: 0.0000e+00 - val_loss: 3.5449 - val_acc: 0.0000e+00\n",
            "Epoch 111/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 3.6057 - acc: 0.0000e+00 - val_loss: 3.4857 - val_acc: 0.0000e+00\n",
            "Epoch 112/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 3.5465 - acc: 0.0000e+00 - val_loss: 3.4262 - val_acc: 0.0000e+00\n",
            "Epoch 113/1000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 3.4869 - acc: 0.0000e+00 - val_loss: 3.3663 - val_acc: 0.0000e+00\n",
            "Epoch 114/1000\n",
            "80/80 [==============================] - 0s 349us/step - loss: 3.4270 - acc: 0.0000e+00 - val_loss: 3.3060 - val_acc: 0.0000e+00\n",
            "Epoch 115/1000\n",
            "80/80 [==============================] - 0s 436us/step - loss: 3.3666 - acc: 0.0000e+00 - val_loss: 3.2454 - val_acc: 0.0000e+00\n",
            "Epoch 116/1000\n",
            "80/80 [==============================] - 0s 387us/step - loss: 3.3058 - acc: 0.0000e+00 - val_loss: 3.1844 - val_acc: 0.0000e+00\n",
            "Epoch 117/1000\n",
            "80/80 [==============================] - 0s 369us/step - loss: 3.2447 - acc: 0.0000e+00 - val_loss: 3.1229 - val_acc: 0.0000e+00\n",
            "Epoch 118/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 3.1830 - acc: 0.0000e+00 - val_loss: 3.0609 - val_acc: 0.0000e+00\n",
            "Epoch 119/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 3.1210 - acc: 0.0000e+00 - val_loss: 2.9985 - val_acc: 0.0000e+00\n",
            "Epoch 120/1000\n",
            "80/80 [==============================] - 0s 370us/step - loss: 3.0584 - acc: 0.0000e+00 - val_loss: 2.9356 - val_acc: 0.0000e+00\n",
            "Epoch 121/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 2.9954 - acc: 0.0000e+00 - val_loss: 2.8722 - val_acc: 0.0000e+00\n",
            "Epoch 122/1000\n",
            "80/80 [==============================] - 0s 393us/step - loss: 2.9318 - acc: 0.0000e+00 - val_loss: 2.8083 - val_acc: 0.0000e+00\n",
            "Epoch 123/1000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 2.8677 - acc: 0.0000e+00 - val_loss: 2.7438 - val_acc: 0.0000e+00\n",
            "Epoch 124/1000\n",
            "80/80 [==============================] - 0s 428us/step - loss: 2.8030 - acc: 0.0000e+00 - val_loss: 2.6788 - val_acc: 0.0000e+00\n",
            "Epoch 125/1000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 2.7379 - acc: 0.0000e+00 - val_loss: 2.6132 - val_acc: 0.0000e+00\n",
            "Epoch 126/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 2.6721 - acc: 0.0000e+00 - val_loss: 2.5471 - val_acc: 0.0000e+00\n",
            "Epoch 127/1000\n",
            "80/80 [==============================] - 0s 378us/step - loss: 2.6059 - acc: 0.0000e+00 - val_loss: 2.4805 - val_acc: 0.0000e+00\n",
            "Epoch 128/1000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 2.5391 - acc: 0.0000e+00 - val_loss: 2.4133 - val_acc: 0.0000e+00\n",
            "Epoch 129/1000\n",
            "80/80 [==============================] - 0s 355us/step - loss: 2.4717 - acc: 0.0000e+00 - val_loss: 2.3455 - val_acc: 0.0000e+00\n",
            "Epoch 130/1000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 2.4037 - acc: 0.0000e+00 - val_loss: 2.2771 - val_acc: 0.0000e+00\n",
            "Epoch 131/1000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 2.3352 - acc: 0.0000e+00 - val_loss: 2.2081 - val_acc: 0.0000e+00\n",
            "Epoch 132/1000\n",
            "80/80 [==============================] - 0s 364us/step - loss: 2.2660 - acc: 0.0000e+00 - val_loss: 2.1384 - val_acc: 0.0000e+00\n",
            "Epoch 133/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 2.1961 - acc: 0.0000e+00 - val_loss: 2.0682 - val_acc: 0.0000e+00\n",
            "Epoch 134/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 2.1257 - acc: 0.0000e+00 - val_loss: 1.9972 - val_acc: 0.0000e+00\n",
            "Epoch 135/1000\n",
            "80/80 [==============================] - 0s 425us/step - loss: 2.0546 - acc: 0.0000e+00 - val_loss: 1.9257 - val_acc: 0.0000e+00\n",
            "Epoch 136/1000\n",
            "80/80 [==============================] - 0s 386us/step - loss: 1.9829 - acc: 0.0000e+00 - val_loss: 1.8536 - val_acc: 0.0000e+00\n",
            "Epoch 137/1000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 1.9106 - acc: 0.0000e+00 - val_loss: 1.7808 - val_acc: 0.0000e+00\n",
            "Epoch 138/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 1.8378 - acc: 0.0000e+00 - val_loss: 1.7079 - val_acc: 0.0000e+00\n",
            "Epoch 139/1000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 1.7654 - acc: 0.0000e+00 - val_loss: 1.6371 - val_acc: 0.0000e+00\n",
            "Epoch 140/1000\n",
            "80/80 [==============================] - 0s 360us/step - loss: 1.6954 - acc: 0.0000e+00 - val_loss: 1.5690 - val_acc: 0.0000e+00\n",
            "Epoch 141/1000\n",
            "80/80 [==============================] - 0s 360us/step - loss: 1.6270 - acc: 0.0000e+00 - val_loss: 1.5011 - val_acc: 0.0000e+00\n",
            "Epoch 142/1000\n",
            "80/80 [==============================] - 0s 429us/step - loss: 1.5589 - acc: 0.0000e+00 - val_loss: 1.4331 - val_acc: 0.0000e+00\n",
            "Epoch 143/1000\n",
            "80/80 [==============================] - 0s 387us/step - loss: 1.4907 - acc: 0.0000e+00 - val_loss: 1.3649 - val_acc: 0.0000e+00\n",
            "Epoch 144/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 1.4224 - acc: 0.0000e+00 - val_loss: 1.2964 - val_acc: 0.0000e+00\n",
            "Epoch 145/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 1.3537 - acc: 0.0000e+00 - val_loss: 1.2275 - val_acc: 0.0000e+00\n",
            "Epoch 146/1000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 1.2846 - acc: 0.0000e+00 - val_loss: 1.1582 - val_acc: 0.0000e+00\n",
            "Epoch 147/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 1.2151 - acc: 0.0000e+00 - val_loss: 1.0884 - val_acc: 0.0000e+00\n",
            "Epoch 148/1000\n",
            "80/80 [==============================] - 0s 368us/step - loss: 1.1452 - acc: 0.0000e+00 - val_loss: 1.0182 - val_acc: 0.0000e+00\n",
            "Epoch 149/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 1.0748 - acc: 0.0000e+00 - val_loss: 0.9475 - val_acc: 0.0000e+00\n",
            "Epoch 150/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 1.0039 - acc: 0.0000e+00 - val_loss: 0.8763 - val_acc: 0.0000e+00\n",
            "Epoch 151/1000\n",
            "80/80 [==============================] - 0s 410us/step - loss: 0.9325 - acc: 0.0000e+00 - val_loss: 0.8047 - val_acc: 0.0000e+00\n",
            "Epoch 152/1000\n",
            "80/80 [==============================] - 0s 371us/step - loss: 0.8611 - acc: 0.0000e+00 - val_loss: 0.7332 - val_acc: 0.0000e+00\n",
            "Epoch 153/1000\n",
            "80/80 [==============================] - 0s 372us/step - loss: 0.7899 - acc: 0.0000e+00 - val_loss: 0.6620 - val_acc: 0.0000e+00\n",
            "Epoch 154/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.7191 - acc: 0.0000e+00 - val_loss: 0.5914 - val_acc: 0.0000e+00\n",
            "Epoch 155/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.6484 - acc: 0.0000e+00 - val_loss: 0.5212 - val_acc: 0.0000e+00\n",
            "Epoch 156/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.5778 - acc: 0.0000e+00 - val_loss: 0.4508 - val_acc: 0.0000e+00\n",
            "Epoch 157/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.5073 - acc: 0.0000e+00 - val_loss: 0.3801 - val_acc: 0.0000e+00\n",
            "Epoch 158/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.4365 - acc: 0.0000e+00 - val_loss: 0.3095 - val_acc: 0.0000e+00\n",
            "Epoch 159/1000\n",
            "80/80 [==============================] - 0s 354us/step - loss: 0.3703 - acc: 0.0000e+00 - val_loss: 0.2448 - val_acc: 0.0000e+00\n",
            "Epoch 160/1000\n",
            "80/80 [==============================] - 0s 371us/step - loss: 0.3166 - acc: 0.0125 - val_loss: 0.1971 - val_acc: 0.0000e+00\n",
            "Epoch 161/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.2780 - acc: 0.0125 - val_loss: 0.1661 - val_acc: 0.0000e+00\n",
            "Epoch 162/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.2499 - acc: 0.0125 - val_loss: 0.1510 - val_acc: 0.0000e+00\n",
            "Epoch 163/1000\n",
            "80/80 [==============================] - 0s 396us/step - loss: 0.2300 - acc: 0.0125 - val_loss: 0.1544 - val_acc: 0.0000e+00\n",
            "Epoch 164/1000\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.2176 - acc: 0.0125 - val_loss: 0.1653 - val_acc: 0.0000e+00\n",
            "Epoch 165/1000\n",
            "80/80 [==============================] - 0s 469us/step - loss: 0.2100 - acc: 0.0125 - val_loss: 0.1766 - val_acc: 0.0000e+00\n",
            "Epoch 166/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.2099 - acc: 0.0125 - val_loss: 0.1867 - val_acc: 0.0000e+00\n",
            "Epoch 167/1000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.2119 - acc: 0.0125 - val_loss: 0.1973 - val_acc: 0.0000e+00\n",
            "Epoch 168/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.2154 - acc: 0.0125 - val_loss: 0.2068 - val_acc: 0.0000e+00\n",
            "Epoch 169/1000\n",
            "80/80 [==============================] - 0s 366us/step - loss: 0.2185 - acc: 0.0125 - val_loss: 0.2131 - val_acc: 0.0000e+00\n",
            "Epoch 170/1000\n",
            "80/80 [==============================] - 0s 377us/step - loss: 0.2216 - acc: 0.0125 - val_loss: 0.2170 - val_acc: 0.0000e+00\n",
            "Epoch 171/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.2235 - acc: 0.0125 - val_loss: 0.2186 - val_acc: 0.0000e+00\n",
            "Epoch 172/1000\n",
            "80/80 [==============================] - 0s 353us/step - loss: 0.2242 - acc: 0.0125 - val_loss: 0.2178 - val_acc: 0.0000e+00\n",
            "Epoch 173/1000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.2238 - acc: 0.0125 - val_loss: 0.2152 - val_acc: 0.0000e+00\n",
            "Epoch 174/1000\n",
            "80/80 [==============================] - 0s 393us/step - loss: 0.2222 - acc: 0.0125 - val_loss: 0.2119 - val_acc: 0.0000e+00\n",
            "Epoch 175/1000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.2204 - acc: 0.0125 - val_loss: 0.2073 - val_acc: 0.0000e+00\n",
            "Epoch 176/1000\n",
            "80/80 [==============================] - 0s 356us/step - loss: 0.2182 - acc: 0.0125 - val_loss: 0.2022 - val_acc: 0.0000e+00\n",
            "Epoch 177/1000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.2166 - acc: 0.0125 - val_loss: 0.1973 - val_acc: 0.0000e+00\n",
            "Epoch 178/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.2142 - acc: 0.0125 - val_loss: 0.1930 - val_acc: 0.0000e+00\n",
            "Epoch 179/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.2130 - acc: 0.0125 - val_loss: 0.1895 - val_acc: 0.0000e+00\n",
            "Epoch 180/1000\n",
            "80/80 [==============================] - 0s 479us/step - loss: 0.2113 - acc: 0.0125 - val_loss: 0.1858 - val_acc: 0.0000e+00\n",
            "Epoch 181/1000\n",
            "80/80 [==============================] - 0s 368us/step - loss: 0.2104 - acc: 0.0125 - val_loss: 0.1822 - val_acc: 0.0000e+00\n",
            "Epoch 182/1000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.2098 - acc: 0.0125 - val_loss: 0.1797 - val_acc: 0.0000e+00\n",
            "Epoch 183/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.2085 - acc: 0.0125 - val_loss: 0.1779 - val_acc: 0.0000e+00\n",
            "Epoch 184/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.2081 - acc: 0.0125 - val_loss: 0.1761 - val_acc: 0.0000e+00\n",
            "Epoch 185/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.2077 - acc: 0.0125 - val_loss: 0.1747 - val_acc: 0.0000e+00\n",
            "Epoch 186/1000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.2074 - acc: 0.0125 - val_loss: 0.1736 - val_acc: 0.0000e+00\n",
            "Epoch 187/1000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.2073 - acc: 0.0125 - val_loss: 0.1729 - val_acc: 0.0000e+00\n",
            "Epoch 188/1000\n",
            "80/80 [==============================] - 0s 367us/step - loss: 0.2070 - acc: 0.0125 - val_loss: 0.1726 - val_acc: 0.0000e+00\n",
            "Epoch 189/1000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.2069 - acc: 0.0125 - val_loss: 0.1724 - val_acc: 0.0000e+00\n",
            "Epoch 190/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.2067 - acc: 0.0125 - val_loss: 0.1719 - val_acc: 0.0000e+00\n",
            "Epoch 191/1000\n",
            "80/80 [==============================] - 0s 362us/step - loss: 0.2065 - acc: 0.0125 - val_loss: 0.1716 - val_acc: 0.0000e+00\n",
            "Epoch 192/1000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.2064 - acc: 0.0125 - val_loss: 0.1715 - val_acc: 0.0000e+00\n",
            "Epoch 193/1000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.2062 - acc: 0.0125 - val_loss: 0.1716 - val_acc: 0.0000e+00\n",
            "Epoch 194/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.2062 - acc: 0.0125 - val_loss: 0.1716 - val_acc: 0.0000e+00\n",
            "Epoch 195/1000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.2059 - acc: 0.0125 - val_loss: 0.1710 - val_acc: 0.0000e+00\n",
            "Epoch 196/1000\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.2058 - acc: 0.0125 - val_loss: 0.1709 - val_acc: 0.0000e+00\n",
            "Epoch 197/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.2056 - acc: 0.0125 - val_loss: 0.1715 - val_acc: 0.0000e+00\n",
            "Epoch 198/1000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.2055 - acc: 0.0125 - val_loss: 0.1724 - val_acc: 0.0000e+00\n",
            "Epoch 199/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.2053 - acc: 0.0125 - val_loss: 0.1730 - val_acc: 0.0000e+00\n",
            "Epoch 200/1000\n",
            "80/80 [==============================] - 0s 391us/step - loss: 0.2052 - acc: 0.0125 - val_loss: 0.1736 - val_acc: 0.0000e+00\n",
            "Epoch 201/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.2051 - acc: 0.0125 - val_loss: 0.1741 - val_acc: 0.0000e+00\n",
            "Epoch 202/1000\n",
            "80/80 [==============================] - 0s 364us/step - loss: 0.2050 - acc: 0.0125 - val_loss: 0.1744 - val_acc: 0.0000e+00\n",
            "Epoch 203/1000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.2049 - acc: 0.0125 - val_loss: 0.1743 - val_acc: 0.0000e+00\n",
            "Epoch 204/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.2047 - acc: 0.0125 - val_loss: 0.1737 - val_acc: 0.0000e+00\n",
            "Epoch 205/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.2044 - acc: 0.0125 - val_loss: 0.1722 - val_acc: 0.0000e+00\n",
            "Epoch 206/1000\n",
            "80/80 [==============================] - 0s 364us/step - loss: 0.2041 - acc: 0.0125 - val_loss: 0.1702 - val_acc: 0.0000e+00\n",
            "Epoch 207/1000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.2039 - acc: 0.0125 - val_loss: 0.1684 - val_acc: 0.0000e+00\n",
            "Epoch 208/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.2038 - acc: 0.0125 - val_loss: 0.1670 - val_acc: 0.0000e+00\n",
            "Epoch 209/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.2036 - acc: 0.0125 - val_loss: 0.1660 - val_acc: 0.0000e+00\n",
            "Epoch 210/1000\n",
            "80/80 [==============================] - 0s 396us/step - loss: 0.2035 - acc: 0.0125 - val_loss: 0.1648 - val_acc: 0.0000e+00\n",
            "Epoch 211/1000\n",
            "80/80 [==============================] - 0s 430us/step - loss: 0.2037 - acc: 0.0125 - val_loss: 0.1643 - val_acc: 0.0000e+00\n",
            "Epoch 212/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.2034 - acc: 0.0125 - val_loss: 0.1647 - val_acc: 0.0000e+00\n",
            "Epoch 213/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.2031 - acc: 0.0125 - val_loss: 0.1655 - val_acc: 0.0000e+00\n",
            "Epoch 214/1000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.2028 - acc: 0.0125 - val_loss: 0.1668 - val_acc: 0.0000e+00\n",
            "Epoch 215/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.2025 - acc: 0.0125 - val_loss: 0.1681 - val_acc: 0.0000e+00\n",
            "Epoch 216/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.2027 - acc: 0.0125 - val_loss: 0.1686 - val_acc: 0.0000e+00\n",
            "Epoch 217/1000\n",
            "80/80 [==============================] - 0s 373us/step - loss: 0.2021 - acc: 0.0125 - val_loss: 0.1684 - val_acc: 0.0000e+00\n",
            "Epoch 218/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.2019 - acc: 0.0125 - val_loss: 0.1684 - val_acc: 0.0000e+00\n",
            "Epoch 219/1000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.2017 - acc: 0.0125 - val_loss: 0.1687 - val_acc: 0.0000e+00\n",
            "Epoch 220/1000\n",
            "80/80 [==============================] - 0s 367us/step - loss: 0.2016 - acc: 0.0125 - val_loss: 0.1692 - val_acc: 0.0000e+00\n",
            "Epoch 221/1000\n",
            "80/80 [==============================] - 0s 401us/step - loss: 0.2015 - acc: 0.0125 - val_loss: 0.1696 - val_acc: 0.0000e+00\n",
            "Epoch 222/1000\n",
            "80/80 [==============================] - 0s 387us/step - loss: 0.2013 - acc: 0.0125 - val_loss: 0.1699 - val_acc: 0.0000e+00\n",
            "Epoch 223/1000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.2012 - acc: 0.0125 - val_loss: 0.1706 - val_acc: 0.0000e+00\n",
            "Epoch 224/1000\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.2011 - acc: 0.0125 - val_loss: 0.1708 - val_acc: 0.0000e+00\n",
            "Epoch 225/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.2010 - acc: 0.0125 - val_loss: 0.1708 - val_acc: 0.0000e+00\n",
            "Epoch 226/1000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.2008 - acc: 0.0125 - val_loss: 0.1706 - val_acc: 0.0000e+00\n",
            "Epoch 227/1000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.2006 - acc: 0.0125 - val_loss: 0.1705 - val_acc: 0.0000e+00\n",
            "Epoch 228/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.2004 - acc: 0.0125 - val_loss: 0.1700 - val_acc: 0.0000e+00\n",
            "Epoch 229/1000\n",
            "80/80 [==============================] - 0s 403us/step - loss: 0.2001 - acc: 0.0125 - val_loss: 0.1691 - val_acc: 0.0000e+00\n",
            "Epoch 230/1000\n",
            "80/80 [==============================] - 0s 401us/step - loss: 0.1999 - acc: 0.0125 - val_loss: 0.1684 - val_acc: 0.0000e+00\n",
            "Epoch 231/1000\n",
            "80/80 [==============================] - 0s 365us/step - loss: 0.1996 - acc: 0.0125 - val_loss: 0.1679 - val_acc: 0.0000e+00\n",
            "Epoch 232/1000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.1994 - acc: 0.0125 - val_loss: 0.1672 - val_acc: 0.0000e+00\n",
            "Epoch 233/1000\n",
            "80/80 [==============================] - 0s 384us/step - loss: 0.1992 - acc: 0.0125 - val_loss: 0.1663 - val_acc: 0.0000e+00\n",
            "Epoch 234/1000\n",
            "80/80 [==============================] - 0s 352us/step - loss: 0.1989 - acc: 0.0125 - val_loss: 0.1656 - val_acc: 0.0000e+00\n",
            "Epoch 235/1000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.1987 - acc: 0.0125 - val_loss: 0.1650 - val_acc: 0.0000e+00\n",
            "Epoch 236/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.1985 - acc: 0.0125 - val_loss: 0.1642 - val_acc: 0.0000e+00\n",
            "Epoch 237/1000\n",
            "80/80 [==============================] - 0s 377us/step - loss: 0.1982 - acc: 0.0125 - val_loss: 0.1628 - val_acc: 0.0000e+00\n",
            "Epoch 238/1000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.1982 - acc: 0.0125 - val_loss: 0.1611 - val_acc: 0.0000e+00\n",
            "Epoch 239/1000\n",
            "80/80 [==============================] - 0s 372us/step - loss: 0.1981 - acc: 0.0125 - val_loss: 0.1598 - val_acc: 0.0000e+00\n",
            "Epoch 240/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.1981 - acc: 0.0125 - val_loss: 0.1586 - val_acc: 0.0000e+00\n",
            "Epoch 241/1000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 0.1981 - acc: 0.0125 - val_loss: 0.1576 - val_acc: 0.0000e+00\n",
            "Epoch 242/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.1982 - acc: 0.0125 - val_loss: 0.1572 - val_acc: 0.0000e+00\n",
            "Epoch 243/1000\n",
            "80/80 [==============================] - 0s 356us/step - loss: 0.1979 - acc: 0.0125 - val_loss: 0.1578 - val_acc: 0.0000e+00\n",
            "Epoch 244/1000\n",
            "80/80 [==============================] - 0s 354us/step - loss: 0.1975 - acc: 0.0125 - val_loss: 0.1588 - val_acc: 0.0000e+00\n",
            "Epoch 245/1000\n",
            "80/80 [==============================] - 0s 444us/step - loss: 0.1971 - acc: 0.0125 - val_loss: 0.1597 - val_acc: 0.0000e+00\n",
            "Epoch 246/1000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.1967 - acc: 0.0125 - val_loss: 0.1603 - val_acc: 0.0000e+00\n",
            "Epoch 247/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.1965 - acc: 0.0125 - val_loss: 0.1604 - val_acc: 0.0000e+00\n",
            "Epoch 248/1000\n",
            "80/80 [==============================] - 0s 356us/step - loss: 0.1962 - acc: 0.0125 - val_loss: 0.1600 - val_acc: 0.0000e+00\n",
            "Epoch 249/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.1961 - acc: 0.0125 - val_loss: 0.1600 - val_acc: 0.0000e+00\n",
            "Epoch 250/1000\n",
            "80/80 [==============================] - 0s 358us/step - loss: 0.1958 - acc: 0.0125 - val_loss: 0.1605 - val_acc: 0.0000e+00\n",
            "Epoch 251/1000\n",
            "80/80 [==============================] - 0s 385us/step - loss: 0.1954 - acc: 0.0125 - val_loss: 0.1607 - val_acc: 0.0000e+00\n",
            "Epoch 252/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.1952 - acc: 0.0125 - val_loss: 0.1609 - val_acc: 0.0000e+00\n",
            "Epoch 253/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.1950 - acc: 0.0125 - val_loss: 0.1610 - val_acc: 0.0000e+00\n",
            "Epoch 254/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.1948 - acc: 0.0125 - val_loss: 0.1612 - val_acc: 0.0000e+00\n",
            "Epoch 255/1000\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.1945 - acc: 0.0125 - val_loss: 0.1622 - val_acc: 0.0000e+00\n",
            "Epoch 256/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.1942 - acc: 0.0125 - val_loss: 0.1635 - val_acc: 0.0000e+00\n",
            "Epoch 257/1000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.1942 - acc: 0.0125 - val_loss: 0.1646 - val_acc: 0.0000e+00\n",
            "Epoch 258/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.1940 - acc: 0.0125 - val_loss: 0.1657 - val_acc: 0.0000e+00\n",
            "Epoch 259/1000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.1946 - acc: 0.0125 - val_loss: 0.1663 - val_acc: 0.0000e+00\n",
            "Epoch 260/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.1940 - acc: 0.0125 - val_loss: 0.1653 - val_acc: 0.0000e+00\n",
            "Epoch 261/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.1939 - acc: 0.0125 - val_loss: 0.1644 - val_acc: 0.0000e+00\n",
            "Epoch 262/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.1933 - acc: 0.0125 - val_loss: 0.1640 - val_acc: 0.0000e+00\n",
            "Epoch 263/1000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.1930 - acc: 0.0125 - val_loss: 0.1630 - val_acc: 0.0000e+00\n",
            "Epoch 264/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.1926 - acc: 0.0125 - val_loss: 0.1616 - val_acc: 0.0000e+00\n",
            "Epoch 265/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.1923 - acc: 0.0125 - val_loss: 0.1599 - val_acc: 0.0000e+00\n",
            "Epoch 266/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.1919 - acc: 0.0125 - val_loss: 0.1583 - val_acc: 0.0000e+00\n",
            "Epoch 267/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.1919 - acc: 0.0125 - val_loss: 0.1567 - val_acc: 0.0000e+00\n",
            "Epoch 268/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.1918 - acc: 0.0125 - val_loss: 0.1559 - val_acc: 0.0000e+00\n",
            "Epoch 269/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.1915 - acc: 0.0125 - val_loss: 0.1558 - val_acc: 0.0000e+00\n",
            "Epoch 270/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.1913 - acc: 0.0125 - val_loss: 0.1557 - val_acc: 0.0000e+00\n",
            "Epoch 271/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.1910 - acc: 0.0125 - val_loss: 0.1559 - val_acc: 0.0000e+00\n",
            "Epoch 272/1000\n",
            "80/80 [==============================] - 0s 353us/step - loss: 0.1907 - acc: 0.0125 - val_loss: 0.1564 - val_acc: 0.0000e+00\n",
            "Epoch 273/1000\n",
            "80/80 [==============================] - 0s 401us/step - loss: 0.1904 - acc: 0.0125 - val_loss: 0.1570 - val_acc: 0.0000e+00\n",
            "Epoch 274/1000\n",
            "80/80 [==============================] - 0s 421us/step - loss: 0.1901 - acc: 0.0125 - val_loss: 0.1572 - val_acc: 0.0000e+00\n",
            "Epoch 275/1000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.1898 - acc: 0.0125 - val_loss: 0.1573 - val_acc: 0.0000e+00\n",
            "Epoch 276/1000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.1895 - acc: 0.0125 - val_loss: 0.1577 - val_acc: 0.0000e+00\n",
            "Epoch 277/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.1894 - acc: 0.0125 - val_loss: 0.1580 - val_acc: 0.0000e+00\n",
            "Epoch 278/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.1891 - acc: 0.0125 - val_loss: 0.1581 - val_acc: 0.0000e+00\n",
            "Epoch 279/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.1888 - acc: 0.0125 - val_loss: 0.1586 - val_acc: 0.0000e+00\n",
            "Epoch 280/1000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.1886 - acc: 0.0125 - val_loss: 0.1591 - val_acc: 0.0000e+00\n",
            "Epoch 281/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.1885 - acc: 0.0125 - val_loss: 0.1591 - val_acc: 0.0000e+00\n",
            "Epoch 282/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.1881 - acc: 0.0125 - val_loss: 0.1582 - val_acc: 0.0000e+00\n",
            "Epoch 283/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.1878 - acc: 0.0125 - val_loss: 0.1571 - val_acc: 0.0000e+00\n",
            "Epoch 284/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.1875 - acc: 0.0125 - val_loss: 0.1560 - val_acc: 0.0000e+00\n",
            "Epoch 285/1000\n",
            "80/80 [==============================] - 0s 385us/step - loss: 0.1872 - acc: 0.0125 - val_loss: 0.1552 - val_acc: 0.0000e+00\n",
            "Epoch 286/1000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.1869 - acc: 0.0125 - val_loss: 0.1548 - val_acc: 0.0000e+00\n",
            "Epoch 287/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.1867 - acc: 0.0125 - val_loss: 0.1548 - val_acc: 0.0000e+00\n",
            "Epoch 288/1000\n",
            "80/80 [==============================] - 0s 365us/step - loss: 0.1864 - acc: 0.0125 - val_loss: 0.1555 - val_acc: 0.0000e+00\n",
            "Epoch 289/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.1861 - acc: 0.0125 - val_loss: 0.1559 - val_acc: 0.0000e+00\n",
            "Epoch 290/1000\n",
            "80/80 [==============================] - 0s 359us/step - loss: 0.1858 - acc: 0.0125 - val_loss: 0.1568 - val_acc: 0.0000e+00\n",
            "Epoch 291/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.1859 - acc: 0.0125 - val_loss: 0.1573 - val_acc: 0.0000e+00\n",
            "Epoch 292/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.1855 - acc: 0.0125 - val_loss: 0.1569 - val_acc: 0.0000e+00\n",
            "Epoch 293/1000\n",
            "80/80 [==============================] - 0s 353us/step - loss: 0.1851 - acc: 0.0125 - val_loss: 0.1564 - val_acc: 0.0000e+00\n",
            "Epoch 294/1000\n",
            "80/80 [==============================] - 0s 413us/step - loss: 0.1848 - acc: 0.0125 - val_loss: 0.1554 - val_acc: 0.0000e+00\n",
            "Epoch 295/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.1845 - acc: 0.0125 - val_loss: 0.1543 - val_acc: 0.0000e+00\n",
            "Epoch 296/1000\n",
            "80/80 [==============================] - 0s 361us/step - loss: 0.1841 - acc: 0.0125 - val_loss: 0.1535 - val_acc: 0.0000e+00\n",
            "Epoch 297/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.1838 - acc: 0.0125 - val_loss: 0.1527 - val_acc: 0.0000e+00\n",
            "Epoch 298/1000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.1836 - acc: 0.0125 - val_loss: 0.1525 - val_acc: 0.0000e+00\n",
            "Epoch 299/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.1831 - acc: 0.0125 - val_loss: 0.1531 - val_acc: 0.0000e+00\n",
            "Epoch 300/1000\n",
            "80/80 [==============================] - 0s 370us/step - loss: 0.1828 - acc: 0.0125 - val_loss: 0.1538 - val_acc: 0.0000e+00\n",
            "Epoch 301/1000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.1826 - acc: 0.0125 - val_loss: 0.1544 - val_acc: 0.0000e+00\n",
            "Epoch 302/1000\n",
            "80/80 [==============================] - 0s 373us/step - loss: 0.1824 - acc: 0.0125 - val_loss: 0.1548 - val_acc: 0.0000e+00\n",
            "Epoch 303/1000\n",
            "80/80 [==============================] - 0s 371us/step - loss: 0.1822 - acc: 0.0125 - val_loss: 0.1552 - val_acc: 0.0000e+00\n",
            "Epoch 304/1000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.1820 - acc: 0.0125 - val_loss: 0.1554 - val_acc: 0.0000e+00\n",
            "Epoch 305/1000\n",
            "80/80 [==============================] - 0s 362us/step - loss: 0.1818 - acc: 0.0125 - val_loss: 0.1551 - val_acc: 0.0000e+00\n",
            "Epoch 306/1000\n",
            "80/80 [==============================] - 0s 402us/step - loss: 0.1814 - acc: 0.0125 - val_loss: 0.1545 - val_acc: 0.0000e+00\n",
            "Epoch 307/1000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.1810 - acc: 0.0125 - val_loss: 0.1538 - val_acc: 0.0000e+00\n",
            "Epoch 308/1000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.1807 - acc: 0.0125 - val_loss: 0.1531 - val_acc: 0.0000e+00\n",
            "Epoch 309/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.1803 - acc: 0.0125 - val_loss: 0.1524 - val_acc: 0.0000e+00\n",
            "Epoch 310/1000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.1799 - acc: 0.0125 - val_loss: 0.1514 - val_acc: 0.0000e+00\n",
            "Epoch 311/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.1794 - acc: 0.0125 - val_loss: 0.1499 - val_acc: 0.0000e+00\n",
            "Epoch 312/1000\n",
            "80/80 [==============================] - 0s 432us/step - loss: 0.1789 - acc: 0.0125 - val_loss: 0.1479 - val_acc: 0.0000e+00\n",
            "Epoch 313/1000\n",
            "80/80 [==============================] - 0s 369us/step - loss: 0.1786 - acc: 0.0125 - val_loss: 0.1456 - val_acc: 0.0000e+00\n",
            "Epoch 314/1000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.1784 - acc: 0.0125 - val_loss: 0.1435 - val_acc: 0.0000e+00\n",
            "Epoch 315/1000\n",
            "80/80 [==============================] - 0s 362us/step - loss: 0.1782 - acc: 0.0125 - val_loss: 0.1416 - val_acc: 0.0000e+00\n",
            "Epoch 316/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.1785 - acc: 0.0125 - val_loss: 0.1402 - val_acc: 0.0000e+00\n",
            "Epoch 317/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.1783 - acc: 0.0125 - val_loss: 0.1399 - val_acc: 0.0000e+00\n",
            "Epoch 318/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.1780 - acc: 0.0125 - val_loss: 0.1399 - val_acc: 0.0000e+00\n",
            "Epoch 319/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.1775 - acc: 0.0125 - val_loss: 0.1399 - val_acc: 0.0000e+00\n",
            "Epoch 320/1000\n",
            "80/80 [==============================] - 0s 419us/step - loss: 0.1771 - acc: 0.0125 - val_loss: 0.1406 - val_acc: 0.0000e+00\n",
            "Epoch 321/1000\n",
            "80/80 [==============================] - 0s 379us/step - loss: 0.1764 - acc: 0.0125 - val_loss: 0.1418 - val_acc: 0.0000e+00\n",
            "Epoch 322/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.1758 - acc: 0.0125 - val_loss: 0.1436 - val_acc: 0.0000e+00\n",
            "Epoch 323/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.1755 - acc: 0.0125 - val_loss: 0.1448 - val_acc: 0.0000e+00\n",
            "Epoch 324/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.1748 - acc: 0.0125 - val_loss: 0.1453 - val_acc: 0.0000e+00\n",
            "Epoch 325/1000\n",
            "80/80 [==============================] - 0s 491us/step - loss: 0.1743 - acc: 0.0125 - val_loss: 0.1465 - val_acc: 0.0000e+00\n",
            "Epoch 326/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.1740 - acc: 0.0125 - val_loss: 0.1484 - val_acc: 0.0000e+00\n",
            "Epoch 327/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.1743 - acc: 0.0125 - val_loss: 0.1498 - val_acc: 0.0000e+00\n",
            "Epoch 328/1000\n",
            "80/80 [==============================] - 0s 378us/step - loss: 0.1742 - acc: 0.0125 - val_loss: 0.1497 - val_acc: 0.0000e+00\n",
            "Epoch 329/1000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.1738 - acc: 0.0125 - val_loss: 0.1487 - val_acc: 0.0000e+00\n",
            "Epoch 330/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.1733 - acc: 0.0125 - val_loss: 0.1474 - val_acc: 0.0000e+00\n",
            "Epoch 331/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.1726 - acc: 0.0125 - val_loss: 0.1458 - val_acc: 0.0000e+00\n",
            "Epoch 332/1000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.1719 - acc: 0.0125 - val_loss: 0.1432 - val_acc: 0.0000e+00\n",
            "Epoch 333/1000\n",
            "80/80 [==============================] - 0s 393us/step - loss: 0.1717 - acc: 0.0125 - val_loss: 0.1409 - val_acc: 0.0000e+00\n",
            "Epoch 334/1000\n",
            "80/80 [==============================] - 0s 382us/step - loss: 0.1711 - acc: 0.0125 - val_loss: 0.1394 - val_acc: 0.0000e+00\n",
            "Epoch 335/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.1709 - acc: 0.0125 - val_loss: 0.1382 - val_acc: 0.0000e+00\n",
            "Epoch 336/1000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.1705 - acc: 0.0125 - val_loss: 0.1379 - val_acc: 0.0000e+00\n",
            "Epoch 337/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.1701 - acc: 0.0125 - val_loss: 0.1382 - val_acc: 0.0000e+00\n",
            "Epoch 338/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.1698 - acc: 0.0125 - val_loss: 0.1387 - val_acc: 0.0000e+00\n",
            "Epoch 339/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.1692 - acc: 0.0125 - val_loss: 0.1388 - val_acc: 0.0000e+00\n",
            "Epoch 340/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.1688 - acc: 0.0125 - val_loss: 0.1390 - val_acc: 0.0000e+00\n",
            "Epoch 341/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.1684 - acc: 0.0125 - val_loss: 0.1389 - val_acc: 0.0000e+00\n",
            "Epoch 342/1000\n",
            "80/80 [==============================] - 0s 432us/step - loss: 0.1680 - acc: 0.0125 - val_loss: 0.1386 - val_acc: 0.0000e+00\n",
            "Epoch 343/1000\n",
            "80/80 [==============================] - 0s 354us/step - loss: 0.1676 - acc: 0.0125 - val_loss: 0.1380 - val_acc: 0.0000e+00\n",
            "Epoch 344/1000\n",
            "80/80 [==============================] - 0s 354us/step - loss: 0.1672 - acc: 0.0125 - val_loss: 0.1382 - val_acc: 0.0000e+00\n",
            "Epoch 345/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.1666 - acc: 0.0125 - val_loss: 0.1392 - val_acc: 0.0000e+00\n",
            "Epoch 346/1000\n",
            "80/80 [==============================] - 0s 352us/step - loss: 0.1664 - acc: 0.0125 - val_loss: 0.1400 - val_acc: 0.0000e+00\n",
            "Epoch 347/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.1661 - acc: 0.0125 - val_loss: 0.1401 - val_acc: 0.0000e+00\n",
            "Epoch 348/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.1657 - acc: 0.0125 - val_loss: 0.1400 - val_acc: 0.0000e+00\n",
            "Epoch 349/1000\n",
            "80/80 [==============================] - 0s 360us/step - loss: 0.1653 - acc: 0.0125 - val_loss: 0.1395 - val_acc: 0.0000e+00\n",
            "Epoch 350/1000\n",
            "80/80 [==============================] - 0s 363us/step - loss: 0.1649 - acc: 0.0125 - val_loss: 0.1388 - val_acc: 0.0000e+00\n",
            "Epoch 351/1000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.1645 - acc: 0.0125 - val_loss: 0.1383 - val_acc: 0.0000e+00\n",
            "Epoch 352/1000\n",
            "80/80 [==============================] - 0s 370us/step - loss: 0.1640 - acc: 0.0125 - val_loss: 0.1379 - val_acc: 0.0000e+00\n",
            "Epoch 353/1000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.1636 - acc: 0.0125 - val_loss: 0.1375 - val_acc: 0.0000e+00\n",
            "Epoch 354/1000\n",
            "80/80 [==============================] - 0s 360us/step - loss: 0.1632 - acc: 0.0125 - val_loss: 0.1370 - val_acc: 0.0000e+00\n",
            "Epoch 355/1000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.1626 - acc: 0.0125 - val_loss: 0.1355 - val_acc: 0.0000e+00\n",
            "Epoch 356/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.1622 - acc: 0.0125 - val_loss: 0.1343 - val_acc: 0.0000e+00\n",
            "Epoch 357/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.1616 - acc: 0.0125 - val_loss: 0.1338 - val_acc: 0.0000e+00\n",
            "Epoch 358/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.1611 - acc: 0.0125 - val_loss: 0.1339 - val_acc: 0.0000e+00\n",
            "Epoch 359/1000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.1608 - acc: 0.0125 - val_loss: 0.1340 - val_acc: 0.0000e+00\n",
            "Epoch 360/1000\n",
            "80/80 [==============================] - 0s 365us/step - loss: 0.1603 - acc: 0.0125 - val_loss: 0.1334 - val_acc: 0.0000e+00\n",
            "Epoch 361/1000\n",
            "80/80 [==============================] - 0s 369us/step - loss: 0.1599 - acc: 0.0125 - val_loss: 0.1327 - val_acc: 0.0000e+00\n",
            "Epoch 362/1000\n",
            "80/80 [==============================] - 0s 376us/step - loss: 0.1593 - acc: 0.0125 - val_loss: 0.1325 - val_acc: 0.0000e+00\n",
            "Epoch 363/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.1589 - acc: 0.0125 - val_loss: 0.1319 - val_acc: 0.0000e+00\n",
            "Epoch 364/1000\n",
            "80/80 [==============================] - 0s 404us/step - loss: 0.1584 - acc: 0.0125 - val_loss: 0.1309 - val_acc: 0.0000e+00\n",
            "Epoch 365/1000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.1579 - acc: 0.0125 - val_loss: 0.1298 - val_acc: 0.0000e+00\n",
            "Epoch 366/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.1574 - acc: 0.0125 - val_loss: 0.1288 - val_acc: 0.0000e+00\n",
            "Epoch 367/1000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.1569 - acc: 0.0125 - val_loss: 0.1276 - val_acc: 0.0000e+00\n",
            "Epoch 368/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.1566 - acc: 0.0125 - val_loss: 0.1269 - val_acc: 0.0000e+00\n",
            "Epoch 369/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.1561 - acc: 0.0125 - val_loss: 0.1267 - val_acc: 0.0000e+00\n",
            "Epoch 370/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.1555 - acc: 0.0125 - val_loss: 0.1261 - val_acc: 0.0000e+00\n",
            "Epoch 371/1000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.1550 - acc: 0.0125 - val_loss: 0.1254 - val_acc: 0.0000e+00\n",
            "Epoch 372/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.1545 - acc: 0.0125 - val_loss: 0.1243 - val_acc: 0.0000e+00\n",
            "Epoch 373/1000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.1540 - acc: 0.0125 - val_loss: 0.1228 - val_acc: 0.0000e+00\n",
            "Epoch 374/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.1536 - acc: 0.0125 - val_loss: 0.1213 - val_acc: 0.0000e+00\n",
            "Epoch 375/1000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.1536 - acc: 0.0125 - val_loss: 0.1205 - val_acc: 0.0000e+00\n",
            "Epoch 376/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.1529 - acc: 0.0125 - val_loss: 0.1210 - val_acc: 0.0000e+00\n",
            "Epoch 377/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.1521 - acc: 0.0125 - val_loss: 0.1217 - val_acc: 0.0000e+00\n",
            "Epoch 378/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.1514 - acc: 0.0125 - val_loss: 0.1229 - val_acc: 0.0000e+00\n",
            "Epoch 379/1000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.1507 - acc: 0.0125 - val_loss: 0.1234 - val_acc: 0.0000e+00\n",
            "Epoch 380/1000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.1501 - acc: 0.0125 - val_loss: 0.1236 - val_acc: 0.0000e+00\n",
            "Epoch 381/1000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.1495 - acc: 0.0125 - val_loss: 0.1238 - val_acc: 0.0000e+00\n",
            "Epoch 382/1000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.1489 - acc: 0.0125 - val_loss: 0.1243 - val_acc: 0.0000e+00\n",
            "Epoch 383/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.1484 - acc: 0.0125 - val_loss: 0.1254 - val_acc: 0.0000e+00\n",
            "Epoch 384/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.1481 - acc: 0.0125 - val_loss: 0.1262 - val_acc: 0.0000e+00\n",
            "Epoch 385/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.1479 - acc: 0.0125 - val_loss: 0.1262 - val_acc: 0.0000e+00\n",
            "Epoch 386/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.1475 - acc: 0.0125 - val_loss: 0.1256 - val_acc: 0.0000e+00\n",
            "Epoch 387/1000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.1468 - acc: 0.0125 - val_loss: 0.1256 - val_acc: 0.0000e+00\n",
            "Epoch 388/1000\n",
            "80/80 [==============================] - 0s 403us/step - loss: 0.1463 - acc: 0.0125 - val_loss: 0.1251 - val_acc: 0.0000e+00\n",
            "Epoch 389/1000\n",
            "80/80 [==============================] - 0s 377us/step - loss: 0.1458 - acc: 0.0125 - val_loss: 0.1239 - val_acc: 0.0000e+00\n",
            "Epoch 390/1000\n",
            "80/80 [==============================] - 0s 407us/step - loss: 0.1449 - acc: 0.0125 - val_loss: 0.1223 - val_acc: 0.0000e+00\n",
            "Epoch 391/1000\n",
            "80/80 [==============================] - 0s 353us/step - loss: 0.1440 - acc: 0.0125 - val_loss: 0.1201 - val_acc: 0.0000e+00\n",
            "Epoch 392/1000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.1432 - acc: 0.0125 - val_loss: 0.1177 - val_acc: 0.0000e+00\n",
            "Epoch 393/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.1425 - acc: 0.0125 - val_loss: 0.1158 - val_acc: 0.0000e+00\n",
            "Epoch 394/1000\n",
            "80/80 [==============================] - 0s 405us/step - loss: 0.1419 - acc: 0.0125 - val_loss: 0.1145 - val_acc: 0.0000e+00\n",
            "Epoch 395/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.1413 - acc: 0.0125 - val_loss: 0.1138 - val_acc: 0.0000e+00\n",
            "Epoch 396/1000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.1406 - acc: 0.0125 - val_loss: 0.1137 - val_acc: 0.0000e+00\n",
            "Epoch 397/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.1399 - acc: 0.0125 - val_loss: 0.1140 - val_acc: 0.0000e+00\n",
            "Epoch 398/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.1394 - acc: 0.0125 - val_loss: 0.1141 - val_acc: 0.0000e+00\n",
            "Epoch 399/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.1386 - acc: 0.0125 - val_loss: 0.1136 - val_acc: 0.0000e+00\n",
            "Epoch 400/1000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.1379 - acc: 0.0125 - val_loss: 0.1134 - val_acc: 0.0000e+00\n",
            "Epoch 401/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.1372 - acc: 0.0125 - val_loss: 0.1137 - val_acc: 0.0000e+00\n",
            "Epoch 402/1000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.1367 - acc: 0.0125 - val_loss: 0.1139 - val_acc: 0.0000e+00\n",
            "Epoch 403/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.1360 - acc: 0.0125 - val_loss: 0.1130 - val_acc: 0.0000e+00\n",
            "Epoch 404/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.1353 - acc: 0.0125 - val_loss: 0.1117 - val_acc: 0.0000e+00\n",
            "Epoch 405/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.1344 - acc: 0.0125 - val_loss: 0.1107 - val_acc: 0.0000e+00\n",
            "Epoch 406/1000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.1336 - acc: 0.0125 - val_loss: 0.1093 - val_acc: 0.0000e+00\n",
            "Epoch 407/1000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.1328 - acc: 0.0125 - val_loss: 0.1078 - val_acc: 0.0000e+00\n",
            "Epoch 408/1000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.1322 - acc: 0.0125 - val_loss: 0.1069 - val_acc: 0.0000e+00\n",
            "Epoch 409/1000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.1313 - acc: 0.0125 - val_loss: 0.1066 - val_acc: 0.0000e+00\n",
            "Epoch 410/1000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.1305 - acc: 0.0125 - val_loss: 0.1057 - val_acc: 0.0000e+00\n",
            "Epoch 411/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.1298 - acc: 0.0125 - val_loss: 0.1048 - val_acc: 0.0000e+00\n",
            "Epoch 412/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.1289 - acc: 0.0125 - val_loss: 0.1047 - val_acc: 0.0000e+00\n",
            "Epoch 413/1000\n",
            "80/80 [==============================] - 0s 355us/step - loss: 0.1281 - acc: 0.0125 - val_loss: 0.1049 - val_acc: 0.0000e+00\n",
            "Epoch 414/1000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.1274 - acc: 0.0125 - val_loss: 0.1052 - val_acc: 0.0000e+00\n",
            "Epoch 415/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.1266 - acc: 0.0125 - val_loss: 0.1044 - val_acc: 0.0000e+00\n",
            "Epoch 416/1000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.1257 - acc: 0.0125 - val_loss: 0.1029 - val_acc: 0.0000e+00\n",
            "Epoch 417/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.1249 - acc: 0.0125 - val_loss: 0.1012 - val_acc: 0.0000e+00\n",
            "Epoch 418/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.1239 - acc: 0.0125 - val_loss: 0.0996 - val_acc: 0.0000e+00\n",
            "Epoch 419/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.1232 - acc: 0.0125 - val_loss: 0.0981 - val_acc: 0.0000e+00\n",
            "Epoch 420/1000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.1223 - acc: 0.0125 - val_loss: 0.0972 - val_acc: 0.0000e+00\n",
            "Epoch 421/1000\n",
            "80/80 [==============================] - 0s 406us/step - loss: 0.1215 - acc: 0.0125 - val_loss: 0.0965 - val_acc: 0.0000e+00\n",
            "Epoch 422/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.1206 - acc: 0.0125 - val_loss: 0.0963 - val_acc: 0.0000e+00\n",
            "Epoch 423/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.1197 - acc: 0.0125 - val_loss: 0.0964 - val_acc: 0.0000e+00\n",
            "Epoch 424/1000\n",
            "80/80 [==============================] - 0s 361us/step - loss: 0.1189 - acc: 0.0125 - val_loss: 0.0965 - val_acc: 0.0000e+00\n",
            "Epoch 425/1000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.1180 - acc: 0.0125 - val_loss: 0.0958 - val_acc: 0.0000e+00\n",
            "Epoch 426/1000\n",
            "80/80 [==============================] - 0s 352us/step - loss: 0.1171 - acc: 0.0125 - val_loss: 0.0948 - val_acc: 0.0000e+00\n",
            "Epoch 427/1000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 0.1161 - acc: 0.0125 - val_loss: 0.0934 - val_acc: 0.0000e+00\n",
            "Epoch 428/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.1152 - acc: 0.0125 - val_loss: 0.0917 - val_acc: 0.0000e+00\n",
            "Epoch 429/1000\n",
            "80/80 [==============================] - 0s 386us/step - loss: 0.1145 - acc: 0.0125 - val_loss: 0.0910 - val_acc: 0.0000e+00\n",
            "Epoch 430/1000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.1134 - acc: 0.0125 - val_loss: 0.0913 - val_acc: 0.0000e+00\n",
            "Epoch 431/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.1123 - acc: 0.0125 - val_loss: 0.0905 - val_acc: 0.0000e+00\n",
            "Epoch 432/1000\n",
            "80/80 [==============================] - 0s 389us/step - loss: 0.1113 - acc: 0.0125 - val_loss: 0.0888 - val_acc: 0.0000e+00\n",
            "Epoch 433/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.1102 - acc: 0.0125 - val_loss: 0.0869 - val_acc: 0.0000e+00\n",
            "Epoch 434/1000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.1092 - acc: 0.0125 - val_loss: 0.0854 - val_acc: 0.0000e+00\n",
            "Epoch 435/1000\n",
            "80/80 [==============================] - 0s 356us/step - loss: 0.1082 - acc: 0.0125 - val_loss: 0.0844 - val_acc: 0.0000e+00\n",
            "Epoch 436/1000\n",
            "80/80 [==============================] - 0s 371us/step - loss: 0.1071 - acc: 0.0125 - val_loss: 0.0838 - val_acc: 0.0000e+00\n",
            "Epoch 437/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.1059 - acc: 0.0125 - val_loss: 0.0838 - val_acc: 0.0000e+00\n",
            "Epoch 438/1000\n",
            "80/80 [==============================] - 0s 385us/step - loss: 0.1048 - acc: 0.0125 - val_loss: 0.0841 - val_acc: 0.0000e+00\n",
            "Epoch 439/1000\n",
            "80/80 [==============================] - 0s 387us/step - loss: 0.1036 - acc: 0.0125 - val_loss: 0.0842 - val_acc: 0.0000e+00\n",
            "Epoch 440/1000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.1026 - acc: 0.0125 - val_loss: 0.0843 - val_acc: 0.0000e+00\n",
            "Epoch 441/1000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.1017 - acc: 0.0125 - val_loss: 0.0843 - val_acc: 0.0000e+00\n",
            "Epoch 442/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.1007 - acc: 0.0125 - val_loss: 0.0833 - val_acc: 0.0000e+00\n",
            "Epoch 443/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0996 - acc: 0.0125 - val_loss: 0.0811 - val_acc: 0.0000e+00\n",
            "Epoch 444/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0981 - acc: 0.0125 - val_loss: 0.0774 - val_acc: 0.0000e+00\n",
            "Epoch 445/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0967 - acc: 0.0125 - val_loss: 0.0747 - val_acc: 0.0000e+00\n",
            "Epoch 446/1000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0953 - acc: 0.0125 - val_loss: 0.0729 - val_acc: 0.0000e+00\n",
            "Epoch 447/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0941 - acc: 0.0125 - val_loss: 0.0710 - val_acc: 0.0000e+00\n",
            "Epoch 448/1000\n",
            "80/80 [==============================] - 0s 253us/step - loss: 0.0930 - acc: 0.0125 - val_loss: 0.0699 - val_acc: 0.0000e+00\n",
            "Epoch 449/1000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0916 - acc: 0.0125 - val_loss: 0.0696 - val_acc: 0.0000e+00\n",
            "Epoch 450/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0900 - acc: 0.0125 - val_loss: 0.0703 - val_acc: 0.0000e+00\n",
            "Epoch 451/1000\n",
            "80/80 [==============================] - 0s 359us/step - loss: 0.0888 - acc: 0.0125 - val_loss: 0.0707 - val_acc: 0.0000e+00\n",
            "Epoch 452/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0873 - acc: 0.0125 - val_loss: 0.0700 - val_acc: 0.0000e+00\n",
            "Epoch 453/1000\n",
            "80/80 [==============================] - 0s 396us/step - loss: 0.0860 - acc: 0.0125 - val_loss: 0.0691 - val_acc: 0.0000e+00\n",
            "Epoch 454/1000\n",
            "80/80 [==============================] - 0s 456us/step - loss: 0.0847 - acc: 0.0125 - val_loss: 0.0674 - val_acc: 0.0000e+00\n",
            "Epoch 455/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.0831 - acc: 0.0125 - val_loss: 0.0652 - val_acc: 0.0000e+00\n",
            "Epoch 456/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0815 - acc: 0.0125 - val_loss: 0.0628 - val_acc: 0.0000e+00\n",
            "Epoch 457/1000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.0799 - acc: 0.0125 - val_loss: 0.0604 - val_acc: 0.0000e+00\n",
            "Epoch 458/1000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.0784 - acc: 0.0125 - val_loss: 0.0578 - val_acc: 0.0000e+00\n",
            "Epoch 459/1000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0771 - acc: 0.0125 - val_loss: 0.0556 - val_acc: 0.0000e+00\n",
            "Epoch 460/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0757 - acc: 0.0125 - val_loss: 0.0548 - val_acc: 0.0000e+00\n",
            "Epoch 461/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0739 - acc: 0.0125 - val_loss: 0.0548 - val_acc: 0.0000e+00\n",
            "Epoch 462/1000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.0719 - acc: 0.0125 - val_loss: 0.0547 - val_acc: 0.0000e+00\n",
            "Epoch 463/1000\n",
            "80/80 [==============================] - 0s 459us/step - loss: 0.0702 - acc: 0.0125 - val_loss: 0.0550 - val_acc: 0.0000e+00\n",
            "Epoch 464/1000\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.0692 - acc: 0.0125 - val_loss: 0.0544 - val_acc: 0.0000e+00\n",
            "Epoch 465/1000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.0672 - acc: 0.0125 - val_loss: 0.0510 - val_acc: 0.0000e+00\n",
            "Epoch 466/1000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.0658 - acc: 0.0125 - val_loss: 0.0472 - val_acc: 0.0000e+00\n",
            "Epoch 467/1000\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.0633 - acc: 0.0125 - val_loss: 0.0451 - val_acc: 0.0000e+00\n",
            "Epoch 468/1000\n",
            "80/80 [==============================] - 0s 358us/step - loss: 0.0616 - acc: 0.0125 - val_loss: 0.0430 - val_acc: 0.0000e+00\n",
            "Epoch 469/1000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0599 - acc: 0.0125 - val_loss: 0.0413 - val_acc: 0.0000e+00\n",
            "Epoch 470/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0580 - acc: 0.0125 - val_loss: 0.0405 - val_acc: 0.0000e+00\n",
            "Epoch 471/1000\n",
            "80/80 [==============================] - 0s 385us/step - loss: 0.0559 - acc: 0.0125 - val_loss: 0.0409 - val_acc: 0.0000e+00\n",
            "Epoch 472/1000\n",
            "80/80 [==============================] - 0s 415us/step - loss: 0.0542 - acc: 0.0125 - val_loss: 0.0414 - val_acc: 0.0000e+00\n",
            "Epoch 473/1000\n",
            "80/80 [==============================] - 0s 375us/step - loss: 0.0525 - acc: 0.0125 - val_loss: 0.0402 - val_acc: 0.0000e+00\n",
            "Epoch 474/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.0508 - acc: 0.0125 - val_loss: 0.0375 - val_acc: 0.0000e+00\n",
            "Epoch 475/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0483 - acc: 0.0125 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
            "Epoch 476/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0460 - acc: 0.0125 - val_loss: 0.0292 - val_acc: 0.0000e+00\n",
            "Epoch 477/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0441 - acc: 0.0125 - val_loss: 0.0273 - val_acc: 0.0000e+00\n",
            "Epoch 478/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0418 - acc: 0.0125 - val_loss: 0.0273 - val_acc: 0.0000e+00\n",
            "Epoch 479/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0395 - acc: 0.0125 - val_loss: 0.0270 - val_acc: 0.0000e+00\n",
            "Epoch 480/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0373 - acc: 0.0125 - val_loss: 0.0259 - val_acc: 0.0000e+00\n",
            "Epoch 481/1000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.0354 - acc: 0.0125 - val_loss: 0.0242 - val_acc: 0.0000e+00\n",
            "Epoch 482/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0336 - acc: 0.0125 - val_loss: 0.0222 - val_acc: 0.0000e+00\n",
            "Epoch 483/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0322 - acc: 0.0125 - val_loss: 0.0207 - val_acc: 0.0000e+00\n",
            "Epoch 484/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0309 - acc: 0.0125 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
            "Epoch 485/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0297 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 486/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0289 - acc: 0.0125 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
            "Epoch 487/1000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0280 - acc: 0.0125 - val_loss: 0.0179 - val_acc: 0.0000e+00\n",
            "Epoch 488/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0274 - acc: 0.0125 - val_loss: 0.0173 - val_acc: 0.0000e+00\n",
            "Epoch 489/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0268 - acc: 0.0125 - val_loss: 0.0179 - val_acc: 0.0000e+00\n",
            "Epoch 490/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0263 - acc: 0.0125 - val_loss: 0.0198 - val_acc: 0.0000e+00\n",
            "Epoch 491/1000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.0262 - acc: 0.0125 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
            "Epoch 492/1000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.0260 - acc: 0.0125 - val_loss: 0.0200 - val_acc: 0.0000e+00\n",
            "Epoch 493/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0255 - acc: 0.0125 - val_loss: 0.0178 - val_acc: 0.0000e+00\n",
            "Epoch 494/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0250 - acc: 0.0125 - val_loss: 0.0154 - val_acc: 0.0000e+00\n",
            "Epoch 495/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0246 - acc: 0.0125 - val_loss: 0.0147 - val_acc: 0.0000e+00\n",
            "Epoch 496/1000\n",
            "80/80 [==============================] - 0s 380us/step - loss: 0.0246 - acc: 0.0125 - val_loss: 0.0141 - val_acc: 0.0000e+00\n",
            "Epoch 497/1000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0247 - acc: 0.0125 - val_loss: 0.0138 - val_acc: 0.0000e+00\n",
            "Epoch 498/1000\n",
            "80/80 [==============================] - 0s 398us/step - loss: 0.0248 - acc: 0.0125 - val_loss: 0.0135 - val_acc: 0.0000e+00\n",
            "Epoch 499/1000\n",
            "80/80 [==============================] - 0s 402us/step - loss: 0.0251 - acc: 0.0125 - val_loss: 0.0136 - val_acc: 0.0000e+00\n",
            "Epoch 500/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0241 - acc: 0.0125 - val_loss: 0.0172 - val_acc: 0.0000e+00\n",
            "Epoch 501/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0234 - acc: 0.0125 - val_loss: 0.0250 - val_acc: 0.0000e+00\n",
            "Epoch 502/1000\n",
            "80/80 [==============================] - 0s 355us/step - loss: 0.0247 - acc: 0.0125 - val_loss: 0.0256 - val_acc: 0.0000e+00\n",
            "Epoch 503/1000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0243 - acc: 0.0125 - val_loss: 0.0170 - val_acc: 0.0000e+00\n",
            "Epoch 504/1000\n",
            "80/80 [==============================] - 0s 382us/step - loss: 0.0223 - acc: 0.0125 - val_loss: 0.0132 - val_acc: 0.0000e+00\n",
            "Epoch 505/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0259 - acc: 0.0125 - val_loss: 0.0132 - val_acc: 0.0000e+00\n",
            "Epoch 506/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0260 - acc: 0.0125 - val_loss: 0.0156 - val_acc: 0.0000e+00\n",
            "Epoch 507/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0226 - acc: 0.0125 - val_loss: 0.0214 - val_acc: 0.0000e+00\n",
            "Epoch 508/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0230 - acc: 0.0125 - val_loss: 0.0224 - val_acc: 0.0000e+00\n",
            "Epoch 509/1000\n",
            "80/80 [==============================] - 0s 362us/step - loss: 0.0232 - acc: 0.0125 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
            "Epoch 510/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0224 - acc: 0.0125 - val_loss: 0.0165 - val_acc: 0.0000e+00\n",
            "Epoch 511/1000\n",
            "80/80 [==============================] - 0s 364us/step - loss: 0.0221 - acc: 0.0125 - val_loss: 0.0144 - val_acc: 0.0000e+00\n",
            "Epoch 512/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0223 - acc: 0.0125 - val_loss: 0.0147 - val_acc: 0.0000e+00\n",
            "Epoch 513/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0220 - acc: 0.0125 - val_loss: 0.0177 - val_acc: 0.0000e+00\n",
            "Epoch 514/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0218 - acc: 0.0125 - val_loss: 0.0220 - val_acc: 0.0000e+00\n",
            "Epoch 515/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0227 - acc: 0.0125 - val_loss: 0.0233 - val_acc: 0.0000e+00\n",
            "Epoch 516/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.0228 - acc: 0.0125 - val_loss: 0.0192 - val_acc: 0.0000e+00\n",
            "Epoch 517/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0219 - acc: 0.0125 - val_loss: 0.0161 - val_acc: 0.0000e+00\n",
            "Epoch 518/1000\n",
            "80/80 [==============================] - 0s 390us/step - loss: 0.0215 - acc: 0.0125 - val_loss: 0.0148 - val_acc: 0.0000e+00\n",
            "Epoch 519/1000\n",
            "80/80 [==============================] - 0s 380us/step - loss: 0.0215 - acc: 0.0125 - val_loss: 0.0149 - val_acc: 0.0000e+00\n",
            "Epoch 520/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0217 - acc: 0.0125 - val_loss: 0.0142 - val_acc: 0.0000e+00\n",
            "Epoch 521/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0217 - acc: 0.0125 - val_loss: 0.0130 - val_acc: 0.0000e+00\n",
            "Epoch 522/1000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0220 - acc: 0.0125 - val_loss: 0.0148 - val_acc: 0.0000e+00\n",
            "Epoch 523/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.0211 - acc: 0.0125 - val_loss: 0.0209 - val_acc: 0.0000e+00\n",
            "Epoch 524/1000\n",
            "80/80 [==============================] - 0s 402us/step - loss: 0.0220 - acc: 0.0125 - val_loss: 0.0234 - val_acc: 0.0000e+00\n",
            "Epoch 525/1000\n",
            "80/80 [==============================] - 0s 349us/step - loss: 0.0222 - acc: 0.0125 - val_loss: 0.0177 - val_acc: 0.0000e+00\n",
            "Epoch 526/1000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0212 - acc: 0.0125 - val_loss: 0.0133 - val_acc: 0.0000e+00\n",
            "Epoch 527/1000\n",
            "80/80 [==============================] - 0s 429us/step - loss: 0.0214 - acc: 0.0125 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
            "Epoch 528/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0218 - acc: 0.0125 - val_loss: 0.0145 - val_acc: 0.0000e+00\n",
            "Epoch 529/1000\n",
            "80/80 [==============================] - 0s 360us/step - loss: 0.0210 - acc: 0.0125 - val_loss: 0.0210 - val_acc: 0.0000e+00\n",
            "Epoch 530/1000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.0218 - acc: 0.0125 - val_loss: 0.0227 - val_acc: 0.0000e+00\n",
            "Epoch 531/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0221 - acc: 0.0125 - val_loss: 0.0179 - val_acc: 0.0000e+00\n",
            "Epoch 532/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0209 - acc: 0.0125 - val_loss: 0.0159 - val_acc: 0.0000e+00\n",
            "Epoch 533/1000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.0208 - acc: 0.0125 - val_loss: 0.0176 - val_acc: 0.0000e+00\n",
            "Epoch 534/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0207 - acc: 0.0125 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
            "Epoch 535/1000\n",
            "80/80 [==============================] - 0s 400us/step - loss: 0.0211 - acc: 0.0125 - val_loss: 0.0205 - val_acc: 0.0000e+00\n",
            "Epoch 536/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0211 - acc: 0.0125 - val_loss: 0.0183 - val_acc: 0.0000e+00\n",
            "Epoch 537/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0209 - acc: 0.0125 - val_loss: 0.0154 - val_acc: 0.0000e+00\n",
            "Epoch 538/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0205 - acc: 0.0125 - val_loss: 0.0147 - val_acc: 0.0000e+00\n",
            "Epoch 539/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0205 - acc: 0.0125 - val_loss: 0.0142 - val_acc: 0.0000e+00\n",
            "Epoch 540/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0205 - acc: 0.0125 - val_loss: 0.0158 - val_acc: 0.0000e+00\n",
            "Epoch 541/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0202 - acc: 0.0125 - val_loss: 0.0203 - val_acc: 0.0000e+00\n",
            "Epoch 542/1000\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.0211 - acc: 0.0125 - val_loss: 0.0222 - val_acc: 0.0000e+00\n",
            "Epoch 543/1000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0214 - acc: 0.0125 - val_loss: 0.0178 - val_acc: 0.0000e+00\n",
            "Epoch 544/1000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0204 - acc: 0.0125 - val_loss: 0.0146 - val_acc: 0.0000e+00\n",
            "Epoch 545/1000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.0204 - acc: 0.0125 - val_loss: 0.0144 - val_acc: 0.0000e+00\n",
            "Epoch 546/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0202 - acc: 0.0125 - val_loss: 0.0176 - val_acc: 0.0000e+00\n",
            "Epoch 547/1000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.0205 - acc: 0.0125 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 548/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0205 - acc: 0.0125 - val_loss: 0.0170 - val_acc: 0.0000e+00\n",
            "Epoch 549/1000\n",
            "80/80 [==============================] - 0s 382us/step - loss: 0.0201 - acc: 0.0125 - val_loss: 0.0147 - val_acc: 0.0000e+00\n",
            "Epoch 550/1000\n",
            "80/80 [==============================] - 0s 475us/step - loss: 0.0202 - acc: 0.0125 - val_loss: 0.0142 - val_acc: 0.0000e+00\n",
            "Epoch 551/1000\n",
            "80/80 [==============================] - 0s 427us/step - loss: 0.0203 - acc: 0.0125 - val_loss: 0.0146 - val_acc: 0.0000e+00\n",
            "Epoch 552/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0200 - acc: 0.0125 - val_loss: 0.0138 - val_acc: 0.0000e+00\n",
            "Epoch 553/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0201 - acc: 0.0125 - val_loss: 0.0144 - val_acc: 0.0000e+00\n",
            "Epoch 554/1000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.0199 - acc: 0.0125 - val_loss: 0.0169 - val_acc: 0.0000e+00\n",
            "Epoch 555/1000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.0199 - acc: 0.0125 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
            "Epoch 556/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0204 - acc: 0.0125 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
            "Epoch 557/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0202 - acc: 0.0125 - val_loss: 0.0156 - val_acc: 0.0000e+00\n",
            "Epoch 558/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0199 - acc: 0.0125 - val_loss: 0.0139 - val_acc: 0.0000e+00\n",
            "Epoch 559/1000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.0198 - acc: 0.0125 - val_loss: 0.0142 - val_acc: 0.0000e+00\n",
            "Epoch 560/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.0197 - acc: 0.0125 - val_loss: 0.0142 - val_acc: 0.0000e+00\n",
            "Epoch 561/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0198 - acc: 0.0125 - val_loss: 0.0156 - val_acc: 0.0000e+00\n",
            "Epoch 562/1000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.0198 - acc: 0.0125 - val_loss: 0.0178 - val_acc: 0.0000e+00\n",
            "Epoch 563/1000\n",
            "80/80 [==============================] - 0s 363us/step - loss: 0.0198 - acc: 0.0125 - val_loss: 0.0168 - val_acc: 0.0000e+00\n",
            "Epoch 564/1000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.0197 - acc: 0.0125 - val_loss: 0.0153 - val_acc: 0.0000e+00\n",
            "Epoch 565/1000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0196 - acc: 0.0125 - val_loss: 0.0160 - val_acc: 0.0000e+00\n",
            "Epoch 566/1000\n",
            "80/80 [==============================] - 0s 424us/step - loss: 0.0195 - acc: 0.0125 - val_loss: 0.0177 - val_acc: 0.0000e+00\n",
            "Epoch 567/1000\n",
            "80/80 [==============================] - 0s 371us/step - loss: 0.0197 - acc: 0.0125 - val_loss: 0.0171 - val_acc: 0.0000e+00\n",
            "Epoch 568/1000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.0196 - acc: 0.0125 - val_loss: 0.0156 - val_acc: 0.0000e+00\n",
            "Epoch 569/1000\n",
            "80/80 [==============================] - 0s 392us/step - loss: 0.0194 - acc: 0.0125 - val_loss: 0.0138 - val_acc: 0.0000e+00\n",
            "Epoch 570/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0195 - acc: 0.0125 - val_loss: 0.0121 - val_acc: 0.0000e+00\n",
            "Epoch 571/1000\n",
            "80/80 [==============================] - 0s 391us/step - loss: 0.0201 - acc: 0.0125 - val_loss: 0.0124 - val_acc: 0.0000e+00\n",
            "Epoch 572/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0196 - acc: 0.0125 - val_loss: 0.0163 - val_acc: 0.0000e+00\n",
            "Epoch 573/1000\n",
            "80/80 [==============================] - 0s 445us/step - loss: 0.0198 - acc: 0.0125 - val_loss: 0.0214 - val_acc: 0.0000e+00\n",
            "Epoch 574/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0204 - acc: 0.0125 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 575/1000\n",
            "80/80 [==============================] - 0s 356us/step - loss: 0.0197 - acc: 0.0125 - val_loss: 0.0158 - val_acc: 0.0000e+00\n",
            "Epoch 576/1000\n",
            "80/80 [==============================] - 0s 355us/step - loss: 0.0192 - acc: 0.0125 - val_loss: 0.0132 - val_acc: 0.0000e+00\n",
            "Epoch 577/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0194 - acc: 0.0125 - val_loss: 0.0126 - val_acc: 0.0000e+00\n",
            "Epoch 578/1000\n",
            "80/80 [==============================] - 0s 437us/step - loss: 0.0195 - acc: 0.0125 - val_loss: 0.0147 - val_acc: 0.0000e+00\n",
            "Epoch 579/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0191 - acc: 0.0125 - val_loss: 0.0196 - val_acc: 0.0000e+00\n",
            "Epoch 580/1000\n",
            "80/80 [==============================] - 0s 379us/step - loss: 0.0198 - acc: 0.0125 - val_loss: 0.0208 - val_acc: 0.0000e+00\n",
            "Epoch 581/1000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.0200 - acc: 0.0125 - val_loss: 0.0177 - val_acc: 0.0000e+00\n",
            "Epoch 582/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0191 - acc: 0.0125 - val_loss: 0.0130 - val_acc: 0.0000e+00\n",
            "Epoch 583/1000\n",
            "80/80 [==============================] - 0s 403us/step - loss: 0.0193 - acc: 0.0125 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
            "Epoch 584/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0211 - acc: 0.0125 - val_loss: 0.0116 - val_acc: 0.0000e+00\n",
            "Epoch 585/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0202 - acc: 0.0125 - val_loss: 0.0140 - val_acc: 0.0000e+00\n",
            "Epoch 586/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0189 - acc: 0.0125 - val_loss: 0.0185 - val_acc: 0.0000e+00\n",
            "Epoch 587/1000\n",
            "80/80 [==============================] - 0s 360us/step - loss: 0.0196 - acc: 0.0125 - val_loss: 0.0186 - val_acc: 0.0000e+00\n",
            "Epoch 588/1000\n",
            "80/80 [==============================] - 0s 349us/step - loss: 0.0196 - acc: 0.0125 - val_loss: 0.0147 - val_acc: 0.0000e+00\n",
            "Epoch 589/1000\n",
            "80/80 [==============================] - 0s 388us/step - loss: 0.0189 - acc: 0.0125 - val_loss: 0.0135 - val_acc: 0.0000e+00\n",
            "Epoch 590/1000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.0192 - acc: 0.0125 - val_loss: 0.0151 - val_acc: 0.0000e+00\n",
            "Epoch 591/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.0187 - acc: 0.0125 - val_loss: 0.0208 - val_acc: 0.0000e+00\n",
            "Epoch 592/1000\n",
            "80/80 [==============================] - 0s 402us/step - loss: 0.0199 - acc: 0.0125 - val_loss: 0.0220 - val_acc: 0.0000e+00\n",
            "Epoch 593/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0201 - acc: 0.0125 - val_loss: 0.0166 - val_acc: 0.0000e+00\n",
            "Epoch 594/1000\n",
            "80/80 [==============================] - 0s 355us/step - loss: 0.0195 - acc: 0.0125 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
            "Epoch 595/1000\n",
            "80/80 [==============================] - 0s 355us/step - loss: 0.0190 - acc: 0.0125 - val_loss: 0.0139 - val_acc: 0.0000e+00\n",
            "Epoch 596/1000\n",
            "80/80 [==============================] - 0s 366us/step - loss: 0.0190 - acc: 0.0125 - val_loss: 0.0161 - val_acc: 0.0000e+00\n",
            "Epoch 597/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0188 - acc: 0.0125 - val_loss: 0.0162 - val_acc: 0.0000e+00\n",
            "Epoch 598/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0188 - acc: 0.0125 - val_loss: 0.0159 - val_acc: 0.0000e+00\n",
            "Epoch 599/1000\n",
            "80/80 [==============================] - 0s 391us/step - loss: 0.0189 - acc: 0.0125 - val_loss: 0.0160 - val_acc: 0.0000e+00\n",
            "Epoch 600/1000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0187 - acc: 0.0125 - val_loss: 0.0173 - val_acc: 0.0000e+00\n",
            "Epoch 601/1000\n",
            "80/80 [==============================] - 0s 352us/step - loss: 0.0189 - acc: 0.0125 - val_loss: 0.0166 - val_acc: 0.0000e+00\n",
            "Epoch 602/1000\n",
            "80/80 [==============================] - 0s 410us/step - loss: 0.0187 - acc: 0.0125 - val_loss: 0.0141 - val_acc: 0.0000e+00\n",
            "Epoch 603/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0188 - acc: 0.0125 - val_loss: 0.0125 - val_acc: 0.0000e+00\n",
            "Epoch 604/1000\n",
            "80/80 [==============================] - 0s 365us/step - loss: 0.0188 - acc: 0.0125 - val_loss: 0.0138 - val_acc: 0.0000e+00\n",
            "Epoch 605/1000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.0186 - acc: 0.0125 - val_loss: 0.0156 - val_acc: 0.0000e+00\n",
            "Epoch 606/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0185 - acc: 0.0125 - val_loss: 0.0159 - val_acc: 0.0000e+00\n",
            "Epoch 607/1000\n",
            "80/80 [==============================] - 0s 385us/step - loss: 0.0186 - acc: 0.0125 - val_loss: 0.0159 - val_acc: 0.0000e+00\n",
            "Epoch 608/1000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.0185 - acc: 0.0125 - val_loss: 0.0156 - val_acc: 0.0000e+00\n",
            "Epoch 609/1000\n",
            "80/80 [==============================] - 0s 375us/step - loss: 0.0184 - acc: 0.0125 - val_loss: 0.0130 - val_acc: 0.0000e+00\n",
            "Epoch 610/1000\n",
            "80/80 [==============================] - 0s 372us/step - loss: 0.0186 - acc: 0.0125 - val_loss: 0.0119 - val_acc: 0.0000e+00\n",
            "Epoch 611/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0188 - acc: 0.0125 - val_loss: 0.0150 - val_acc: 0.0000e+00\n",
            "Epoch 612/1000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0184 - acc: 0.0125 - val_loss: 0.0222 - val_acc: 0.0000e+00\n",
            "Epoch 613/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0201 - acc: 0.0125 - val_loss: 0.0227 - val_acc: 0.0000e+00\n",
            "Epoch 614/1000\n",
            "80/80 [==============================] - 0s 355us/step - loss: 0.0202 - acc: 0.0125 - val_loss: 0.0167 - val_acc: 0.0000e+00\n",
            "Epoch 615/1000\n",
            "80/80 [==============================] - 0s 362us/step - loss: 0.0184 - acc: 0.0125 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
            "Epoch 616/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0188 - acc: 0.0125 - val_loss: 0.0111 - val_acc: 0.0000e+00\n",
            "Epoch 617/1000\n",
            "80/80 [==============================] - 0s 377us/step - loss: 0.0199 - acc: 0.0125 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
            "Epoch 618/1000\n",
            "80/80 [==============================] - 0s 363us/step - loss: 0.0182 - acc: 0.0125 - val_loss: 0.0203 - val_acc: 0.0000e+00\n",
            "Epoch 619/1000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.0195 - acc: 0.0125 - val_loss: 0.0228 - val_acc: 0.0000e+00\n",
            "Epoch 620/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0201 - acc: 0.0125 - val_loss: 0.0168 - val_acc: 0.0000e+00\n",
            "Epoch 621/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0186 - acc: 0.0125 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
            "Epoch 622/1000\n",
            "80/80 [==============================] - 0s 349us/step - loss: 0.0184 - acc: 0.0125 - val_loss: 0.0118 - val_acc: 0.0000e+00\n",
            "Epoch 623/1000\n",
            "80/80 [==============================] - 0s 353us/step - loss: 0.0186 - acc: 0.0125 - val_loss: 0.0138 - val_acc: 0.0000e+00\n",
            "Epoch 624/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0182 - acc: 0.0125 - val_loss: 0.0173 - val_acc: 0.0000e+00\n",
            "Epoch 625/1000\n",
            "80/80 [==============================] - 0s 417us/step - loss: 0.0185 - acc: 0.0125 - val_loss: 0.0154 - val_acc: 0.0000e+00\n",
            "Epoch 626/1000\n",
            "80/80 [==============================] - 0s 416us/step - loss: 0.0180 - acc: 0.0125 - val_loss: 0.0124 - val_acc: 0.0000e+00\n",
            "Epoch 627/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0183 - acc: 0.0125 - val_loss: 0.0119 - val_acc: 0.0000e+00\n",
            "Epoch 628/1000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0184 - acc: 0.0125 - val_loss: 0.0135 - val_acc: 0.0000e+00\n",
            "Epoch 629/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.0179 - acc: 0.0125 - val_loss: 0.0174 - val_acc: 0.0000e+00\n",
            "Epoch 630/1000\n",
            "80/80 [==============================] - 0s 408us/step - loss: 0.0185 - acc: 0.0125 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
            "Epoch 631/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0187 - acc: 0.0125 - val_loss: 0.0157 - val_acc: 0.0000e+00\n",
            "Epoch 632/1000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.0182 - acc: 0.0125 - val_loss: 0.0140 - val_acc: 0.0000e+00\n",
            "Epoch 633/1000\n",
            "80/80 [==============================] - 0s 353us/step - loss: 0.0179 - acc: 0.0125 - val_loss: 0.0148 - val_acc: 0.0000e+00\n",
            "Epoch 634/1000\n",
            "80/80 [==============================] - 0s 408us/step - loss: 0.0180 - acc: 0.0125 - val_loss: 0.0161 - val_acc: 0.0000e+00\n",
            "Epoch 635/1000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.0180 - acc: 0.0125 - val_loss: 0.0136 - val_acc: 0.0000e+00\n",
            "Epoch 636/1000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0182 - acc: 0.0125 - val_loss: 0.0118 - val_acc: 0.0000e+00\n",
            "Epoch 637/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0182 - acc: 0.0125 - val_loss: 0.0130 - val_acc: 0.0000e+00\n",
            "Epoch 638/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0178 - acc: 0.0125 - val_loss: 0.0160 - val_acc: 0.0000e+00\n",
            "Epoch 639/1000\n",
            "80/80 [==============================] - 0s 349us/step - loss: 0.0180 - acc: 0.0125 - val_loss: 0.0183 - val_acc: 0.0000e+00\n",
            "Epoch 640/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0184 - acc: 0.0125 - val_loss: 0.0141 - val_acc: 0.0000e+00\n",
            "Epoch 641/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.0175 - acc: 0.0125 - val_loss: 0.0110 - val_acc: 0.0000e+00\n",
            "Epoch 642/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0189 - acc: 0.0125 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
            "Epoch 643/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0185 - acc: 0.0125 - val_loss: 0.0154 - val_acc: 0.0000e+00\n",
            "Epoch 644/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0177 - acc: 0.0125 - val_loss: 0.0158 - val_acc: 0.0000e+00\n",
            "Epoch 645/1000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.0178 - acc: 0.0125 - val_loss: 0.0145 - val_acc: 0.0000e+00\n",
            "Epoch 646/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0176 - acc: 0.0125 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
            "Epoch 647/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0177 - acc: 0.0125 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
            "Epoch 648/1000\n",
            "80/80 [==============================] - 0s 370us/step - loss: 0.0181 - acc: 0.0125 - val_loss: 0.0118 - val_acc: 0.0000e+00\n",
            "Epoch 649/1000\n",
            "80/80 [==============================] - 0s 354us/step - loss: 0.0180 - acc: 0.0125 - val_loss: 0.0144 - val_acc: 0.0000e+00\n",
            "Epoch 650/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0176 - acc: 0.0125 - val_loss: 0.0152 - val_acc: 0.0000e+00\n",
            "Epoch 651/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0176 - acc: 0.0125 - val_loss: 0.0136 - val_acc: 0.0000e+00\n",
            "Epoch 652/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0175 - acc: 0.0125 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
            "Epoch 653/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0177 - acc: 0.0125 - val_loss: 0.0123 - val_acc: 0.0000e+00\n",
            "Epoch 654/1000\n",
            "80/80 [==============================] - 0s 383us/step - loss: 0.0176 - acc: 0.0125 - val_loss: 0.0135 - val_acc: 0.0000e+00\n",
            "Epoch 655/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0174 - acc: 0.0125 - val_loss: 0.0160 - val_acc: 0.0000e+00\n",
            "Epoch 656/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0176 - acc: 0.0125 - val_loss: 0.0178 - val_acc: 0.0000e+00\n",
            "Epoch 657/1000\n",
            "80/80 [==============================] - 0s 385us/step - loss: 0.0181 - acc: 0.0125 - val_loss: 0.0164 - val_acc: 0.0000e+00\n",
            "Epoch 658/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0177 - acc: 0.0125 - val_loss: 0.0119 - val_acc: 0.0000e+00\n",
            "Epoch 659/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0176 - acc: 0.0125 - val_loss: 0.0113 - val_acc: 0.0000e+00\n",
            "Epoch 660/1000\n",
            "80/80 [==============================] - 0s 361us/step - loss: 0.0178 - acc: 0.0125 - val_loss: 0.0123 - val_acc: 0.0000e+00\n",
            "Epoch 661/1000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.0174 - acc: 0.0125 - val_loss: 0.0150 - val_acc: 0.0000e+00\n",
            "Epoch 662/1000\n",
            "80/80 [==============================] - 0s 382us/step - loss: 0.0176 - acc: 0.0125 - val_loss: 0.0184 - val_acc: 0.0000e+00\n",
            "Epoch 663/1000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.0179 - acc: 0.0125 - val_loss: 0.0146 - val_acc: 0.0000e+00\n",
            "Epoch 664/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0172 - acc: 0.0125 - val_loss: 0.0110 - val_acc: 0.0000e+00\n",
            "Epoch 665/1000\n",
            "80/80 [==============================] - 0s 383us/step - loss: 0.0179 - acc: 0.0125 - val_loss: 0.0108 - val_acc: 0.0000e+00\n",
            "Epoch 666/1000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0179 - acc: 0.0125 - val_loss: 0.0141 - val_acc: 0.0000e+00\n",
            "Epoch 667/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0175 - acc: 0.0125 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
            "Epoch 668/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.0182 - acc: 0.0125 - val_loss: 0.0169 - val_acc: 0.0000e+00\n",
            "Epoch 669/1000\n",
            "80/80 [==============================] - 0s 384us/step - loss: 0.0174 - acc: 0.0125 - val_loss: 0.0120 - val_acc: 0.0000e+00\n",
            "Epoch 670/1000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.0172 - acc: 0.0125 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
            "Epoch 671/1000\n",
            "80/80 [==============================] - 0s 395us/step - loss: 0.0182 - acc: 0.0125 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
            "Epoch 672/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0174 - acc: 0.0125 - val_loss: 0.0158 - val_acc: 0.0000e+00\n",
            "Epoch 673/1000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.0175 - acc: 0.0125 - val_loss: 0.0174 - val_acc: 0.0000e+00\n",
            "Epoch 674/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0176 - acc: 0.0125 - val_loss: 0.0145 - val_acc: 0.0000e+00\n",
            "Epoch 675/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0171 - acc: 0.0125 - val_loss: 0.0136 - val_acc: 0.0000e+00\n",
            "Epoch 676/1000\n",
            "80/80 [==============================] - 0s 372us/step - loss: 0.0170 - acc: 0.0125 - val_loss: 0.0147 - val_acc: 0.0000e+00\n",
            "Epoch 677/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0170 - acc: 0.0125 - val_loss: 0.0161 - val_acc: 0.0000e+00\n",
            "Epoch 678/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0174 - acc: 0.0125 - val_loss: 0.0141 - val_acc: 0.0000e+00\n",
            "Epoch 679/1000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.0169 - acc: 0.0125 - val_loss: 0.0108 - val_acc: 0.0000e+00\n",
            "Epoch 680/1000\n",
            "80/80 [==============================] - 0s 364us/step - loss: 0.0175 - acc: 0.0125 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
            "Epoch 681/1000\n",
            "80/80 [==============================] - 0s 356us/step - loss: 0.0179 - acc: 0.0125 - val_loss: 0.0119 - val_acc: 0.0000e+00\n",
            "Epoch 682/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0167 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 683/1000\n",
            "80/80 [==============================] - 0s 352us/step - loss: 0.0181 - acc: 0.0125 - val_loss: 0.0243 - val_acc: 0.0000e+00\n",
            "Epoch 684/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0201 - acc: 0.0125 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 685/1000\n",
            "80/80 [==============================] - 0s 486us/step - loss: 0.0179 - acc: 0.0125 - val_loss: 0.0116 - val_acc: 0.0000e+00\n",
            "Epoch 686/1000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.0169 - acc: 0.0125 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
            "Epoch 687/1000\n",
            "80/80 [==============================] - 0s 356us/step - loss: 0.0184 - acc: 0.0125 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
            "Epoch 688/1000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 0.0171 - acc: 0.0125 - val_loss: 0.0172 - val_acc: 0.0000e+00\n",
            "Epoch 689/1000\n",
            "80/80 [==============================] - 0s 364us/step - loss: 0.0178 - acc: 0.0125 - val_loss: 0.0223 - val_acc: 0.0000e+00\n",
            "Epoch 690/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0189 - acc: 0.0125 - val_loss: 0.0150 - val_acc: 0.0000e+00\n",
            "Epoch 691/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0167 - acc: 0.0125 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
            "Epoch 692/1000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0185 - acc: 0.0125 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
            "Epoch 693/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0196 - acc: 0.0125 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
            "Epoch 694/1000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0171 - acc: 0.0125 - val_loss: 0.0142 - val_acc: 0.0000e+00\n",
            "Epoch 695/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0171 - acc: 0.0125 - val_loss: 0.0184 - val_acc: 0.0000e+00\n",
            "Epoch 696/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0175 - acc: 0.0125 - val_loss: 0.0152 - val_acc: 0.0000e+00\n",
            "Epoch 697/1000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0169 - acc: 0.0125 - val_loss: 0.0126 - val_acc: 0.0000e+00\n",
            "Epoch 698/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0166 - acc: 0.0125 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
            "Epoch 699/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0164 - val_acc: 0.0000e+00\n",
            "Epoch 700/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0171 - acc: 0.0125 - val_loss: 0.0180 - val_acc: 0.0000e+00\n",
            "Epoch 701/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0171 - acc: 0.0125 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
            "Epoch 702/1000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
            "Epoch 703/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0174 - acc: 0.0125 - val_loss: 0.0106 - val_acc: 0.0000e+00\n",
            "Epoch 704/1000\n",
            "80/80 [==============================] - 0s 444us/step - loss: 0.0170 - acc: 0.0125 - val_loss: 0.0140 - val_acc: 0.0000e+00\n",
            "Epoch 705/1000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0153 - val_acc: 0.0000e+00\n",
            "Epoch 706/1000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.0166 - acc: 0.0125 - val_loss: 0.0135 - val_acc: 0.0000e+00\n",
            "Epoch 707/1000\n",
            "80/80 [==============================] - 0s 423us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
            "Epoch 708/1000\n",
            "80/80 [==============================] - 0s 371us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0137 - val_acc: 0.0000e+00\n",
            "Epoch 709/1000\n",
            "80/80 [==============================] - 0s 360us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0153 - val_acc: 0.0000e+00\n",
            "Epoch 710/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0166 - acc: 0.0125 - val_loss: 0.0132 - val_acc: 0.0000e+00\n",
            "Epoch 711/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
            "Epoch 712/1000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0146 - val_acc: 0.0000e+00\n",
            "Epoch 713/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0178 - val_acc: 0.0000e+00\n",
            "Epoch 714/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0170 - acc: 0.0125 - val_loss: 0.0136 - val_acc: 0.0000e+00\n",
            "Epoch 715/1000\n",
            "80/80 [==============================] - 0s 353us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
            "Epoch 716/1000\n",
            "80/80 [==============================] - 0s 352us/step - loss: 0.0175 - acc: 0.0125 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
            "Epoch 717/1000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0168 - acc: 0.0125 - val_loss: 0.0169 - val_acc: 0.0000e+00\n",
            "Epoch 718/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0172 - acc: 0.0125 - val_loss: 0.0184 - val_acc: 0.0000e+00\n",
            "Epoch 719/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0170 - acc: 0.0125 - val_loss: 0.0124 - val_acc: 0.0000e+00\n",
            "Epoch 720/1000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
            "Epoch 721/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0181 - acc: 0.0125 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
            "Epoch 722/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0168 - acc: 0.0125 - val_loss: 0.0153 - val_acc: 0.0000e+00\n",
            "Epoch 723/1000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0182 - val_acc: 0.0000e+00\n",
            "Epoch 724/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0171 - acc: 0.0125 - val_loss: 0.0162 - val_acc: 0.0000e+00\n",
            "Epoch 725/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0108 - val_acc: 0.0000e+00\n",
            "Epoch 726/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
            "Epoch 727/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0178 - acc: 0.0125 - val_loss: 0.0110 - val_acc: 0.0000e+00\n",
            "Epoch 728/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0153 - val_acc: 0.0000e+00\n",
            "Epoch 729/1000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0145 - val_acc: 0.0000e+00\n",
            "Epoch 730/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0110 - val_acc: 0.0000e+00\n",
            "Epoch 731/1000\n",
            "80/80 [==============================] - 0s 381us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
            "Epoch 732/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0166 - acc: 0.0125 - val_loss: 0.0109 - val_acc: 0.0000e+00\n",
            "Epoch 733/1000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0131 - val_acc: 0.0000e+00\n",
            "Epoch 734/1000\n",
            "80/80 [==============================] - 0s 404us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0141 - val_acc: 0.0000e+00\n",
            "Epoch 735/1000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0124 - val_acc: 0.0000e+00\n",
            "Epoch 736/1000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
            "Epoch 737/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0119 - val_acc: 0.0000e+00\n",
            "Epoch 738/1000\n",
            "80/80 [==============================] - 0s 352us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
            "Epoch 739/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0167 - acc: 0.0125 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
            "Epoch 740/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
            "Epoch 741/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0166 - val_acc: 0.0000e+00\n",
            "Epoch 742/1000\n",
            "80/80 [==============================] - 0s 423us/step - loss: 0.0167 - acc: 0.0125 - val_loss: 0.0168 - val_acc: 0.0000e+00\n",
            "Epoch 743/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0112 - val_acc: 0.0000e+00\n",
            "Epoch 744/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
            "Epoch 745/1000\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.0161 - acc: 0.0125 - val_loss: 0.0147 - val_acc: 0.0000e+00\n",
            "Epoch 746/1000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.0167 - acc: 0.0125 - val_loss: 0.0187 - val_acc: 0.0000e+00\n",
            "Epoch 747/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0167 - acc: 0.0125 - val_loss: 0.0124 - val_acc: 0.0000e+00\n",
            "Epoch 748/1000\n",
            "80/80 [==============================] - 0s 359us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
            "Epoch 749/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0165 - acc: 0.0125 - val_loss: 0.0109 - val_acc: 0.0000e+00\n",
            "Epoch 750/1000\n",
            "80/80 [==============================] - 0s 555us/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0167 - val_acc: 0.0000e+00\n",
            "Epoch 751/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0201 - val_acc: 0.0000e+00\n",
            "Epoch 752/1000\n",
            "80/80 [==============================] - 0s 383us/step - loss: 0.0175 - acc: 0.0125 - val_loss: 0.0152 - val_acc: 0.0000e+00\n",
            "Epoch 753/1000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.0155 - acc: 0.0125 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
            "Epoch 754/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0170 - acc: 0.0125 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
            "Epoch 755/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0173 - acc: 0.0125 - val_loss: 0.0141 - val_acc: 0.0000e+00\n",
            "Epoch 756/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0221 - val_acc: 0.0000e+00\n",
            "Epoch 757/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0184 - acc: 0.0125 - val_loss: 0.0184 - val_acc: 0.0000e+00\n",
            "Epoch 758/1000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0108 - val_acc: 0.0000e+00\n",
            "Epoch 759/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0096 - val_acc: 0.0000e+00\n",
            "Epoch 760/1000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0164 - acc: 0.0125 - val_loss: 0.0119 - val_acc: 0.0000e+00\n",
            "Epoch 761/1000\n",
            "80/80 [==============================] - 0s 363us/step - loss: 0.0155 - acc: 0.0125 - val_loss: 0.0145 - val_acc: 0.0000e+00\n",
            "Epoch 762/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0138 - val_acc: 0.0000e+00\n",
            "Epoch 763/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
            "Epoch 764/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0154 - acc: 0.0125 - val_loss: 0.0101 - val_acc: 0.0000e+00\n",
            "Epoch 765/1000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
            "Epoch 766/1000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0160 - acc: 0.0125 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
            "Epoch 767/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0153 - acc: 0.0125 - val_loss: 0.0169 - val_acc: 0.0000e+00\n",
            "Epoch 768/1000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0163 - acc: 0.0125 - val_loss: 0.0152 - val_acc: 0.0000e+00\n",
            "Epoch 769/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0158 - acc: 0.0125 - val_loss: 0.0107 - val_acc: 0.0000e+00\n",
            "Epoch 770/1000\n",
            "80/80 [==============================] - 0s 353us/step - loss: 0.0154 - acc: 0.0125 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
            "Epoch 771/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0108 - val_acc: 0.0000e+00\n",
            "Epoch 772/1000\n",
            "80/80 [==============================] - 0s 401us/step - loss: 0.0154 - acc: 0.0125 - val_loss: 0.0116 - val_acc: 0.0000e+00\n",
            "Epoch 773/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0153 - acc: 0.0125 - val_loss: 0.0111 - val_acc: 0.0000e+00\n",
            "Epoch 774/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0152 - acc: 0.0125 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
            "Epoch 775/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0154 - acc: 0.0125 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
            "Epoch 776/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0154 - acc: 0.0125 - val_loss: 0.0138 - val_acc: 0.0000e+00\n",
            "Epoch 777/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0153 - acc: 0.0125 - val_loss: 0.0110 - val_acc: 0.0000e+00\n",
            "Epoch 778/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0151 - acc: 0.0125 - val_loss: 0.0093 - val_acc: 0.0000e+00\n",
            "Epoch 779/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0168 - acc: 0.0125 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
            "Epoch 780/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0140 - val_acc: 0.0000e+00\n",
            "Epoch 781/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0153 - acc: 0.0125 - val_loss: 0.0162 - val_acc: 0.0000e+00\n",
            "Epoch 782/1000\n",
            "80/80 [==============================] - 0s 384us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0158 - val_acc: 0.0000e+00\n",
            "Epoch 783/1000\n",
            "80/80 [==============================] - 0s 418us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0158 - val_acc: 0.0000e+00\n",
            "Epoch 784/1000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0127 - val_acc: 0.0000e+00\n",
            "Epoch 785/1000\n",
            "80/80 [==============================] - 0s 412us/step - loss: 0.0150 - acc: 0.0125 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
            "Epoch 786/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0156 - acc: 0.0125 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
            "Epoch 787/1000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0154 - acc: 0.0125 - val_loss: 0.0123 - val_acc: 0.0000e+00\n",
            "Epoch 788/1000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0149 - acc: 0.0125 - val_loss: 0.0163 - val_acc: 0.0000e+00\n",
            "Epoch 789/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0165 - val_acc: 0.0000e+00\n",
            "Epoch 790/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0139 - val_acc: 0.0000e+00\n",
            "Epoch 791/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0154 - acc: 0.0125 - val_loss: 0.0126 - val_acc: 0.0000e+00\n",
            "Epoch 792/1000\n",
            "80/80 [==============================] - 0s 391us/step - loss: 0.0150 - acc: 0.0125 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
            "Epoch 793/1000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.0150 - acc: 0.0125 - val_loss: 0.0112 - val_acc: 0.0000e+00\n",
            "Epoch 794/1000\n",
            "80/80 [==============================] - 0s 369us/step - loss: 0.0149 - acc: 0.0125 - val_loss: 0.0106 - val_acc: 0.0000e+00\n",
            "Epoch 795/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.0150 - acc: 0.0125 - val_loss: 0.0116 - val_acc: 0.0000e+00\n",
            "Epoch 796/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0147 - acc: 0.0125 - val_loss: 0.0169 - val_acc: 0.0000e+00\n",
            "Epoch 797/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0162 - acc: 0.0125 - val_loss: 0.0174 - val_acc: 0.0000e+00\n",
            "Epoch 798/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0100 - val_acc: 0.0000e+00\n",
            "Epoch 799/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.0151 - acc: 0.0125 - val_loss: 0.0090 - val_acc: 0.0000e+00\n",
            "Epoch 800/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0159 - acc: 0.0125 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
            "Epoch 801/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0152 - acc: 0.0125 - val_loss: 0.0141 - val_acc: 0.0000e+00\n",
            "Epoch 802/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0149 - acc: 0.0125 - val_loss: 0.0126 - val_acc: 0.0000e+00\n",
            "Epoch 803/1000\n",
            "80/80 [==============================] - 0s 414us/step - loss: 0.0147 - acc: 0.0125 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
            "Epoch 804/1000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.0147 - acc: 0.0125 - val_loss: 0.0096 - val_acc: 0.0000e+00\n",
            "Epoch 805/1000\n",
            "80/80 [==============================] - 0s 433us/step - loss: 0.0150 - acc: 0.0125 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
            "Epoch 806/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0148 - acc: 0.0125 - val_loss: 0.0130 - val_acc: 0.0000e+00\n",
            "Epoch 807/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0147 - acc: 0.0125 - val_loss: 0.0154 - val_acc: 0.0000e+00\n",
            "Epoch 808/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.0152 - acc: 0.0125 - val_loss: 0.0149 - val_acc: 0.0000e+00\n",
            "Epoch 809/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.0151 - acc: 0.0125 - val_loss: 0.0118 - val_acc: 0.0000e+00\n",
            "Epoch 810/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0146 - acc: 0.0125 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
            "Epoch 811/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0146 - acc: 0.0125 - val_loss: 0.0120 - val_acc: 0.0000e+00\n",
            "Epoch 812/1000\n",
            "80/80 [==============================] - 0s 380us/step - loss: 0.0146 - acc: 0.0125 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
            "Epoch 813/1000\n",
            "80/80 [==============================] - 0s 359us/step - loss: 0.0145 - acc: 0.0125 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
            "Epoch 814/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.0154 - acc: 0.0125 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
            "Epoch 815/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.0151 - acc: 0.0125 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
            "Epoch 816/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0147 - acc: 0.0125 - val_loss: 0.0141 - val_acc: 0.0000e+00\n",
            "Epoch 817/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0149 - acc: 0.0125 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
            "Epoch 818/1000\n",
            "80/80 [==============================] - 0s 395us/step - loss: 0.0144 - acc: 0.0125 - val_loss: 0.0110 - val_acc: 0.0000e+00\n",
            "Epoch 819/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0144 - acc: 0.0125 - val_loss: 0.0098 - val_acc: 0.0000e+00\n",
            "Epoch 820/1000\n",
            "80/80 [==============================] - 0s 381us/step - loss: 0.0146 - acc: 0.0125 - val_loss: 0.0103 - val_acc: 0.0000e+00\n",
            "Epoch 821/1000\n",
            "80/80 [==============================] - 0s 380us/step - loss: 0.0146 - acc: 0.0125 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
            "Epoch 822/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0145 - acc: 0.0125 - val_loss: 0.0103 - val_acc: 0.0000e+00\n",
            "Epoch 823/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0145 - acc: 0.0125 - val_loss: 0.0123 - val_acc: 0.0000e+00\n",
            "Epoch 824/1000\n",
            "80/80 [==============================] - 0s 386us/step - loss: 0.0143 - acc: 0.0125 - val_loss: 0.0125 - val_acc: 0.0000e+00\n",
            "Epoch 825/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0143 - acc: 0.0125 - val_loss: 0.0111 - val_acc: 0.0000e+00\n",
            "Epoch 826/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0143 - acc: 0.0125 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
            "Epoch 827/1000\n",
            "80/80 [==============================] - 0s 391us/step - loss: 0.0143 - acc: 0.0125 - val_loss: 0.0118 - val_acc: 0.0000e+00\n",
            "Epoch 828/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0144 - acc: 0.0125 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
            "Epoch 829/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0141 - acc: 0.0125 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
            "Epoch 830/1000\n",
            "80/80 [==============================] - 0s 370us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0088 - val_acc: 0.0000e+00\n",
            "Epoch 831/1000\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.0157 - acc: 0.0125 - val_loss: 0.0126 - val_acc: 0.0000e+00\n",
            "Epoch 832/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0143 - acc: 0.0125 - val_loss: 0.0113 - val_acc: 0.0000e+00\n",
            "Epoch 833/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0143 - acc: 0.0125 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
            "Epoch 834/1000\n",
            "80/80 [==============================] - 0s 396us/step - loss: 0.0143 - acc: 0.0125 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
            "Epoch 835/1000\n",
            "80/80 [==============================] - 0s 403us/step - loss: 0.0142 - acc: 0.0125 - val_loss: 0.0103 - val_acc: 0.0000e+00\n",
            "Epoch 836/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0142 - acc: 0.0125 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
            "Epoch 837/1000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0143 - acc: 0.0125 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
            "Epoch 838/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0140 - acc: 0.0125 - val_loss: 0.0140 - val_acc: 0.0000e+00\n",
            "Epoch 839/1000\n",
            "80/80 [==============================] - 0s 440us/step - loss: 0.0145 - acc: 0.0125 - val_loss: 0.0158 - val_acc: 0.0000e+00\n",
            "Epoch 840/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0148 - acc: 0.0125 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
            "Epoch 841/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0141 - acc: 0.0125 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
            "Epoch 842/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0148 - acc: 0.0125 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
            "Epoch 843/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0141 - acc: 0.0125 - val_loss: 0.0147 - val_acc: 0.0000e+00\n",
            "Epoch 844/1000\n",
            "80/80 [==============================] - 0s 363us/step - loss: 0.0146 - acc: 0.0125 - val_loss: 0.0123 - val_acc: 0.0000e+00\n",
            "Epoch 845/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0143 - acc: 0.0125 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
            "Epoch 846/1000\n",
            "80/80 [==============================] - 0s 388us/step - loss: 0.0141 - acc: 0.0125 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
            "Epoch 847/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0142 - acc: 0.0125 - val_loss: 0.0096 - val_acc: 0.0000e+00\n",
            "Epoch 848/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0141 - acc: 0.0125 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
            "Epoch 849/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0142 - acc: 0.0125 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
            "Epoch 850/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0142 - acc: 0.0125 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
            "Epoch 851/1000\n",
            "80/80 [==============================] - 0s 432us/step - loss: 0.0138 - acc: 0.0125 - val_loss: 0.0106 - val_acc: 0.0000e+00\n",
            "Epoch 852/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0138 - acc: 0.0125 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
            "Epoch 853/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0139 - acc: 0.0125 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
            "Epoch 854/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0141 - acc: 0.0125 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
            "Epoch 855/1000\n",
            "80/80 [==============================] - 0s 349us/step - loss: 0.0137 - acc: 0.0125 - val_loss: 0.0126 - val_acc: 0.0000e+00\n",
            "Epoch 856/1000\n",
            "80/80 [==============================] - 0s 381us/step - loss: 0.0139 - acc: 0.0125 - val_loss: 0.0135 - val_acc: 0.0000e+00\n",
            "Epoch 857/1000\n",
            "80/80 [==============================] - 0s 380us/step - loss: 0.0141 - acc: 0.0125 - val_loss: 0.0111 - val_acc: 0.0000e+00\n",
            "Epoch 858/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.0137 - acc: 0.0125 - val_loss: 0.0085 - val_acc: 0.0000e+00\n",
            "Epoch 859/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0144 - acc: 0.0125 - val_loss: 0.0085 - val_acc: 0.0000e+00\n",
            "Epoch 860/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0142 - acc: 0.0125 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
            "Epoch 861/1000\n",
            "80/80 [==============================] - 0s 384us/step - loss: 0.0135 - acc: 0.0125 - val_loss: 0.0168 - val_acc: 0.0000e+00\n",
            "Epoch 862/1000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0155 - acc: 0.0125 - val_loss: 0.0168 - val_acc: 0.0000e+00\n",
            "Epoch 863/1000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.0150 - acc: 0.0125 - val_loss: 0.0086 - val_acc: 0.0000e+00\n",
            "Epoch 864/1000\n",
            "80/80 [==============================] - 0s 370us/step - loss: 0.0143 - acc: 0.0125 - val_loss: 0.0083 - val_acc: 0.0000e+00\n",
            "Epoch 865/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0147 - acc: 0.0125 - val_loss: 0.0121 - val_acc: 0.0000e+00\n",
            "Epoch 866/1000\n",
            "80/80 [==============================] - 0s 353us/step - loss: 0.0141 - acc: 0.0125 - val_loss: 0.0150 - val_acc: 0.0000e+00\n",
            "Epoch 867/1000\n",
            "80/80 [==============================] - 0s 411us/step - loss: 0.0142 - acc: 0.0125 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
            "Epoch 868/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0136 - acc: 0.0125 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
            "Epoch 869/1000\n",
            "80/80 [==============================] - 0s 368us/step - loss: 0.0143 - acc: 0.0125 - val_loss: 0.0100 - val_acc: 0.0000e+00\n",
            "Epoch 870/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0137 - acc: 0.0125 - val_loss: 0.0136 - val_acc: 0.0000e+00\n",
            "Epoch 871/1000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0139 - acc: 0.0125 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
            "Epoch 872/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0135 - acc: 0.0125 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
            "Epoch 873/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0136 - acc: 0.0125 - val_loss: 0.0094 - val_acc: 0.0000e+00\n",
            "Epoch 874/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0136 - acc: 0.0125 - val_loss: 0.0112 - val_acc: 0.0000e+00\n",
            "Epoch 875/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0135 - acc: 0.0125 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
            "Epoch 876/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0134 - acc: 0.0125 - val_loss: 0.0094 - val_acc: 0.0000e+00\n",
            "Epoch 877/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0138 - acc: 0.0125 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
            "Epoch 878/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0140 - acc: 0.0125 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
            "Epoch 879/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0134 - acc: 0.0125 - val_loss: 0.0118 - val_acc: 0.0000e+00\n",
            "Epoch 880/1000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.0134 - acc: 0.0125 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
            "Epoch 881/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0134 - acc: 0.0125 - val_loss: 0.0093 - val_acc: 0.0000e+00\n",
            "Epoch 882/1000\n",
            "80/80 [==============================] - 0s 443us/step - loss: 0.0135 - acc: 0.0125 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
            "Epoch 883/1000\n",
            "80/80 [==============================] - 0s 379us/step - loss: 0.0135 - acc: 0.0125 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
            "Epoch 884/1000\n",
            "80/80 [==============================] - 0s 370us/step - loss: 0.0133 - acc: 0.0125 - val_loss: 0.0106 - val_acc: 0.0000e+00\n",
            "Epoch 885/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0133 - acc: 0.0125 - val_loss: 0.0116 - val_acc: 0.0000e+00\n",
            "Epoch 886/1000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0134 - acc: 0.0125 - val_loss: 0.0135 - val_acc: 0.0000e+00\n",
            "Epoch 887/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0138 - acc: 0.0125 - val_loss: 0.0135 - val_acc: 0.0000e+00\n",
            "Epoch 888/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0135 - acc: 0.0125 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
            "Epoch 889/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0134 - acc: 0.0125 - val_loss: 0.0094 - val_acc: 0.0000e+00\n",
            "Epoch 890/1000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.0133 - acc: 0.0125 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
            "Epoch 891/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0136 - acc: 0.0125 - val_loss: 0.0124 - val_acc: 0.0000e+00\n",
            "Epoch 892/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0132 - acc: 0.0125 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
            "Epoch 893/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0137 - acc: 0.0125 - val_loss: 0.0081 - val_acc: 0.0000e+00\n",
            "Epoch 894/1000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0138 - acc: 0.0125 - val_loss: 0.0115 - val_acc: 0.0000e+00\n",
            "Epoch 895/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0132 - acc: 0.0125 - val_loss: 0.0166 - val_acc: 0.0000e+00\n",
            "Epoch 896/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0146 - acc: 0.0125 - val_loss: 0.0115 - val_acc: 0.0000e+00\n",
            "Epoch 897/1000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0132 - acc: 0.0125 - val_loss: 0.0081 - val_acc: 0.0000e+00\n",
            "Epoch 898/1000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.0142 - acc: 0.0125 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
            "Epoch 899/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.0129 - acc: 0.0125 - val_loss: 0.0158 - val_acc: 0.0000e+00\n",
            "Epoch 900/1000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.0146 - acc: 0.0125 - val_loss: 0.0157 - val_acc: 0.0000e+00\n",
            "Epoch 901/1000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.0140 - acc: 0.0125 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
            "Epoch 902/1000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.0130 - acc: 0.0125 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
            "Epoch 903/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0155 - acc: 0.0125 - val_loss: 0.0080 - val_acc: 0.0000e+00\n",
            "Epoch 904/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.0133 - acc: 0.0125 - val_loss: 0.0137 - val_acc: 0.0000e+00\n",
            "Epoch 905/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0136 - acc: 0.0125 - val_loss: 0.0172 - val_acc: 0.0000e+00\n",
            "Epoch 906/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0146 - acc: 0.0125 - val_loss: 0.0098 - val_acc: 0.0000e+00\n",
            "Epoch 907/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0137 - acc: 0.0125 - val_loss: 0.0080 - val_acc: 0.0000e+00\n",
            "Epoch 908/1000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.0147 - acc: 0.0125 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
            "Epoch 909/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0128 - acc: 0.0125 - val_loss: 0.0133 - val_acc: 0.0000e+00\n",
            "Epoch 910/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0133 - acc: 0.0125 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
            "Epoch 911/1000\n",
            "80/80 [==============================] - 0s 363us/step - loss: 0.0131 - acc: 0.0125 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
            "Epoch 912/1000\n",
            "80/80 [==============================] - 0s 380us/step - loss: 0.0132 - acc: 0.0125 - val_loss: 0.0086 - val_acc: 0.0000e+00\n",
            "Epoch 913/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0131 - acc: 0.0125 - val_loss: 0.0114 - val_acc: 0.0000e+00\n",
            "Epoch 914/1000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.0129 - acc: 0.0125 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
            "Epoch 915/1000\n",
            "80/80 [==============================] - 0s 409us/step - loss: 0.0131 - acc: 0.0125 - val_loss: 0.0125 - val_acc: 0.0000e+00\n",
            "Epoch 916/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0131 - acc: 0.0125 - val_loss: 0.0115 - val_acc: 0.0000e+00\n",
            "Epoch 917/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0129 - acc: 0.0125 - val_loss: 0.0091 - val_acc: 0.0000e+00\n",
            "Epoch 918/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0128 - acc: 0.0125 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
            "Epoch 919/1000\n",
            "80/80 [==============================] - 0s 370us/step - loss: 0.0137 - acc: 0.0125 - val_loss: 0.0093 - val_acc: 0.0000e+00\n",
            "Epoch 920/1000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.0127 - acc: 0.0125 - val_loss: 0.0152 - val_acc: 0.0000e+00\n",
            "Epoch 921/1000\n",
            "80/80 [==============================] - 0s 447us/step - loss: 0.0140 - acc: 0.0125 - val_loss: 0.0126 - val_acc: 0.0000e+00\n",
            "Epoch 922/1000\n",
            "80/80 [==============================] - 0s 349us/step - loss: 0.0127 - acc: 0.0125 - val_loss: 0.0081 - val_acc: 0.0000e+00\n",
            "Epoch 923/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0152 - acc: 0.0125 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
            "Epoch 924/1000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0136 - acc: 0.0125 - val_loss: 0.0147 - val_acc: 0.0000e+00\n",
            "Epoch 925/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0138 - acc: 0.0125 - val_loss: 0.0175 - val_acc: 0.0000e+00\n",
            "Epoch 926/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0147 - acc: 0.0125 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
            "Epoch 927/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0126 - acc: 0.0125 - val_loss: 0.0078 - val_acc: 0.0000e+00\n",
            "Epoch 928/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0134 - acc: 0.0125 - val_loss: 0.0078 - val_acc: 0.0000e+00\n",
            "Epoch 929/1000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.0134 - acc: 0.0125 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
            "Epoch 930/1000\n",
            "80/80 [==============================] - 0s 428us/step - loss: 0.0125 - acc: 0.0125 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
            "Epoch 931/1000\n",
            "80/80 [==============================] - 0s 596us/step - loss: 0.0129 - acc: 0.0125 - val_loss: 0.0096 - val_acc: 0.0000e+00\n",
            "Epoch 932/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.0131 - acc: 0.0125 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
            "Epoch 933/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0126 - acc: 0.0125 - val_loss: 0.0136 - val_acc: 0.0000e+00\n",
            "Epoch 934/1000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.0134 - acc: 0.0125 - val_loss: 0.0146 - val_acc: 0.0000e+00\n",
            "Epoch 935/1000\n",
            "80/80 [==============================] - 0s 414us/step - loss: 0.0134 - acc: 0.0125 - val_loss: 0.0081 - val_acc: 0.0000e+00\n",
            "Epoch 936/1000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.0129 - acc: 0.0125 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
            "Epoch 937/1000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0131 - acc: 0.0125 - val_loss: 0.0119 - val_acc: 0.0000e+00\n",
            "Epoch 938/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.0129 - acc: 0.0125 - val_loss: 0.0172 - val_acc: 0.0000e+00\n",
            "Epoch 939/1000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.0146 - acc: 0.0125 - val_loss: 0.0117 - val_acc: 0.0000e+00\n",
            "Epoch 940/1000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.0124 - acc: 0.0125 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
            "Epoch 941/1000\n",
            "80/80 [==============================] - 0s 411us/step - loss: 0.0139 - acc: 0.0125 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
            "Epoch 942/1000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.0138 - acc: 0.0125 - val_loss: 0.0098 - val_acc: 0.0000e+00\n",
            "Epoch 943/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0124 - acc: 0.0125 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
            "Epoch 944/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0126 - acc: 0.0125 - val_loss: 0.0105 - val_acc: 0.0000e+00\n",
            "Epoch 945/1000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.0122 - acc: 0.0125 - val_loss: 0.0080 - val_acc: 0.0000e+00\n",
            "Epoch 946/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0128 - acc: 0.0125 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
            "Epoch 947/1000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.0128 - acc: 0.0125 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
            "Epoch 948/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0122 - acc: 0.0125 - val_loss: 0.0126 - val_acc: 0.0000e+00\n",
            "Epoch 949/1000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.0130 - acc: 0.0125 - val_loss: 0.0131 - val_acc: 0.0000e+00\n",
            "Epoch 950/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0126 - acc: 0.0125 - val_loss: 0.0082 - val_acc: 0.0000e+00\n",
            "Epoch 951/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0124 - acc: 0.0125 - val_loss: 0.0075 - val_acc: 0.0000e+00\n",
            "Epoch 952/1000\n",
            "80/80 [==============================] - 0s 383us/step - loss: 0.0136 - acc: 0.0125 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
            "Epoch 953/1000\n",
            "80/80 [==============================] - 0s 359us/step - loss: 0.0122 - acc: 0.0125 - val_loss: 0.0141 - val_acc: 0.0000e+00\n",
            "Epoch 954/1000\n",
            "80/80 [==============================] - 0s 397us/step - loss: 0.0131 - acc: 0.0125 - val_loss: 0.0159 - val_acc: 0.0000e+00\n",
            "Epoch 955/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0138 - acc: 0.0125 - val_loss: 0.0112 - val_acc: 0.0000e+00\n",
            "Epoch 956/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0122 - acc: 0.0125 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
            "Epoch 957/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0127 - acc: 0.0125 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
            "Epoch 958/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0128 - acc: 0.0125 - val_loss: 0.0126 - val_acc: 0.0000e+00\n",
            "Epoch 959/1000\n",
            "80/80 [==============================] - 0s 379us/step - loss: 0.0125 - acc: 0.0125 - val_loss: 0.0079 - val_acc: 0.0000e+00\n",
            "Epoch 960/1000\n",
            "80/80 [==============================] - 0s 385us/step - loss: 0.0130 - acc: 0.0125 - val_loss: 0.0075 - val_acc: 0.0000e+00\n",
            "Epoch 961/1000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0135 - acc: 0.0125 - val_loss: 0.0108 - val_acc: 0.0000e+00\n",
            "Epoch 962/1000\n",
            "80/80 [==============================] - 0s 408us/step - loss: 0.0123 - acc: 0.0125 - val_loss: 0.0151 - val_acc: 0.0000e+00\n",
            "Epoch 963/1000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0133 - acc: 0.0125 - val_loss: 0.0103 - val_acc: 0.0000e+00\n",
            "Epoch 964/1000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0121 - acc: 0.0125 - val_loss: 0.0075 - val_acc: 0.0000e+00\n",
            "Epoch 965/1000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0139 - acc: 0.0125 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
            "Epoch 966/1000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0120 - acc: 0.0125 - val_loss: 0.0165 - val_acc: 0.0000e+00\n",
            "Epoch 967/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0142 - acc: 0.0125 - val_loss: 0.0132 - val_acc: 0.0000e+00\n",
            "Epoch 968/1000\n",
            "80/80 [==============================] - 0s 267us/step - loss: 0.0126 - acc: 0.0125 - val_loss: 0.0074 - val_acc: 0.0000e+00\n",
            "Epoch 969/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0127 - acc: 0.0125 - val_loss: 0.0074 - val_acc: 0.0000e+00\n",
            "Epoch 970/1000\n",
            "80/80 [==============================] - 0s 356us/step - loss: 0.0133 - acc: 0.0125 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
            "Epoch 971/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0119 - acc: 0.0125 - val_loss: 0.0142 - val_acc: 0.0000e+00\n",
            "Epoch 972/1000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.0131 - acc: 0.0125 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
            "Epoch 973/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0115 - acc: 0.0125 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
            "Epoch 974/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0142 - acc: 0.0125 - val_loss: 0.0080 - val_acc: 0.0000e+00\n",
            "Epoch 975/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0130 - acc: 0.0125 - val_loss: 0.0139 - val_acc: 0.0000e+00\n",
            "Epoch 976/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0128 - acc: 0.0125 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
            "Epoch 977/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0119 - acc: 0.0125 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
            "Epoch 978/1000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.0125 - acc: 0.0125 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
            "Epoch 979/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0119 - acc: 0.0125 - val_loss: 0.0129 - val_acc: 0.0000e+00\n",
            "Epoch 980/1000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.0125 - acc: 0.0125 - val_loss: 0.0149 - val_acc: 0.0000e+00\n",
            "Epoch 981/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0132 - acc: 0.0125 - val_loss: 0.0103 - val_acc: 0.0000e+00\n",
            "Epoch 982/1000\n",
            "80/80 [==============================] - 0s 383us/step - loss: 0.0119 - acc: 0.0125 - val_loss: 0.0082 - val_acc: 0.0000e+00\n",
            "Epoch 983/1000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.0119 - acc: 0.0125 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
            "Epoch 984/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0118 - acc: 0.0125 - val_loss: 0.0112 - val_acc: 0.0000e+00\n",
            "Epoch 985/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0120 - acc: 0.0125 - val_loss: 0.0112 - val_acc: 0.0000e+00\n",
            "Epoch 986/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0118 - acc: 0.0125 - val_loss: 0.0072 - val_acc: 0.0000e+00\n",
            "Epoch 987/1000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.0124 - acc: 0.0125 - val_loss: 0.0076 - val_acc: 0.0000e+00\n",
            "Epoch 988/1000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0141 - acc: 0.0125 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
            "Epoch 989/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.0117 - acc: 0.0125 - val_loss: 0.0134 - val_acc: 0.0000e+00\n",
            "Epoch 990/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0125 - acc: 0.0125 - val_loss: 0.0096 - val_acc: 0.0000e+00\n",
            "Epoch 991/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0117 - acc: 0.0125 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
            "Epoch 992/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0126 - acc: 0.0125 - val_loss: 0.0090 - val_acc: 0.0000e+00\n",
            "Epoch 993/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0115 - acc: 0.0125 - val_loss: 0.0148 - val_acc: 0.0000e+00\n",
            "Epoch 994/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0131 - acc: 0.0125 - val_loss: 0.0118 - val_acc: 0.0000e+00\n",
            "Epoch 995/1000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.0121 - acc: 0.0125 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
            "Epoch 996/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0124 - acc: 0.0125 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
            "Epoch 997/1000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.0126 - acc: 0.0125 - val_loss: 0.0100 - val_acc: 0.0000e+00\n",
            "Epoch 998/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0121 - acc: 0.0125 - val_loss: 0.0141 - val_acc: 0.0000e+00\n",
            "Epoch 999/1000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.0126 - acc: 0.0125 - val_loss: 0.0093 - val_acc: 0.0000e+00\n",
            "Epoch 1000/1000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0115 - acc: 0.0125 - val_loss: 0.0072 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1lJMvLFE-if",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predict = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PyZBrWfFTWo",
        "colab_type": "code",
        "outputId": "719f01e0-6cbd-4abe-af26-937d1bbfb308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "np.round(y_predict*500)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3456.],\n",
              "       [3287.],\n",
              "       [3359.],\n",
              "       [3266.],\n",
              "       [3493.],\n",
              "       [3239.],\n",
              "       [3167.],\n",
              "       [3222.],\n",
              "       [3206.],\n",
              "       [3303.],\n",
              "       [3593.],\n",
              "       [3313.],\n",
              "       [3475.],\n",
              "       [3329.],\n",
              "       [3428.],\n",
              "       [3297.],\n",
              "       [3339.],\n",
              "       [3413.],\n",
              "       [3178.],\n",
              "       [3470.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uuk0EKEaFXgu",
        "colab_type": "code",
        "outputId": "0bbb7b15-26a8-4fe4-bd24-2327c166e54f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "np.round(y_test*500)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3455., 3285., 3355., 3265., 3495., 3240., 3175., 3225., 3210.,\n",
              "       3300., 3610., 3310., 3475., 3325., 3425., 3295., 3335., 3410.,\n",
              "       3185., 3470.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mE29TU-FazF",
        "colab_type": "code",
        "outputId": "1f16dbf4-7648-45ac-b2ed-42683a96e927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.scatter(range(20),y_predict,c = 'r')\n",
        "plt.scatter(range(20),y_test ,c='g')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMfYIQiOFdwq",
        "colab_type": "code",
        "outputId": "ef30ab34-051f-415c-d9a9-b3c9f16baa67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGVhJREFUeJzt3XtwW+d55/HvA4BX8CoRpGhSikhZ\nF8u32GFdu8m2sbNxbSdN2t20a0+7SRN3tJnJdtOdzHji6Uwzmf1jd2d32yQz3UzUxGlmk0naOsk2\ndbNOWtde113bKeX4IutiSZRk62aSuvIikQTx7B84pCCaEkESwDkAfp8ZDICDA+o5OJofXrznPec1\nd0dERMpHLOwCRERkeRTcIiJlRsEtIlJmFNwiImVGwS0iUmYU3CIiZUbBLSJSZhTcIiJlRsEtIlJm\nEkutYGZbgb/IWdQP/JG7f+lq7+no6PCNGzeuvjoRkSqxa9euUXdP5bPuksHt7vuBdwOYWRw4Dvzw\nWu/ZuHEjg4OD+fz7IiICmNnRfNddblfJB4BD7p73PyAiIoW13OB+EPjuYi+Y2Q4zGzSzwZGRkdVX\nJiIii8o7uM2sFvgI8FeLve7uO919wN0HUqm8umlERGQFltPivh94yd3fLlYxIiKytOUE90NcpZtE\nRERKJ6/gNrMk8EHgB8UtR0RElrLkcEAAd58A1ha5FhERyUOkzpz8ylMHeGHodNhliIhEWmSC+8Kl\nGb79wlEe3PkC/+Zrz/P8IQW4iMhiIhPcLfU1PPvI3fzRh7dzeHSCh/7sBR7a+QL7Tl0IuzQRkUiJ\nTHAD1NfE+dT7+nj2kbv5wq9tZ++pC3zoK8/xn57Yw6WZ2bDLExGJhEgF95z6mjiffG8fT3/u/fzW\nwHq+8dxhfuN//j8OjYyHXZqISOgiGdxz2pO1/Od/dTPf/N1f4NT5i/z6n/6TDl6KSNWLdHDPuXtb\nJ3/z+++js7mOjz/2M57ZPxx2SSIioSmL4AbobW/k8U//Eps7m/j0t3ex6+iZsEsSEQlF2QQ3ZLtO\nvvWpO+hubeDhbw1y/NzFsEsSESm5sgpugI6mOh773V8gPet85jsvMZ3OhF2SiEhJlV1wA/R1JPlv\nH7uFl986x5f+/o2wyxERKamyDG6A+2/u5mPv6WXns0PsOaGTdESkepRtcAP84QM30NpQw6M/fI1M\nxsMuR0SkJMo6uNuTtTz6wA288tY5/va1k2GXIyJSEmUd3AC/cVsPW7ua+R8/3c/MrA5UikjlK/vg\njseMR+7bypHTk3x/17GwyxERKbqyD26Ae7Z1cnNPKzv/cUh93SJS8SoiuM2M3/sXfQyNTPDMGzod\nXkQqW0UEN8ADN3fT3VrPnz17OOxSRESKqmKCuyYe4+N3beT5odMcHNblX0WkcuU7y3ubmT1uZvvM\nbK+Z3VXswlbiX7+nh3jMeFwHKUWkguXb4v4y8KS7bwNuBfYWr6SV62yu5+6tKb7/0jHSGhooIhVq\nyeA2s1bgl4FvALj7tLufK3ZhK/WbA+sZGZvi/74xEnYpIiJFkU+Luw8YAb5pZj83s6+bWXLhSma2\nw8wGzWxwZCS80LxnWydrkrX89csnQqtBRKSY8gnuBHA78FV3vw2YAD6/cCV33+nuA+4+kEqlClxm\n/mriMX71xi6e2vu2JhgWkYqUT3AfA465+4vB88fJBnlk3X9TNxPTs/zjgdGwSxERKbglg9vdTwFv\nmdnWYNEHgD1FrWqV7tq0ltaGGn6sC0+JSAVK5Lne7wPfMbNaYAj4ZPFKWr2aeIx7t3fx5O5TTKcz\n1CYqZri6iEh+wwHd/eWg//oWd/91dz9b7MJW694b1zE2lWbwiCYVFpHKUrFN0V/atJbaeIxnNCxQ\nRCpMxQZ3si7BHX1reHqfLjolIpWlYoMb4P1bUxwYHufY2cmwSxERKZgKD+5OAJ7Zr+4SEakcFR3c\nm1JJetsbFNwiUlEqOrjNjF/ZkuL5Q6Oaj1JEKkZFBzdkT8aZmJ5l9/HzYZciIlIQFR/cd/avBeD5\nodMhVyIiUhgVH9wdTXVs6WrihSGdiCMilaHigxvgrv61DB45o35uEakIVRHcd/avZXJ6llePRXb+\nBxGRvFVFcP9i0M+t7hIRqQRVEdxrkrVsW9fMCzpAKSIVoCqCG2BgYzsvv3mO2YyHXYqIyKpUTXC/\n513tjE2lOTA8FnYpIiKrUj3BvWENALuORv5S4iIi11Q1wb1+TQMdTXUKbhEpe1UT3GbGe97VxksK\nbhEpc1UT3JDt5z5yepLR8amwSxERWbGqC25ArW4RKWt5BbeZHTGz18zsZTMbLHZRxXLjda3UxmPs\nelPBLSLlK7GMde9299GiVVIC9TVxbuppYdcRBbeIlK+q6ioBePf6dnafOE9aF5wSkTKVb3A78FMz\n22VmO4pZULHdur6VSzMZ3nh7POxSRERWJN/gfp+73w7cD3zGzH554QpmtsPMBs1scGQkunM83tLb\nBqArBYpI2coruN39eHA/DPwQuGORdXa6+4C7D6RSqcJWWUAb1zbSUp/glWOaykxEytOSwW1mSTNr\nnnsM3AvsLnZhxWJm3NLbpha3iJStfFrcXcBzZvYK8DPgb939yeKWVVy39Lay/9QYl2Zmwy5FRGTZ\nlhwO6O5DwK0lqKVkbultI51x9py8wO0b2sMuR0RkWapuOCBkR5YAvPqWuktEpPxUZXCva6kn1VzH\nqzpAKSJlqCqD28y4tbeVV3SAUkTKUFUGN8DNPW0MjU4wdmkm7FJERJalaoP7lvWtuMNrx9VdIiLl\npWqD+6brsgco95y4EHIlIiLLU7XBnWquo6uljtcV3CJSZqo2uCF7fe7XT6irRETKS5UHdwsHh8e5\nOK0zKEWkfFR9cGcc9p1Sd4mIlI8qD+7sAUr1c4tIOanq4O5tb6C1oUbBLSJlpaqD28zY3t3CHh2g\nFJEyUtXBDdl+7n2nxjQHpYiUDQV3TwtT6QyHRibCLkVEJC9VH9w3zR+gVHeJiJSHqg/u/lQT9TUx\nHaAUkbJR9cEdjxnb1rWwWxebEpEyUfXBDdkDlHtOXsDdwy5FRGRJCm6yJ+KMXUrz1pmLYZciIrKk\nvIPbzOJm9nMze6KYBYXhpp4WQAcoRaQ8LKfF/Vlgb7EKCdOWrmZiBvtOjYVdiojIkvIKbjPrBT4E\nfL245YSjviZOX0eSvSc1skREoi/fFveXgEeAij29cFt3i1rcIlIWlgxuM/swMOzuu5ZYb4eZDZrZ\n4MjISMEKLJUb1jXz5plJxqfSYZciInJN+bS43wt8xMyOAN8D7jGzby9cyd13uvuAuw+kUqkCl1l8\n29ZlD1DuV6tbRCJuyeB290fdvdfdNwIPAv/g7r9T9MpKbFt3M6BJFUQk+jSOO9DT1kBzXYJ9J9Xi\nFpFoSyxnZXd/BnimKJWEzMzY1t2skSUiEnlqcefYti47skSnvotIlCm4c9zQ3cL4VJpjZ3Xqu4hE\nl4I7x+UDlOrnFpHoUnDn2NoVBLf6uUUkwhTcOZJ1Cd61tpG9GhIoIhGm4F5g27pmDQkUkUhTcC+w\nbV0Lh09PcHF6NuxSREQWpeBe4IbuZtzhjbfV6haRaFJwLzB3zRKd+i4iUaXgXmDDmkYaa+PsVT+3\niESUgnuBWMzY3NWsqwSKSGQpuBexpbOJA8MKbhGJJgX3IrZ0NTM6Ps2ZiemwSxEReQcF9yI2dzUB\nGlkiItGk4F7EluDU9wMKbhGJIAX3Irpb62muS/DG2+NhlyIi8g4K7kWYGdd3NamrREQiScF9FVs6\nmzkwrBa3iESPgvsqNnc1cWZimtHxqbBLERG5goL7Krauyx6gVHeJiESNgvsqLo8sUXeJiETLksFt\nZvVm9jMze8XMXjezL5aisLB1NtfRUp9Qi1tEIieRxzpTwD3uPm5mNcBzZvZ/3P2FItcWKjNjS1ez\nWtwiEjlLtrg9ay69aoKbF7WqiNjc1cwbw2O4V8XmikiZyKuP28ziZvYyMAz8nbu/uMg6O8xs0MwG\nR0ZGCl1nKLZ0NXFucoYRjSwRkQjJK7jdfdbd3w30AneY2U2LrLPT3QfcfSCVShW6zlDoAKWIRNGy\nRpW4+zngaeC+4pQTLbrYlIhEUT6jSlJm1hY8bgA+COwrdmFRkGqqo62xRtcsEZFIyWdUSTfwLTOL\nkw36v3T3J4pbVjSYGZs7mzioSRVEJEKWDG53fxW4rQS1RNL1nU389PW3wy5DRGSezpxcQn9HE6cn\npjmr2XBEJCIU3EvY1JkEYGhU/dwiEg0K7iVsSmVHlhwangi5EhGRLAX3EnrbG6mNxzikFreIRISC\newnxmNHXkVSLW0QiQ8Gdh02dSYZG1OIWkWhQcOehv6OJo2cmmU5nwi5FRETBnY9NnUlmM86bZ9Rd\nIiLhU3DnYX5kyYiCW0TCp+DOQ/98cKufW0TCp+DOQ1NdgnUt9RpZIiKRoODO06bOpFrcIhIJCu48\n9Xc0cWhkXNOYiUjoFNx52pRKMnYprWnMRCR0Cu48berMHqAc0sgSEQmZgjtPc0MCDw6rn1tEwqXg\nztO6lnoaauIcHlWLW0TCpeDOUyxmbOxIKrhFJHQK7mXoV3CLSAQouJehP5XkTV1sSkRCtmRwm9l6\nM3vazPaY2etm9tlSFBZFfR3Zi029dXYy7FJEpIrl0+JOA59z9+3AncBnzGx7ccuKpr6O7PyThzUk\nUERCtGRwu/tJd38peDwG7AV6il1YFPV3ZIcEqp9bRMK0rD5uM9sI3Aa8WIxioq61sYa1yVrN+C4i\noco7uM2sCfg+8AfufmGR13eY2aCZDY6MjBSyxkjp60jq7EkRCVVewW1mNWRD+zvu/oPF1nH3ne4+\n4O4DqVSqkDVGSp+GBIpIyPIZVWLAN4C97v7HxS8p2vpSSYbHphifSoddiohUqXxa3O8F/i1wj5m9\nHNweKHJdkdWvkSUiErLEUiu4+3OAlaCWsjA3jdnQ6Dg397aGXI2IVCOdOblMG9Y0YqYhgSISHgX3\nMtXXxOlpa1Bwi0hoFNwroCGBIhImBfcKbEo1cXh0QvNPikgoFNwr0NeRZHxK80+KSDgU3Cugi02J\nSJgU3CswF9xDOkApIiFQcK9AT1sDtYmYRpaISCgU3CsQixl9azWyRETCoeBeoezFpnR5VxEpPQX3\nCvUF80+mZzX/pIiUloJ7hfo6kszMOsfOXgy7FBGpMgruFdqUCoYE6gCliJSYgnuF+jrmrhKo4BaR\n0lJwr1B7Yw2tDTUMjegApYiUloJ7hcxM05iJSCgU3KvQn1Jwi0jpKbhXob8jycnzl5ic1vyTIlI6\nCu5VmDtAqVa3iJSSgnsV5q8SqOAWkRJaMrjN7DEzGzaz3aUoqJzo8q4iEoZ8Wtx/DtxX5DrKUkNt\nnOta69XiFpGSWjK43f1Z4EwJailLfamkTsIRkZJSH/cqZScOHtf8kyJSMgULbjPbYWaDZjY4MjJS\nqD8beX0dTVy4lObMxHTYpYhIlShYcLv7TncfcPeBVCpVqD8bef262JSIlJi6SlapX/NPikiJ5TMc\n8LvA88BWMztmZg8Xv6zy0dPWQE3cNI2ZiJRMYqkV3P2hUhRSrhLxGBvWNGoaMxEpGXWVFEB/qkl9\n3CJSMgruAujvSHLk9CSzGQ0JFJHiU3AXQF9Hkul0hhPnNP+kiBSfgrsA+jSyRERKSMFdAP2p4PKu\nmsZMREpAwV0AHU21NNcldIBSREpCwV0AZqaLTYlIySi4CyR7sSkFt4gUn4K7QPo6kpw4f5FLM7Nh\nlyIiFU7BXSD9qSbc4ejpybBLEZEKp+AukPmLTWlkiYgUmYK7QDZqLLeIlIiCu0Ca6hJ0NtdpSKCI\nFJ2Cu4D6U0kFt4gUnYK7gPo6mjik+SdFpMgU3AV0a28r5yZn2HtyLOxSRKSCKbgL6AM3dGEGT7x6\nAoDpdEaXehWRgltyBhzJX6q5jvtuXMfXnh3inw6O8trx8zjQ3VLPhrWNrG9vpKE2TjxmJGJGPBYL\n7o2auJGIZ58nYjmP47Hsa7EYtYkYdYmF93Hqgud1iTi1wfJ4zML+OESkSBTcBfbFj97I2KU0l2Zm\n+Xe/solEzDh29iJHT0/w7IERptMZ0hlnNuPz98VoldfEjdp4jLqaeHB/ZdhfuSx+xRfC3BdA3RW3\nnGU1MWrj8eA++zxZmyBZl6CpLkFtQj/kRIpJwV1gnc31fPv3fnFZ78nkhPhMJkN61knP3QePZ2ad\n6XSG6dlZpmYyTM1msvfpWabTGaaCW/Zx7rLLjxcum5hIX142M8v0/N/MMD2bWfFnUBuP0VSfIFkX\np6muhqa6+HyotzTUsKaxlvZkLWuSNbQ31rImWUt7Yy1rm2ppqIljpl8LItei4I6AWMyoDbo2GoiH\nXE1WJuNMz2ZywvzqXwCXZjJMTqeZmEozPpVmbCp4fCnN+NQs41MznB6f5ujpSc5fnOHc5DRX+5FR\nl4jNB3lHcx09bfVc19rAdW0N9LQ30NPWQFdLvVr1UtXyCm4zuw/4MhAHvu7u/6WoVUnoYjGjPhan\nviYO9YX925mMc+HSDGcmpjk7Oc2ZiRnOTkxzZnI6ex8sf/vCFHtOnGd0fPqK95vBda0NbOlqYsu6\nZrata2ZLVzObUk3ZekUq3JLBbWZx4E+BDwLHgH82sx+5+55iFyeVKRYz2hpraWuszWv9SzOznDx/\niRPnLnL83EVOnLvI4dEJ9p8a47mDo8zMZpvvMcteemBrVzNb1zXT295IS32CxtoE8eAgcDwGMcs+\njpmRiBtxM2Kx4N4MM4KbYXB5GYAFz2G+S2euYye3h8fmltqVr11ed/H3zr1vsd6iq62z5N9U11PF\nyafFfQdw0N2HAMzse8BHAQW3lER9TZy+juT83J65ZmYzHD09wf5T4+w/dYF9p8bYe/ICT75+Cp0H\ntbgrv2Dmll37i4R3fElc+Xo+f3PuQe4X4XK/VGLBt2ful9Zyaplfbu98vKxtyXmSu86axlr+8tN3\n5b9BK5RPcPcAb+U8Pwa84+ibme0AdgBs2LChIMWJLKUmHuP6zmau72zmQ7d0zy+/OD3LyNgU5y/O\nMDmdZtadTIbgPhjN45dH9WSCx+6Q8ey9M3efuwxwn++jnztLNvc7Yu4Lw7lynXe+7ldZ/8rXc5dd\nfp7fexe+nvuH8n3PO+q5yvbl1rjU3577PPPhOIbhZD/3y++7/Deu9Zld63O92rYs/r6cty3c78GD\n5vrSHDYs2L/i7juBnQADAwNq60ioGmrjbFjbGHYZIkWRz6H548D6nOe9wTIREQlBPsH9z8BmM+sz\ns1rgQeBHxS1LRESuZsmuEndPm9m/B35CdjjgY+7+etErExGRReXVx+3uPwZ+XORaREQkDzr9TESk\nzCi4RUTKjIJbRKTMKLhFRMqMFWN+RDMbAY6u8O0dwGgByykH2ubqoG2ufKvZ3ne5eyqfFYsS3Kth\nZoPuPhB2HaWkba4O2ubKV6rtVVeJiEiZUXCLiJSZKAb3zrALCIG2uTpomytfSbY3cn3cIiJybVFs\ncYuIyDVEJrjN7D4z229mB83s82HXUyhmtt7MnjazPWb2upl9Nli+xsz+zswOBPftwXIzs68En8Or\nZnZ7uFuwcmYWN7Ofm9kTwfM+M3sx2La/CK42iZnVBc8PBq9vDLPulTKzNjN73Mz2mdleM7ur0vez\nmf3H4P/1bjP7rpnVV9p+NrPHzGzYzHbnLFv2fjWzTwTrHzCzT6ympkgEd868lvcD24GHzGx7uFUV\nTBr4nLtvB+4EPhNs2+eBp9x9M/BU8Byyn8Hm4LYD+GrpSy6YzwJ7c57/V+BP3P164CzwcLD8YeBs\nsPxPgvXK0ZeBJ919G3Ar2W2v2P1sZj3AfwAG3P0mslcPfZDK289/Dty3YNmy9quZrQG+QHb2sDuA\nL8yF/Yq4e+g34C7gJznPHwUeDbuuIm3rX5OdeHk/0B0s6wb2B4+/BjyUs/78euV0IzvhxlPAPcAT\nZKfmGwUSC/c52UsG3xU8TgTrWdjbsMztbQUOL6y7kvczl6c1XBPstyeAX63E/QxsBHavdL8CDwFf\ny1l+xXrLvUWixc3i81r2hFRL0QQ/DW8DXgS63P1k8NIpoCt4XCmfxZeAR4BM8HwtcM7d08Hz3O2a\n3+bg9fPB+uWkDxgBvhl0D33dzJJU8H529+PAfwfeBE6S3W+7qOz9PGe5+7Wg+zsqwV3xzKwJ+D7w\nB+5+Ifc1z34FV8zwHjP7MDDs7rvCrqWEEsDtwFfd/TZggss/n4GK3M/twEfJfmldByR5Z5dCxQtj\nv0YluCt6XkszqyEb2t9x9x8Ei982s+7g9W5gOFheCZ/Fe4GPmNkR4Htku0u+DLSZ2dzkHbnbNb/N\nweutwOlSFlwAx4Bj7v5i8PxxskFeyfv5XwKH3X3E3WeAH5Dd95W8n+csd78WdH9HJbgrdl5LMzPg\nG8Bed//jnJd+BMwdWf4E2b7vueUfD45O3wmcz/lJVhbc/VF373X3jWT35T+4+28DTwMfC1ZbuM1z\nn8XHgvXLqmXq7qeAt8xsa7DoA8AeKng/k+0iudPMGoP/53PbXLH7Ocdy9+tPgHvNrD34pXJvsGxl\nwu70z+msfwB4AzgE/GHY9RRwu95H9mfUq8DLwe0Bsn17TwEHgL8H1gTrG9kRNoeA18gesQ99O1ax\n/e8Hngge9wM/Aw4CfwXUBcvrg+cHg9f7w657hdv6bmAw2Nf/G2iv9P0MfBHYB+wG/hdQV2n7Gfgu\n2T78GbK/rB5eyX4FPhVs+0Hgk6upSWdOioiUmah0lYiISJ4U3CIiZUbBLSJSZhTcIiJlRsEtIlJm\nFNwiImVGwS0iUmYU3CIiZeb/A2N9Z2m65YsFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsy5UwhiFh_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}