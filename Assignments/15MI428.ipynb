{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15MI428.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDGlJKpGk9-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24ebb514-761d-4c6d-d11c-38167ffeef07"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,LSTM\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDQdO--QlF8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1=[]\n",
        "for num in range (1,101):\n",
        "  X1.append(((num+num)-1)/100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC198GPSlZPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a6cwSjxld_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X2=X1[::-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ0FSzVmllbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Liq40h1zlvlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.column_stack((X1, X2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VkKg8BUlm6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD3IJNUVl_hE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = [(x1*x2)/5 for x1,x2 in zip(X1,X2)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtTNy95kmRO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlb9AiixmX8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.array(data,dtype=float)\n",
        "target = np.array(target,dtype=float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMBwDIaTmeQR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4421d2dc-1b44-4775-d798-4ec93aa95ea4"
      },
      "source": [
        "data = np.array(data).reshape(100, 2,1)\n",
        "data.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 2, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMKGA0KtmrXc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82c07755-1504-47d0-fa7a-b2e7324bb9bb"
      },
      "source": [
        "target.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jormCXfmvC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(data,target,test_size=0.2,random_state=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_lEh2d5mxm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "6885d2ee-ca2b-4b82-e290-66a903138d17"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(2,1)))\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(25, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "print(model.summary())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 2, 200)            161600    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 2, 100)            120400    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 2, 50)             30200     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 25)                7600      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                520       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                210       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 320,541\n",
            "Trainable params: 320,541\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_tiD6X0m1KN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a2f77128-9edd-4dab-bca9-4baf1c29f427"
      },
      "source": [
        "history = model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1185e-07 - val_loss: 4.9597e-07\n",
            "Epoch 2/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.1472e-07 - val_loss: 1.0416e-07\n",
            "Epoch 3/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.3158e-07 - val_loss: 2.1552e-07\n",
            "Epoch 4/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.6231e-08 - val_loss: 4.8827e-07\n",
            "Epoch 5/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.0160e-07 - val_loss: 9.4448e-07\n",
            "Epoch 6/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.5509e-06 - val_loss: 2.4630e-07\n",
            "Epoch 7/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.3879e-07 - val_loss: 3.9726e-07\n",
            "Epoch 8/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.5950e-07 - val_loss: 2.7494e-07\n",
            "Epoch 9/500\n",
            "80/80 [==============================] - 0s 997us/step - loss: 1.4778e-07 - val_loss: 9.4995e-08\n",
            "Epoch 10/500\n",
            "80/80 [==============================] - 0s 984us/step - loss: 1.2833e-07 - val_loss: 5.2014e-07\n",
            "Epoch 11/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.5948e-07 - val_loss: 1.0291e-07\n",
            "Epoch 12/500\n",
            "80/80 [==============================] - 0s 996us/step - loss: 1.1021e-07 - val_loss: 7.0489e-08\n",
            "Epoch 13/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.7759e-08 - val_loss: 7.8458e-08\n",
            "Epoch 14/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.2143e-08 - val_loss: 5.9150e-08\n",
            "Epoch 15/500\n",
            "80/80 [==============================] - 0s 945us/step - loss: 3.8547e-08 - val_loss: 2.3748e-08\n",
            "Epoch 16/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8086e-08 - val_loss: 6.6811e-08\n",
            "Epoch 17/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.8039e-08 - val_loss: 1.1313e-07\n",
            "Epoch 18/500\n",
            "80/80 [==============================] - 0s 970us/step - loss: 9.8310e-08 - val_loss: 6.1718e-07\n",
            "Epoch 19/500\n",
            "80/80 [==============================] - 0s 937us/step - loss: 3.5653e-07 - val_loss: 7.3365e-07\n",
            "Epoch 20/500\n",
            "80/80 [==============================] - 0s 963us/step - loss: 1.0350e-06 - val_loss: 2.1553e-07\n",
            "Epoch 21/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.4984e-07 - val_loss: 3.2062e-06\n",
            "Epoch 22/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8158e-06 - val_loss: 1.7105e-06\n",
            "Epoch 23/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8715e-06 - val_loss: 1.1942e-06\n",
            "Epoch 24/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.4427e-06 - val_loss: 5.8902e-06\n",
            "Epoch 25/500\n",
            "80/80 [==============================] - 0s 995us/step - loss: 2.9837e-06 - val_loss: 3.9122e-06\n",
            "Epoch 26/500\n",
            "80/80 [==============================] - 0s 949us/step - loss: 1.9310e-06 - val_loss: 1.7798e-06\n",
            "Epoch 27/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.9842e-06 - val_loss: 6.8059e-07\n",
            "Epoch 28/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.0987e-07 - val_loss: 3.5067e-06\n",
            "Epoch 29/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.9485e-06 - val_loss: 2.0625e-06\n",
            "Epoch 30/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4225e-06 - val_loss: 1.0933e-06\n",
            "Epoch 31/500\n",
            "80/80 [==============================] - 0s 999us/step - loss: 1.0837e-06 - val_loss: 4.0123e-06\n",
            "Epoch 32/500\n",
            "80/80 [==============================] - 0s 987us/step - loss: 4.6560e-06 - val_loss: 2.2912e-07\n",
            "Epoch 33/500\n",
            "80/80 [==============================] - 0s 923us/step - loss: 1.3172e-06 - val_loss: 8.4486e-07\n",
            "Epoch 34/500\n",
            "80/80 [==============================] - 0s 981us/step - loss: 7.8788e-07 - val_loss: 2.7844e-07\n",
            "Epoch 35/500\n",
            "80/80 [==============================] - 0s 989us/step - loss: 8.1790e-07 - val_loss: 7.4122e-07\n",
            "Epoch 36/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4736e-06 - val_loss: 3.6538e-06\n",
            "Epoch 37/500\n",
            "80/80 [==============================] - 0s 960us/step - loss: 2.0770e-06 - val_loss: 2.2951e-06\n",
            "Epoch 38/500\n",
            "80/80 [==============================] - 0s 965us/step - loss: 1.5473e-06 - val_loss: 4.7729e-06\n",
            "Epoch 39/500\n",
            "80/80 [==============================] - 0s 986us/step - loss: 4.7151e-06 - val_loss: 1.6851e-07\n",
            "Epoch 40/500\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 9.1112e-07 - val_loss: 1.5636e-07\n",
            "Epoch 41/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.4146e-07 - val_loss: 3.9581e-07\n",
            "Epoch 42/500\n",
            "80/80 [==============================] - 0s 996us/step - loss: 3.5922e-07 - val_loss: 3.4748e-07\n",
            "Epoch 43/500\n",
            "80/80 [==============================] - 0s 987us/step - loss: 5.1752e-07 - val_loss: 2.8809e-07\n",
            "Epoch 44/500\n",
            "80/80 [==============================] - 0s 990us/step - loss: 4.2490e-07 - val_loss: 5.1383e-07\n",
            "Epoch 45/500\n",
            "80/80 [==============================] - 0s 961us/step - loss: 3.7792e-07 - val_loss: 1.2282e-07\n",
            "Epoch 46/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0162e-07 - val_loss: 3.3975e-07\n",
            "Epoch 47/500\n",
            "80/80 [==============================] - 0s 962us/step - loss: 3.2221e-07 - val_loss: 2.5587e-07\n",
            "Epoch 48/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.6950e-08 - val_loss: 3.7507e-08\n",
            "Epoch 49/500\n",
            "80/80 [==============================] - 0s 993us/step - loss: 1.6349e-07 - val_loss: 1.5139e-07\n",
            "Epoch 50/500\n",
            "80/80 [==============================] - 0s 942us/step - loss: 5.8636e-08 - val_loss: 2.9414e-07\n",
            "Epoch 51/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8436e-07 - val_loss: 2.3400e-07\n",
            "Epoch 52/500\n",
            "80/80 [==============================] - 0s 964us/step - loss: 1.8884e-07 - val_loss: 3.0931e-08\n",
            "Epoch 53/500\n",
            "80/80 [==============================] - 0s 982us/step - loss: 8.3677e-08 - val_loss: 1.0599e-07\n",
            "Epoch 54/500\n",
            "80/80 [==============================] - 0s 999us/step - loss: 9.2445e-08 - val_loss: 3.6944e-07\n",
            "Epoch 55/500\n",
            "80/80 [==============================] - 0s 974us/step - loss: 2.9310e-07 - val_loss: 7.4011e-08\n",
            "Epoch 56/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8160e-07 - val_loss: 5.0483e-07\n",
            "Epoch 57/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7142e-07 - val_loss: 6.7429e-07\n",
            "Epoch 58/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.7199e-07 - val_loss: 2.5489e-07\n",
            "Epoch 59/500\n",
            "80/80 [==============================] - 0s 949us/step - loss: 1.6092e-07 - val_loss: 3.4960e-07\n",
            "Epoch 60/500\n",
            "80/80 [==============================] - 0s 997us/step - loss: 2.1917e-07 - val_loss: 3.5325e-07\n",
            "Epoch 61/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.7971e-07 - val_loss: 1.2116e-07\n",
            "Epoch 62/500\n",
            "80/80 [==============================] - 0s 982us/step - loss: 1.4125e-06 - val_loss: 5.4530e-07\n",
            "Epoch 63/500\n",
            "80/80 [==============================] - 0s 958us/step - loss: 5.5940e-07 - val_loss: 3.1399e-07\n",
            "Epoch 64/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.2308e-07 - val_loss: 3.0429e-07\n",
            "Epoch 65/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.6391e-07 - val_loss: 2.0633e-07\n",
            "Epoch 66/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.1167e-08 - val_loss: 1.7403e-07\n",
            "Epoch 67/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.9474e-08 - val_loss: 3.3163e-07\n",
            "Epoch 68/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.9648e-08 - val_loss: 9.8400e-08\n",
            "Epoch 69/500\n",
            "80/80 [==============================] - 0s 981us/step - loss: 3.9174e-08 - val_loss: 2.4651e-08\n",
            "Epoch 70/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.6757e-08 - val_loss: 7.7321e-08\n",
            "Epoch 71/500\n",
            "80/80 [==============================] - 0s 984us/step - loss: 3.5228e-08 - val_loss: 3.4433e-08\n",
            "Epoch 72/500\n",
            "80/80 [==============================] - 0s 986us/step - loss: 1.5403e-08 - val_loss: 4.1256e-08\n",
            "Epoch 73/500\n",
            "80/80 [==============================] - 0s 959us/step - loss: 3.4116e-08 - val_loss: 2.7978e-07\n",
            "Epoch 74/500\n",
            "80/80 [==============================] - 0s 984us/step - loss: 1.1389e-07 - val_loss: 1.9267e-07\n",
            "Epoch 75/500\n",
            "80/80 [==============================] - 0s 965us/step - loss: 1.8619e-07 - val_loss: 2.5327e-08\n",
            "Epoch 76/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.5603e-07 - val_loss: 3.6227e-07\n",
            "Epoch 77/500\n",
            "80/80 [==============================] - 0s 935us/step - loss: 2.5448e-07 - val_loss: 3.5456e-07\n",
            "Epoch 78/500\n",
            "80/80 [==============================] - 0s 971us/step - loss: 5.4751e-07 - val_loss: 1.7925e-07\n",
            "Epoch 79/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.9937e-07 - val_loss: 5.0167e-08\n",
            "Epoch 80/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.1283e-07 - val_loss: 8.4175e-07\n",
            "Epoch 81/500\n",
            "80/80 [==============================] - 0s 986us/step - loss: 6.5345e-07 - val_loss: 3.8383e-07\n",
            "Epoch 82/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.2256e-07 - val_loss: 2.1759e-07\n",
            "Epoch 83/500\n",
            "80/80 [==============================] - 0s 959us/step - loss: 1.6334e-06 - val_loss: 5.6951e-06\n",
            "Epoch 84/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.6979e-06 - val_loss: 1.2855e-06\n",
            "Epoch 85/500\n",
            "80/80 [==============================] - 0s 955us/step - loss: 2.1284e-06 - val_loss: 3.3723e-07\n",
            "Epoch 86/500\n",
            "80/80 [==============================] - 0s 985us/step - loss: 1.1621e-06 - val_loss: 2.6528e-06\n",
            "Epoch 87/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 1.3222e-06 - val_loss: 1.2575e-06\n",
            "Epoch 88/500\n",
            "80/80 [==============================] - 0s 916us/step - loss: 1.3038e-06 - val_loss: 6.8888e-07\n",
            "Epoch 89/500\n",
            "80/80 [==============================] - 0s 980us/step - loss: 5.6081e-07 - val_loss: 6.8796e-07\n",
            "Epoch 90/500\n",
            "80/80 [==============================] - 0s 982us/step - loss: 3.6351e-07 - val_loss: 4.3593e-07\n",
            "Epoch 91/500\n",
            "80/80 [==============================] - 0s 984us/step - loss: 8.9264e-07 - val_loss: 1.2905e-06\n",
            "Epoch 92/500\n",
            "80/80 [==============================] - 0s 973us/step - loss: 8.5244e-07 - val_loss: 9.0070e-08\n",
            "Epoch 93/500\n",
            "80/80 [==============================] - 0s 966us/step - loss: 1.6415e-06 - val_loss: 5.4361e-06\n",
            "Epoch 94/500\n",
            "80/80 [==============================] - 0s 978us/step - loss: 3.0827e-06 - val_loss: 1.8012e-05\n",
            "Epoch 95/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0252e-05 - val_loss: 4.3144e-06\n",
            "Epoch 96/500\n",
            "80/80 [==============================] - 0s 996us/step - loss: 4.7444e-06 - val_loss: 2.1100e-06\n",
            "Epoch 97/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.9710e-06 - val_loss: 1.5016e-07\n",
            "Epoch 98/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.2451e-06 - val_loss: 8.0606e-06\n",
            "Epoch 99/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.5700e-06 - val_loss: 5.5007e-06\n",
            "Epoch 100/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.4162e-06 - val_loss: 6.0147e-06\n",
            "Epoch 101/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.4408e-06 - val_loss: 2.6129e-06\n",
            "Epoch 102/500\n",
            "80/80 [==============================] - 0s 921us/step - loss: 2.9057e-06 - val_loss: 1.8776e-06\n",
            "Epoch 103/500\n",
            "80/80 [==============================] - 0s 963us/step - loss: 9.7823e-07 - val_loss: 1.7846e-07\n",
            "Epoch 104/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.2683e-07 - val_loss: 1.7123e-07\n",
            "Epoch 105/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.3826e-07 - val_loss: 5.3942e-07\n",
            "Epoch 106/500\n",
            "80/80 [==============================] - 0s 973us/step - loss: 9.3742e-07 - val_loss: 1.7162e-07\n",
            "Epoch 107/500\n",
            "80/80 [==============================] - 0s 934us/step - loss: 7.7879e-07 - val_loss: 3.4958e-06\n",
            "Epoch 108/500\n",
            "80/80 [==============================] - 0s 944us/step - loss: 2.2677e-06 - val_loss: 4.6013e-06\n",
            "Epoch 109/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.5812e-06 - val_loss: 2.2511e-06\n",
            "Epoch 110/500\n",
            "80/80 [==============================] - 0s 985us/step - loss: 2.5178e-06 - val_loss: 1.0799e-06\n",
            "Epoch 111/500\n",
            "80/80 [==============================] - 0s 989us/step - loss: 2.2788e-06 - val_loss: 1.0451e-07\n",
            "Epoch 112/500\n",
            "80/80 [==============================] - 0s 989us/step - loss: 1.3781e-06 - val_loss: 3.1593e-07\n",
            "Epoch 113/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.7896e-07 - val_loss: 2.1687e-06\n",
            "Epoch 114/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3364e-06 - val_loss: 1.8438e-06\n",
            "Epoch 115/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1060e-06 - val_loss: 7.1215e-07\n",
            "Epoch 116/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.7745e-07 - val_loss: 3.5203e-07\n",
            "Epoch 117/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7563e-07 - val_loss: 2.3880e-07\n",
            "Epoch 118/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.6204e-07 - val_loss: 8.4103e-08\n",
            "Epoch 119/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0804e-07 - val_loss: 8.4151e-08\n",
            "Epoch 120/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.5495e-08 - val_loss: 1.8495e-07\n",
            "Epoch 121/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.1794e-07 - val_loss: 2.3118e-08\n",
            "Epoch 122/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1446e-07 - val_loss: 1.8127e-07\n",
            "Epoch 123/500\n",
            "80/80 [==============================] - 0s 964us/step - loss: 6.0477e-08 - val_loss: 4.1509e-08\n",
            "Epoch 124/500\n",
            "80/80 [==============================] - 0s 949us/step - loss: 5.4212e-08 - val_loss: 1.2463e-07\n",
            "Epoch 125/500\n",
            "80/80 [==============================] - 0s 991us/step - loss: 5.6566e-08 - val_loss: 1.7080e-07\n",
            "Epoch 126/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.2571e-08 - val_loss: 4.1825e-08\n",
            "Epoch 127/500\n",
            "80/80 [==============================] - 0s 923us/step - loss: 1.6691e-08 - val_loss: 5.9286e-08\n",
            "Epoch 128/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.0222e-08 - val_loss: 3.8440e-08\n",
            "Epoch 129/500\n",
            "80/80 [==============================] - 0s 923us/step - loss: 2.2427e-08 - val_loss: 2.6495e-08\n",
            "Epoch 130/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2668e-08 - val_loss: 2.9281e-08\n",
            "Epoch 131/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3233e-08 - val_loss: 2.4278e-08\n",
            "Epoch 132/500\n",
            "80/80 [==============================] - 0s 939us/step - loss: 9.6547e-09 - val_loss: 3.7324e-08\n",
            "Epoch 133/500\n",
            "80/80 [==============================] - 0s 975us/step - loss: 3.5668e-08 - val_loss: 2.6906e-08\n",
            "Epoch 134/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3317e-08 - val_loss: 2.3436e-08\n",
            "Epoch 135/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.9419e-08 - val_loss: 2.4160e-08\n",
            "Epoch 136/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8264e-08 - val_loss: 2.8548e-08\n",
            "Epoch 137/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.9439e-08 - val_loss: 3.5777e-08\n",
            "Epoch 138/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.1200e-08 - val_loss: 1.7859e-08\n",
            "Epoch 139/500\n",
            "80/80 [==============================] - 0s 996us/step - loss: 3.0710e-08 - val_loss: 1.1160e-07\n",
            "Epoch 140/500\n",
            "80/80 [==============================] - 0s 949us/step - loss: 6.8158e-08 - val_loss: 2.1189e-07\n",
            "Epoch 141/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1712e-07 - val_loss: 9.3477e-08\n",
            "Epoch 142/500\n",
            "80/80 [==============================] - 0s 984us/step - loss: 5.3044e-08 - val_loss: 5.0126e-08\n",
            "Epoch 143/500\n",
            "80/80 [==============================] - 0s 966us/step - loss: 2.2723e-08 - val_loss: 8.2744e-08\n",
            "Epoch 144/500\n",
            "80/80 [==============================] - 0s 992us/step - loss: 4.4458e-08 - val_loss: 4.2610e-08\n",
            "Epoch 145/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.9194e-08 - val_loss: 2.0802e-08\n",
            "Epoch 146/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.0311e-08 - val_loss: 1.5593e-07\n",
            "Epoch 147/500\n",
            "80/80 [==============================] - 0s 992us/step - loss: 7.9660e-08 - val_loss: 1.7587e-07\n",
            "Epoch 148/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.9909e-08 - val_loss: 6.3244e-08\n",
            "Epoch 149/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.5317e-08 - val_loss: 5.9197e-08\n",
            "Epoch 150/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.0581e-08 - val_loss: 6.2358e-08\n",
            "Epoch 151/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.9534e-08 - val_loss: 4.2361e-08\n",
            "Epoch 152/500\n",
            "80/80 [==============================] - 0s 968us/step - loss: 4.2947e-08 - val_loss: 3.4150e-08\n",
            "Epoch 153/500\n",
            "80/80 [==============================] - 0s 981us/step - loss: 1.0083e-07 - val_loss: 7.4361e-08\n",
            "Epoch 154/500\n",
            "80/80 [==============================] - 0s 982us/step - loss: 9.9459e-08 - val_loss: 4.7264e-07\n",
            "Epoch 155/500\n",
            "80/80 [==============================] - 0s 925us/step - loss: 2.5716e-07 - val_loss: 1.3096e-07\n",
            "Epoch 156/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3173e-07 - val_loss: 5.5193e-07\n",
            "Epoch 157/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.5471e-07 - val_loss: 2.2580e-07\n",
            "Epoch 158/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.2329e-07 - val_loss: 3.5982e-07\n",
            "Epoch 159/500\n",
            "80/80 [==============================] - 0s 974us/step - loss: 4.8510e-07 - val_loss: 9.9310e-07\n",
            "Epoch 160/500\n",
            "80/80 [==============================] - 0s 987us/step - loss: 5.8889e-07 - val_loss: 5.5383e-07\n",
            "Epoch 161/500\n",
            "80/80 [==============================] - 0s 982us/step - loss: 3.8184e-07 - val_loss: 1.3198e-07\n",
            "Epoch 162/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8037e-07 - val_loss: 4.9196e-08\n",
            "Epoch 163/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4819e-07 - val_loss: 2.1916e-07\n",
            "Epoch 164/500\n",
            "80/80 [==============================] - 0s 961us/step - loss: 7.3487e-08 - val_loss: 5.4252e-08\n",
            "Epoch 165/500\n",
            "80/80 [==============================] - 0s 953us/step - loss: 6.4186e-08 - val_loss: 3.9426e-08\n",
            "Epoch 166/500\n",
            "80/80 [==============================] - 0s 974us/step - loss: 1.2910e-07 - val_loss: 2.1182e-07\n",
            "Epoch 167/500\n",
            "80/80 [==============================] - 0s 944us/step - loss: 1.1258e-07 - val_loss: 7.0407e-08\n",
            "Epoch 168/500\n",
            "80/80 [==============================] - 0s 962us/step - loss: 6.8850e-08 - val_loss: 2.3920e-08\n",
            "Epoch 169/500\n",
            "80/80 [==============================] - 0s 913us/step - loss: 3.1103e-08 - val_loss: 1.7098e-07\n",
            "Epoch 170/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 1.3923e-07 - val_loss: 3.8185e-08\n",
            "Epoch 171/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.9495e-08 - val_loss: 3.0050e-08\n",
            "Epoch 172/500\n",
            "80/80 [==============================] - 0s 989us/step - loss: 2.6886e-08 - val_loss: 1.6358e-07\n",
            "Epoch 173/500\n",
            "80/80 [==============================] - 0s 978us/step - loss: 5.8899e-08 - val_loss: 3.2421e-08\n",
            "Epoch 174/500\n",
            "80/80 [==============================] - 0s 996us/step - loss: 2.7287e-08 - val_loss: 7.1889e-08\n",
            "Epoch 175/500\n",
            "80/80 [==============================] - 0s 959us/step - loss: 5.4302e-08 - val_loss: 4.0207e-08\n",
            "Epoch 176/500\n",
            "80/80 [==============================] - 0s 997us/step - loss: 1.3510e-08 - val_loss: 4.3667e-08\n",
            "Epoch 177/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8036e-08 - val_loss: 2.1811e-08\n",
            "Epoch 178/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1061e-08 - val_loss: 2.8591e-08\n",
            "Epoch 179/500\n",
            "80/80 [==============================] - 0s 924us/step - loss: 9.2458e-09 - val_loss: 3.6001e-08\n",
            "Epoch 180/500\n",
            "80/80 [==============================] - 0s 946us/step - loss: 2.2286e-08 - val_loss: 2.2414e-08\n",
            "Epoch 181/500\n",
            "80/80 [==============================] - 0s 974us/step - loss: 7.8601e-09 - val_loss: 3.1569e-08\n",
            "Epoch 182/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.5514e-08 - val_loss: 2.0712e-08\n",
            "Epoch 183/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.8401e-09 - val_loss: 2.2537e-08\n",
            "Epoch 184/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.6220e-09 - val_loss: 1.8243e-08\n",
            "Epoch 185/500\n",
            "80/80 [==============================] - 0s 988us/step - loss: 7.4590e-09 - val_loss: 2.2738e-08\n",
            "Epoch 186/500\n",
            "80/80 [==============================] - 0s 949us/step - loss: 8.4776e-09 - val_loss: 1.8829e-08\n",
            "Epoch 187/500\n",
            "80/80 [==============================] - 0s 922us/step - loss: 5.9590e-09 - val_loss: 2.0752e-08\n",
            "Epoch 188/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.5156e-09 - val_loss: 7.3059e-08\n",
            "Epoch 189/500\n",
            "80/80 [==============================] - 0s 978us/step - loss: 8.2599e-08 - val_loss: 4.6429e-08\n",
            "Epoch 190/500\n",
            "80/80 [==============================] - 0s 971us/step - loss: 4.1411e-08 - val_loss: 8.7715e-08\n",
            "Epoch 191/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.1934e-08 - val_loss: 9.0558e-08\n",
            "Epoch 192/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.1797e-08 - val_loss: 1.7918e-07\n",
            "Epoch 193/500\n",
            "80/80 [==============================] - 0s 996us/step - loss: 1.0090e-07 - val_loss: 5.9824e-08\n",
            "Epoch 194/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.7672e-08 - val_loss: 5.9725e-08\n",
            "Epoch 195/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.9055e-08 - val_loss: 6.7724e-08\n",
            "Epoch 196/500\n",
            "80/80 [==============================] - 0s 970us/step - loss: 8.2021e-08 - val_loss: 9.3940e-08\n",
            "Epoch 197/500\n",
            "80/80 [==============================] - 0s 978us/step - loss: 7.1534e-08 - val_loss: 2.5610e-08\n",
            "Epoch 198/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.1727e-08 - val_loss: 3.3490e-08\n",
            "Epoch 199/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.6992e-08 - val_loss: 1.7160e-07\n",
            "Epoch 200/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2989e-07 - val_loss: 3.4944e-08\n",
            "Epoch 201/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.1042e-09 - val_loss: 9.9449e-08\n",
            "Epoch 202/500\n",
            "80/80 [==============================] - 0s 982us/step - loss: 2.2145e-08 - val_loss: 1.3168e-07\n",
            "Epoch 203/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.0434e-08 - val_loss: 4.4070e-08\n",
            "Epoch 204/500\n",
            "80/80 [==============================] - 0s 985us/step - loss: 4.2408e-08 - val_loss: 7.7686e-08\n",
            "Epoch 205/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.4017e-08 - val_loss: 9.0229e-08\n",
            "Epoch 206/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0864e-07 - val_loss: 2.8280e-08\n",
            "Epoch 207/500\n",
            "80/80 [==============================] - 0s 950us/step - loss: 4.9056e-08 - val_loss: 7.0111e-08\n",
            "Epoch 208/500\n",
            "80/80 [==============================] - 0s 983us/step - loss: 6.8199e-08 - val_loss: 5.6168e-08\n",
            "Epoch 209/500\n",
            "80/80 [==============================] - 0s 951us/step - loss: 2.3601e-08 - val_loss: 2.8007e-08\n",
            "Epoch 210/500\n",
            "80/80 [==============================] - 0s 968us/step - loss: 2.5853e-08 - val_loss: 5.9452e-08\n",
            "Epoch 211/500\n",
            "80/80 [==============================] - 0s 983us/step - loss: 4.6716e-08 - val_loss: 3.7146e-08\n",
            "Epoch 212/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.3886e-08 - val_loss: 5.3360e-08\n",
            "Epoch 213/500\n",
            "80/80 [==============================] - 0s 996us/step - loss: 1.2380e-08 - val_loss: 2.9320e-08\n",
            "Epoch 214/500\n",
            "80/80 [==============================] - 0s 956us/step - loss: 3.1245e-08 - val_loss: 3.0509e-08\n",
            "Epoch 215/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4416e-08 - val_loss: 5.8386e-08\n",
            "Epoch 216/500\n",
            "80/80 [==============================] - 0s 980us/step - loss: 2.0248e-08 - val_loss: 5.6108e-08\n",
            "Epoch 217/500\n",
            "80/80 [==============================] - 0s 972us/step - loss: 4.4685e-08 - val_loss: 1.3999e-07\n",
            "Epoch 218/500\n",
            "80/80 [==============================] - 0s 991us/step - loss: 7.1191e-08 - val_loss: 3.4560e-08\n",
            "Epoch 219/500\n",
            "80/80 [==============================] - 0s 974us/step - loss: 2.5435e-08 - val_loss: 1.1367e-07\n",
            "Epoch 220/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.2364e-08 - val_loss: 1.3218e-07\n",
            "Epoch 221/500\n",
            "80/80 [==============================] - 0s 949us/step - loss: 1.0616e-07 - val_loss: 2.9317e-07\n",
            "Epoch 222/500\n",
            "80/80 [==============================] - 0s 981us/step - loss: 2.5790e-07 - val_loss: 3.0445e-07\n",
            "Epoch 223/500\n",
            "80/80 [==============================] - 0s 976us/step - loss: 4.4305e-07 - val_loss: 3.0683e-07\n",
            "Epoch 224/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.3319e-07 - val_loss: 1.3818e-06\n",
            "Epoch 225/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0792e-06 - val_loss: 3.4194e-07\n",
            "Epoch 226/500\n",
            "80/80 [==============================] - 0s 986us/step - loss: 3.8550e-07 - val_loss: 1.1038e-06\n",
            "Epoch 227/500\n",
            "80/80 [==============================] - 0s 998us/step - loss: 1.2822e-06 - val_loss: 1.6410e-07\n",
            "Epoch 228/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.6827e-07 - val_loss: 3.0206e-06\n",
            "Epoch 229/500\n",
            "80/80 [==============================] - 0s 989us/step - loss: 3.3367e-06 - val_loss: 4.8912e-07\n",
            "Epoch 230/500\n",
            "80/80 [==============================] - 0s 946us/step - loss: 6.7582e-07 - val_loss: 1.5285e-06\n",
            "Epoch 231/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.3276e-07 - val_loss: 2.1887e-06\n",
            "Epoch 232/500\n",
            "80/80 [==============================] - 0s 976us/step - loss: 1.7037e-06 - val_loss: 1.9322e-07\n",
            "Epoch 233/500\n",
            "80/80 [==============================] - 0s 985us/step - loss: 4.8020e-07 - val_loss: 1.4627e-06\n",
            "Epoch 234/500\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 4.0040e-06 - val_loss: 3.3724e-06\n",
            "Epoch 235/500\n",
            "80/80 [==============================] - 0s 945us/step - loss: 1.6903e-06 - val_loss: 3.7458e-06\n",
            "Epoch 236/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7667e-06 - val_loss: 1.9329e-06\n",
            "Epoch 237/500\n",
            "80/80 [==============================] - 0s 982us/step - loss: 3.3750e-06 - val_loss: 3.9103e-06\n",
            "Epoch 238/500\n",
            "80/80 [==============================] - 0s 942us/step - loss: 3.1306e-06 - val_loss: 3.6939e-06\n",
            "Epoch 239/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.5394e-06 - val_loss: 3.5029e-06\n",
            "Epoch 240/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4320e-06 - val_loss: 3.2361e-06\n",
            "Epoch 241/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.5369e-06 - val_loss: 3.5489e-06\n",
            "Epoch 242/500\n",
            "80/80 [==============================] - 0s 953us/step - loss: 6.6895e-06 - val_loss: 6.4758e-06\n",
            "Epoch 243/500\n",
            "80/80 [==============================] - 0s 952us/step - loss: 3.2181e-06 - val_loss: 1.7232e-06\n",
            "Epoch 244/500\n",
            "80/80 [==============================] - 0s 979us/step - loss: 6.2128e-06 - val_loss: 4.5647e-07\n",
            "Epoch 245/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 3.0105e-06 - val_loss: 7.0300e-06\n",
            "Epoch 246/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.5867e-06 - val_loss: 5.6374e-07\n",
            "Epoch 247/500\n",
            "80/80 [==============================] - 0s 968us/step - loss: 1.1988e-06 - val_loss: 6.1000e-07\n",
            "Epoch 248/500\n",
            "80/80 [==============================] - 0s 942us/step - loss: 9.6580e-07 - val_loss: 3.1362e-06\n",
            "Epoch 249/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.7970e-06 - val_loss: 1.5153e-06\n",
            "Epoch 250/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.5414e-06 - val_loss: 9.7446e-06\n",
            "Epoch 251/500\n",
            "80/80 [==============================] - 0s 925us/step - loss: 4.9039e-06 - val_loss: 6.2345e-06\n",
            "Epoch 252/500\n",
            "80/80 [==============================] - 0s 962us/step - loss: 3.1340e-06 - val_loss: 4.1507e-06\n",
            "Epoch 253/500\n",
            "80/80 [==============================] - 0s 927us/step - loss: 2.7172e-06 - val_loss: 1.0133e-05\n",
            "Epoch 254/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.8223e-06 - val_loss: 2.3946e-06\n",
            "Epoch 255/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.5196e-06 - val_loss: 7.5541e-07\n",
            "Epoch 256/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0920e-06 - val_loss: 2.2649e-06\n",
            "Epoch 257/500\n",
            "80/80 [==============================] - 0s 946us/step - loss: 2.8640e-06 - val_loss: 5.1791e-07\n",
            "Epoch 258/500\n",
            "80/80 [==============================] - 0s 956us/step - loss: 7.1101e-06 - val_loss: 4.2201e-07\n",
            "Epoch 259/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 3.2751e-06 - val_loss: 6.6274e-06\n",
            "Epoch 260/500\n",
            "80/80 [==============================] - 0s 935us/step - loss: 4.4935e-06 - val_loss: 2.4011e-06\n",
            "Epoch 261/500\n",
            "80/80 [==============================] - 0s 998us/step - loss: 7.7258e-06 - val_loss: 3.4261e-06\n",
            "Epoch 262/500\n",
            "80/80 [==============================] - 0s 983us/step - loss: 5.5193e-06 - val_loss: 8.1234e-06\n",
            "Epoch 263/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.7605e-06 - val_loss: 5.9890e-06\n",
            "Epoch 264/500\n",
            "80/80 [==============================] - 0s 956us/step - loss: 5.9558e-06 - val_loss: 4.5759e-06\n",
            "Epoch 265/500\n",
            "80/80 [==============================] - 0s 987us/step - loss: 3.0286e-06 - val_loss: 6.5765e-06\n",
            "Epoch 266/500\n",
            "80/80 [==============================] - 0s 997us/step - loss: 5.2157e-06 - val_loss: 2.2876e-06\n",
            "Epoch 267/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.1095e-06 - val_loss: 2.1342e-06\n",
            "Epoch 268/500\n",
            "80/80 [==============================] - 0s 963us/step - loss: 2.4594e-06 - val_loss: 6.0255e-06\n",
            "Epoch 269/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.2966e-06 - val_loss: 2.1695e-06\n",
            "Epoch 270/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.9206e-06 - val_loss: 1.2070e-06\n",
            "Epoch 271/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7008e-06 - val_loss: 4.0615e-06\n",
            "Epoch 272/500\n",
            "80/80 [==============================] - 0s 945us/step - loss: 2.9440e-06 - val_loss: 4.1943e-06\n",
            "Epoch 273/500\n",
            "80/80 [==============================] - 0s 969us/step - loss: 3.2323e-06 - val_loss: 4.6001e-06\n",
            "Epoch 274/500\n",
            "80/80 [==============================] - 0s 966us/step - loss: 4.2521e-06 - val_loss: 6.1121e-06\n",
            "Epoch 275/500\n",
            "80/80 [==============================] - 0s 988us/step - loss: 4.2812e-06 - val_loss: 3.1620e-06\n",
            "Epoch 276/500\n",
            "80/80 [==============================] - 0s 942us/step - loss: 3.0930e-06 - val_loss: 3.8419e-06\n",
            "Epoch 277/500\n",
            "80/80 [==============================] - 0s 935us/step - loss: 3.9340e-06 - val_loss: 1.2124e-06\n",
            "Epoch 278/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2846e-06 - val_loss: 2.8105e-06\n",
            "Epoch 279/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.1659e-06 - val_loss: 2.0788e-06\n",
            "Epoch 280/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2994e-06 - val_loss: 5.8310e-07\n",
            "Epoch 281/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3384e-06 - val_loss: 6.1907e-07\n",
            "Epoch 282/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.1471e-06 - val_loss: 1.2752e-06\n",
            "Epoch 283/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7916e-06 - val_loss: 3.2918e-07\n",
            "Epoch 284/500\n",
            "80/80 [==============================] - 0s 975us/step - loss: 1.5716e-06 - val_loss: 1.4286e-06\n",
            "Epoch 285/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8685e-06 - val_loss: 1.5106e-06\n",
            "Epoch 286/500\n",
            "80/80 [==============================] - 0s 923us/step - loss: 2.9217e-06 - val_loss: 1.0965e-06\n",
            "Epoch 287/500\n",
            "80/80 [==============================] - 0s 959us/step - loss: 1.8458e-06 - val_loss: 2.6643e-06\n",
            "Epoch 288/500\n",
            "80/80 [==============================] - 0s 997us/step - loss: 2.4590e-06 - val_loss: 4.1128e-06\n",
            "Epoch 289/500\n",
            "80/80 [==============================] - 0s 998us/step - loss: 3.6928e-06 - val_loss: 1.6452e-06\n",
            "Epoch 290/500\n",
            "80/80 [==============================] - 0s 965us/step - loss: 9.4236e-07 - val_loss: 5.4704e-07\n",
            "Epoch 291/500\n",
            "80/80 [==============================] - 0s 954us/step - loss: 2.6573e-07 - val_loss: 2.5308e-07\n",
            "Epoch 292/500\n",
            "80/80 [==============================] - 0s 960us/step - loss: 1.5603e-07 - val_loss: 1.1669e-07\n",
            "Epoch 293/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3561e-07 - val_loss: 1.1061e-07\n",
            "Epoch 294/500\n",
            "80/80 [==============================] - 0s 988us/step - loss: 1.0383e-07 - val_loss: 9.9888e-08\n",
            "Epoch 295/500\n",
            "80/80 [==============================] - 0s 947us/step - loss: 6.6042e-08 - val_loss: 3.9731e-08\n",
            "Epoch 296/500\n",
            "80/80 [==============================] - 0s 917us/step - loss: 1.3521e-07 - val_loss: 6.1069e-08\n",
            "Epoch 297/500\n",
            "80/80 [==============================] - 0s 961us/step - loss: 1.1446e-07 - val_loss: 2.2675e-07\n",
            "Epoch 298/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7880e-07 - val_loss: 2.5089e-07\n",
            "Epoch 299/500\n",
            "80/80 [==============================] - 0s 961us/step - loss: 3.8211e-07 - val_loss: 8.6852e-07\n",
            "Epoch 300/500\n",
            "80/80 [==============================] - 0s 997us/step - loss: 7.0778e-07 - val_loss: 9.2101e-07\n",
            "Epoch 301/500\n",
            "80/80 [==============================] - 0s 968us/step - loss: 5.6149e-07 - val_loss: 4.7205e-07\n",
            "Epoch 302/500\n",
            "80/80 [==============================] - 0s 984us/step - loss: 3.6513e-07 - val_loss: 5.3190e-07\n",
            "Epoch 303/500\n",
            "80/80 [==============================] - 0s 963us/step - loss: 4.9886e-07 - val_loss: 4.8478e-07\n",
            "Epoch 304/500\n",
            "80/80 [==============================] - 0s 982us/step - loss: 4.0342e-07 - val_loss: 8.5937e-07\n",
            "Epoch 305/500\n",
            "80/80 [==============================] - 0s 909us/step - loss: 7.0393e-07 - val_loss: 6.4343e-07\n",
            "Epoch 306/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.2723e-07 - val_loss: 2.1237e-06\n",
            "Epoch 307/500\n",
            "80/80 [==============================] - 0s 957us/step - loss: 1.5526e-06 - val_loss: 6.5748e-07\n",
            "Epoch 308/500\n",
            "80/80 [==============================] - 0s 942us/step - loss: 1.1942e-06 - val_loss: 1.3578e-07\n",
            "Epoch 309/500\n",
            "80/80 [==============================] - 0s 978us/step - loss: 5.0564e-07 - val_loss: 8.8544e-07\n",
            "Epoch 310/500\n",
            "80/80 [==============================] - 0s 925us/step - loss: 3.2752e-07 - val_loss: 5.1360e-07\n",
            "Epoch 311/500\n",
            "80/80 [==============================] - 0s 992us/step - loss: 2.6844e-07 - val_loss: 2.8353e-07\n",
            "Epoch 312/500\n",
            "80/80 [==============================] - 0s 963us/step - loss: 3.4692e-07 - val_loss: 8.3122e-07\n",
            "Epoch 313/500\n",
            "80/80 [==============================] - 0s 960us/step - loss: 8.2603e-07 - val_loss: 9.3802e-08\n",
            "Epoch 314/500\n",
            "80/80 [==============================] - 0s 933us/step - loss: 7.0472e-07 - val_loss: 1.7365e-07\n",
            "Epoch 315/500\n",
            "80/80 [==============================] - 0s 946us/step - loss: 3.9311e-07 - val_loss: 1.7666e-07\n",
            "Epoch 316/500\n",
            "80/80 [==============================] - 0s 973us/step - loss: 2.1183e-07 - val_loss: 1.1495e-07\n",
            "Epoch 317/500\n",
            "80/80 [==============================] - 0s 995us/step - loss: 1.1109e-07 - val_loss: 8.7880e-08\n",
            "Epoch 318/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.7477e-08 - val_loss: 1.0476e-07\n",
            "Epoch 319/500\n",
            "80/80 [==============================] - 0s 974us/step - loss: 6.0561e-08 - val_loss: 3.0471e-08\n",
            "Epoch 320/500\n",
            "80/80 [==============================] - 0s 951us/step - loss: 1.3733e-07 - val_loss: 1.1513e-07\n",
            "Epoch 321/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4977e-07 - val_loss: 9.7188e-08\n",
            "Epoch 322/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.9427e-07 - val_loss: 8.2253e-08\n",
            "Epoch 323/500\n",
            "80/80 [==============================] - 0s 949us/step - loss: 1.7918e-07 - val_loss: 6.3950e-08\n",
            "Epoch 324/500\n",
            "80/80 [==============================] - 0s 938us/step - loss: 3.4590e-07 - val_loss: 1.6477e-07\n",
            "Epoch 325/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.7881e-07 - val_loss: 4.3644e-07\n",
            "Epoch 326/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 4.9167e-07 - val_loss: 1.3264e-07\n",
            "Epoch 327/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.0575e-07 - val_loss: 2.5325e-07\n",
            "Epoch 328/500\n",
            "80/80 [==============================] - 0s 991us/step - loss: 4.1114e-07 - val_loss: 3.5210e-07\n",
            "Epoch 329/500\n",
            "80/80 [==============================] - 0s 942us/step - loss: 3.5755e-07 - val_loss: 2.9746e-08\n",
            "Epoch 330/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.5137e-07 - val_loss: 7.3593e-08\n",
            "Epoch 331/500\n",
            "80/80 [==============================] - 0s 954us/step - loss: 1.6938e-07 - val_loss: 9.7862e-08\n",
            "Epoch 332/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3473e-07 - val_loss: 6.5546e-08\n",
            "Epoch 333/500\n",
            "80/80 [==============================] - 0s 913us/step - loss: 9.5763e-08 - val_loss: 3.9403e-08\n",
            "Epoch 334/500\n",
            "80/80 [==============================] - 0s 911us/step - loss: 5.0828e-08 - val_loss: 4.3002e-08\n",
            "Epoch 335/500\n",
            "80/80 [==============================] - 0s 970us/step - loss: 2.0478e-07 - val_loss: 9.0364e-08\n",
            "Epoch 336/500\n",
            "80/80 [==============================] - 0s 994us/step - loss: 7.2912e-08 - val_loss: 2.2241e-07\n",
            "Epoch 337/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.6098e-08 - val_loss: 2.0625e-07\n",
            "Epoch 338/500\n",
            "80/80 [==============================] - 0s 946us/step - loss: 1.1328e-07 - val_loss: 1.5540e-06\n",
            "Epoch 339/500\n",
            "80/80 [==============================] - 0s 981us/step - loss: 8.7515e-07 - val_loss: 8.3586e-07\n",
            "Epoch 340/500\n",
            "80/80 [==============================] - 0s 951us/step - loss: 2.8606e-07 - val_loss: 6.0989e-07\n",
            "Epoch 341/500\n",
            "80/80 [==============================] - 0s 974us/step - loss: 3.0659e-07 - val_loss: 4.8841e-07\n",
            "Epoch 342/500\n",
            "80/80 [==============================] - 0s 981us/step - loss: 2.1135e-07 - val_loss: 6.4049e-07\n",
            "Epoch 343/500\n",
            "80/80 [==============================] - 0s 942us/step - loss: 6.2961e-07 - val_loss: 2.6382e-07\n",
            "Epoch 344/500\n",
            "80/80 [==============================] - 0s 969us/step - loss: 2.1573e-07 - val_loss: 1.8981e-07\n",
            "Epoch 345/500\n",
            "80/80 [==============================] - 0s 976us/step - loss: 1.6955e-07 - val_loss: 2.8924e-07\n",
            "Epoch 346/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.6917e-07 - val_loss: 1.3901e-07\n",
            "Epoch 347/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2244e-07 - val_loss: 5.4122e-07\n",
            "Epoch 348/500\n",
            "80/80 [==============================] - 0s 965us/step - loss: 3.9782e-07 - val_loss: 4.1266e-07\n",
            "Epoch 349/500\n",
            "80/80 [==============================] - 0s 911us/step - loss: 1.7313e-07 - val_loss: 2.8216e-07\n",
            "Epoch 350/500\n",
            "80/80 [==============================] - 0s 930us/step - loss: 1.9878e-07 - val_loss: 6.3537e-07\n",
            "Epoch 351/500\n",
            "80/80 [==============================] - 0s 932us/step - loss: 4.8158e-07 - val_loss: 1.4367e-07\n",
            "Epoch 352/500\n",
            "80/80 [==============================] - 0s 994us/step - loss: 3.9970e-08 - val_loss: 1.2936e-07\n",
            "Epoch 353/500\n",
            "80/80 [==============================] - 0s 964us/step - loss: 1.8375e-07 - val_loss: 1.1948e-07\n",
            "Epoch 354/500\n",
            "80/80 [==============================] - 0s 972us/step - loss: 7.4762e-08 - val_loss: 6.3659e-08\n",
            "Epoch 355/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.4027e-08 - val_loss: 5.7236e-08\n",
            "Epoch 356/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.6279e-08 - val_loss: 1.1849e-07\n",
            "Epoch 357/500\n",
            "80/80 [==============================] - 0s 996us/step - loss: 5.3575e-08 - val_loss: 7.7324e-08\n",
            "Epoch 358/500\n",
            "80/80 [==============================] - 0s 964us/step - loss: 4.6449e-08 - val_loss: 1.4938e-07\n",
            "Epoch 359/500\n",
            "80/80 [==============================] - 0s 941us/step - loss: 1.2411e-07 - val_loss: 1.1441e-07\n",
            "Epoch 360/500\n",
            "80/80 [==============================] - 0s 912us/step - loss: 6.8782e-08 - val_loss: 8.2564e-08\n",
            "Epoch 361/500\n",
            "80/80 [==============================] - 0s 942us/step - loss: 7.4576e-08 - val_loss: 1.5180e-07\n",
            "Epoch 362/500\n",
            "80/80 [==============================] - 0s 944us/step - loss: 9.4283e-08 - val_loss: 6.3152e-08\n",
            "Epoch 363/500\n",
            "80/80 [==============================] - 0s 971us/step - loss: 3.3372e-08 - val_loss: 1.3698e-07\n",
            "Epoch 364/500\n",
            "80/80 [==============================] - 0s 960us/step - loss: 3.4888e-08 - val_loss: 2.5785e-08\n",
            "Epoch 365/500\n",
            "80/80 [==============================] - 0s 968us/step - loss: 3.4550e-08 - val_loss: 7.6360e-08\n",
            "Epoch 366/500\n",
            "80/80 [==============================] - 0s 951us/step - loss: 2.5607e-08 - val_loss: 9.0584e-08\n",
            "Epoch 367/500\n",
            "80/80 [==============================] - 0s 984us/step - loss: 4.5354e-08 - val_loss: 8.9807e-08\n",
            "Epoch 368/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.8005e-08 - val_loss: 8.4477e-08\n",
            "Epoch 369/500\n",
            "80/80 [==============================] - 0s 937us/step - loss: 2.8136e-08 - val_loss: 1.3000e-07\n",
            "Epoch 370/500\n",
            "80/80 [==============================] - 0s 936us/step - loss: 3.1664e-08 - val_loss: 1.5150e-07\n",
            "Epoch 371/500\n",
            "80/80 [==============================] - 0s 961us/step - loss: 7.8129e-08 - val_loss: 1.3388e-07\n",
            "Epoch 372/500\n",
            "80/80 [==============================] - 0s 956us/step - loss: 9.2658e-08 - val_loss: 6.9128e-08\n",
            "Epoch 373/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.5291e-08 - val_loss: 4.1502e-08\n",
            "Epoch 374/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0512e-08 - val_loss: 3.9979e-08\n",
            "Epoch 375/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3908e-08 - val_loss: 3.2887e-08\n",
            "Epoch 376/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4282e-08 - val_loss: 6.1310e-08\n",
            "Epoch 377/500\n",
            "80/80 [==============================] - 0s 992us/step - loss: 2.4966e-08 - val_loss: 4.9003e-08\n",
            "Epoch 378/500\n",
            "80/80 [==============================] - 0s 978us/step - loss: 1.0751e-08 - val_loss: 2.9269e-08\n",
            "Epoch 379/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2393e-08 - val_loss: 3.6256e-08\n",
            "Epoch 380/500\n",
            "80/80 [==============================] - 0s 981us/step - loss: 1.1242e-08 - val_loss: 7.2395e-08\n",
            "Epoch 381/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.2766e-08 - val_loss: 4.8250e-08\n",
            "Epoch 382/500\n",
            "80/80 [==============================] - 0s 981us/step - loss: 2.8521e-08 - val_loss: 6.2687e-08\n",
            "Epoch 383/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.0536e-08 - val_loss: 1.4411e-07\n",
            "Epoch 384/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.1680e-08 - val_loss: 5.4155e-08\n",
            "Epoch 385/500\n",
            "80/80 [==============================] - 0s 947us/step - loss: 3.0580e-08 - val_loss: 6.1858e-08\n",
            "Epoch 386/500\n",
            "80/80 [==============================] - 0s 970us/step - loss: 3.3948e-08 - val_loss: 6.5789e-08\n",
            "Epoch 387/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.1668e-08 - val_loss: 3.4425e-08\n",
            "Epoch 388/500\n",
            "80/80 [==============================] - 0s 991us/step - loss: 1.8823e-08 - val_loss: 5.7598e-08\n",
            "Epoch 389/500\n",
            "80/80 [==============================] - 0s 970us/step - loss: 1.6776e-08 - val_loss: 6.8341e-08\n",
            "Epoch 390/500\n",
            "80/80 [==============================] - 0s 953us/step - loss: 1.8081e-08 - val_loss: 4.0197e-08\n",
            "Epoch 391/500\n",
            "80/80 [==============================] - 0s 993us/step - loss: 7.3177e-08 - val_loss: 9.8020e-08\n",
            "Epoch 392/500\n",
            "80/80 [==============================] - 0s 966us/step - loss: 6.3613e-08 - val_loss: 1.5310e-07\n",
            "Epoch 393/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.8472e-08 - val_loss: 1.4725e-07\n",
            "Epoch 394/500\n",
            "80/80 [==============================] - 0s 971us/step - loss: 1.4211e-07 - val_loss: 9.7727e-08\n",
            "Epoch 395/500\n",
            "80/80 [==============================] - 0s 950us/step - loss: 9.0249e-08 - val_loss: 4.0953e-08\n",
            "Epoch 396/500\n",
            "80/80 [==============================] - 0s 930us/step - loss: 7.9831e-08 - val_loss: 7.8828e-08\n",
            "Epoch 397/500\n",
            "80/80 [==============================] - 0s 974us/step - loss: 5.0016e-08 - val_loss: 7.8212e-08\n",
            "Epoch 398/500\n",
            "80/80 [==============================] - 0s 959us/step - loss: 8.5671e-08 - val_loss: 1.3634e-07\n",
            "Epoch 399/500\n",
            "80/80 [==============================] - 0s 995us/step - loss: 1.2045e-07 - val_loss: 4.7674e-07\n",
            "Epoch 400/500\n",
            "80/80 [==============================] - 0s 954us/step - loss: 1.8946e-07 - val_loss: 3.2505e-07\n",
            "Epoch 401/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 1.3366e-07 - val_loss: 9.2225e-08\n",
            "Epoch 402/500\n",
            "80/80 [==============================] - 0s 945us/step - loss: 1.1860e-07 - val_loss: 4.6465e-08\n",
            "Epoch 403/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7427e-08 - val_loss: 9.7522e-08\n",
            "Epoch 404/500\n",
            "80/80 [==============================] - 0s 980us/step - loss: 2.1860e-08 - val_loss: 3.6816e-08\n",
            "Epoch 405/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.7715e-08 - val_loss: 1.0151e-07\n",
            "Epoch 406/500\n",
            "80/80 [==============================] - 0s 985us/step - loss: 2.2707e-07 - val_loss: 2.0475e-07\n",
            "Epoch 407/500\n",
            "80/80 [==============================] - 0s 998us/step - loss: 9.6934e-08 - val_loss: 5.4509e-08\n",
            "Epoch 408/500\n",
            "80/80 [==============================] - 0s 976us/step - loss: 3.7681e-08 - val_loss: 5.2174e-08\n",
            "Epoch 409/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.9007e-08 - val_loss: 1.4830e-07\n",
            "Epoch 410/500\n",
            "80/80 [==============================] - 0s 944us/step - loss: 9.1184e-08 - val_loss: 1.0105e-07\n",
            "Epoch 411/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.5783e-07 - val_loss: 2.1069e-07\n",
            "Epoch 412/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1131e-07 - val_loss: 1.1216e-07\n",
            "Epoch 413/500\n",
            "80/80 [==============================] - 0s 985us/step - loss: 1.2305e-07 - val_loss: 1.6498e-07\n",
            "Epoch 414/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 1.0842e-07 - val_loss: 5.2499e-07\n",
            "Epoch 415/500\n",
            "80/80 [==============================] - 0s 942us/step - loss: 1.6358e-07 - val_loss: 4.3242e-07\n",
            "Epoch 416/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.6547e-07 - val_loss: 1.7988e-07\n",
            "Epoch 417/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.0478e-07 - val_loss: 7.8171e-07\n",
            "Epoch 418/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.9406e-07 - val_loss: 1.0965e-07\n",
            "Epoch 419/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.5978e-07 - val_loss: 4.6673e-07\n",
            "Epoch 420/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8082e-07 - val_loss: 1.5433e-07\n",
            "Epoch 421/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4801e-07 - val_loss: 1.5623e-07\n",
            "Epoch 422/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.4346e-08 - val_loss: 1.9344e-07\n",
            "Epoch 423/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.8515e-08 - val_loss: 1.4145e-07\n",
            "Epoch 424/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.2866e-07 - val_loss: 3.4713e-07\n",
            "Epoch 425/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.9774e-07 - val_loss: 4.7127e-07\n",
            "Epoch 426/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.1291e-07 - val_loss: 2.8385e-07\n",
            "Epoch 427/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.1886e-07 - val_loss: 1.7263e-07\n",
            "Epoch 428/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.1725e-07 - val_loss: 2.4854e-07\n",
            "Epoch 429/500\n",
            "80/80 [==============================] - 0s 960us/step - loss: 1.3438e-06 - val_loss: 7.8578e-07\n",
            "Epoch 430/500\n",
            "80/80 [==============================] - 0s 999us/step - loss: 2.3202e-06 - val_loss: 2.0206e-06\n",
            "Epoch 431/500\n",
            "80/80 [==============================] - 0s 942us/step - loss: 1.8358e-06 - val_loss: 4.4768e-06\n",
            "Epoch 432/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 2.2772e-06 - val_loss: 2.2832e-06\n",
            "Epoch 433/500\n",
            "80/80 [==============================] - 0s 941us/step - loss: 1.5110e-06 - val_loss: 4.2110e-07\n",
            "Epoch 434/500\n",
            "80/80 [==============================] - 0s 945us/step - loss: 7.1372e-07 - val_loss: 6.0113e-07\n",
            "Epoch 435/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.6314e-07 - val_loss: 2.2902e-07\n",
            "Epoch 436/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.5912e-07 - val_loss: 5.3077e-07\n",
            "Epoch 437/500\n",
            "80/80 [==============================] - 0s 958us/step - loss: 4.3314e-07 - val_loss: 1.6519e-07\n",
            "Epoch 438/500\n",
            "80/80 [==============================] - 0s 991us/step - loss: 1.1517e-07 - val_loss: 8.7779e-08\n",
            "Epoch 439/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2092e-07 - val_loss: 1.0091e-07\n",
            "Epoch 440/500\n",
            "80/80 [==============================] - 0s 969us/step - loss: 5.9398e-08 - val_loss: 1.1351e-07\n",
            "Epoch 441/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.2727e-08 - val_loss: 6.7922e-08\n",
            "Epoch 442/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.9331e-08 - val_loss: 1.4437e-07\n",
            "Epoch 443/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.8475e-08 - val_loss: 2.3581e-07\n",
            "Epoch 444/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.1542e-08 - val_loss: 4.6564e-08\n",
            "Epoch 445/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.2684e-08 - val_loss: 3.5331e-08\n",
            "Epoch 446/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.5389e-08 - val_loss: 6.8349e-08\n",
            "Epoch 447/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.6212e-08 - val_loss: 6.7910e-08\n",
            "Epoch 448/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.8652e-08 - val_loss: 3.2113e-07\n",
            "Epoch 449/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.6786e-07 - val_loss: 7.5202e-08\n",
            "Epoch 450/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.6315e-07 - val_loss: 7.6106e-07\n",
            "Epoch 451/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.4353e-07 - val_loss: 7.6203e-08\n",
            "Epoch 452/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.5571e-07 - val_loss: 2.9217e-07\n",
            "Epoch 453/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0271e-07 - val_loss: 5.0919e-07\n",
            "Epoch 454/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.3959e-07 - val_loss: 7.7340e-08\n",
            "Epoch 455/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.2548e-08 - val_loss: 1.3750e-07\n",
            "Epoch 456/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.1397e-08 - val_loss: 2.9956e-08\n",
            "Epoch 457/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.1587e-08 - val_loss: 1.0684e-07\n",
            "Epoch 458/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2334e-07 - val_loss: 7.0137e-08\n",
            "Epoch 459/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2542e-07 - val_loss: 2.8948e-07\n",
            "Epoch 460/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2746e-07 - val_loss: 1.6269e-07\n",
            "Epoch 461/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2471e-07 - val_loss: 3.1945e-07\n",
            "Epoch 462/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.5781e-07 - val_loss: 1.0396e-07\n",
            "Epoch 463/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.8651e-08 - val_loss: 3.2319e-08\n",
            "Epoch 464/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.3567e-08 - val_loss: 5.1277e-07\n",
            "Epoch 465/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7031e-07 - val_loss: 3.0215e-07\n",
            "Epoch 466/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2808e-07 - val_loss: 3.6656e-08\n",
            "Epoch 467/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4839e-07 - val_loss: 8.7461e-07\n",
            "Epoch 468/500\n",
            "80/80 [==============================] - 0s 988us/step - loss: 4.8406e-07 - val_loss: 5.8648e-07\n",
            "Epoch 469/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.1317e-07 - val_loss: 2.3616e-07\n",
            "Epoch 470/500\n",
            "80/80 [==============================] - 0s 970us/step - loss: 2.8910e-07 - val_loss: 1.9346e-06\n",
            "Epoch 471/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8653e-06 - val_loss: 1.0969e-07\n",
            "Epoch 472/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.9163e-06 - val_loss: 4.0905e-06\n",
            "Epoch 473/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3126e-06 - val_loss: 5.0019e-07\n",
            "Epoch 474/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.2699e-07 - val_loss: 1.6329e-06\n",
            "Epoch 475/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.9964e-07 - val_loss: 1.1747e-06\n",
            "Epoch 476/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1275e-06 - val_loss: 3.1254e-07\n",
            "Epoch 477/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.1609e-07 - val_loss: 7.0637e-07\n",
            "Epoch 478/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.4354e-07 - val_loss: 3.1728e-06\n",
            "Epoch 479/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4899e-06 - val_loss: 4.4827e-06\n",
            "Epoch 480/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2236e-05 - val_loss: 3.5559e-07\n",
            "Epoch 481/500\n",
            "80/80 [==============================] - 0s 999us/step - loss: 1.0375e-05 - val_loss: 1.4159e-05\n",
            "Epoch 482/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.2755e-06 - val_loss: 3.1543e-05\n",
            "Epoch 483/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3582e-05 - val_loss: 3.0087e-05\n",
            "Epoch 484/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4657e-05 - val_loss: 4.0534e-05\n",
            "Epoch 485/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.6094e-05 - val_loss: 2.3903e-05\n",
            "Epoch 486/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1757e-05 - val_loss: 5.7172e-06\n",
            "Epoch 487/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.5680e-06 - val_loss: 7.1311e-07\n",
            "Epoch 488/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2113e-06 - val_loss: 1.3302e-06\n",
            "Epoch 489/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2207e-06 - val_loss: 8.4312e-06\n",
            "Epoch 490/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.0448e-06 - val_loss: 7.8354e-06\n",
            "Epoch 491/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.3621e-06 - val_loss: 3.5951e-06\n",
            "Epoch 492/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8400e-06 - val_loss: 1.7465e-06\n",
            "Epoch 493/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.5965e-06 - val_loss: 2.4270e-06\n",
            "Epoch 494/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0524e-06 - val_loss: 4.6203e-06\n",
            "Epoch 495/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.2719e-06 - val_loss: 1.7357e-06\n",
            "Epoch 496/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4115e-06 - val_loss: 1.4039e-06\n",
            "Epoch 497/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.0764e-06 - val_loss: 2.2988e-06\n",
            "Epoch 498/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4403e-06 - val_loss: 8.5838e-07\n",
            "Epoch 499/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8970e-06 - val_loss: 1.5759e-06\n",
            "Epoch 500/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.9928e-06 - val_loss: 1.5986e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YjqyGphnkkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkg6MIzynlMV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7c16d7e-810f-4191-f5df-d1b9c8c8697a"
      },
      "source": [
        "results.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSwwt6LhnlWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbe6ca56-47e5-4cfd-a55e-4013d40f6e35"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4KirRxDnoj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "8b15af2f-e9b1-4c0d-e0a6-a601dcb42011"
      },
      "source": [
        "plt.scatter(range(20),results,c='r')\n",
        "plt.scatter(range(20),y_test,c='g')\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7C0xIDjnlec",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "e29cc127-e443-4f66-b8da-e0648d9536cc"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAD8CAYAAABU4IIeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}