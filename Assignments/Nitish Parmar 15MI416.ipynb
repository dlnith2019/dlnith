{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwkDYZlKKd7M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "161dea8e-af83-4f2a-92b6-ce589f0a9635"
      },
      "source": [
        "import math\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,LSTM\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8P7R0wBK4G2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=[]\n",
        "Y1=[]\n",
        "for i in range(100):\n",
        "  X.append(i)\n",
        "  Y1.append(math.sin(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0V0FVCBLyMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y2=[]\n",
        "for i in range(100):\n",
        "  Y2.append(math.cos(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGoORbOENY7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "inpt = np.column_stack((Y1, Y2))\n",
        "tst = [Y1-Y2 for Y1,Y2 in zip(Y1,Y2)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP5mFr44NgR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inpt = np.array(inpt, dtype=\"float32\")\n",
        "trgt = np.array(tst, dtype=\"float32\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNHZUjYoPX71",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f07a0aa9-5c13-458c-a56d-61857a7df7fe"
      },
      "source": [
        "inpt= np.array(inpt).reshape(100, 2,1)\n",
        "inpt.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 2, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmrwEw6DkEWc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0f938f38-92e6-4eb3-ef9e-9473c3221344"
      },
      "source": [
        "trgt.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "medTU78GkGQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(inpt,trgt,test_size=0.2,random_state=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C8wYedGkNQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "419079be-07f7-4d7f-c848-7b5e2d8c9596"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(2,1)))\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(25, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "print(model.summary())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 2, 200)            161600    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 2, 100)            120400    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 2, 50)             30200     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 25)                7600      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                520       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                210       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 320,541\n",
            "Trainable params: 320,541\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhEyK56qkdZC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "720f7cb9-1be3-4edf-b445-dca8ff829838"
      },
      "source": [
        "history = model.fit(x_train,y_train,epochs=2000,validation_data=(x_test,y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/2000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 1.0313 - val_loss: 0.8465\n",
            "Epoch 2/2000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 1.0311 - val_loss: 0.8491\n",
            "Epoch 3/2000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 1.0305 - val_loss: 0.8512\n",
            "Epoch 4/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0299 - val_loss: 0.8529\n",
            "Epoch 5/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 1.0300 - val_loss: 0.8543\n",
            "Epoch 6/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 1.0294 - val_loss: 0.8544\n",
            "Epoch 7/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 1.0292 - val_loss: 0.8550\n",
            "Epoch 8/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 1.0292 - val_loss: 0.8561\n",
            "Epoch 9/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0287 - val_loss: 0.8560\n",
            "Epoch 10/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 1.0282 - val_loss: 0.8567\n",
            "Epoch 11/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 1.0273 - val_loss: 0.8570\n",
            "Epoch 12/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 1.0263 - val_loss: 0.8582\n",
            "Epoch 13/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 1.0247 - val_loss: 0.8592\n",
            "Epoch 14/2000\n",
            "80/80 [==============================] - 0s 977us/step - loss: 1.0227 - val_loss: 0.8602\n",
            "Epoch 15/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 1.0202 - val_loss: 0.8610\n",
            "Epoch 16/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0163 - val_loss: 0.8611\n",
            "Epoch 17/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0115 - val_loss: 0.8611\n",
            "Epoch 18/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 1.0036 - val_loss: 0.8604\n",
            "Epoch 19/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 0.9933 - val_loss: 0.8600\n",
            "Epoch 20/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.9764 - val_loss: 0.8587\n",
            "Epoch 21/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 0.9515 - val_loss: 0.8606\n",
            "Epoch 22/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 0.9150 - val_loss: 0.8727\n",
            "Epoch 23/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 0.8565 - val_loss: 0.9337\n",
            "Epoch 24/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 0.8393 - val_loss: 0.9588\n",
            "Epoch 25/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 0.8291 - val_loss: 0.8782\n",
            "Epoch 26/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 0.8120 - val_loss: 0.8467\n",
            "Epoch 27/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 0.8072 - val_loss: 0.8430\n",
            "Epoch 28/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 0.7941 - val_loss: 0.8510\n",
            "Epoch 29/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.7766 - val_loss: 0.8594\n",
            "Epoch 30/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.7754 - val_loss: 0.8751\n",
            "Epoch 31/2000\n",
            "80/80 [==============================] - 0s 979us/step - loss: 0.7616 - val_loss: 0.8460\n",
            "Epoch 32/2000\n",
            "80/80 [==============================] - 0s 797us/step - loss: 0.7489 - val_loss: 0.8218\n",
            "Epoch 33/2000\n",
            "80/80 [==============================] - 0s 817us/step - loss: 0.7396 - val_loss: 0.8116\n",
            "Epoch 34/2000\n",
            "80/80 [==============================] - 0s 778us/step - loss: 0.7272 - val_loss: 0.8108\n",
            "Epoch 35/2000\n",
            "80/80 [==============================] - 0s 837us/step - loss: 0.7126 - val_loss: 0.8181\n",
            "Epoch 36/2000\n",
            "80/80 [==============================] - 0s 814us/step - loss: 0.6968 - val_loss: 0.8144\n",
            "Epoch 37/2000\n",
            "80/80 [==============================] - 0s 867us/step - loss: 0.6839 - val_loss: 0.8078\n",
            "Epoch 38/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 0.6661 - val_loss: 0.7829\n",
            "Epoch 39/2000\n",
            "80/80 [==============================] - 0s 846us/step - loss: 0.6443 - val_loss: 0.7491\n",
            "Epoch 40/2000\n",
            "80/80 [==============================] - 0s 890us/step - loss: 0.6235 - val_loss: 0.7293\n",
            "Epoch 41/2000\n",
            "80/80 [==============================] - 0s 858us/step - loss: 0.5920 - val_loss: 0.7107\n",
            "Epoch 42/2000\n",
            "80/80 [==============================] - 0s 862us/step - loss: 0.5641 - val_loss: 0.6844\n",
            "Epoch 43/2000\n",
            "80/80 [==============================] - 0s 847us/step - loss: 0.4892 - val_loss: 0.5935\n",
            "Epoch 44/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 0.3739 - val_loss: 0.6111\n",
            "Epoch 45/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 0.3784 - val_loss: 0.5987\n",
            "Epoch 46/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 0.3308 - val_loss: 0.4994\n",
            "Epoch 47/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 0.2792 - val_loss: 0.4608\n",
            "Epoch 48/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 0.2650 - val_loss: 0.3428\n",
            "Epoch 49/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 0.2218 - val_loss: 0.3011\n",
            "Epoch 50/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1793 - val_loss: 0.2553\n",
            "Epoch 51/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1415 - val_loss: 0.2104\n",
            "Epoch 52/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 0.1082 - val_loss: 0.1574\n",
            "Epoch 53/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0930 - val_loss: 0.1208\n",
            "Epoch 54/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 0.0768 - val_loss: 0.0871\n",
            "Epoch 55/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 0.0534 - val_loss: 0.0652\n",
            "Epoch 56/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 0.0427 - val_loss: 0.0745\n",
            "Epoch 57/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 0.0400 - val_loss: 0.0360\n",
            "Epoch 58/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 0.0268 - val_loss: 0.0595\n",
            "Epoch 59/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 0.0339 - val_loss: 0.0383\n",
            "Epoch 60/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 0.0264 - val_loss: 0.0412\n",
            "Epoch 61/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0217 - val_loss: 0.0193\n",
            "Epoch 62/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 0.0149 - val_loss: 0.0263\n",
            "Epoch 63/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 0.0127 - val_loss: 0.0098\n",
            "Epoch 64/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 0.0127 - val_loss: 0.0155\n",
            "Epoch 65/2000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 0.0090 - val_loss: 0.0096\n",
            "Epoch 66/2000\n",
            "80/80 [==============================] - 0s 993us/step - loss: 0.0072 - val_loss: 0.0093\n",
            "Epoch 67/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 0.0060 - val_loss: 0.0072\n",
            "Epoch 68/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 0.0048 - val_loss: 0.0077\n",
            "Epoch 69/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0049\n",
            "Epoch 70/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 0.0034 - val_loss: 0.0046\n",
            "Epoch 71/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0047\n",
            "Epoch 72/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 0.0026 - val_loss: 0.0035\n",
            "Epoch 73/2000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 0.0022 - val_loss: 0.0026\n",
            "Epoch 74/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 0.0022 - val_loss: 0.0038\n",
            "Epoch 75/2000\n",
            "80/80 [==============================] - 0s 893us/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 76/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 77/2000\n",
            "80/80 [==============================] - 0s 890us/step - loss: 0.0012 - val_loss: 0.0021\n",
            "Epoch 78/2000\n",
            "80/80 [==============================] - 0s 983us/step - loss: 0.0011 - val_loss: 0.0015\n",
            "Epoch 79/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 0.0010 - val_loss: 0.0013\n",
            "Epoch 80/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 9.4293e-04 - val_loss: 0.0018\n",
            "Epoch 81/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.2697e-04 - val_loss: 0.0011\n",
            "Epoch 82/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.0156e-04 - val_loss: 0.0013\n",
            "Epoch 83/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 9.2430e-04 - val_loss: 9.2188e-04\n",
            "Epoch 84/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 8.4296e-04 - val_loss: 8.9307e-04\n",
            "Epoch 85/2000\n",
            "80/80 [==============================] - 0s 811us/step - loss: 6.8077e-04 - val_loss: 8.3098e-04\n",
            "Epoch 86/2000\n",
            "80/80 [==============================] - 0s 799us/step - loss: 5.6311e-04 - val_loss: 7.7918e-04\n",
            "Epoch 87/2000\n",
            "80/80 [==============================] - 0s 787us/step - loss: 8.8322e-04 - val_loss: 0.0024\n",
            "Epoch 88/2000\n",
            "80/80 [==============================] - 0s 811us/step - loss: 0.0013 - val_loss: 5.8038e-04\n",
            "Epoch 89/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 6.5943e-04 - val_loss: 8.7168e-04\n",
            "Epoch 90/2000\n",
            "80/80 [==============================] - 0s 801us/step - loss: 4.8921e-04 - val_loss: 6.1924e-04\n",
            "Epoch 91/2000\n",
            "80/80 [==============================] - 0s 836us/step - loss: 5.5300e-04 - val_loss: 5.6845e-04\n",
            "Epoch 92/2000\n",
            "80/80 [==============================] - 0s 854us/step - loss: 5.1635e-04 - val_loss: 8.4690e-04\n",
            "Epoch 93/2000\n",
            "80/80 [==============================] - 0s 816us/step - loss: 4.9842e-04 - val_loss: 5.4954e-04\n",
            "Epoch 94/2000\n",
            "80/80 [==============================] - 0s 853us/step - loss: 4.1627e-04 - val_loss: 0.0011\n",
            "Epoch 95/2000\n",
            "80/80 [==============================] - 0s 874us/step - loss: 6.0718e-04 - val_loss: 4.6028e-04\n",
            "Epoch 96/2000\n",
            "80/80 [==============================] - 0s 846us/step - loss: 3.5840e-04 - val_loss: 7.4369e-04\n",
            "Epoch 97/2000\n",
            "80/80 [==============================] - 0s 865us/step - loss: 3.6726e-04 - val_loss: 4.3991e-04\n",
            "Epoch 98/2000\n",
            "80/80 [==============================] - 0s 837us/step - loss: 3.6700e-04 - val_loss: 3.8393e-04\n",
            "Epoch 99/2000\n",
            "80/80 [==============================] - 0s 790us/step - loss: 3.3401e-04 - val_loss: 4.9222e-04\n",
            "Epoch 100/2000\n",
            "80/80 [==============================] - 0s 847us/step - loss: 2.8912e-04 - val_loss: 4.6393e-04\n",
            "Epoch 101/2000\n",
            "80/80 [==============================] - 0s 832us/step - loss: 2.9080e-04 - val_loss: 7.0460e-04\n",
            "Epoch 102/2000\n",
            "80/80 [==============================] - 0s 872us/step - loss: 3.3754e-04 - val_loss: 3.7476e-04\n",
            "Epoch 103/2000\n",
            "80/80 [==============================] - 0s 883us/step - loss: 2.9146e-04 - val_loss: 7.2560e-04\n",
            "Epoch 104/2000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 4.2548e-04 - val_loss: 7.9240e-04\n",
            "Epoch 105/2000\n",
            "80/80 [==============================] - 0s 880us/step - loss: 4.9704e-04 - val_loss: 5.4269e-04\n",
            "Epoch 106/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 5.0945e-04 - val_loss: 5.1928e-04\n",
            "Epoch 107/2000\n",
            "80/80 [==============================] - 0s 835us/step - loss: 2.8562e-04 - val_loss: 3.9644e-04\n",
            "Epoch 108/2000\n",
            "80/80 [==============================] - 0s 847us/step - loss: 2.9467e-04 - val_loss: 4.8475e-04\n",
            "Epoch 109/2000\n",
            "80/80 [==============================] - 0s 885us/step - loss: 3.4359e-04 - val_loss: 0.0011\n",
            "Epoch 110/2000\n",
            "80/80 [==============================] - 0s 879us/step - loss: 5.6949e-04 - val_loss: 3.8213e-04\n",
            "Epoch 111/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 2.5523e-04 - val_loss: 7.3480e-04\n",
            "Epoch 112/2000\n",
            "80/80 [==============================] - 0s 885us/step - loss: 3.6679e-04 - val_loss: 3.5486e-04\n",
            "Epoch 113/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 3.7724e-04 - val_loss: 3.3425e-04\n",
            "Epoch 114/2000\n",
            "80/80 [==============================] - 0s 858us/step - loss: 3.1455e-04 - val_loss: 4.0516e-04\n",
            "Epoch 115/2000\n",
            "80/80 [==============================] - 0s 848us/step - loss: 1.9093e-04 - val_loss: 3.7122e-04\n",
            "Epoch 116/2000\n",
            "80/80 [==============================] - 0s 865us/step - loss: 2.4491e-04 - val_loss: 5.1335e-04\n",
            "Epoch 117/2000\n",
            "80/80 [==============================] - 0s 805us/step - loss: 2.0887e-04 - val_loss: 3.5804e-04\n",
            "Epoch 118/2000\n",
            "80/80 [==============================] - 0s 826us/step - loss: 2.0429e-04 - val_loss: 5.9852e-04\n",
            "Epoch 119/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.5269e-04 - val_loss: 4.9697e-04\n",
            "Epoch 120/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 2.5746e-04 - val_loss: 5.9809e-04\n",
            "Epoch 121/2000\n",
            "80/80 [==============================] - 0s 869us/step - loss: 2.7812e-04 - val_loss: 4.1438e-04\n",
            "Epoch 122/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 2.8417e-04 - val_loss: 6.6465e-04\n",
            "Epoch 123/2000\n",
            "80/80 [==============================] - 0s 898us/step - loss: 6.9431e-04 - val_loss: 3.5995e-04\n",
            "Epoch 124/2000\n",
            "80/80 [==============================] - 0s 803us/step - loss: 6.5554e-04 - val_loss: 8.1119e-04\n",
            "Epoch 125/2000\n",
            "80/80 [==============================] - 0s 844us/step - loss: 7.5281e-04 - val_loss: 0.0013\n",
            "Epoch 126/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 3.6192e-04\n",
            "Epoch 127/2000\n",
            "80/80 [==============================] - 0s 837us/step - loss: 9.6235e-04 - val_loss: 0.0038\n",
            "Epoch 128/2000\n",
            "80/80 [==============================] - 0s 864us/step - loss: 0.0028 - val_loss: 0.0129\n",
            "Epoch 129/2000\n",
            "80/80 [==============================] - 0s 839us/step - loss: 0.0073 - val_loss: 0.0116\n",
            "Epoch 130/2000\n",
            "80/80 [==============================] - 0s 800us/step - loss: 0.0076 - val_loss: 0.0035\n",
            "Epoch 131/2000\n",
            "80/80 [==============================] - 0s 825us/step - loss: 0.0034 - val_loss: 0.0034\n",
            "Epoch 132/2000\n",
            "80/80 [==============================] - 0s 844us/step - loss: 0.0020 - val_loss: 0.0045\n",
            "Epoch 133/2000\n",
            "80/80 [==============================] - 0s 820us/step - loss: 0.0035 - val_loss: 0.0016\n",
            "Epoch 134/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 0.0032 - val_loss: 0.0014\n",
            "Epoch 135/2000\n",
            "80/80 [==============================] - 0s 812us/step - loss: 0.0023 - val_loss: 0.0011\n",
            "Epoch 136/2000\n",
            "80/80 [==============================] - 0s 837us/step - loss: 0.0019 - val_loss: 0.0013\n",
            "Epoch 137/2000\n",
            "80/80 [==============================] - 0s 886us/step - loss: 0.0020 - val_loss: 8.6821e-04\n",
            "Epoch 138/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 0.0017 - val_loss: 5.9866e-04\n",
            "Epoch 139/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 0.0020 - val_loss: 0.0012\n",
            "Epoch 140/2000\n",
            "80/80 [==============================] - 0s 815us/step - loss: 0.0016 - val_loss: 0.0017\n",
            "Epoch 141/2000\n",
            "80/80 [==============================] - 0s 877us/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 142/2000\n",
            "80/80 [==============================] - 0s 804us/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 143/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 0.0012 - val_loss: 0.0015\n",
            "Epoch 144/2000\n",
            "80/80 [==============================] - 0s 885us/step - loss: 9.1576e-04 - val_loss: 0.0023\n",
            "Epoch 145/2000\n",
            "80/80 [==============================] - 0s 808us/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 146/2000\n",
            "80/80 [==============================] - 0s 757us/step - loss: 0.0010 - val_loss: 0.0015\n",
            "Epoch 147/2000\n",
            "80/80 [==============================] - 0s 845us/step - loss: 8.6736e-04 - val_loss: 4.7701e-04\n",
            "Epoch 148/2000\n",
            "80/80 [==============================] - 0s 829us/step - loss: 7.8285e-04 - val_loss: 6.0860e-04\n",
            "Epoch 149/2000\n",
            "80/80 [==============================] - 0s 757us/step - loss: 6.8948e-04 - val_loss: 2.0821e-04\n",
            "Epoch 150/2000\n",
            "80/80 [==============================] - 0s 830us/step - loss: 3.9475e-04 - val_loss: 1.8576e-04\n",
            "Epoch 151/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 2.1979e-04 - val_loss: 4.1440e-04\n",
            "Epoch 152/2000\n",
            "80/80 [==============================] - 0s 858us/step - loss: 1.8329e-04 - val_loss: 1.9407e-04\n",
            "Epoch 153/2000\n",
            "80/80 [==============================] - 0s 892us/step - loss: 1.5607e-04 - val_loss: 4.2037e-04\n",
            "Epoch 154/2000\n",
            "80/80 [==============================] - 0s 843us/step - loss: 2.0512e-04 - val_loss: 1.8464e-04\n",
            "Epoch 155/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 1.4205e-04 - val_loss: 2.9144e-04\n",
            "Epoch 156/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3076e-04 - val_loss: 1.7783e-04\n",
            "Epoch 157/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4185e-04 - val_loss: 2.1538e-04\n",
            "Epoch 158/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 1.1068e-04 - val_loss: 1.9475e-04\n",
            "Epoch 159/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 1.2195e-04 - val_loss: 2.1338e-04\n",
            "Epoch 160/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 9.4919e-05 - val_loss: 1.7820e-04\n",
            "Epoch 161/2000\n",
            "80/80 [==============================] - 0s 883us/step - loss: 1.0410e-04 - val_loss: 1.9612e-04\n",
            "Epoch 162/2000\n",
            "80/80 [==============================] - 0s 870us/step - loss: 9.8633e-05 - val_loss: 1.3765e-04\n",
            "Epoch 163/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0908e-04 - val_loss: 2.2105e-04\n",
            "Epoch 164/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 1.2170e-04 - val_loss: 1.3543e-04\n",
            "Epoch 165/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 1.0874e-04 - val_loss: 1.7539e-04\n",
            "Epoch 166/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 1.0880e-04 - val_loss: 1.5795e-04\n",
            "Epoch 167/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 1.0088e-04 - val_loss: 1.3873e-04\n",
            "Epoch 168/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 9.7872e-05 - val_loss: 1.2281e-04\n",
            "Epoch 169/2000\n",
            "80/80 [==============================] - 0s 793us/step - loss: 1.0519e-04 - val_loss: 1.8330e-04\n",
            "Epoch 170/2000\n",
            "80/80 [==============================] - 0s 892us/step - loss: 9.1780e-05 - val_loss: 1.4668e-04\n",
            "Epoch 171/2000\n",
            "80/80 [==============================] - 0s 859us/step - loss: 9.7973e-05 - val_loss: 1.5115e-04\n",
            "Epoch 172/2000\n",
            "80/80 [==============================] - 0s 858us/step - loss: 8.9129e-05 - val_loss: 1.5632e-04\n",
            "Epoch 173/2000\n",
            "80/80 [==============================] - 0s 835us/step - loss: 7.6363e-05 - val_loss: 1.4200e-04\n",
            "Epoch 174/2000\n",
            "80/80 [==============================] - 0s 795us/step - loss: 8.6220e-05 - val_loss: 1.0898e-04\n",
            "Epoch 175/2000\n",
            "80/80 [==============================] - 0s 809us/step - loss: 7.5265e-05 - val_loss: 1.5234e-04\n",
            "Epoch 176/2000\n",
            "80/80 [==============================] - 0s 821us/step - loss: 7.5718e-05 - val_loss: 1.1153e-04\n",
            "Epoch 177/2000\n",
            "80/80 [==============================] - 0s 853us/step - loss: 8.2800e-05 - val_loss: 1.1670e-04\n",
            "Epoch 178/2000\n",
            "80/80 [==============================] - 0s 852us/step - loss: 7.0757e-05 - val_loss: 1.0107e-04\n",
            "Epoch 179/2000\n",
            "80/80 [==============================] - 0s 872us/step - loss: 7.2496e-05 - val_loss: 1.2697e-04\n",
            "Epoch 180/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 7.1529e-05 - val_loss: 1.1859e-04\n",
            "Epoch 181/2000\n",
            "80/80 [==============================] - 0s 889us/step - loss: 6.2859e-05 - val_loss: 1.0149e-04\n",
            "Epoch 182/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 7.0350e-05 - val_loss: 1.0417e-04\n",
            "Epoch 183/2000\n",
            "80/80 [==============================] - 0s 870us/step - loss: 6.5224e-05 - val_loss: 9.8243e-05\n",
            "Epoch 184/2000\n",
            "80/80 [==============================] - 0s 827us/step - loss: 6.2710e-05 - val_loss: 1.2470e-04\n",
            "Epoch 185/2000\n",
            "80/80 [==============================] - 0s 882us/step - loss: 6.9074e-05 - val_loss: 1.0277e-04\n",
            "Epoch 186/2000\n",
            "80/80 [==============================] - 0s 824us/step - loss: 6.4949e-05 - val_loss: 1.0252e-04\n",
            "Epoch 187/2000\n",
            "80/80 [==============================] - 0s 793us/step - loss: 6.3885e-05 - val_loss: 9.4514e-05\n",
            "Epoch 188/2000\n",
            "80/80 [==============================] - 0s 889us/step - loss: 5.9572e-05 - val_loss: 1.1182e-04\n",
            "Epoch 189/2000\n",
            "80/80 [==============================] - 0s 771us/step - loss: 5.6053e-05 - val_loss: 8.5901e-05\n",
            "Epoch 190/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 6.9421e-05 - val_loss: 1.1082e-04\n",
            "Epoch 191/2000\n",
            "80/80 [==============================] - 0s 786us/step - loss: 5.7284e-05 - val_loss: 8.7113e-05\n",
            "Epoch 192/2000\n",
            "80/80 [==============================] - 0s 807us/step - loss: 5.5222e-05 - val_loss: 1.2457e-04\n",
            "Epoch 193/2000\n",
            "80/80 [==============================] - 0s 863us/step - loss: 7.0663e-05 - val_loss: 7.9293e-05\n",
            "Epoch 194/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 6.4465e-05 - val_loss: 1.0993e-04\n",
            "Epoch 195/2000\n",
            "80/80 [==============================] - 0s 804us/step - loss: 5.6246e-05 - val_loss: 7.7591e-05\n",
            "Epoch 196/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 5.8242e-05 - val_loss: 8.9830e-05\n",
            "Epoch 197/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 5.3149e-05 - val_loss: 8.8415e-05\n",
            "Epoch 198/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 5.4071e-05 - val_loss: 8.0549e-05\n",
            "Epoch 199/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 5.4026e-05 - val_loss: 7.2035e-05\n",
            "Epoch 200/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.3216e-05 - val_loss: 9.8174e-05\n",
            "Epoch 201/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 5.1106e-05 - val_loss: 7.1816e-05\n",
            "Epoch 202/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.1238e-05 - val_loss: 8.8235e-05\n",
            "Epoch 203/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 5.0010e-05 - val_loss: 8.1469e-05\n",
            "Epoch 204/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 4.6899e-05 - val_loss: 7.3627e-05\n",
            "Epoch 205/2000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 5.0920e-05 - val_loss: 8.9073e-05\n",
            "Epoch 206/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 4.8738e-05 - val_loss: 1.0258e-04\n",
            "Epoch 207/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.0416e-05 - val_loss: 7.5899e-05\n",
            "Epoch 208/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 6.7504e-05 - val_loss: 1.4426e-04\n",
            "Epoch 209/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 6.6941e-05 - val_loss: 6.8197e-05\n",
            "Epoch 210/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 5.5554e-05 - val_loss: 8.0175e-05\n",
            "Epoch 211/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 6.1894e-05 - val_loss: 1.0116e-04\n",
            "Epoch 212/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 5.2421e-05 - val_loss: 7.9630e-05\n",
            "Epoch 213/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 4.3475e-05 - val_loss: 6.8976e-05\n",
            "Epoch 214/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 4.4969e-05 - val_loss: 8.4713e-05\n",
            "Epoch 215/2000\n",
            "80/80 [==============================] - 0s 894us/step - loss: 4.6108e-05 - val_loss: 6.4101e-05\n",
            "Epoch 216/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.5899e-05 - val_loss: 7.5119e-05\n",
            "Epoch 217/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 4.2820e-05 - val_loss: 6.5132e-05\n",
            "Epoch 218/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 4.6614e-05 - val_loss: 8.8235e-05\n",
            "Epoch 219/2000\n",
            "80/80 [==============================] - 0s 981us/step - loss: 4.3121e-05 - val_loss: 6.6539e-05\n",
            "Epoch 220/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 3.9730e-05 - val_loss: 7.4690e-05\n",
            "Epoch 221/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 3.7438e-05 - val_loss: 6.2815e-05\n",
            "Epoch 222/2000\n",
            "80/80 [==============================] - 0s 993us/step - loss: 4.0999e-05 - val_loss: 7.5858e-05\n",
            "Epoch 223/2000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 3.8861e-05 - val_loss: 6.7207e-05\n",
            "Epoch 224/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.9208e-05 - val_loss: 6.4392e-05\n",
            "Epoch 225/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.0461e-05 - val_loss: 6.0113e-05\n",
            "Epoch 226/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.8252e-05 - val_loss: 6.8722e-05\n",
            "Epoch 227/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.6914e-05 - val_loss: 5.7132e-05\n",
            "Epoch 228/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.9755e-05 - val_loss: 7.9889e-05\n",
            "Epoch 229/2000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 3.8126e-05 - val_loss: 6.3129e-05\n",
            "Epoch 230/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 3.5462e-05 - val_loss: 6.9925e-05\n",
            "Epoch 231/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 3.7403e-05 - val_loss: 6.2922e-05\n",
            "Epoch 232/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 3.5213e-05 - val_loss: 6.7532e-05\n",
            "Epoch 233/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 3.8751e-05 - val_loss: 7.3250e-05\n",
            "Epoch 234/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 4.0280e-05 - val_loss: 5.2255e-05\n",
            "Epoch 235/2000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 4.9048e-05 - val_loss: 9.1603e-05\n",
            "Epoch 236/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.8871e-05 - val_loss: 5.4640e-05\n",
            "Epoch 237/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 4.0946e-05 - val_loss: 1.4234e-04\n",
            "Epoch 238/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 5.6527e-05 - val_loss: 5.0898e-05\n",
            "Epoch 239/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 3.9493e-05 - val_loss: 1.1420e-04\n",
            "Epoch 240/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 5.5416e-05 - val_loss: 5.1441e-05\n",
            "Epoch 241/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 3.4599e-05 - val_loss: 1.0308e-04\n",
            "Epoch 242/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 3.6972e-05 - val_loss: 7.8502e-05\n",
            "Epoch 243/2000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 5.1288e-05 - val_loss: 2.0577e-04\n",
            "Epoch 244/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 7.9456e-05 - val_loss: 5.2019e-05\n",
            "Epoch 245/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 6.2397e-05 - val_loss: 6.1008e-05\n",
            "Epoch 246/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 7.2943e-05 - val_loss: 1.0408e-04\n",
            "Epoch 247/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 6.8799e-05 - val_loss: 5.5363e-05\n",
            "Epoch 248/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 6.7040e-05 - val_loss: 1.4658e-04\n",
            "Epoch 249/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 7.2573e-05 - val_loss: 4.6812e-05\n",
            "Epoch 250/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 4.6971e-05 - val_loss: 6.1016e-05\n",
            "Epoch 251/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 3.4995e-05 - val_loss: 5.6078e-05\n",
            "Epoch 252/2000\n",
            "80/80 [==============================] - 0s 875us/step - loss: 3.1628e-05 - val_loss: 5.0251e-05\n",
            "Epoch 253/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 3.2908e-05 - val_loss: 8.4953e-05\n",
            "Epoch 254/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 3.7351e-05 - val_loss: 4.3905e-05\n",
            "Epoch 255/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 2.9961e-05 - val_loss: 7.2518e-05\n",
            "Epoch 256/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 3.9877e-05 - val_loss: 6.1119e-05\n",
            "Epoch 257/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 4.1570e-05 - val_loss: 4.2603e-05\n",
            "Epoch 258/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.9329e-05 - val_loss: 1.1481e-04\n",
            "Epoch 259/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 4.2337e-05 - val_loss: 4.4709e-05\n",
            "Epoch 260/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.7114e-05 - val_loss: 1.1468e-04\n",
            "Epoch 261/2000\n",
            "80/80 [==============================] - 0s 983us/step - loss: 5.1088e-05 - val_loss: 4.3305e-05\n",
            "Epoch 262/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 3.8299e-05 - val_loss: 7.0798e-05\n",
            "Epoch 263/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 4.6354e-05 - val_loss: 5.6212e-05\n",
            "Epoch 264/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.2920e-05 - val_loss: 4.4168e-05\n",
            "Epoch 265/2000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 3.9828e-05 - val_loss: 7.3057e-05\n",
            "Epoch 266/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 3.1986e-05 - val_loss: 4.2074e-05\n",
            "Epoch 267/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.6120e-05 - val_loss: 7.4901e-05\n",
            "Epoch 268/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.0518e-05 - val_loss: 4.0739e-05\n",
            "Epoch 269/2000\n",
            "80/80 [==============================] - 0s 993us/step - loss: 2.9845e-05 - val_loss: 4.7993e-05\n",
            "Epoch 270/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.0488e-05 - val_loss: 6.6405e-05\n",
            "Epoch 271/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 3.2523e-05 - val_loss: 4.0973e-05\n",
            "Epoch 272/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 3.2071e-05 - val_loss: 7.2321e-05\n",
            "Epoch 273/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 3.2965e-05 - val_loss: 7.2564e-05\n",
            "Epoch 274/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 4.2383e-05 - val_loss: 4.2804e-05\n",
            "Epoch 275/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 4.7596e-05 - val_loss: 1.2556e-04\n",
            "Epoch 276/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 4.3567e-05 - val_loss: 6.4626e-05\n",
            "Epoch 277/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 6.9885e-05 - val_loss: 7.2906e-05\n",
            "Epoch 278/2000\n",
            "80/80 [==============================] - 0s 983us/step - loss: 4.8124e-05 - val_loss: 8.6722e-05\n",
            "Epoch 279/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 6.3198e-05 - val_loss: 6.9575e-05\n",
            "Epoch 280/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 3.6333e-05 - val_loss: 4.9043e-05\n",
            "Epoch 281/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.7486e-05 - val_loss: 6.9286e-05\n",
            "Epoch 282/2000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 4.4641e-05 - val_loss: 5.7547e-05\n",
            "Epoch 283/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 4.8789e-05 - val_loss: 3.9985e-05\n",
            "Epoch 284/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 4.2877e-05 - val_loss: 4.5796e-05\n",
            "Epoch 285/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 3.5157e-05 - val_loss: 4.9405e-05\n",
            "Epoch 286/2000\n",
            "80/80 [==============================] - 0s 850us/step - loss: 2.7079e-05 - val_loss: 5.6101e-05\n",
            "Epoch 287/2000\n",
            "80/80 [==============================] - 0s 884us/step - loss: 3.5458e-05 - val_loss: 4.4756e-05\n",
            "Epoch 288/2000\n",
            "80/80 [==============================] - 0s 884us/step - loss: 3.1717e-05 - val_loss: 6.0629e-05\n",
            "Epoch 289/2000\n",
            "80/80 [==============================] - 0s 815us/step - loss: 2.6338e-05 - val_loss: 3.9101e-05\n",
            "Epoch 290/2000\n",
            "80/80 [==============================] - 0s 834us/step - loss: 2.8690e-05 - val_loss: 5.4284e-05\n",
            "Epoch 291/2000\n",
            "80/80 [==============================] - 0s 817us/step - loss: 2.3175e-05 - val_loss: 3.9188e-05\n",
            "Epoch 292/2000\n",
            "80/80 [==============================] - 0s 872us/step - loss: 2.8593e-05 - val_loss: 1.0405e-04\n",
            "Epoch 293/2000\n",
            "80/80 [==============================] - 0s 784us/step - loss: 3.9593e-05 - val_loss: 3.9292e-05\n",
            "Epoch 294/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.3930e-05 - val_loss: 7.7271e-05\n",
            "Epoch 295/2000\n",
            "80/80 [==============================] - 0s 862us/step - loss: 3.5266e-05 - val_loss: 3.5623e-05\n",
            "Epoch 296/2000\n",
            "80/80 [==============================] - 0s 819us/step - loss: 3.4632e-05 - val_loss: 3.4789e-05\n",
            "Epoch 297/2000\n",
            "80/80 [==============================] - 0s 801us/step - loss: 3.1861e-05 - val_loss: 9.7902e-05\n",
            "Epoch 298/2000\n",
            "80/80 [==============================] - 0s 832us/step - loss: 4.2402e-05 - val_loss: 8.3632e-05\n",
            "Epoch 299/2000\n",
            "80/80 [==============================] - 0s 855us/step - loss: 7.5808e-05 - val_loss: 7.5661e-05\n",
            "Epoch 300/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 6.3570e-05 - val_loss: 7.4884e-05\n",
            "Epoch 301/2000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 1.1564e-04 - val_loss: 1.9802e-04\n",
            "Epoch 302/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 1.2557e-04 - val_loss: 2.8166e-04\n",
            "Epoch 303/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 1.2715e-04 - val_loss: 6.2680e-05\n",
            "Epoch 304/2000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 7.4234e-05 - val_loss: 7.2111e-05\n",
            "Epoch 305/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 8.8826e-05 - val_loss: 7.7816e-05\n",
            "Epoch 306/2000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 5.2813e-05 - val_loss: 4.8815e-05\n",
            "Epoch 307/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.0606e-05 - val_loss: 6.4869e-05\n",
            "Epoch 308/2000\n",
            "80/80 [==============================] - 0s 885us/step - loss: 4.2083e-05 - val_loss: 5.3822e-05\n",
            "Epoch 309/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 3.2575e-05 - val_loss: 3.9702e-05\n",
            "Epoch 310/2000\n",
            "80/80 [==============================] - 0s 996us/step - loss: 2.7683e-05 - val_loss: 4.7142e-05\n",
            "Epoch 311/2000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 3.9600e-05 - val_loss: 3.4251e-05\n",
            "Epoch 312/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 3.1831e-05 - val_loss: 6.3908e-05\n",
            "Epoch 313/2000\n",
            "80/80 [==============================] - 0s 771us/step - loss: 3.3546e-05 - val_loss: 3.3069e-05\n",
            "Epoch 314/2000\n",
            "80/80 [==============================] - 0s 893us/step - loss: 3.1415e-05 - val_loss: 5.3284e-05\n",
            "Epoch 315/2000\n",
            "80/80 [==============================] - 0s 825us/step - loss: 2.9708e-05 - val_loss: 5.6867e-05\n",
            "Epoch 316/2000\n",
            "80/80 [==============================] - 0s 824us/step - loss: 2.6770e-05 - val_loss: 3.5081e-05\n",
            "Epoch 317/2000\n",
            "80/80 [==============================] - 0s 825us/step - loss: 2.9119e-05 - val_loss: 5.7346e-05\n",
            "Epoch 318/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 2.5986e-05 - val_loss: 5.7484e-05\n",
            "Epoch 319/2000\n",
            "80/80 [==============================] - 0s 864us/step - loss: 2.9973e-05 - val_loss: 4.3638e-05\n",
            "Epoch 320/2000\n",
            "80/80 [==============================] - 0s 842us/step - loss: 4.1843e-05 - val_loss: 3.7564e-05\n",
            "Epoch 321/2000\n",
            "80/80 [==============================] - 0s 767us/step - loss: 2.5421e-05 - val_loss: 4.6348e-05\n",
            "Epoch 322/2000\n",
            "80/80 [==============================] - 0s 804us/step - loss: 2.6325e-05 - val_loss: 3.5539e-05\n",
            "Epoch 323/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 3.1697e-05 - val_loss: 6.4415e-05\n",
            "Epoch 324/2000\n",
            "80/80 [==============================] - 0s 844us/step - loss: 2.9264e-05 - val_loss: 3.2863e-05\n",
            "Epoch 325/2000\n",
            "80/80 [==============================] - 0s 883us/step - loss: 2.7513e-05 - val_loss: 4.6148e-05\n",
            "Epoch 326/2000\n",
            "80/80 [==============================] - 0s 893us/step - loss: 2.5610e-05 - val_loss: 4.6466e-05\n",
            "Epoch 327/2000\n",
            "80/80 [==============================] - 0s 851us/step - loss: 2.3561e-05 - val_loss: 2.9854e-05\n",
            "Epoch 328/2000\n",
            "80/80 [==============================] - 0s 801us/step - loss: 2.2124e-05 - val_loss: 5.8844e-05\n",
            "Epoch 329/2000\n",
            "80/80 [==============================] - 0s 832us/step - loss: 2.5144e-05 - val_loss: 3.3516e-05\n",
            "Epoch 330/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 2.2063e-05 - val_loss: 3.2350e-05\n",
            "Epoch 331/2000\n",
            "80/80 [==============================] - 0s 829us/step - loss: 2.3711e-05 - val_loss: 6.8245e-05\n",
            "Epoch 332/2000\n",
            "80/80 [==============================] - 0s 855us/step - loss: 2.9037e-05 - val_loss: 3.0394e-05\n",
            "Epoch 333/2000\n",
            "80/80 [==============================] - 0s 791us/step - loss: 2.1769e-05 - val_loss: 3.2559e-05\n",
            "Epoch 334/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 2.6856e-05 - val_loss: 8.6984e-05\n",
            "Epoch 335/2000\n",
            "80/80 [==============================] - 0s 843us/step - loss: 3.6457e-05 - val_loss: 4.1283e-05\n",
            "Epoch 336/2000\n",
            "80/80 [==============================] - 0s 765us/step - loss: 3.3825e-05 - val_loss: 1.3820e-04\n",
            "Epoch 337/2000\n",
            "80/80 [==============================] - 0s 752us/step - loss: 4.9879e-05 - val_loss: 4.4933e-05\n",
            "Epoch 338/2000\n",
            "80/80 [==============================] - 0s 837us/step - loss: 6.6618e-05 - val_loss: 3.5994e-05\n",
            "Epoch 339/2000\n",
            "80/80 [==============================] - 0s 816us/step - loss: 3.9368e-05 - val_loss: 9.1000e-05\n",
            "Epoch 340/2000\n",
            "80/80 [==============================] - 0s 809us/step - loss: 3.7844e-05 - val_loss: 4.1090e-05\n",
            "Epoch 341/2000\n",
            "80/80 [==============================] - 0s 992us/step - loss: 4.6455e-05 - val_loss: 3.6711e-05\n",
            "Epoch 342/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 4.8336e-05 - val_loss: 1.0646e-04\n",
            "Epoch 343/2000\n",
            "80/80 [==============================] - 0s 823us/step - loss: 6.2978e-05 - val_loss: 7.5413e-05\n",
            "Epoch 344/2000\n",
            "80/80 [==============================] - 0s 873us/step - loss: 8.0669e-05 - val_loss: 8.9086e-05\n",
            "Epoch 345/2000\n",
            "80/80 [==============================] - 0s 820us/step - loss: 7.6239e-05 - val_loss: 1.0783e-04\n",
            "Epoch 346/2000\n",
            "80/80 [==============================] - 0s 825us/step - loss: 7.1599e-05 - val_loss: 4.0057e-05\n",
            "Epoch 347/2000\n",
            "80/80 [==============================] - 0s 830us/step - loss: 5.7433e-05 - val_loss: 1.4869e-04\n",
            "Epoch 348/2000\n",
            "80/80 [==============================] - 0s 891us/step - loss: 7.8800e-05 - val_loss: 8.3443e-05\n",
            "Epoch 349/2000\n",
            "80/80 [==============================] - 0s 855us/step - loss: 6.5920e-05 - val_loss: 9.2751e-05\n",
            "Epoch 350/2000\n",
            "80/80 [==============================] - 0s 875us/step - loss: 7.2122e-05 - val_loss: 8.3162e-05\n",
            "Epoch 351/2000\n",
            "80/80 [==============================] - 0s 826us/step - loss: 6.4230e-05 - val_loss: 1.2829e-04\n",
            "Epoch 352/2000\n",
            "80/80 [==============================] - 0s 861us/step - loss: 9.6130e-05 - val_loss: 1.0897e-04\n",
            "Epoch 353/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 7.6589e-05 - val_loss: 4.4768e-05\n",
            "Epoch 354/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 1.0208e-04 - val_loss: 1.2565e-04\n",
            "Epoch 355/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 1.1818e-04 - val_loss: 2.1507e-04\n",
            "Epoch 356/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4948e-04 - val_loss: 9.8495e-05\n",
            "Epoch 357/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 1.5369e-04 - val_loss: 8.0172e-05\n",
            "Epoch 358/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 1.2077e-04 - val_loss: 2.7012e-04\n",
            "Epoch 359/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 1.7426e-04 - val_loss: 1.2910e-04\n",
            "Epoch 360/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 1.4552e-04 - val_loss: 7.8268e-05\n",
            "Epoch 361/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.0711e-05 - val_loss: 1.6613e-04\n",
            "Epoch 362/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.3101e-05 - val_loss: 6.0384e-05\n",
            "Epoch 363/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 6.4660e-05 - val_loss: 3.6257e-05\n",
            "Epoch 364/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 3.0034e-05 - val_loss: 5.3085e-05\n",
            "Epoch 365/2000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 2.3581e-05 - val_loss: 2.9247e-05\n",
            "Epoch 366/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 2.6711e-05 - val_loss: 2.9109e-05\n",
            "Epoch 367/2000\n",
            "80/80 [==============================] - 0s 979us/step - loss: 2.2792e-05 - val_loss: 4.1655e-05\n",
            "Epoch 368/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 2.3844e-05 - val_loss: 3.2898e-05\n",
            "Epoch 369/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 2.3223e-05 - val_loss: 2.6661e-05\n",
            "Epoch 370/2000\n",
            "80/80 [==============================] - 0s 993us/step - loss: 2.7813e-05 - val_loss: 4.7257e-05\n",
            "Epoch 371/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 1.9579e-05 - val_loss: 2.8480e-05\n",
            "Epoch 372/2000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 1.8793e-05 - val_loss: 3.4041e-05\n",
            "Epoch 373/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2620e-05 - val_loss: 4.0135e-05\n",
            "Epoch 374/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2204e-05 - val_loss: 2.4757e-05\n",
            "Epoch 375/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2391e-05 - val_loss: 3.8081e-05\n",
            "Epoch 376/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 2.1318e-05 - val_loss: 5.7146e-05\n",
            "Epoch 377/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.9276e-05 - val_loss: 3.9018e-05\n",
            "Epoch 378/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.9858e-05 - val_loss: 1.0137e-04\n",
            "Epoch 379/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 2.6036e-05 - val_loss: 3.3943e-05\n",
            "Epoch 380/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.5632e-05 - val_loss: 3.7891e-05\n",
            "Epoch 381/2000\n",
            "80/80 [==============================] - 0s 989us/step - loss: 2.0422e-05 - val_loss: 4.2638e-05\n",
            "Epoch 382/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 2.2614e-05 - val_loss: 4.1746e-05\n",
            "Epoch 383/2000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 3.3935e-05 - val_loss: 9.2380e-05\n",
            "Epoch 384/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.6350e-05 - val_loss: 6.5003e-05\n",
            "Epoch 385/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 3.3814e-05 - val_loss: 5.9212e-05\n",
            "Epoch 386/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.3736e-05 - val_loss: 2.9383e-05\n",
            "Epoch 387/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 6.6229e-05 - val_loss: 2.1348e-04\n",
            "Epoch 388/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 9.9155e-05 - val_loss: 3.8293e-05\n",
            "Epoch 389/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 7.5729e-05 - val_loss: 1.0752e-04\n",
            "Epoch 390/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.4472e-05 - val_loss: 1.6352e-04\n",
            "Epoch 391/2000\n",
            "80/80 [==============================] - 0s 977us/step - loss: 7.0707e-05 - val_loss: 3.8003e-05\n",
            "Epoch 392/2000\n",
            "80/80 [==============================] - 0s 979us/step - loss: 2.9118e-05 - val_loss: 3.2355e-05\n",
            "Epoch 393/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 3.1499e-05 - val_loss: 6.1333e-05\n",
            "Epoch 394/2000\n",
            "80/80 [==============================] - 0s 761us/step - loss: 2.2199e-05 - val_loss: 5.1542e-05\n",
            "Epoch 395/2000\n",
            "80/80 [==============================] - 0s 775us/step - loss: 4.7732e-05 - val_loss: 3.3791e-05\n",
            "Epoch 396/2000\n",
            "80/80 [==============================] - 0s 843us/step - loss: 3.2251e-05 - val_loss: 6.2133e-05\n",
            "Epoch 397/2000\n",
            "80/80 [==============================] - 0s 861us/step - loss: 4.2414e-05 - val_loss: 3.7977e-05\n",
            "Epoch 398/2000\n",
            "80/80 [==============================] - 0s 824us/step - loss: 5.7495e-05 - val_loss: 1.1229e-04\n",
            "Epoch 399/2000\n",
            "80/80 [==============================] - 0s 828us/step - loss: 1.7920e-04 - val_loss: 3.9953e-04\n",
            "Epoch 400/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 2.6917e-04 - val_loss: 1.5736e-04\n",
            "Epoch 401/2000\n",
            "80/80 [==============================] - 0s 766us/step - loss: 2.1823e-04 - val_loss: 5.4369e-05\n",
            "Epoch 402/2000\n",
            "80/80 [==============================] - 0s 815us/step - loss: 1.5790e-04 - val_loss: 1.5945e-04\n",
            "Epoch 403/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 7.6116e-05 - val_loss: 5.9557e-05\n",
            "Epoch 404/2000\n",
            "80/80 [==============================] - 0s 845us/step - loss: 7.2739e-05 - val_loss: 6.1077e-05\n",
            "Epoch 405/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 4.4755e-05 - val_loss: 5.9259e-05\n",
            "Epoch 406/2000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 5.2672e-05 - val_loss: 4.5481e-05\n",
            "Epoch 407/2000\n",
            "80/80 [==============================] - 0s 768us/step - loss: 3.4509e-05 - val_loss: 3.3207e-05\n",
            "Epoch 408/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.4020e-05 - val_loss: 4.9612e-05\n",
            "Epoch 409/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 3.6145e-05 - val_loss: 3.2177e-05\n",
            "Epoch 410/2000\n",
            "80/80 [==============================] - 0s 817us/step - loss: 2.5639e-05 - val_loss: 3.1454e-05\n",
            "Epoch 411/2000\n",
            "80/80 [==============================] - 0s 807us/step - loss: 2.7246e-05 - val_loss: 3.7894e-05\n",
            "Epoch 412/2000\n",
            "80/80 [==============================] - 0s 862us/step - loss: 1.9496e-05 - val_loss: 4.4700e-05\n",
            "Epoch 413/2000\n",
            "80/80 [==============================] - 0s 846us/step - loss: 2.4859e-05 - val_loss: 3.1802e-05\n",
            "Epoch 414/2000\n",
            "80/80 [==============================] - 0s 847us/step - loss: 1.7802e-05 - val_loss: 3.0713e-05\n",
            "Epoch 415/2000\n",
            "80/80 [==============================] - 0s 841us/step - loss: 2.0552e-05 - val_loss: 2.6175e-05\n",
            "Epoch 416/2000\n",
            "80/80 [==============================] - 0s 848us/step - loss: 2.3994e-05 - val_loss: 3.2521e-05\n",
            "Epoch 417/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 3.2828e-05 - val_loss: 2.1723e-05\n",
            "Epoch 418/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 2.4505e-05 - val_loss: 4.3085e-05\n",
            "Epoch 419/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 2.1674e-05 - val_loss: 2.7528e-05\n",
            "Epoch 420/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 1.8982e-05 - val_loss: 2.0997e-05\n",
            "Epoch 421/2000\n",
            "80/80 [==============================] - 0s 843us/step - loss: 1.9135e-05 - val_loss: 2.7879e-05\n",
            "Epoch 422/2000\n",
            "80/80 [==============================] - 0s 846us/step - loss: 2.1438e-05 - val_loss: 3.0745e-05\n",
            "Epoch 423/2000\n",
            "80/80 [==============================] - 0s 854us/step - loss: 1.5693e-05 - val_loss: 2.0816e-05\n",
            "Epoch 424/2000\n",
            "80/80 [==============================] - 0s 877us/step - loss: 1.4007e-05 - val_loss: 2.3341e-05\n",
            "Epoch 425/2000\n",
            "80/80 [==============================] - 0s 835us/step - loss: 1.3959e-05 - val_loss: 2.2244e-05\n",
            "Epoch 426/2000\n",
            "80/80 [==============================] - 0s 814us/step - loss: 1.4612e-05 - val_loss: 2.1134e-05\n",
            "Epoch 427/2000\n",
            "80/80 [==============================] - 0s 800us/step - loss: 1.8366e-05 - val_loss: 2.1151e-05\n",
            "Epoch 428/2000\n",
            "80/80 [==============================] - 0s 868us/step - loss: 1.6402e-05 - val_loss: 2.2967e-05\n",
            "Epoch 429/2000\n",
            "80/80 [==============================] - 0s 824us/step - loss: 1.5483e-05 - val_loss: 2.4088e-05\n",
            "Epoch 430/2000\n",
            "80/80 [==============================] - 0s 830us/step - loss: 1.5423e-05 - val_loss: 2.1062e-05\n",
            "Epoch 431/2000\n",
            "80/80 [==============================] - 0s 816us/step - loss: 1.2801e-05 - val_loss: 2.1969e-05\n",
            "Epoch 432/2000\n",
            "80/80 [==============================] - 0s 789us/step - loss: 1.1700e-05 - val_loss: 2.3685e-05\n",
            "Epoch 433/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 1.5428e-05 - val_loss: 2.5392e-05\n",
            "Epoch 434/2000\n",
            "80/80 [==============================] - 0s 883us/step - loss: 1.7839e-05 - val_loss: 2.2330e-05\n",
            "Epoch 435/2000\n",
            "80/80 [==============================] - 0s 802us/step - loss: 1.9042e-05 - val_loss: 3.9044e-05\n",
            "Epoch 436/2000\n",
            "80/80 [==============================] - 0s 858us/step - loss: 2.1687e-05 - val_loss: 2.0937e-05\n",
            "Epoch 437/2000\n",
            "80/80 [==============================] - 0s 853us/step - loss: 1.5592e-05 - val_loss: 2.5662e-05\n",
            "Epoch 438/2000\n",
            "80/80 [==============================] - 0s 811us/step - loss: 2.4461e-05 - val_loss: 1.7960e-05\n",
            "Epoch 439/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 2.3441e-05 - val_loss: 3.0154e-05\n",
            "Epoch 440/2000\n",
            "80/80 [==============================] - 0s 830us/step - loss: 1.4055e-05 - val_loss: 1.8294e-05\n",
            "Epoch 441/2000\n",
            "80/80 [==============================] - 0s 840us/step - loss: 1.5318e-05 - val_loss: 2.0417e-05\n",
            "Epoch 442/2000\n",
            "80/80 [==============================] - 0s 865us/step - loss: 1.4189e-05 - val_loss: 2.0048e-05\n",
            "Epoch 443/2000\n",
            "80/80 [==============================] - 0s 827us/step - loss: 1.2604e-05 - val_loss: 2.7400e-05\n",
            "Epoch 444/2000\n",
            "80/80 [==============================] - 0s 853us/step - loss: 1.6497e-05 - val_loss: 2.3261e-05\n",
            "Epoch 445/2000\n",
            "80/80 [==============================] - 0s 815us/step - loss: 1.4343e-05 - val_loss: 2.2286e-05\n",
            "Epoch 446/2000\n",
            "80/80 [==============================] - 0s 891us/step - loss: 1.9217e-05 - val_loss: 3.7985e-05\n",
            "Epoch 447/2000\n",
            "80/80 [==============================] - 0s 862us/step - loss: 1.8942e-05 - val_loss: 2.2266e-05\n",
            "Epoch 448/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 1.5524e-05 - val_loss: 4.2504e-05\n",
            "Epoch 449/2000\n",
            "80/80 [==============================] - 0s 890us/step - loss: 3.4204e-05 - val_loss: 3.3005e-05\n",
            "Epoch 450/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.5069e-05 - val_loss: 5.5510e-05\n",
            "Epoch 451/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 4.9574e-05 - val_loss: 6.5849e-05\n",
            "Epoch 452/2000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 9.3025e-05 - val_loss: 1.3037e-04\n",
            "Epoch 453/2000\n",
            "80/80 [==============================] - 0s 996us/step - loss: 9.9668e-05 - val_loss: 8.9142e-05\n",
            "Epoch 454/2000\n",
            "80/80 [==============================] - 0s 885us/step - loss: 7.0638e-05 - val_loss: 4.2115e-05\n",
            "Epoch 455/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 6.9364e-05 - val_loss: 8.3106e-05\n",
            "Epoch 456/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.0605e-05 - val_loss: 2.7027e-05\n",
            "Epoch 457/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 2.6230e-05 - val_loss: 6.1180e-05\n",
            "Epoch 458/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 3.5409e-05 - val_loss: 1.4035e-04\n",
            "Epoch 459/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 8.4711e-05 - val_loss: 5.5844e-05\n",
            "Epoch 460/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.4676e-05 - val_loss: 1.6078e-04\n",
            "Epoch 461/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.3780e-05 - val_loss: 3.7309e-05\n",
            "Epoch 462/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 5.0753e-05 - val_loss: 4.5828e-05\n",
            "Epoch 463/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 4.3589e-05 - val_loss: 2.0137e-04\n",
            "Epoch 464/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.5943e-05 - val_loss: 3.5295e-05\n",
            "Epoch 465/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1626e-04 - val_loss: 1.3345e-04\n",
            "Epoch 466/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 1.4731e-04 - val_loss: 1.5355e-04\n",
            "Epoch 467/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 1.8558e-04 - val_loss: 7.2602e-04\n",
            "Epoch 468/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 4.7910e-04 - val_loss: 2.8566e-04\n",
            "Epoch 469/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 3.8700e-04 - val_loss: 3.8872e-04\n",
            "Epoch 470/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 3.2767e-04 - val_loss: 4.0008e-04\n",
            "Epoch 471/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 2.6750e-04 - val_loss: 6.0596e-04\n",
            "Epoch 472/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.2262e-04 - val_loss: 1.5300e-04\n",
            "Epoch 473/2000\n",
            "80/80 [==============================] - 0s 989us/step - loss: 1.6861e-04 - val_loss: 1.5505e-04\n",
            "Epoch 474/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 2.3570e-04 - val_loss: 3.5462e-04\n",
            "Epoch 475/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 2.3241e-04 - val_loss: 2.5588e-04\n",
            "Epoch 476/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 1.5679e-04 - val_loss: 3.3087e-04\n",
            "Epoch 477/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 2.5272e-04 - val_loss: 3.7285e-04\n",
            "Epoch 478/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 2.8409e-04 - val_loss: 3.0436e-04\n",
            "Epoch 479/2000\n",
            "80/80 [==============================] - 0s 889us/step - loss: 2.6856e-04 - val_loss: 1.4962e-04\n",
            "Epoch 480/2000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 1.6656e-04 - val_loss: 6.1293e-05\n",
            "Epoch 481/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 1.1367e-04 - val_loss: 1.9602e-04\n",
            "Epoch 482/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 1.1382e-04 - val_loss: 8.8123e-05\n",
            "Epoch 483/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 1.1230e-04 - val_loss: 1.0581e-04\n",
            "Epoch 484/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 7.7773e-05 - val_loss: 7.4843e-05\n",
            "Epoch 485/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.8207e-05 - val_loss: 5.2445e-05\n",
            "Epoch 486/2000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 4.1217e-05 - val_loss: 4.8872e-05\n",
            "Epoch 487/2000\n",
            "80/80 [==============================] - 0s 993us/step - loss: 4.7498e-05 - val_loss: 7.4662e-05\n",
            "Epoch 488/2000\n",
            "80/80 [==============================] - 0s 851us/step - loss: 3.1931e-05 - val_loss: 4.7218e-05\n",
            "Epoch 489/2000\n",
            "80/80 [==============================] - 0s 756us/step - loss: 4.5653e-05 - val_loss: 2.5973e-05\n",
            "Epoch 490/2000\n",
            "80/80 [==============================] - 0s 849us/step - loss: 3.9589e-05 - val_loss: 1.5876e-04\n",
            "Epoch 491/2000\n",
            "80/80 [==============================] - 0s 802us/step - loss: 5.4249e-05 - val_loss: 3.7995e-05\n",
            "Epoch 492/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 5.9615e-05 - val_loss: 4.8515e-05\n",
            "Epoch 493/2000\n",
            "80/80 [==============================] - 0s 761us/step - loss: 3.4633e-05 - val_loss: 8.6033e-05\n",
            "Epoch 494/2000\n",
            "80/80 [==============================] - 0s 823us/step - loss: 5.5933e-05 - val_loss: 2.6939e-05\n",
            "Epoch 495/2000\n",
            "80/80 [==============================] - 0s 862us/step - loss: 4.0040e-05 - val_loss: 1.1267e-04\n",
            "Epoch 496/2000\n",
            "80/80 [==============================] - 0s 824us/step - loss: 1.1114e-04 - val_loss: 1.4064e-04\n",
            "Epoch 497/2000\n",
            "80/80 [==============================] - 0s 859us/step - loss: 1.0585e-04 - val_loss: 1.5438e-04\n",
            "Epoch 498/2000\n",
            "80/80 [==============================] - 0s 881us/step - loss: 9.7913e-05 - val_loss: 1.7572e-04\n",
            "Epoch 499/2000\n",
            "80/80 [==============================] - 0s 780us/step - loss: 1.9242e-04 - val_loss: 2.9106e-05\n",
            "Epoch 500/2000\n",
            "80/80 [==============================] - 0s 778us/step - loss: 1.1411e-04 - val_loss: 2.5519e-04\n",
            "Epoch 501/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 1.1697e-04 - val_loss: 5.9237e-05\n",
            "Epoch 502/2000\n",
            "80/80 [==============================] - 0s 881us/step - loss: 8.4302e-05 - val_loss: 7.5553e-05\n",
            "Epoch 503/2000\n",
            "80/80 [==============================] - 0s 821us/step - loss: 1.0372e-04 - val_loss: 9.6644e-05\n",
            "Epoch 504/2000\n",
            "80/80 [==============================] - 0s 826us/step - loss: 6.5887e-05 - val_loss: 2.3351e-05\n",
            "Epoch 505/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 6.6139e-05 - val_loss: 1.0095e-04\n",
            "Epoch 506/2000\n",
            "80/80 [==============================] - 0s 777us/step - loss: 6.4853e-05 - val_loss: 2.6706e-05\n",
            "Epoch 507/2000\n",
            "80/80 [==============================] - 0s 824us/step - loss: 3.1503e-05 - val_loss: 7.1177e-05\n",
            "Epoch 508/2000\n",
            "80/80 [==============================] - 0s 810us/step - loss: 3.7223e-05 - val_loss: 4.6578e-05\n",
            "Epoch 509/2000\n",
            "80/80 [==============================] - 0s 837us/step - loss: 5.3851e-05 - val_loss: 4.0078e-05\n",
            "Epoch 510/2000\n",
            "80/80 [==============================] - 0s 800us/step - loss: 4.7578e-05 - val_loss: 3.2700e-05\n",
            "Epoch 511/2000\n",
            "80/80 [==============================] - 0s 981us/step - loss: 3.8160e-05 - val_loss: 1.4166e-04\n",
            "Epoch 512/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 6.7397e-05 - val_loss: 3.8859e-05\n",
            "Epoch 513/2000\n",
            "80/80 [==============================] - 0s 850us/step - loss: 5.0424e-05 - val_loss: 8.0413e-05\n",
            "Epoch 514/2000\n",
            "80/80 [==============================] - 0s 815us/step - loss: 9.2637e-05 - val_loss: 7.2655e-05\n",
            "Epoch 515/2000\n",
            "80/80 [==============================] - 0s 890us/step - loss: 7.9231e-05 - val_loss: 1.3136e-04\n",
            "Epoch 516/2000\n",
            "80/80 [==============================] - 0s 842us/step - loss: 8.2647e-05 - val_loss: 9.0796e-05\n",
            "Epoch 517/2000\n",
            "80/80 [==============================] - 0s 834us/step - loss: 1.8717e-04 - val_loss: 1.1975e-04\n",
            "Epoch 518/2000\n",
            "80/80 [==============================] - 0s 885us/step - loss: 1.7997e-04 - val_loss: 2.5856e-04\n",
            "Epoch 519/2000\n",
            "80/80 [==============================] - 0s 813us/step - loss: 2.2741e-04 - val_loss: 2.4405e-04\n",
            "Epoch 520/2000\n",
            "80/80 [==============================] - 0s 845us/step - loss: 2.6400e-04 - val_loss: 2.3592e-04\n",
            "Epoch 521/2000\n",
            "80/80 [==============================] - 0s 873us/step - loss: 1.7581e-04 - val_loss: 5.6091e-05\n",
            "Epoch 522/2000\n",
            "80/80 [==============================] - 0s 796us/step - loss: 1.2649e-04 - val_loss: 2.0576e-04\n",
            "Epoch 523/2000\n",
            "80/80 [==============================] - 0s 792us/step - loss: 1.2601e-04 - val_loss: 3.6307e-05\n",
            "Epoch 524/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 6.4103e-05 - val_loss: 7.9982e-05\n",
            "Epoch 525/2000\n",
            "80/80 [==============================] - 0s 861us/step - loss: 6.6489e-05 - val_loss: 7.8287e-05\n",
            "Epoch 526/2000\n",
            "80/80 [==============================] - 0s 814us/step - loss: 5.0443e-05 - val_loss: 3.6067e-05\n",
            "Epoch 527/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 4.8201e-05 - val_loss: 5.6859e-05\n",
            "Epoch 528/2000\n",
            "80/80 [==============================] - 0s 801us/step - loss: 7.2810e-05 - val_loss: 2.4036e-05\n",
            "Epoch 529/2000\n",
            "80/80 [==============================] - 0s 800us/step - loss: 6.6005e-05 - val_loss: 1.6767e-04\n",
            "Epoch 530/2000\n",
            "80/80 [==============================] - 0s 873us/step - loss: 9.6264e-05 - val_loss: 2.0309e-05\n",
            "Epoch 531/2000\n",
            "80/80 [==============================] - 0s 869us/step - loss: 7.1734e-05 - val_loss: 9.1020e-05\n",
            "Epoch 532/2000\n",
            "80/80 [==============================] - 0s 836us/step - loss: 7.3303e-05 - val_loss: 2.2728e-05\n",
            "Epoch 533/2000\n",
            "80/80 [==============================] - 0s 848us/step - loss: 4.9288e-05 - val_loss: 1.2749e-04\n",
            "Epoch 534/2000\n",
            "80/80 [==============================] - 0s 796us/step - loss: 8.3739e-05 - val_loss: 2.7665e-05\n",
            "Epoch 535/2000\n",
            "80/80 [==============================] - 0s 883us/step - loss: 7.6128e-05 - val_loss: 3.9363e-05\n",
            "Epoch 536/2000\n",
            "80/80 [==============================] - 0s 854us/step - loss: 5.9739e-05 - val_loss: 2.6778e-05\n",
            "Epoch 537/2000\n",
            "80/80 [==============================] - 0s 785us/step - loss: 3.4429e-05 - val_loss: 3.5318e-05\n",
            "Epoch 538/2000\n",
            "80/80 [==============================] - 0s 800us/step - loss: 2.2270e-05 - val_loss: 1.9407e-05\n",
            "Epoch 539/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 1.6795e-05 - val_loss: 1.5499e-05\n",
            "Epoch 540/2000\n",
            "80/80 [==============================] - 0s 863us/step - loss: 1.7256e-05 - val_loss: 3.0488e-05\n",
            "Epoch 541/2000\n",
            "80/80 [==============================] - 0s 814us/step - loss: 2.1838e-05 - val_loss: 1.9667e-05\n",
            "Epoch 542/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 1.8767e-05 - val_loss: 2.0187e-05\n",
            "Epoch 543/2000\n",
            "80/80 [==============================] - 0s 792us/step - loss: 2.5770e-05 - val_loss: 4.1656e-05\n",
            "Epoch 544/2000\n",
            "80/80 [==============================] - 0s 836us/step - loss: 2.9137e-05 - val_loss: 1.8378e-05\n",
            "Epoch 545/2000\n",
            "80/80 [==============================] - 0s 898us/step - loss: 2.8550e-05 - val_loss: 4.7440e-05\n",
            "Epoch 546/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 5.4321e-05 - val_loss: 2.5230e-05\n",
            "Epoch 547/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.4328e-05 - val_loss: 7.0303e-05\n",
            "Epoch 548/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 3.9945e-05 - val_loss: 2.4412e-05\n",
            "Epoch 549/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 4.0543e-05 - val_loss: 2.8000e-05\n",
            "Epoch 550/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 3.5813e-05 - val_loss: 2.2752e-05\n",
            "Epoch 551/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 3.6758e-05 - val_loss: 2.8071e-05\n",
            "Epoch 552/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 4.2666e-05 - val_loss: 5.5789e-05\n",
            "Epoch 553/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 6.1527e-05 - val_loss: 2.6841e-05\n",
            "Epoch 554/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 5.5784e-05 - val_loss: 3.1410e-05\n",
            "Epoch 555/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.8135e-05 - val_loss: 3.2076e-05\n",
            "Epoch 556/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.9924e-05 - val_loss: 2.0866e-05\n",
            "Epoch 557/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.5107e-05 - val_loss: 2.0792e-05\n",
            "Epoch 558/2000\n",
            "80/80 [==============================] - 0s 981us/step - loss: 2.1953e-05 - val_loss: 2.3258e-05\n",
            "Epoch 559/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.9686e-05 - val_loss: 3.8453e-05\n",
            "Epoch 560/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 2.0878e-05 - val_loss: 2.8292e-05\n",
            "Epoch 561/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 1.9936e-05 - val_loss: 1.5494e-05\n",
            "Epoch 562/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 1.5227e-05 - val_loss: 3.5000e-05\n",
            "Epoch 563/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 2.1746e-05 - val_loss: 2.0262e-05\n",
            "Epoch 564/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.5837e-05 - val_loss: 1.8267e-05\n",
            "Epoch 565/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 1.7518e-05 - val_loss: 1.6188e-05\n",
            "Epoch 566/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 1.9962e-05 - val_loss: 2.0384e-05\n",
            "Epoch 567/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 1.7430e-05 - val_loss: 1.9776e-05\n",
            "Epoch 568/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 1.5426e-05 - val_loss: 1.5449e-05\n",
            "Epoch 569/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 1.4585e-05 - val_loss: 1.2881e-05\n",
            "Epoch 570/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 1.7396e-05 - val_loss: 1.2206e-05\n",
            "Epoch 571/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 9.6245e-06 - val_loss: 1.3199e-05\n",
            "Epoch 572/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0721e-05 - val_loss: 1.8686e-05\n",
            "Epoch 573/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 1.5578e-05 - val_loss: 2.0665e-05\n",
            "Epoch 574/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 1.5531e-05 - val_loss: 2.5306e-05\n",
            "Epoch 575/2000\n",
            "80/80 [==============================] - 0s 891us/step - loss: 1.7682e-05 - val_loss: 2.8547e-05\n",
            "Epoch 576/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 1.4600e-05 - val_loss: 2.5979e-05\n",
            "Epoch 577/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 3.0956e-05 - val_loss: 6.0999e-05\n",
            "Epoch 578/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 6.3165e-05 - val_loss: 3.2371e-05\n",
            "Epoch 579/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 3.9887e-05 - val_loss: 2.0050e-05\n",
            "Epoch 580/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.9812e-05 - val_loss: 2.8279e-05\n",
            "Epoch 581/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 2.0536e-05 - val_loss: 1.8058e-05\n",
            "Epoch 582/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 1.8044e-05 - val_loss: 3.6289e-05\n",
            "Epoch 583/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 1.8489e-05 - val_loss: 1.2009e-05\n",
            "Epoch 584/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 1.3321e-05 - val_loss: 2.0779e-05\n",
            "Epoch 585/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8934e-05 - val_loss: 1.4916e-05\n",
            "Epoch 586/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.1496e-05 - val_loss: 4.2360e-05\n",
            "Epoch 587/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 2.1471e-05 - val_loss: 2.1143e-05\n",
            "Epoch 588/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 1.1924e-05 - val_loss: 1.7683e-05\n",
            "Epoch 589/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.6508e-05 - val_loss: 1.2465e-05\n",
            "Epoch 590/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 1.7009e-05 - val_loss: 2.3886e-05\n",
            "Epoch 591/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3562e-05 - val_loss: 1.3264e-05\n",
            "Epoch 592/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 9.2418e-06 - val_loss: 1.2387e-05\n",
            "Epoch 593/2000\n",
            "80/80 [==============================] - 0s 977us/step - loss: 1.1124e-05 - val_loss: 1.1564e-05\n",
            "Epoch 594/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 9.9530e-06 - val_loss: 1.2882e-05\n",
            "Epoch 595/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 1.1796e-05 - val_loss: 1.2551e-05\n",
            "Epoch 596/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 1.1622e-05 - val_loss: 3.2283e-05\n",
            "Epoch 597/2000\n",
            "80/80 [==============================] - 0s 867us/step - loss: 2.1237e-05 - val_loss: 4.2279e-05\n",
            "Epoch 598/2000\n",
            "80/80 [==============================] - 0s 875us/step - loss: 2.3148e-05 - val_loss: 1.4338e-05\n",
            "Epoch 599/2000\n",
            "80/80 [==============================] - 0s 825us/step - loss: 1.5340e-05 - val_loss: 1.6709e-05\n",
            "Epoch 600/2000\n",
            "80/80 [==============================] - 0s 786us/step - loss: 1.7225e-05 - val_loss: 1.2762e-05\n",
            "Epoch 601/2000\n",
            "80/80 [==============================] - 0s 822us/step - loss: 1.2169e-05 - val_loss: 4.8728e-05\n",
            "Epoch 602/2000\n",
            "80/80 [==============================] - 0s 866us/step - loss: 1.6154e-05 - val_loss: 2.3103e-05\n",
            "Epoch 603/2000\n",
            "80/80 [==============================] - 0s 790us/step - loss: 4.4227e-05 - val_loss: 5.9206e-05\n",
            "Epoch 604/2000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 4.4405e-05 - val_loss: 3.3168e-05\n",
            "Epoch 605/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 2.7349e-05 - val_loss: 8.0058e-05\n",
            "Epoch 606/2000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 3.8553e-05 - val_loss: 2.7816e-05\n",
            "Epoch 607/2000\n",
            "80/80 [==============================] - 0s 853us/step - loss: 2.6853e-05 - val_loss: 1.8601e-05\n",
            "Epoch 608/2000\n",
            "80/80 [==============================] - 0s 979us/step - loss: 2.0937e-05 - val_loss: 3.3468e-05\n",
            "Epoch 609/2000\n",
            "80/80 [==============================] - 0s 840us/step - loss: 2.7306e-05 - val_loss: 3.4436e-05\n",
            "Epoch 610/2000\n",
            "80/80 [==============================] - 0s 833us/step - loss: 3.4788e-05 - val_loss: 6.0487e-05\n",
            "Epoch 611/2000\n",
            "80/80 [==============================] - 0s 835us/step - loss: 3.0546e-05 - val_loss: 4.3930e-05\n",
            "Epoch 612/2000\n",
            "80/80 [==============================] - 0s 839us/step - loss: 3.1658e-05 - val_loss: 3.0579e-05\n",
            "Epoch 613/2000\n",
            "80/80 [==============================] - 0s 853us/step - loss: 3.0149e-05 - val_loss: 9.6980e-05\n",
            "Epoch 614/2000\n",
            "80/80 [==============================] - 0s 823us/step - loss: 6.8171e-05 - val_loss: 4.1387e-05\n",
            "Epoch 615/2000\n",
            "80/80 [==============================] - 0s 873us/step - loss: 8.3169e-05 - val_loss: 1.0117e-04\n",
            "Epoch 616/2000\n",
            "80/80 [==============================] - 0s 824us/step - loss: 1.2325e-04 - val_loss: 1.0422e-04\n",
            "Epoch 617/2000\n",
            "80/80 [==============================] - 0s 869us/step - loss: 1.8010e-04 - val_loss: 1.1358e-04\n",
            "Epoch 618/2000\n",
            "80/80 [==============================] - 0s 813us/step - loss: 2.5522e-04 - val_loss: 2.7782e-04\n",
            "Epoch 619/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 2.2174e-04 - val_loss: 4.0665e-05\n",
            "Epoch 620/2000\n",
            "80/80 [==============================] - 0s 874us/step - loss: 1.5553e-04 - val_loss: 2.5499e-04\n",
            "Epoch 621/2000\n",
            "80/80 [==============================] - 0s 831us/step - loss: 2.5003e-04 - val_loss: 3.8936e-05\n",
            "Epoch 622/2000\n",
            "80/80 [==============================] - 0s 850us/step - loss: 4.6672e-05 - val_loss: 2.2432e-04\n",
            "Epoch 623/2000\n",
            "80/80 [==============================] - 0s 886us/step - loss: 7.8445e-05 - val_loss: 1.2652e-04\n",
            "Epoch 624/2000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 7.1798e-05 - val_loss: 1.1062e-04\n",
            "Epoch 625/2000\n",
            "80/80 [==============================] - 0s 883us/step - loss: 1.0370e-04 - val_loss: 1.0828e-04\n",
            "Epoch 626/2000\n",
            "80/80 [==============================] - 0s 837us/step - loss: 1.0750e-04 - val_loss: 1.1032e-04\n",
            "Epoch 627/2000\n",
            "80/80 [==============================] - 0s 843us/step - loss: 8.4417e-05 - val_loss: 9.9242e-05\n",
            "Epoch 628/2000\n",
            "80/80 [==============================] - 0s 832us/step - loss: 9.3647e-05 - val_loss: 1.2495e-04\n",
            "Epoch 629/2000\n",
            "80/80 [==============================] - 0s 835us/step - loss: 1.2363e-04 - val_loss: 9.0756e-05\n",
            "Epoch 630/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.2839e-05 - val_loss: 5.7775e-05\n",
            "Epoch 631/2000\n",
            "80/80 [==============================] - 0s 881us/step - loss: 8.4185e-05 - val_loss: 1.3376e-04\n",
            "Epoch 632/2000\n",
            "80/80 [==============================] - 0s 865us/step - loss: 1.1789e-04 - val_loss: 1.0966e-04\n",
            "Epoch 633/2000\n",
            "80/80 [==============================] - 0s 836us/step - loss: 8.3891e-05 - val_loss: 4.8840e-05\n",
            "Epoch 634/2000\n",
            "80/80 [==============================] - 0s 850us/step - loss: 6.1197e-05 - val_loss: 1.8082e-04\n",
            "Epoch 635/2000\n",
            "80/80 [==============================] - 0s 816us/step - loss: 2.0311e-04 - val_loss: 1.3076e-04\n",
            "Epoch 636/2000\n",
            "80/80 [==============================] - 0s 787us/step - loss: 1.9791e-04 - val_loss: 1.3221e-04\n",
            "Epoch 637/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.1137e-04 - val_loss: 5.6849e-04\n",
            "Epoch 638/2000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 3.6106e-04 - val_loss: 4.1713e-04\n",
            "Epoch 639/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 4.0886e-04 - val_loss: 6.3161e-05\n",
            "Epoch 640/2000\n",
            "80/80 [==============================] - 0s 834us/step - loss: 1.0022e-04 - val_loss: 1.1730e-04\n",
            "Epoch 641/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 9.7341e-05 - val_loss: 5.1385e-05\n",
            "Epoch 642/2000\n",
            "80/80 [==============================] - 0s 830us/step - loss: 6.0854e-05 - val_loss: 2.7807e-05\n",
            "Epoch 643/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 4.9404e-05 - val_loss: 3.1512e-05\n",
            "Epoch 644/2000\n",
            "80/80 [==============================] - 0s 853us/step - loss: 2.8781e-05 - val_loss: 2.4233e-05\n",
            "Epoch 645/2000\n",
            "80/80 [==============================] - 0s 834us/step - loss: 3.5762e-05 - val_loss: 1.6132e-05\n",
            "Epoch 646/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 3.9374e-05 - val_loss: 3.7026e-05\n",
            "Epoch 647/2000\n",
            "80/80 [==============================] - 0s 848us/step - loss: 3.3514e-05 - val_loss: 5.8416e-05\n",
            "Epoch 648/2000\n",
            "80/80 [==============================] - 0s 886us/step - loss: 4.1590e-05 - val_loss: 1.6369e-05\n",
            "Epoch 649/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 2.6207e-05 - val_loss: 3.9683e-05\n",
            "Epoch 650/2000\n",
            "80/80 [==============================] - 0s 836us/step - loss: 3.5334e-05 - val_loss: 2.7886e-05\n",
            "Epoch 651/2000\n",
            "80/80 [==============================] - 0s 855us/step - loss: 1.8707e-05 - val_loss: 3.2010e-05\n",
            "Epoch 652/2000\n",
            "80/80 [==============================] - 0s 892us/step - loss: 2.4956e-05 - val_loss: 2.6976e-05\n",
            "Epoch 653/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 1.9086e-05 - val_loss: 2.8290e-05\n",
            "Epoch 654/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 2.4347e-05 - val_loss: 1.9159e-05\n",
            "Epoch 655/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0467e-05 - val_loss: 1.5168e-05\n",
            "Epoch 656/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 3.1186e-05 - val_loss: 5.0503e-05\n",
            "Epoch 657/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 4.0918e-05 - val_loss: 2.1541e-05\n",
            "Epoch 658/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 2.5491e-05 - val_loss: 3.9121e-05\n",
            "Epoch 659/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 3.5325e-05 - val_loss: 1.8776e-05\n",
            "Epoch 660/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 2.9537e-05 - val_loss: 1.0101e-05\n",
            "Epoch 661/2000\n",
            "80/80 [==============================] - 0s 977us/step - loss: 1.4441e-05 - val_loss: 7.1731e-05\n",
            "Epoch 662/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 3.6970e-05 - val_loss: 2.1490e-05\n",
            "Epoch 663/2000\n",
            "80/80 [==============================] - 0s 994us/step - loss: 2.0050e-05 - val_loss: 1.6128e-05\n",
            "Epoch 664/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 1.3791e-05 - val_loss: 2.5054e-05\n",
            "Epoch 665/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 1.9487e-05 - val_loss: 1.9465e-05\n",
            "Epoch 666/2000\n",
            "80/80 [==============================] - 0s 876us/step - loss: 2.4604e-05 - val_loss: 2.3327e-05\n",
            "Epoch 667/2000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 3.3641e-05 - val_loss: 2.2186e-05\n",
            "Epoch 668/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 1.4340e-05 - val_loss: 2.0592e-05\n",
            "Epoch 669/2000\n",
            "80/80 [==============================] - 0s 837us/step - loss: 1.7406e-05 - val_loss: 3.3252e-05\n",
            "Epoch 670/2000\n",
            "80/80 [==============================] - 0s 837us/step - loss: 2.5099e-05 - val_loss: 5.0953e-05\n",
            "Epoch 671/2000\n",
            "80/80 [==============================] - 0s 842us/step - loss: 4.4975e-05 - val_loss: 1.7497e-04\n",
            "Epoch 672/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 1.1063e-04 - val_loss: 4.5783e-05\n",
            "Epoch 673/2000\n",
            "80/80 [==============================] - 0s 823us/step - loss: 6.2706e-05 - val_loss: 5.2726e-05\n",
            "Epoch 674/2000\n",
            "80/80 [==============================] - 0s 856us/step - loss: 8.0233e-05 - val_loss: 1.7362e-04\n",
            "Epoch 675/2000\n",
            "80/80 [==============================] - 0s 794us/step - loss: 1.6473e-04 - val_loss: 5.8425e-05\n",
            "Epoch 676/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 1.3555e-04 - val_loss: 4.5335e-05\n",
            "Epoch 677/2000\n",
            "80/80 [==============================] - 0s 850us/step - loss: 9.7347e-05 - val_loss: 3.6858e-04\n",
            "Epoch 678/2000\n",
            "80/80 [==============================] - 0s 845us/step - loss: 2.4321e-04 - val_loss: 5.9216e-04\n",
            "Epoch 679/2000\n",
            "80/80 [==============================] - 0s 857us/step - loss: 7.2635e-04 - val_loss: 5.0381e-04\n",
            "Epoch 680/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 8.2851e-04 - val_loss: 5.6111e-04\n",
            "Epoch 681/2000\n",
            "80/80 [==============================] - 0s 825us/step - loss: 8.8843e-04 - val_loss: 9.9807e-04\n",
            "Epoch 682/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 683/2000\n",
            "80/80 [==============================] - 0s 846us/step - loss: 0.0012 - val_loss: 9.6268e-04\n",
            "Epoch 684/2000\n",
            "80/80 [==============================] - 0s 884us/step - loss: 7.8560e-04 - val_loss: 2.4214e-04\n",
            "Epoch 685/2000\n",
            "80/80 [==============================] - 0s 855us/step - loss: 3.5451e-04 - val_loss: 2.7875e-04\n",
            "Epoch 686/2000\n",
            "80/80 [==============================] - 0s 848us/step - loss: 3.6098e-04 - val_loss: 6.0648e-04\n",
            "Epoch 687/2000\n",
            "80/80 [==============================] - 0s 894us/step - loss: 4.1827e-04 - val_loss: 1.3117e-04\n",
            "Epoch 688/2000\n",
            "80/80 [==============================] - 0s 811us/step - loss: 1.8339e-04 - val_loss: 2.2329e-04\n",
            "Epoch 689/2000\n",
            "80/80 [==============================] - 0s 843us/step - loss: 1.6400e-04 - val_loss: 3.2388e-04\n",
            "Epoch 690/2000\n",
            "80/80 [==============================] - 0s 875us/step - loss: 3.1655e-04 - val_loss: 3.2925e-04\n",
            "Epoch 691/2000\n",
            "80/80 [==============================] - 0s 878us/step - loss: 3.7661e-04 - val_loss: 3.9761e-04\n",
            "Epoch 692/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 6.1893e-04 - val_loss: 3.7320e-04\n",
            "Epoch 693/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 6.5535e-04 - val_loss: 3.5074e-04\n",
            "Epoch 694/2000\n",
            "80/80 [==============================] - 0s 843us/step - loss: 2.1710e-04 - val_loss: 1.6048e-04\n",
            "Epoch 695/2000\n",
            "80/80 [==============================] - 0s 796us/step - loss: 1.6191e-04 - val_loss: 2.8952e-05\n",
            "Epoch 696/2000\n",
            "80/80 [==============================] - 0s 793us/step - loss: 6.7851e-05 - val_loss: 2.1882e-04\n",
            "Epoch 697/2000\n",
            "80/80 [==============================] - 0s 875us/step - loss: 9.3561e-05 - val_loss: 4.1550e-05\n",
            "Epoch 698/2000\n",
            "80/80 [==============================] - 0s 818us/step - loss: 3.5532e-05 - val_loss: 5.8159e-05\n",
            "Epoch 699/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 8.0329e-05 - val_loss: 4.6233e-05\n",
            "Epoch 700/2000\n",
            "80/80 [==============================] - 0s 838us/step - loss: 9.3178e-05 - val_loss: 2.6327e-04\n",
            "Epoch 701/2000\n",
            "80/80 [==============================] - 0s 850us/step - loss: 1.6208e-04 - val_loss: 7.5649e-05\n",
            "Epoch 702/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 6.1289e-05 - val_loss: 5.3808e-05\n",
            "Epoch 703/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.1789e-05 - val_loss: 1.6064e-04\n",
            "Epoch 704/2000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 1.3222e-04 - val_loss: 1.4778e-05\n",
            "Epoch 705/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 6.9047e-05 - val_loss: 1.6996e-04\n",
            "Epoch 706/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 1.2287e-04 - val_loss: 7.4060e-05\n",
            "Epoch 707/2000\n",
            "80/80 [==============================] - 0s 812us/step - loss: 7.6020e-05 - val_loss: 2.3696e-04\n",
            "Epoch 708/2000\n",
            "80/80 [==============================] - 0s 851us/step - loss: 1.2783e-04 - val_loss: 2.6285e-04\n",
            "Epoch 709/2000\n",
            "80/80 [==============================] - 0s 824us/step - loss: 3.5246e-04 - val_loss: 4.8708e-04\n",
            "Epoch 710/2000\n",
            "80/80 [==============================] - 0s 841us/step - loss: 0.0010 - val_loss: 0.0025\n",
            "Epoch 711/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 0.0015 - val_loss: 3.3095e-04\n",
            "Epoch 712/2000\n",
            "80/80 [==============================] - 0s 820us/step - loss: 9.8409e-04 - val_loss: 0.0037\n",
            "Epoch 713/2000\n",
            "80/80 [==============================] - 0s 862us/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 714/2000\n",
            "80/80 [==============================] - 0s 871us/step - loss: 0.0026 - val_loss: 0.0015\n",
            "Epoch 715/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 716/2000\n",
            "80/80 [==============================] - 0s 775us/step - loss: 7.6204e-04 - val_loss: 3.5963e-04\n",
            "Epoch 717/2000\n",
            "80/80 [==============================] - 0s 877us/step - loss: 4.7552e-04 - val_loss: 6.0774e-04\n",
            "Epoch 718/2000\n",
            "80/80 [==============================] - 0s 879us/step - loss: 5.7051e-04 - val_loss: 8.3773e-05\n",
            "Epoch 719/2000\n",
            "80/80 [==============================] - 0s 885us/step - loss: 3.9548e-04 - val_loss: 8.4372e-04\n",
            "Epoch 720/2000\n",
            "80/80 [==============================] - 0s 827us/step - loss: 3.5575e-04 - val_loss: 1.5603e-04\n",
            "Epoch 721/2000\n",
            "80/80 [==============================] - 0s 864us/step - loss: 1.6605e-04 - val_loss: 7.2930e-05\n",
            "Epoch 722/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 1.2394e-04 - val_loss: 2.3032e-04\n",
            "Epoch 723/2000\n",
            "80/80 [==============================] - 0s 871us/step - loss: 1.5306e-04 - val_loss: 2.1435e-05\n",
            "Epoch 724/2000\n",
            "80/80 [==============================] - 0s 844us/step - loss: 8.0891e-05 - val_loss: 1.4565e-04\n",
            "Epoch 725/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 1.0038e-04 - val_loss: 1.3060e-04\n",
            "Epoch 726/2000\n",
            "80/80 [==============================] - 0s 875us/step - loss: 1.0789e-04 - val_loss: 1.0992e-04\n",
            "Epoch 727/2000\n",
            "80/80 [==============================] - 0s 842us/step - loss: 6.0309e-05 - val_loss: 6.5153e-05\n",
            "Epoch 728/2000\n",
            "80/80 [==============================] - 0s 828us/step - loss: 6.2709e-05 - val_loss: 9.7074e-05\n",
            "Epoch 729/2000\n",
            "80/80 [==============================] - 0s 817us/step - loss: 8.4497e-05 - val_loss: 3.2122e-05\n",
            "Epoch 730/2000\n",
            "80/80 [==============================] - 0s 874us/step - loss: 2.4144e-05 - val_loss: 2.6355e-05\n",
            "Epoch 731/2000\n",
            "80/80 [==============================] - 0s 881us/step - loss: 1.4500e-05 - val_loss: 3.0080e-05\n",
            "Epoch 732/2000\n",
            "80/80 [==============================] - 0s 862us/step - loss: 2.5908e-05 - val_loss: 2.0708e-05\n",
            "Epoch 733/2000\n",
            "80/80 [==============================] - 0s 798us/step - loss: 1.6979e-05 - val_loss: 3.4126e-05\n",
            "Epoch 734/2000\n",
            "80/80 [==============================] - 0s 847us/step - loss: 1.9522e-05 - val_loss: 2.2209e-05\n",
            "Epoch 735/2000\n",
            "80/80 [==============================] - 0s 817us/step - loss: 2.3463e-05 - val_loss: 8.2337e-05\n",
            "Epoch 736/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 6.0607e-05 - val_loss: 2.2861e-05\n",
            "Epoch 737/2000\n",
            "80/80 [==============================] - 0s 864us/step - loss: 2.2650e-05 - val_loss: 4.1686e-05\n",
            "Epoch 738/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 2.6047e-05 - val_loss: 1.7233e-05\n",
            "Epoch 739/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 2.0407e-05 - val_loss: 1.9249e-05\n",
            "Epoch 740/2000\n",
            "80/80 [==============================] - 0s 821us/step - loss: 1.6934e-05 - val_loss: 3.7040e-05\n",
            "Epoch 741/2000\n",
            "80/80 [==============================] - 0s 886us/step - loss: 2.1672e-05 - val_loss: 1.7461e-05\n",
            "Epoch 742/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 1.6196e-05 - val_loss: 2.5926e-05\n",
            "Epoch 743/2000\n",
            "80/80 [==============================] - 0s 889us/step - loss: 1.5682e-05 - val_loss: 2.3126e-05\n",
            "Epoch 744/2000\n",
            "80/80 [==============================] - 0s 872us/step - loss: 1.2283e-05 - val_loss: 1.7827e-05\n",
            "Epoch 745/2000\n",
            "80/80 [==============================] - 0s 870us/step - loss: 9.4593e-06 - val_loss: 1.1968e-05\n",
            "Epoch 746/2000\n",
            "80/80 [==============================] - 0s 855us/step - loss: 1.1062e-05 - val_loss: 1.0842e-05\n",
            "Epoch 747/2000\n",
            "80/80 [==============================] - 0s 849us/step - loss: 9.7833e-06 - val_loss: 1.6655e-05\n",
            "Epoch 748/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 1.1738e-05 - val_loss: 1.3878e-05\n",
            "Epoch 749/2000\n",
            "80/80 [==============================] - 0s 777us/step - loss: 1.1688e-05 - val_loss: 3.1770e-05\n",
            "Epoch 750/2000\n",
            "80/80 [==============================] - 0s 822us/step - loss: 1.6927e-05 - val_loss: 3.0234e-05\n",
            "Epoch 751/2000\n",
            "80/80 [==============================] - 0s 891us/step - loss: 1.6792e-05 - val_loss: 1.6929e-05\n",
            "Epoch 752/2000\n",
            "80/80 [==============================] - 0s 825us/step - loss: 1.0555e-05 - val_loss: 4.0803e-05\n",
            "Epoch 753/2000\n",
            "80/80 [==============================] - 0s 885us/step - loss: 3.2913e-05 - val_loss: 2.5670e-05\n",
            "Epoch 754/2000\n",
            "80/80 [==============================] - 0s 827us/step - loss: 2.9966e-05 - val_loss: 2.5691e-05\n",
            "Epoch 755/2000\n",
            "80/80 [==============================] - 0s 827us/step - loss: 1.7028e-05 - val_loss: 4.4400e-05\n",
            "Epoch 756/2000\n",
            "80/80 [==============================] - 0s 854us/step - loss: 2.7239e-05 - val_loss: 4.5565e-05\n",
            "Epoch 757/2000\n",
            "80/80 [==============================] - 0s 839us/step - loss: 4.1086e-05 - val_loss: 2.4745e-05\n",
            "Epoch 758/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 3.3729e-05 - val_loss: 4.1341e-05\n",
            "Epoch 759/2000\n",
            "80/80 [==============================] - 0s 859us/step - loss: 6.9083e-05 - val_loss: 1.6588e-05\n",
            "Epoch 760/2000\n",
            "80/80 [==============================] - 0s 838us/step - loss: 3.2177e-05 - val_loss: 6.4849e-05\n",
            "Epoch 761/2000\n",
            "80/80 [==============================] - 0s 808us/step - loss: 4.2392e-05 - val_loss: 2.1813e-05\n",
            "Epoch 762/2000\n",
            "80/80 [==============================] - 0s 879us/step - loss: 4.2398e-05 - val_loss: 5.5792e-05\n",
            "Epoch 763/2000\n",
            "80/80 [==============================] - 0s 879us/step - loss: 3.9159e-05 - val_loss: 2.4440e-05\n",
            "Epoch 764/2000\n",
            "80/80 [==============================] - 0s 826us/step - loss: 2.3397e-05 - val_loss: 3.7472e-05\n",
            "Epoch 765/2000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 1.9123e-05 - val_loss: 4.0815e-05\n",
            "Epoch 766/2000\n",
            "80/80 [==============================] - 0s 851us/step - loss: 1.7862e-05 - val_loss: 1.4832e-05\n",
            "Epoch 767/2000\n",
            "80/80 [==============================] - 0s 828us/step - loss: 1.2830e-05 - val_loss: 1.1971e-05\n",
            "Epoch 768/2000\n",
            "80/80 [==============================] - 0s 795us/step - loss: 1.1790e-05 - val_loss: 2.1585e-05\n",
            "Epoch 769/2000\n",
            "80/80 [==============================] - 0s 808us/step - loss: 1.0139e-05 - val_loss: 1.3980e-05\n",
            "Epoch 770/2000\n",
            "80/80 [==============================] - 0s 870us/step - loss: 7.4864e-06 - val_loss: 1.0355e-05\n",
            "Epoch 771/2000\n",
            "80/80 [==============================] - 0s 883us/step - loss: 9.2156e-06 - val_loss: 2.7808e-05\n",
            "Epoch 772/2000\n",
            "80/80 [==============================] - 0s 819us/step - loss: 2.5095e-05 - val_loss: 1.2276e-05\n",
            "Epoch 773/2000\n",
            "80/80 [==============================] - 0s 860us/step - loss: 2.2175e-05 - val_loss: 2.4781e-05\n",
            "Epoch 774/2000\n",
            "80/80 [==============================] - 0s 830us/step - loss: 2.2376e-05 - val_loss: 1.2529e-04\n",
            "Epoch 775/2000\n",
            "80/80 [==============================] - 0s 865us/step - loss: 7.2893e-05 - val_loss: 4.1353e-05\n",
            "Epoch 776/2000\n",
            "80/80 [==============================] - 0s 804us/step - loss: 5.5331e-05 - val_loss: 4.6265e-05\n",
            "Epoch 777/2000\n",
            "80/80 [==============================] - 0s 825us/step - loss: 3.6338e-05 - val_loss: 3.3615e-05\n",
            "Epoch 778/2000\n",
            "80/80 [==============================] - 0s 848us/step - loss: 3.4782e-05 - val_loss: 2.9512e-05\n",
            "Epoch 779/2000\n",
            "80/80 [==============================] - 0s 820us/step - loss: 2.9557e-05 - val_loss: 1.0212e-04\n",
            "Epoch 780/2000\n",
            "80/80 [==============================] - 0s 771us/step - loss: 3.8984e-05 - val_loss: 2.1180e-05\n",
            "Epoch 781/2000\n",
            "80/80 [==============================] - 0s 841us/step - loss: 4.9623e-05 - val_loss: 3.1445e-05\n",
            "Epoch 782/2000\n",
            "80/80 [==============================] - 0s 879us/step - loss: 2.8944e-05 - val_loss: 1.9056e-05\n",
            "Epoch 783/2000\n",
            "80/80 [==============================] - 0s 823us/step - loss: 1.6600e-05 - val_loss: 2.1742e-05\n",
            "Epoch 784/2000\n",
            "80/80 [==============================] - 0s 804us/step - loss: 1.0533e-05 - val_loss: 1.2992e-05\n",
            "Epoch 785/2000\n",
            "80/80 [==============================] - 0s 840us/step - loss: 6.9881e-06 - val_loss: 1.3164e-05\n",
            "Epoch 786/2000\n",
            "80/80 [==============================] - 0s 842us/step - loss: 6.1272e-06 - val_loss: 2.9439e-05\n",
            "Epoch 787/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 2.0406e-05 - val_loss: 1.1138e-05\n",
            "Epoch 788/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 1.7231e-05 - val_loss: 2.5002e-05\n",
            "Epoch 789/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 1.3607e-05 - val_loss: 4.3039e-05\n",
            "Epoch 790/2000\n",
            "80/80 [==============================] - 0s 778us/step - loss: 1.9310e-05 - val_loss: 9.6019e-06\n",
            "Epoch 791/2000\n",
            "80/80 [==============================] - 0s 874us/step - loss: 1.3272e-05 - val_loss: 1.0106e-05\n",
            "Epoch 792/2000\n",
            "80/80 [==============================] - 0s 862us/step - loss: 1.2349e-05 - val_loss: 1.0026e-05\n",
            "Epoch 793/2000\n",
            "80/80 [==============================] - 0s 776us/step - loss: 7.9343e-06 - val_loss: 1.9139e-05\n",
            "Epoch 794/2000\n",
            "80/80 [==============================] - 0s 858us/step - loss: 9.0901e-06 - val_loss: 2.6558e-05\n",
            "Epoch 795/2000\n",
            "80/80 [==============================] - 0s 826us/step - loss: 8.7894e-06 - val_loss: 8.3003e-06\n",
            "Epoch 796/2000\n",
            "80/80 [==============================] - 0s 853us/step - loss: 7.2726e-06 - val_loss: 1.1595e-05\n",
            "Epoch 797/2000\n",
            "80/80 [==============================] - 0s 808us/step - loss: 5.7489e-06 - val_loss: 1.4402e-05\n",
            "Epoch 798/2000\n",
            "80/80 [==============================] - 0s 891us/step - loss: 5.8529e-06 - val_loss: 1.4158e-05\n",
            "Epoch 799/2000\n",
            "80/80 [==============================] - 0s 790us/step - loss: 1.8588e-05 - val_loss: 1.3418e-05\n",
            "Epoch 800/2000\n",
            "80/80 [==============================] - 0s 809us/step - loss: 9.9685e-06 - val_loss: 1.3369e-05\n",
            "Epoch 801/2000\n",
            "80/80 [==============================] - 0s 804us/step - loss: 6.0329e-06 - val_loss: 3.3099e-05\n",
            "Epoch 802/2000\n",
            "80/80 [==============================] - 0s 844us/step - loss: 1.2928e-05 - val_loss: 1.0918e-05\n",
            "Epoch 803/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 8.4188e-06 - val_loss: 2.0154e-05\n",
            "Epoch 804/2000\n",
            "80/80 [==============================] - 0s 875us/step - loss: 1.2356e-05 - val_loss: 1.1949e-05\n",
            "Epoch 805/2000\n",
            "80/80 [==============================] - 0s 860us/step - loss: 6.3618e-06 - val_loss: 1.2534e-05\n",
            "Epoch 806/2000\n",
            "80/80 [==============================] - 0s 839us/step - loss: 5.8659e-06 - val_loss: 9.4558e-06\n",
            "Epoch 807/2000\n",
            "80/80 [==============================] - 0s 795us/step - loss: 4.3301e-06 - val_loss: 8.0640e-06\n",
            "Epoch 808/2000\n",
            "80/80 [==============================] - 0s 820us/step - loss: 6.6560e-06 - val_loss: 7.6959e-06\n",
            "Epoch 809/2000\n",
            "80/80 [==============================] - 0s 890us/step - loss: 4.7390e-06 - val_loss: 8.8691e-06\n",
            "Epoch 810/2000\n",
            "80/80 [==============================] - 0s 793us/step - loss: 5.6596e-06 - val_loss: 1.0730e-05\n",
            "Epoch 811/2000\n",
            "80/80 [==============================] - 0s 868us/step - loss: 5.0573e-06 - val_loss: 9.8105e-06\n",
            "Epoch 812/2000\n",
            "80/80 [==============================] - 0s 865us/step - loss: 8.2627e-06 - val_loss: 2.5337e-05\n",
            "Epoch 813/2000\n",
            "80/80 [==============================] - 0s 804us/step - loss: 2.5045e-05 - val_loss: 3.0467e-05\n",
            "Epoch 814/2000\n",
            "80/80 [==============================] - 0s 820us/step - loss: 3.6057e-05 - val_loss: 1.3321e-05\n",
            "Epoch 815/2000\n",
            "80/80 [==============================] - 0s 829us/step - loss: 6.9357e-05 - val_loss: 2.5633e-05\n",
            "Epoch 816/2000\n",
            "80/80 [==============================] - 0s 842us/step - loss: 8.3457e-05 - val_loss: 1.2712e-04\n",
            "Epoch 817/2000\n",
            "80/80 [==============================] - 0s 858us/step - loss: 8.2477e-05 - val_loss: 1.3247e-04\n",
            "Epoch 818/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 5.1611e-05 - val_loss: 5.2885e-05\n",
            "Epoch 819/2000\n",
            "80/80 [==============================] - 0s 881us/step - loss: 3.8926e-05 - val_loss: 4.1193e-05\n",
            "Epoch 820/2000\n",
            "80/80 [==============================] - 0s 805us/step - loss: 3.9825e-05 - val_loss: 1.0538e-05\n",
            "Epoch 821/2000\n",
            "80/80 [==============================] - 0s 819us/step - loss: 2.6438e-05 - val_loss: 9.5899e-06\n",
            "Epoch 822/2000\n",
            "80/80 [==============================] - 0s 843us/step - loss: 2.9176e-05 - val_loss: 3.9513e-05\n",
            "Epoch 823/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4961e-05 - val_loss: 1.0340e-05\n",
            "Epoch 824/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 2.5957e-05 - val_loss: 1.8290e-05\n",
            "Epoch 825/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 2.3195e-05 - val_loss: 2.7221e-05\n",
            "Epoch 826/2000\n",
            "80/80 [==============================] - 0s 989us/step - loss: 1.9493e-05 - val_loss: 2.4005e-05\n",
            "Epoch 827/2000\n",
            "80/80 [==============================] - 0s 889us/step - loss: 2.0479e-05 - val_loss: 1.7248e-05\n",
            "Epoch 828/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 2.0058e-05 - val_loss: 3.6847e-05\n",
            "Epoch 829/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 1.7437e-05 - val_loss: 2.6778e-05\n",
            "Epoch 830/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 2.5434e-05 - val_loss: 1.8947e-05\n",
            "Epoch 831/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7246e-05 - val_loss: 4.3083e-05\n",
            "Epoch 832/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.3323e-05 - val_loss: 2.1926e-05\n",
            "Epoch 833/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 6.9947e-05 - val_loss: 1.6136e-04\n",
            "Epoch 834/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 7.0479e-05 - val_loss: 1.3022e-04\n",
            "Epoch 835/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 6.7658e-05 - val_loss: 1.7392e-05\n",
            "Epoch 836/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.4845e-05 - val_loss: 2.8251e-05\n",
            "Epoch 837/2000\n",
            "80/80 [==============================] - 0s 878us/step - loss: 3.6115e-05 - val_loss: 8.6580e-05\n",
            "Epoch 838/2000\n",
            "80/80 [==============================] - 0s 993us/step - loss: 3.8725e-05 - val_loss: 2.1880e-05\n",
            "Epoch 839/2000\n",
            "80/80 [==============================] - 0s 879us/step - loss: 5.0754e-05 - val_loss: 1.4083e-04\n",
            "Epoch 840/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 6.3994e-05 - val_loss: 2.2884e-05\n",
            "Epoch 841/2000\n",
            "80/80 [==============================] - 0s 864us/step - loss: 2.7384e-05 - val_loss: 9.4498e-05\n",
            "Epoch 842/2000\n",
            "80/80 [==============================] - 0s 989us/step - loss: 6.9322e-05 - val_loss: 9.8585e-05\n",
            "Epoch 843/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 6.4131e-05 - val_loss: 5.5095e-05\n",
            "Epoch 844/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 1.1158e-04 - val_loss: 2.6401e-04\n",
            "Epoch 845/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 2.3862e-04 - val_loss: 3.6848e-04\n",
            "Epoch 846/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 2.0470e-04 - val_loss: 3.3759e-04\n",
            "Epoch 847/2000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 5.0731e-04 - val_loss: 4.6495e-04\n",
            "Epoch 848/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.6570e-04 - val_loss: 4.0156e-04\n",
            "Epoch 849/2000\n",
            "80/80 [==============================] - 0s 869us/step - loss: 5.6643e-04 - val_loss: 9.4199e-04\n",
            "Epoch 850/2000\n",
            "80/80 [==============================] - 0s 823us/step - loss: 8.5666e-04 - val_loss: 0.0010\n",
            "Epoch 851/2000\n",
            "80/80 [==============================] - 0s 824us/step - loss: 0.0013 - val_loss: 0.0042\n",
            "Epoch 852/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
            "Epoch 853/2000\n",
            "80/80 [==============================] - 0s 827us/step - loss: 0.0016 - val_loss: 0.0021\n",
            "Epoch 854/2000\n",
            "80/80 [==============================] - 0s 822us/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 855/2000\n",
            "80/80 [==============================] - 0s 790us/step - loss: 0.0014 - val_loss: 4.9130e-04\n",
            "Epoch 856/2000\n",
            "80/80 [==============================] - 0s 832us/step - loss: 0.0011 - val_loss: 5.6601e-04\n",
            "Epoch 857/2000\n",
            "80/80 [==============================] - 0s 885us/step - loss: 9.5666e-04 - val_loss: 0.0023\n",
            "Epoch 858/2000\n",
            "80/80 [==============================] - 0s 841us/step - loss: 0.0011 - val_loss: 3.4066e-04\n",
            "Epoch 859/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 3.5592e-04 - val_loss: 0.0046\n",
            "Epoch 860/2000\n",
            "80/80 [==============================] - 0s 817us/step - loss: 0.0022 - val_loss: 6.6862e-04\n",
            "Epoch 861/2000\n",
            "80/80 [==============================] - 0s 834us/step - loss: 8.8590e-04 - val_loss: 0.0020\n",
            "Epoch 862/2000\n",
            "80/80 [==============================] - 0s 885us/step - loss: 0.0011 - val_loss: 6.2371e-04\n",
            "Epoch 863/2000\n",
            "80/80 [==============================] - 0s 842us/step - loss: 7.9523e-04 - val_loss: 0.0017\n",
            "Epoch 864/2000\n",
            "80/80 [==============================] - 0s 850us/step - loss: 0.0011 - val_loss: 4.5603e-04\n",
            "Epoch 865/2000\n",
            "80/80 [==============================] - 0s 891us/step - loss: 8.3794e-04 - val_loss: 0.0011\n",
            "Epoch 866/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 9.2806e-04 - val_loss: 5.8834e-04\n",
            "Epoch 867/2000\n",
            "80/80 [==============================] - 0s 852us/step - loss: 5.6792e-04 - val_loss: 2.3190e-04\n",
            "Epoch 868/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 2.2094e-04 - val_loss: 1.9123e-04\n",
            "Epoch 869/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 1.7607e-04 - val_loss: 1.0196e-04\n",
            "Epoch 870/2000\n",
            "80/80 [==============================] - 0s 796us/step - loss: 1.0973e-04 - val_loss: 1.8752e-04\n",
            "Epoch 871/2000\n",
            "80/80 [==============================] - 0s 836us/step - loss: 1.1054e-04 - val_loss: 7.4208e-05\n",
            "Epoch 872/2000\n",
            "80/80 [==============================] - 0s 877us/step - loss: 8.9734e-05 - val_loss: 6.5830e-05\n",
            "Epoch 873/2000\n",
            "80/80 [==============================] - 0s 809us/step - loss: 5.8287e-05 - val_loss: 5.7795e-05\n",
            "Epoch 874/2000\n",
            "80/80 [==============================] - 0s 863us/step - loss: 5.3383e-05 - val_loss: 5.1960e-05\n",
            "Epoch 875/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 2.9490e-05 - val_loss: 1.8240e-05\n",
            "Epoch 876/2000\n",
            "80/80 [==============================] - 0s 789us/step - loss: 2.0444e-05 - val_loss: 1.2913e-05\n",
            "Epoch 877/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3271e-05 - val_loss: 3.0573e-05\n",
            "Epoch 878/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0686e-05 - val_loss: 4.2521e-05\n",
            "Epoch 879/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7433e-05 - val_loss: 3.1778e-05\n",
            "Epoch 880/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 2.8188e-05 - val_loss: 3.1386e-05\n",
            "Epoch 881/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 2.5315e-05 - val_loss: 3.9211e-05\n",
            "Epoch 882/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 2.7562e-05 - val_loss: 2.4883e-05\n",
            "Epoch 883/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 1.5192e-05 - val_loss: 3.3097e-05\n",
            "Epoch 884/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 3.3213e-05 - val_loss: 2.8060e-05\n",
            "Epoch 885/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 3.2855e-05 - val_loss: 5.5442e-05\n",
            "Epoch 886/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 4.2081e-05 - val_loss: 6.6670e-05\n",
            "Epoch 887/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 5.3265e-05 - val_loss: 6.4270e-05\n",
            "Epoch 888/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 5.8764e-05 - val_loss: 7.5202e-05\n",
            "Epoch 889/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.0820e-05 - val_loss: 8.5865e-05\n",
            "Epoch 890/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 1.3180e-04 - val_loss: 1.2751e-04\n",
            "Epoch 891/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 6.6421e-05 - val_loss: 3.0172e-05\n",
            "Epoch 892/2000\n",
            "80/80 [==============================] - 0s 983us/step - loss: 4.6182e-05 - val_loss: 3.8300e-05\n",
            "Epoch 893/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 3.4625e-05 - val_loss: 1.3219e-05\n",
            "Epoch 894/2000\n",
            "80/80 [==============================] - 0s 874us/step - loss: 2.0277e-05 - val_loss: 9.2726e-05\n",
            "Epoch 895/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 5.5342e-05 - val_loss: 3.1073e-05\n",
            "Epoch 896/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 5.5807e-05 - val_loss: 2.2131e-05\n",
            "Epoch 897/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 5.7045e-05 - val_loss: 3.6741e-05\n",
            "Epoch 898/2000\n",
            "80/80 [==============================] - 0s 894us/step - loss: 4.3506e-05 - val_loss: 4.3168e-05\n",
            "Epoch 899/2000\n",
            "80/80 [==============================] - 0s 881us/step - loss: 2.4699e-05 - val_loss: 1.5284e-05\n",
            "Epoch 900/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4444e-05 - val_loss: 2.0013e-05\n",
            "Epoch 901/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.9556e-05 - val_loss: 2.3075e-05\n",
            "Epoch 902/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 2.6451e-05 - val_loss: 1.6481e-05\n",
            "Epoch 903/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 2.2000e-05 - val_loss: 2.0976e-05\n",
            "Epoch 904/2000\n",
            "80/80 [==============================] - 0s 890us/step - loss: 1.5384e-05 - val_loss: 3.2011e-05\n",
            "Epoch 905/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 1.6671e-05 - val_loss: 1.4596e-05\n",
            "Epoch 906/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 9.0811e-06 - val_loss: 1.2484e-05\n",
            "Epoch 907/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 8.0842e-06 - val_loss: 3.1218e-05\n",
            "Epoch 908/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 1.1274e-05 - val_loss: 1.6403e-05\n",
            "Epoch 909/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 2.0163e-05 - val_loss: 1.6798e-05\n",
            "Epoch 910/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 1.7844e-05 - val_loss: 2.1737e-05\n",
            "Epoch 911/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 2.3125e-05 - val_loss: 9.9407e-06\n",
            "Epoch 912/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0975e-05 - val_loss: 1.6445e-05\n",
            "Epoch 913/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0393e-05 - val_loss: 1.6678e-05\n",
            "Epoch 914/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2199e-05 - val_loss: 1.3433e-05\n",
            "Epoch 915/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 1.2734e-05 - val_loss: 6.1631e-06\n",
            "Epoch 916/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 8.5867e-06 - val_loss: 6.7108e-06\n",
            "Epoch 917/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 5.5153e-06 - val_loss: 9.7676e-06\n",
            "Epoch 918/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 4.4691e-06 - val_loss: 9.1183e-06\n",
            "Epoch 919/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 5.2259e-06 - val_loss: 1.1497e-05\n",
            "Epoch 920/2000\n",
            "80/80 [==============================] - 0s 891us/step - loss: 5.5015e-06 - val_loss: 1.8486e-05\n",
            "Epoch 921/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 6.9467e-06 - val_loss: 5.7103e-06\n",
            "Epoch 922/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 5.7047e-06 - val_loss: 1.1189e-05\n",
            "Epoch 923/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 1.0443e-05 - val_loss: 1.2582e-05\n",
            "Epoch 924/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 1.4203e-05 - val_loss: 8.5549e-06\n",
            "Epoch 925/2000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 1.0885e-05 - val_loss: 2.0437e-05\n",
            "Epoch 926/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 1.1270e-05 - val_loss: 3.4790e-05\n",
            "Epoch 927/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 1.6458e-05 - val_loss: 8.6560e-06\n",
            "Epoch 928/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 7.1240e-06 - val_loss: 1.9146e-05\n",
            "Epoch 929/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 1.3542e-05 - val_loss: 7.4742e-06\n",
            "Epoch 930/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 8.9123e-06 - val_loss: 9.0270e-06\n",
            "Epoch 931/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 4.8913e-06 - val_loss: 1.0759e-05\n",
            "Epoch 932/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 6.1745e-06 - val_loss: 7.6085e-06\n",
            "Epoch 933/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.4592e-06 - val_loss: 6.5210e-06\n",
            "Epoch 934/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 4.6272e-06 - val_loss: 8.0994e-06\n",
            "Epoch 935/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 3.3276e-06 - val_loss: 6.6095e-06\n",
            "Epoch 936/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 3.2464e-06 - val_loss: 4.9906e-06\n",
            "Epoch 937/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 4.7591e-06 - val_loss: 4.9421e-06\n",
            "Epoch 938/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.3701e-06 - val_loss: 1.0665e-05\n",
            "Epoch 939/2000\n",
            "80/80 [==============================] - 0s 993us/step - loss: 4.4888e-06 - val_loss: 3.0353e-05\n",
            "Epoch 940/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3344e-05 - val_loss: 9.7256e-06\n",
            "Epoch 941/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 8.7146e-06 - val_loss: 9.6229e-06\n",
            "Epoch 942/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 4.5991e-06 - val_loss: 1.1680e-05\n",
            "Epoch 943/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 6.6766e-06 - val_loss: 6.4964e-06\n",
            "Epoch 944/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.3928e-06 - val_loss: 1.1185e-05\n",
            "Epoch 945/2000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 6.7056e-06 - val_loss: 6.6791e-06\n",
            "Epoch 946/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 6.8449e-06 - val_loss: 2.5614e-05\n",
            "Epoch 947/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 9.6161e-06 - val_loss: 2.5422e-05\n",
            "Epoch 948/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 1.0361e-05 - val_loss: 2.0124e-05\n",
            "Epoch 949/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 1.4860e-05 - val_loss: 1.8852e-05\n",
            "Epoch 950/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2317e-05 - val_loss: 1.7062e-05\n",
            "Epoch 951/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 2.5999e-05 - val_loss: 2.9717e-05\n",
            "Epoch 952/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 3.3808e-05 - val_loss: 5.2241e-05\n",
            "Epoch 953/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 3.8035e-05 - val_loss: 5.8131e-05\n",
            "Epoch 954/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 2.1057e-05 - val_loss: 1.3971e-05\n",
            "Epoch 955/2000\n",
            "80/80 [==============================] - 0s 831us/step - loss: 2.3406e-05 - val_loss: 1.5674e-05\n",
            "Epoch 956/2000\n",
            "80/80 [==============================] - 0s 856us/step - loss: 1.8722e-05 - val_loss: 2.6804e-05\n",
            "Epoch 957/2000\n",
            "80/80 [==============================] - 0s 854us/step - loss: 2.6337e-05 - val_loss: 2.8272e-05\n",
            "Epoch 958/2000\n",
            "80/80 [==============================] - 0s 993us/step - loss: 2.4322e-05 - val_loss: 2.9361e-05\n",
            "Epoch 959/2000\n",
            "80/80 [==============================] - 0s 833us/step - loss: 9.4418e-06 - val_loss: 2.5650e-05\n",
            "Epoch 960/2000\n",
            "80/80 [==============================] - 0s 848us/step - loss: 1.5188e-05 - val_loss: 1.0456e-05\n",
            "Epoch 961/2000\n",
            "80/80 [==============================] - 0s 847us/step - loss: 1.6662e-05 - val_loss: 1.6183e-05\n",
            "Epoch 962/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 1.5176e-05 - val_loss: 2.0453e-05\n",
            "Epoch 963/2000\n",
            "80/80 [==============================] - 0s 799us/step - loss: 1.5849e-05 - val_loss: 3.1986e-05\n",
            "Epoch 964/2000\n",
            "80/80 [==============================] - 0s 882us/step - loss: 1.8255e-05 - val_loss: 2.9063e-05\n",
            "Epoch 965/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 6.0359e-05 - val_loss: 2.2852e-05\n",
            "Epoch 966/2000\n",
            "80/80 [==============================] - 0s 837us/step - loss: 3.8576e-05 - val_loss: 1.6470e-05\n",
            "Epoch 967/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 3.2581e-05 - val_loss: 4.8340e-05\n",
            "Epoch 968/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 5.0639e-05 - val_loss: 7.6145e-05\n",
            "Epoch 969/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 4.7678e-05 - val_loss: 2.8949e-05\n",
            "Epoch 970/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 4.1989e-05 - val_loss: 3.7871e-05\n",
            "Epoch 971/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.0515e-05 - val_loss: 4.7485e-05\n",
            "Epoch 972/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 3.0286e-05 - val_loss: 1.6488e-05\n",
            "Epoch 973/2000\n",
            "80/80 [==============================] - 0s 868us/step - loss: 1.3570e-05 - val_loss: 9.2080e-06\n",
            "Epoch 974/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 8.4571e-06 - val_loss: 2.7164e-05\n",
            "Epoch 975/2000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 1.6387e-05 - val_loss: 1.5714e-05\n",
            "Epoch 976/2000\n",
            "80/80 [==============================] - 0s 983us/step - loss: 8.9487e-06 - val_loss: 1.1158e-05\n",
            "Epoch 977/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 7.4947e-06 - val_loss: 5.6610e-06\n",
            "Epoch 978/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 6.1044e-06 - val_loss: 7.3834e-06\n",
            "Epoch 979/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 5.2989e-06 - val_loss: 6.7870e-06\n",
            "Epoch 980/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 4.1845e-06 - val_loss: 6.2093e-06\n",
            "Epoch 981/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 3.1512e-06 - val_loss: 7.1641e-06\n",
            "Epoch 982/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 4.9143e-06 - val_loss: 4.5996e-06\n",
            "Epoch 983/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 3.6648e-06 - val_loss: 5.7272e-06\n",
            "Epoch 984/2000\n",
            "80/80 [==============================] - 0s 889us/step - loss: 2.9724e-06 - val_loss: 4.5267e-06\n",
            "Epoch 985/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 2.9572e-06 - val_loss: 4.6293e-06\n",
            "Epoch 986/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 2.7005e-06 - val_loss: 8.9574e-06\n",
            "Epoch 987/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 3.2280e-06 - val_loss: 5.7444e-06\n",
            "Epoch 988/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 3.4414e-06 - val_loss: 4.9467e-06\n",
            "Epoch 989/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 2.1088e-06 - val_loss: 5.0848e-06\n",
            "Epoch 990/2000\n",
            "80/80 [==============================] - 0s 877us/step - loss: 2.3398e-06 - val_loss: 6.1752e-06\n",
            "Epoch 991/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3321e-06 - val_loss: 4.3190e-06\n",
            "Epoch 992/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 2.0144e-06 - val_loss: 4.4573e-06\n",
            "Epoch 993/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 2.2540e-06 - val_loss: 4.1938e-06\n",
            "Epoch 994/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3291e-06 - val_loss: 4.9036e-06\n",
            "Epoch 995/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 2.3820e-06 - val_loss: 5.6488e-06\n",
            "Epoch 996/2000\n",
            "80/80 [==============================] - 0s 867us/step - loss: 3.9440e-06 - val_loss: 6.1643e-06\n",
            "Epoch 997/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 4.0237e-06 - val_loss: 6.3093e-06\n",
            "Epoch 998/2000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 6.6688e-06 - val_loss: 9.8281e-06\n",
            "Epoch 999/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 5.0719e-06 - val_loss: 1.3531e-05\n",
            "Epoch 1000/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 7.8590e-06 - val_loss: 1.0942e-05\n",
            "Epoch 1001/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 9.7910e-06 - val_loss: 1.6117e-05\n",
            "Epoch 1002/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 1.2415e-05 - val_loss: 2.0348e-05\n",
            "Epoch 1003/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 1.2361e-05 - val_loss: 9.2412e-06\n",
            "Epoch 1004/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.0800e-06 - val_loss: 6.9521e-06\n",
            "Epoch 1005/2000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 6.2057e-06 - val_loss: 2.6850e-05\n",
            "Epoch 1006/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4648e-05 - val_loss: 8.4795e-05\n",
            "Epoch 1007/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 5.1472e-05 - val_loss: 2.2411e-05\n",
            "Epoch 1008/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7798e-05 - val_loss: 8.0546e-06\n",
            "Epoch 1009/2000\n",
            "80/80 [==============================] - 0s 981us/step - loss: 1.2598e-05 - val_loss: 3.6194e-05\n",
            "Epoch 1010/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 3.1738e-05 - val_loss: 4.7728e-05\n",
            "Epoch 1011/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 3.0411e-05 - val_loss: 9.2563e-06\n",
            "Epoch 1012/2000\n",
            "80/80 [==============================] - 0s 992us/step - loss: 1.6983e-05 - val_loss: 2.0931e-05\n",
            "Epoch 1013/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.1340e-05 - val_loss: 5.9017e-05\n",
            "Epoch 1014/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 5.1940e-05 - val_loss: 9.6699e-06\n",
            "Epoch 1015/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.5949e-05 - val_loss: 2.9254e-05\n",
            "Epoch 1016/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.1693e-05 - val_loss: 1.2151e-04\n",
            "Epoch 1017/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1446e-04 - val_loss: 2.0572e-04\n",
            "Epoch 1018/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7331e-04 - val_loss: 3.2349e-04\n",
            "Epoch 1019/2000\n",
            "80/80 [==============================] - 0s 977us/step - loss: 2.4051e-04 - val_loss: 1.1171e-04\n",
            "Epoch 1020/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 1.2034e-04 - val_loss: 9.8395e-05\n",
            "Epoch 1021/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 5.9758e-05 - val_loss: 4.1219e-05\n",
            "Epoch 1022/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 4.8282e-05 - val_loss: 4.5789e-05\n",
            "Epoch 1023/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 9.1197e-05 - val_loss: 1.3728e-05\n",
            "Epoch 1024/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 3.6697e-05 - val_loss: 2.3659e-05\n",
            "Epoch 1025/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.5327e-05 - val_loss: 6.0351e-05\n",
            "Epoch 1026/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.1656e-05 - val_loss: 2.6891e-05\n",
            "Epoch 1027/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 2.0760e-05 - val_loss: 2.9721e-05\n",
            "Epoch 1028/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.6279e-05 - val_loss: 2.1273e-05\n",
            "Epoch 1029/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.4380e-05 - val_loss: 3.5818e-05\n",
            "Epoch 1030/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.7179e-05 - val_loss: 6.2934e-05\n",
            "Epoch 1031/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.6832e-05 - val_loss: 1.8319e-04\n",
            "Epoch 1032/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 8.6453e-05 - val_loss: 1.6763e-04\n",
            "Epoch 1033/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0600e-04 - val_loss: 4.9676e-05\n",
            "Epoch 1034/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0602e-04 - val_loss: 1.9889e-04\n",
            "Epoch 1035/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.6517e-04 - val_loss: 5.5186e-04\n",
            "Epoch 1036/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.6786e-04 - val_loss: 8.4771e-04\n",
            "Epoch 1037/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.7791e-04 - val_loss: 1.3982e-04\n",
            "Epoch 1038/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.6893e-04 - val_loss: 9.5863e-04\n",
            "Epoch 1039/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.8289e-04 - val_loss: 0.0015\n",
            "Epoch 1040/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0052\n",
            "Epoch 1041/2000\n",
            "80/80 [==============================] - 0s 989us/step - loss: 0.0023 - val_loss: 4.7127e-04\n",
            "Epoch 1042/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0020\n",
            "Epoch 1043/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0085\n",
            "Epoch 1044/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 0.0060 - val_loss: 0.0021\n",
            "Epoch 1045/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0104\n",
            "Epoch 1046/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 0.0073 - val_loss: 0.0027\n",
            "Epoch 1047/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 0.0044 - val_loss: 0.0068\n",
            "Epoch 1048/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 0.0036 - val_loss: 0.0022\n",
            "Epoch 1049/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 0.0030 - val_loss: 0.0039\n",
            "Epoch 1050/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0040\n",
            "Epoch 1051/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 0.0022 - val_loss: 0.0061\n",
            "Epoch 1052/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 0.0032 - val_loss: 0.0014\n",
            "Epoch 1053/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 0.0024 - val_loss: 0.0013\n",
            "Epoch 1054/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 1055/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 2.9697e-04\n",
            "Epoch 1056/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.6703e-04 - val_loss: 2.3616e-04\n",
            "Epoch 1057/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.1050e-04 - val_loss: 1.6711e-04\n",
            "Epoch 1058/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.6333e-04 - val_loss: 3.9752e-04\n",
            "Epoch 1059/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 2.8682e-04 - val_loss: 1.4676e-04\n",
            "Epoch 1060/2000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 1.6505e-04 - val_loss: 1.1504e-04\n",
            "Epoch 1061/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 2.2066e-04 - val_loss: 6.5379e-04\n",
            "Epoch 1062/2000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 2.7561e-04 - val_loss: 2.7354e-04\n",
            "Epoch 1063/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 2.0236e-04 - val_loss: 1.0100e-04\n",
            "Epoch 1064/2000\n",
            "80/80 [==============================] - 0s 983us/step - loss: 1.9521e-04 - val_loss: 3.0669e-04\n",
            "Epoch 1065/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0245e-04 - val_loss: 3.1731e-04\n",
            "Epoch 1066/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 2.9776e-04 - val_loss: 1.2221e-04\n",
            "Epoch 1067/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 2.8475e-04 - val_loss: 7.3525e-04\n",
            "Epoch 1068/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 3.7570e-04 - val_loss: 1.1522e-04\n",
            "Epoch 1069/2000\n",
            "80/80 [==============================] - 0s 861us/step - loss: 1.2954e-04 - val_loss: 3.7532e-05\n",
            "Epoch 1070/2000\n",
            "80/80 [==============================] - 0s 854us/step - loss: 1.5946e-04 - val_loss: 3.9432e-04\n",
            "Epoch 1071/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.5413e-04 - val_loss: 7.4952e-05\n",
            "Epoch 1072/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 1.0630e-04 - val_loss: 7.5573e-05\n",
            "Epoch 1073/2000\n",
            "80/80 [==============================] - 0s 805us/step - loss: 1.1960e-04 - val_loss: 8.0803e-05\n",
            "Epoch 1074/2000\n",
            "80/80 [==============================] - 0s 886us/step - loss: 7.8866e-05 - val_loss: 4.8954e-05\n",
            "Epoch 1075/2000\n",
            "80/80 [==============================] - 0s 801us/step - loss: 9.7718e-05 - val_loss: 7.2622e-05\n",
            "Epoch 1076/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 9.1900e-05 - val_loss: 1.2210e-04\n",
            "Epoch 1077/2000\n",
            "80/80 [==============================] - 0s 894us/step - loss: 8.2272e-05 - val_loss: 4.7528e-05\n",
            "Epoch 1078/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 1.0582e-04 - val_loss: 1.9933e-05\n",
            "Epoch 1079/2000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 7.0884e-05 - val_loss: 1.8296e-04\n",
            "Epoch 1080/2000\n",
            "80/80 [==============================] - 0s 833us/step - loss: 8.6736e-05 - val_loss: 2.9709e-04\n",
            "Epoch 1081/2000\n",
            "80/80 [==============================] - 0s 794us/step - loss: 2.1813e-04 - val_loss: 6.1335e-05\n",
            "Epoch 1082/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 1.4564e-04 - val_loss: 2.7188e-04\n",
            "Epoch 1083/2000\n",
            "80/80 [==============================] - 0s 995us/step - loss: 1.9381e-04 - val_loss: 3.4963e-04\n",
            "Epoch 1084/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 1.8255e-04 - val_loss: 5.1101e-05\n",
            "Epoch 1085/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8273e-04 - val_loss: 6.0999e-04\n",
            "Epoch 1086/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 2.0075e-04 - val_loss: 1.3698e-04\n",
            "Epoch 1087/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 1.1659e-04 - val_loss: 1.0556e-04\n",
            "Epoch 1088/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 1.1008e-04 - val_loss: 2.3155e-05\n",
            "Epoch 1089/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.2588e-05 - val_loss: 2.9407e-05\n",
            "Epoch 1090/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.5362e-05 - val_loss: 1.6952e-05\n",
            "Epoch 1091/2000\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 5.7275e-05 - val_loss: 2.8452e-05\n",
            "Epoch 1092/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.2180e-05 - val_loss: 2.2875e-05\n",
            "Epoch 1093/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 3.2414e-05 - val_loss: 1.9818e-05\n",
            "Epoch 1094/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 3.7794e-05 - val_loss: 2.8619e-05\n",
            "Epoch 1095/2000\n",
            "80/80 [==============================] - 0s 829us/step - loss: 2.0132e-05 - val_loss: 1.1111e-05\n",
            "Epoch 1096/2000\n",
            "80/80 [==============================] - 0s 792us/step - loss: 1.8531e-05 - val_loss: 1.0244e-05\n",
            "Epoch 1097/2000\n",
            "80/80 [==============================] - 0s 848us/step - loss: 1.4573e-05 - val_loss: 1.8557e-05\n",
            "Epoch 1098/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 1.5075e-05 - val_loss: 1.4862e-05\n",
            "Epoch 1099/2000\n",
            "80/80 [==============================] - 0s 834us/step - loss: 1.6544e-05 - val_loss: 7.8220e-06\n",
            "Epoch 1100/2000\n",
            "80/80 [==============================] - 0s 842us/step - loss: 1.0596e-05 - val_loss: 1.1427e-05\n",
            "Epoch 1101/2000\n",
            "80/80 [==============================] - 0s 839us/step - loss: 1.1946e-05 - val_loss: 4.2183e-06\n",
            "Epoch 1102/2000\n",
            "80/80 [==============================] - 0s 822us/step - loss: 8.2324e-06 - val_loss: 1.6695e-05\n",
            "Epoch 1103/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 1.2597e-05 - val_loss: 6.3161e-06\n",
            "Epoch 1104/2000\n",
            "80/80 [==============================] - 0s 883us/step - loss: 9.7178e-06 - val_loss: 6.7187e-06\n",
            "Epoch 1105/2000\n",
            "80/80 [==============================] - 0s 844us/step - loss: 1.0145e-05 - val_loss: 5.0376e-06\n",
            "Epoch 1106/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 8.8371e-06 - val_loss: 1.2955e-05\n",
            "Epoch 1107/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 1.1334e-05 - val_loss: 5.9727e-06\n",
            "Epoch 1108/2000\n",
            "80/80 [==============================] - 0s 859us/step - loss: 1.0289e-05 - val_loss: 2.4031e-05\n",
            "Epoch 1109/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7034e-05 - val_loss: 6.3575e-06\n",
            "Epoch 1110/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 1.2105e-05 - val_loss: 9.4420e-06\n",
            "Epoch 1111/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 9.7065e-06 - val_loss: 7.4890e-06\n",
            "Epoch 1112/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 8.2225e-06 - val_loss: 4.3016e-06\n",
            "Epoch 1113/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 6.4879e-06 - val_loss: 5.4622e-06\n",
            "Epoch 1114/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.6974e-06 - val_loss: 6.8452e-06\n",
            "Epoch 1115/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.2622e-06 - val_loss: 8.6124e-06\n",
            "Epoch 1116/2000\n",
            "80/80 [==============================] - 0s 981us/step - loss: 7.3631e-06 - val_loss: 1.4443e-05\n",
            "Epoch 1117/2000\n",
            "80/80 [==============================] - 0s 981us/step - loss: 1.1087e-05 - val_loss: 1.2903e-05\n",
            "Epoch 1118/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0349e-05 - val_loss: 1.5702e-05\n",
            "Epoch 1119/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.1778e-05 - val_loss: 2.3650e-05\n",
            "Epoch 1120/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8016e-05 - val_loss: 1.6328e-05\n",
            "Epoch 1121/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 2.6224e-05 - val_loss: 3.7355e-05\n",
            "Epoch 1122/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 4.3408e-05 - val_loss: 1.9500e-05\n",
            "Epoch 1123/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.0676e-05 - val_loss: 1.9692e-05\n",
            "Epoch 1124/2000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 7.3451e-05 - val_loss: 8.1988e-05\n",
            "Epoch 1125/2000\n",
            "80/80 [==============================] - 0s 798us/step - loss: 9.0980e-05 - val_loss: 1.7542e-05\n",
            "Epoch 1126/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 5.5998e-05 - val_loss: 7.9496e-05\n",
            "Epoch 1127/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 7.3659e-05 - val_loss: 6.5331e-05\n",
            "Epoch 1128/2000\n",
            "80/80 [==============================] - 0s 857us/step - loss: 6.1879e-05 - val_loss: 2.0600e-05\n",
            "Epoch 1129/2000\n",
            "80/80 [==============================] - 0s 791us/step - loss: 3.5532e-05 - val_loss: 1.4445e-05\n",
            "Epoch 1130/2000\n",
            "80/80 [==============================] - 0s 847us/step - loss: 2.4803e-05 - val_loss: 1.5984e-05\n",
            "Epoch 1131/2000\n",
            "80/80 [==============================] - 0s 863us/step - loss: 1.6051e-05 - val_loss: 8.3718e-06\n",
            "Epoch 1132/2000\n",
            "80/80 [==============================] - 0s 840us/step - loss: 1.4207e-05 - val_loss: 8.5643e-06\n",
            "Epoch 1133/2000\n",
            "80/80 [==============================] - 0s 805us/step - loss: 1.0740e-05 - val_loss: 2.0619e-05\n",
            "Epoch 1134/2000\n",
            "80/80 [==============================] - 0s 811us/step - loss: 1.7046e-05 - val_loss: 3.0207e-05\n",
            "Epoch 1135/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 2.2830e-05 - val_loss: 3.5738e-05\n",
            "Epoch 1136/2000\n",
            "80/80 [==============================] - 0s 822us/step - loss: 2.4848e-05 - val_loss: 2.8207e-05\n",
            "Epoch 1137/2000\n",
            "80/80 [==============================] - 0s 840us/step - loss: 3.4533e-05 - val_loss: 6.3459e-05\n",
            "Epoch 1138/2000\n",
            "80/80 [==============================] - 0s 826us/step - loss: 3.7260e-05 - val_loss: 8.8394e-06\n",
            "Epoch 1139/2000\n",
            "80/80 [==============================] - 0s 860us/step - loss: 2.7452e-05 - val_loss: 6.4947e-05\n",
            "Epoch 1140/2000\n",
            "80/80 [==============================] - 0s 827us/step - loss: 4.3155e-05 - val_loss: 5.7145e-06\n",
            "Epoch 1141/2000\n",
            "80/80 [==============================] - 0s 866us/step - loss: 2.1118e-05 - val_loss: 5.8885e-05\n",
            "Epoch 1142/2000\n",
            "80/80 [==============================] - 0s 798us/step - loss: 3.4567e-05 - val_loss: 2.9120e-05\n",
            "Epoch 1143/2000\n",
            "80/80 [==============================] - 0s 867us/step - loss: 3.2652e-05 - val_loss: 1.1879e-05\n",
            "Epoch 1144/2000\n",
            "80/80 [==============================] - 0s 881us/step - loss: 2.6995e-05 - val_loss: 3.8455e-05\n",
            "Epoch 1145/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 2.3243e-05 - val_loss: 1.7397e-05\n",
            "Epoch 1146/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 1.3909e-05 - val_loss: 2.1858e-05\n",
            "Epoch 1147/2000\n",
            "80/80 [==============================] - 0s 890us/step - loss: 1.4875e-05 - val_loss: 2.9050e-05\n",
            "Epoch 1148/2000\n",
            "80/80 [==============================] - 0s 892us/step - loss: 1.7991e-05 - val_loss: 9.5919e-06\n",
            "Epoch 1149/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 2.6563e-05 - val_loss: 5.1828e-05\n",
            "Epoch 1150/2000\n",
            "80/80 [==============================] - 0s 856us/step - loss: 4.3353e-05 - val_loss: 1.3820e-05\n",
            "Epoch 1151/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 4.1512e-05 - val_loss: 6.6606e-05\n",
            "Epoch 1152/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 3.8139e-05 - val_loss: 6.6509e-05\n",
            "Epoch 1153/2000\n",
            "80/80 [==============================] - 0s 882us/step - loss: 5.5992e-05 - val_loss: 2.7450e-05\n",
            "Epoch 1154/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 3.2443e-05 - val_loss: 1.8716e-05\n",
            "Epoch 1155/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 3.7225e-05 - val_loss: 1.7428e-05\n",
            "Epoch 1156/2000\n",
            "80/80 [==============================] - 0s 996us/step - loss: 2.3747e-05 - val_loss: 2.6732e-05\n",
            "Epoch 1157/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 2.1358e-05 - val_loss: 1.2341e-05\n",
            "Epoch 1158/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 2.0414e-05 - val_loss: 3.6055e-05\n",
            "Epoch 1159/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 3.5300e-05 - val_loss: 4.5958e-05\n",
            "Epoch 1160/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 4.4146e-05 - val_loss: 4.2493e-05\n",
            "Epoch 1161/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 4.1351e-05 - val_loss: 7.0627e-05\n",
            "Epoch 1162/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.5534e-05 - val_loss: 3.3187e-05\n",
            "Epoch 1163/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 4.9301e-05 - val_loss: 7.7179e-05\n",
            "Epoch 1164/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 2.8263e-05 - val_loss: 9.1737e-06\n",
            "Epoch 1165/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 2.3966e-05 - val_loss: 2.5803e-05\n",
            "Epoch 1166/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 2.1888e-05 - val_loss: 1.3486e-05\n",
            "Epoch 1167/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 1.5367e-05 - val_loss: 2.0213e-05\n",
            "Epoch 1168/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.9722e-06 - val_loss: 1.0362e-05\n",
            "Epoch 1169/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 1.3433e-05 - val_loss: 1.0281e-05\n",
            "Epoch 1170/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 1.2296e-05 - val_loss: 1.6486e-05\n",
            "Epoch 1171/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 2.0294e-05 - val_loss: 2.7391e-05\n",
            "Epoch 1172/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 2.2009e-05 - val_loss: 6.8931e-05\n",
            "Epoch 1173/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 3.8162e-05 - val_loss: 2.5359e-05\n",
            "Epoch 1174/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.3404e-05 - val_loss: 2.1096e-05\n",
            "Epoch 1175/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 1.8783e-05 - val_loss: 4.7736e-05\n",
            "Epoch 1176/2000\n",
            "80/80 [==============================] - 0s 821us/step - loss: 2.3386e-05 - val_loss: 2.1242e-05\n",
            "Epoch 1177/2000\n",
            "80/80 [==============================] - 0s 824us/step - loss: 2.7992e-05 - val_loss: 5.1788e-05\n",
            "Epoch 1178/2000\n",
            "80/80 [==============================] - 0s 862us/step - loss: 2.8135e-05 - val_loss: 6.6254e-06\n",
            "Epoch 1179/2000\n",
            "80/80 [==============================] - 0s 854us/step - loss: 2.0685e-05 - val_loss: 7.0959e-05\n",
            "Epoch 1180/2000\n",
            "80/80 [==============================] - 0s 853us/step - loss: 2.1444e-05 - val_loss: 4.1990e-06\n",
            "Epoch 1181/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 1.2175e-05 - val_loss: 1.0949e-05\n",
            "Epoch 1182/2000\n",
            "80/80 [==============================] - 0s 784us/step - loss: 8.4919e-06 - val_loss: 1.3350e-05\n",
            "Epoch 1183/2000\n",
            "80/80 [==============================] - 0s 861us/step - loss: 1.2426e-05 - val_loss: 3.4694e-05\n",
            "Epoch 1184/2000\n",
            "80/80 [==============================] - 0s 850us/step - loss: 1.9859e-05 - val_loss: 5.3317e-06\n",
            "Epoch 1185/2000\n",
            "80/80 [==============================] - 0s 812us/step - loss: 8.6798e-06 - val_loss: 4.9534e-06\n",
            "Epoch 1186/2000\n",
            "80/80 [==============================] - 0s 798us/step - loss: 5.7296e-06 - val_loss: 8.4097e-06\n",
            "Epoch 1187/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.7436e-06 - val_loss: 3.7061e-06\n",
            "Epoch 1188/2000\n",
            "80/80 [==============================] - 0s 862us/step - loss: 4.6073e-06 - val_loss: 1.8973e-05\n",
            "Epoch 1189/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 8.5826e-06 - val_loss: 4.8565e-06\n",
            "Epoch 1190/2000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 7.1126e-06 - val_loss: 1.0611e-05\n",
            "Epoch 1191/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 8.0198e-06 - val_loss: 2.7631e-06\n",
            "Epoch 1192/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 5.2401e-06 - val_loss: 4.2788e-06\n",
            "Epoch 1193/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 3.1467e-06 - val_loss: 8.1833e-06\n",
            "Epoch 1194/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 3.4642e-06 - val_loss: 8.9127e-06\n",
            "Epoch 1195/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 6.5880e-06 - val_loss: 3.0924e-06\n",
            "Epoch 1196/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 6.6202e-06 - val_loss: 1.7884e-05\n",
            "Epoch 1197/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 8.9843e-06 - val_loss: 3.8430e-06\n",
            "Epoch 1198/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 4.9370e-06 - val_loss: 5.3669e-06\n",
            "Epoch 1199/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.3606e-06 - val_loss: 4.6893e-06\n",
            "Epoch 1200/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 3.1032e-06 - val_loss: 5.0560e-06\n",
            "Epoch 1201/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 2.4892e-06 - val_loss: 1.9030e-06\n",
            "Epoch 1202/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 2.1650e-06 - val_loss: 2.3897e-06\n",
            "Epoch 1203/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 2.5655e-06 - val_loss: 4.8503e-06\n",
            "Epoch 1204/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 2.7714e-06 - val_loss: 3.6417e-06\n",
            "Epoch 1205/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7357e-06 - val_loss: 2.7618e-06\n",
            "Epoch 1206/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 2.1439e-06 - val_loss: 3.0426e-06\n",
            "Epoch 1207/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 1.9743e-06 - val_loss: 3.3753e-06\n",
            "Epoch 1208/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 2.1689e-06 - val_loss: 3.7134e-06\n",
            "Epoch 1209/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 3.4774e-06 - val_loss: 3.6249e-06\n",
            "Epoch 1210/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 2.6735e-06 - val_loss: 5.5400e-06\n",
            "Epoch 1211/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 3.7245e-06 - val_loss: 8.6525e-06\n",
            "Epoch 1212/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 3.6688e-06 - val_loss: 2.5846e-06\n",
            "Epoch 1213/2000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 1.6085e-06 - val_loss: 2.9320e-06\n",
            "Epoch 1214/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0610e-06 - val_loss: 2.9838e-06\n",
            "Epoch 1215/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 1.7131e-06 - val_loss: 4.0506e-06\n",
            "Epoch 1216/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 2.4301e-06 - val_loss: 9.7229e-06\n",
            "Epoch 1217/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 4.2228e-06 - val_loss: 4.3396e-06\n",
            "Epoch 1218/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 3.9564e-06 - val_loss: 6.1946e-06\n",
            "Epoch 1219/2000\n",
            "80/80 [==============================] - 0s 883us/step - loss: 7.4040e-06 - val_loss: 3.3987e-06\n",
            "Epoch 1220/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 4.5180e-06 - val_loss: 1.5851e-05\n",
            "Epoch 1221/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 6.0240e-06 - val_loss: 5.2491e-06\n",
            "Epoch 1222/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 8.1555e-06 - val_loss: 6.4350e-06\n",
            "Epoch 1223/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 7.2262e-06 - val_loss: 4.0461e-06\n",
            "Epoch 1224/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.1121e-06 - val_loss: 2.1038e-05\n",
            "Epoch 1225/2000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 9.5413e-06 - val_loss: 5.9539e-06\n",
            "Epoch 1226/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 4.9856e-06 - val_loss: 6.9943e-06\n",
            "Epoch 1227/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 2.8573e-06 - val_loss: 5.2693e-06\n",
            "Epoch 1228/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 4.2047e-06 - val_loss: 4.3503e-06\n",
            "Epoch 1229/2000\n",
            "80/80 [==============================] - 0s 983us/step - loss: 2.5901e-06 - val_loss: 2.5093e-06\n",
            "Epoch 1230/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2129e-06 - val_loss: 4.7842e-06\n",
            "Epoch 1231/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7662e-06 - val_loss: 3.6846e-06\n",
            "Epoch 1232/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 2.0105e-06 - val_loss: 3.2655e-06\n",
            "Epoch 1233/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 1.3767e-06 - val_loss: 3.1593e-06\n",
            "Epoch 1234/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 1.8839e-06 - val_loss: 6.9529e-06\n",
            "Epoch 1235/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.6006e-06 - val_loss: 2.2368e-06\n",
            "Epoch 1236/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 1.9334e-06 - val_loss: 3.5038e-06\n",
            "Epoch 1237/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8718e-06 - val_loss: 3.2010e-06\n",
            "Epoch 1238/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 2.1732e-06 - val_loss: 2.6110e-06\n",
            "Epoch 1239/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0128e-06 - val_loss: 3.8298e-06\n",
            "Epoch 1240/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 4.5065e-06 - val_loss: 5.2998e-06\n",
            "Epoch 1241/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 6.3642e-06 - val_loss: 5.6456e-06\n",
            "Epoch 1242/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.7086e-06 - val_loss: 9.1159e-06\n",
            "Epoch 1243/2000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 4.4611e-06 - val_loss: 3.4412e-06\n",
            "Epoch 1244/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 4.3391e-06 - val_loss: 6.8347e-06\n",
            "Epoch 1245/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 4.6810e-06 - val_loss: 6.5943e-06\n",
            "Epoch 1246/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 4.0328e-06 - val_loss: 3.9966e-06\n",
            "Epoch 1247/2000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 3.8142e-06 - val_loss: 3.4901e-06\n",
            "Epoch 1248/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 5.5228e-06 - val_loss: 8.8911e-06\n",
            "Epoch 1249/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 1.0662e-05 - val_loss: 6.2759e-06\n",
            "Epoch 1250/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 8.2019e-06 - val_loss: 1.2838e-05\n",
            "Epoch 1251/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.1405e-06 - val_loss: 8.4325e-06\n",
            "Epoch 1252/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 4.3449e-06 - val_loss: 6.5163e-06\n",
            "Epoch 1253/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3971e-06 - val_loss: 3.1070e-06\n",
            "Epoch 1254/2000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 2.5701e-06 - val_loss: 2.0206e-06\n",
            "Epoch 1255/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 1.6849e-06 - val_loss: 4.2701e-06\n",
            "Epoch 1256/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 1.9694e-06 - val_loss: 4.2305e-06\n",
            "Epoch 1257/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4995e-06 - val_loss: 2.4547e-06\n",
            "Epoch 1258/2000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 1.7780e-06 - val_loss: 2.6842e-06\n",
            "Epoch 1259/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 2.2243e-06 - val_loss: 1.0540e-05\n",
            "Epoch 1260/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.9662e-06 - val_loss: 4.9721e-06\n",
            "Epoch 1261/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.2140e-06 - val_loss: 3.6994e-06\n",
            "Epoch 1262/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 4.6190e-06 - val_loss: 5.1103e-06\n",
            "Epoch 1263/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 3.0522e-06 - val_loss: 2.4864e-06\n",
            "Epoch 1264/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0876e-06 - val_loss: 5.3896e-06\n",
            "Epoch 1265/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2638e-06 - val_loss: 3.8205e-06\n",
            "Epoch 1266/2000\n",
            "80/80 [==============================] - 0s 996us/step - loss: 2.2518e-06 - val_loss: 4.1957e-06\n",
            "Epoch 1267/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 2.2121e-06 - val_loss: 3.1035e-06\n",
            "Epoch 1268/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 1.5248e-06 - val_loss: 5.2347e-06\n",
            "Epoch 1269/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 1.8581e-06 - val_loss: 2.6012e-06\n",
            "Epoch 1270/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 2.5674e-06 - val_loss: 5.4648e-06\n",
            "Epoch 1271/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 4.5981e-06 - val_loss: 4.2589e-06\n",
            "Epoch 1272/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 3.5431e-06 - val_loss: 5.2503e-06\n",
            "Epoch 1273/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 3.3253e-06 - val_loss: 8.3869e-06\n",
            "Epoch 1274/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.6382e-06 - val_loss: 7.6850e-06\n",
            "Epoch 1275/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.3038e-06 - val_loss: 3.2024e-06\n",
            "Epoch 1276/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 3.9253e-06 - val_loss: 7.7230e-06\n",
            "Epoch 1277/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 4.9877e-06 - val_loss: 2.8584e-06\n",
            "Epoch 1278/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 5.9548e-06 - val_loss: 8.9366e-06\n",
            "Epoch 1279/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.5370e-06 - val_loss: 2.7570e-05\n",
            "Epoch 1280/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 1.2306e-05 - val_loss: 2.1307e-05\n",
            "Epoch 1281/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 1.9802e-05 - val_loss: 1.4314e-05\n",
            "Epoch 1282/2000\n",
            "80/80 [==============================] - 0s 898us/step - loss: 8.5528e-06 - val_loss: 7.5792e-06\n",
            "Epoch 1283/2000\n",
            "80/80 [==============================] - 0s 894us/step - loss: 8.8230e-06 - val_loss: 2.8348e-06\n",
            "Epoch 1284/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 1.0712e-05 - val_loss: 4.5479e-06\n",
            "Epoch 1285/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.5516e-06 - val_loss: 9.3174e-06\n",
            "Epoch 1286/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.7688e-06 - val_loss: 7.3456e-06\n",
            "Epoch 1287/2000\n",
            "80/80 [==============================] - 0s 989us/step - loss: 6.3944e-06 - val_loss: 6.4270e-06\n",
            "Epoch 1288/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 1.2464e-05 - val_loss: 2.2653e-05\n",
            "Epoch 1289/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 1.3787e-05 - val_loss: 2.3316e-05\n",
            "Epoch 1290/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 1.7666e-05 - val_loss: 3.1510e-05\n",
            "Epoch 1291/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.4155e-05 - val_loss: 5.4988e-05\n",
            "Epoch 1292/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 5.0848e-05 - val_loss: 6.4769e-05\n",
            "Epoch 1293/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 6.0050e-05 - val_loss: 2.6657e-05\n",
            "Epoch 1294/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 4.1127e-05 - val_loss: 8.6226e-05\n",
            "Epoch 1295/2000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 7.2523e-05 - val_loss: 4.4701e-04\n",
            "Epoch 1296/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 2.2217e-04 - val_loss: 1.5639e-04\n",
            "Epoch 1297/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 2.2089e-04 - val_loss: 1.4845e-04\n",
            "Epoch 1298/2000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 3.2573e-04 - val_loss: 7.2623e-04\n",
            "Epoch 1299/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 4.4666e-04 - val_loss: 1.1893e-04\n",
            "Epoch 1300/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1642e-04 - val_loss: 4.6200e-04\n",
            "Epoch 1301/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 3.3721e-04 - val_loss: 1.4803e-04\n",
            "Epoch 1302/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7229e-04 - val_loss: 2.0915e-04\n",
            "Epoch 1303/2000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 2.1650e-04 - val_loss: 1.5605e-04\n",
            "Epoch 1304/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 2.1499e-04 - val_loss: 2.6839e-04\n",
            "Epoch 1305/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.3456e-04 - val_loss: 2.4032e-04\n",
            "Epoch 1306/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 7.5147e-04 - val_loss: 2.6920e-04\n",
            "Epoch 1307/2000\n",
            "80/80 [==============================] - 0s 898us/step - loss: 3.4429e-04 - val_loss: 0.0011\n",
            "Epoch 1308/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 9.1841e-04 - val_loss: 0.0018\n",
            "Epoch 1309/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 9.0420e-04\n",
            "Epoch 1310/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 9.5409e-04 - val_loss: 8.1289e-04\n",
            "Epoch 1311/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 6.7359e-04 - val_loss: 5.7905e-04\n",
            "Epoch 1312/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 4.4475e-04 - val_loss: 4.8539e-04\n",
            "Epoch 1313/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 3.5944e-04 - val_loss: 2.1717e-04\n",
            "Epoch 1314/2000\n",
            "80/80 [==============================] - 0s 981us/step - loss: 3.2550e-04 - val_loss: 1.4829e-04\n",
            "Epoch 1315/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8725e-04 - val_loss: 2.8949e-04\n",
            "Epoch 1316/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2691e-04 - val_loss: 6.8445e-05\n",
            "Epoch 1317/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 1.5541e-04 - val_loss: 6.2410e-04\n",
            "Epoch 1318/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 4.0461e-04 - val_loss: 1.1155e-04\n",
            "Epoch 1319/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 1.5197e-04 - val_loss: 3.5235e-04\n",
            "Epoch 1320/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4222e-04 - val_loss: 2.5871e-04\n",
            "Epoch 1321/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 1.7088e-04 - val_loss: 2.6497e-04\n",
            "Epoch 1322/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 2.0605e-04 - val_loss: 1.6635e-04\n",
            "Epoch 1323/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 2.3153e-04 - val_loss: 2.3661e-04\n",
            "Epoch 1324/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 3.9629e-04 - val_loss: 9.6578e-04\n",
            "Epoch 1325/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.3404e-04 - val_loss: 1.2984e-04\n",
            "Epoch 1326/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4935e-04 - val_loss: 6.2192e-04\n",
            "Epoch 1327/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.2930e-04 - val_loss: 1.2691e-04\n",
            "Epoch 1328/2000\n",
            "80/80 [==============================] - 0s 996us/step - loss: 3.6092e-04 - val_loss: 0.0010\n",
            "Epoch 1329/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 8.1471e-04 - val_loss: 0.0048\n",
            "Epoch 1330/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 0.0057 - val_loss: 0.0023\n",
            "Epoch 1331/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 0.0077 - val_loss: 0.0087\n",
            "Epoch 1332/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 0.0072 - val_loss: 7.6773e-04\n",
            "Epoch 1333/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0087\n",
            "Epoch 1334/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 0.0047 - val_loss: 7.0504e-04\n",
            "Epoch 1335/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 0.0021 - val_loss: 0.0015\n",
            "Epoch 1336/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 0.0013 - val_loss: 0.0021\n",
            "Epoch 1337/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 0.0015 - val_loss: 2.5645e-04\n",
            "Epoch 1338/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 9.1078e-04 - val_loss: 0.0012\n",
            "Epoch 1339/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 9.0646e-04 - val_loss: 2.4567e-04\n",
            "Epoch 1340/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.5528e-04 - val_loss: 1.9703e-04\n",
            "Epoch 1341/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 5.4449e-04 - val_loss: 9.7201e-04\n",
            "Epoch 1342/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 4.5621e-04 - val_loss: 1.7880e-04\n",
            "Epoch 1343/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 4.1460e-04 - val_loss: 1.6479e-04\n",
            "Epoch 1344/2000\n",
            "80/80 [==============================] - 0s 992us/step - loss: 3.6358e-04 - val_loss: 6.9184e-04\n",
            "Epoch 1345/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 4.6030e-04 - val_loss: 3.4347e-04\n",
            "Epoch 1346/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.3708e-04 - val_loss: 1.3628e-04\n",
            "Epoch 1347/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8941e-04 - val_loss: 3.3414e-04\n",
            "Epoch 1348/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 1.9656e-04 - val_loss: 2.4094e-04\n",
            "Epoch 1349/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 1.6366e-04 - val_loss: 1.0860e-04\n",
            "Epoch 1350/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 9.0801e-05 - val_loss: 5.8483e-05\n",
            "Epoch 1351/2000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 1.2494e-04 - val_loss: 2.4694e-04\n",
            "Epoch 1352/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7227e-04 - val_loss: 9.1206e-04\n",
            "Epoch 1353/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.4894e-04 - val_loss: 0.0010\n",
            "Epoch 1354/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 6.0106e-04 - val_loss: 1.8559e-04\n",
            "Epoch 1355/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 3.5110e-04 - val_loss: 6.0858e-04\n",
            "Epoch 1356/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.2932e-04 - val_loss: 2.0406e-04\n",
            "Epoch 1357/2000\n",
            "80/80 [==============================] - 0s 996us/step - loss: 2.4511e-04 - val_loss: 1.1995e-04\n",
            "Epoch 1358/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 1.4698e-04 - val_loss: 1.2452e-04\n",
            "Epoch 1359/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 1.3467e-04 - val_loss: 7.8509e-05\n",
            "Epoch 1360/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 1.2020e-04 - val_loss: 6.6444e-05\n",
            "Epoch 1361/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 8.5232e-05 - val_loss: 1.4134e-04\n",
            "Epoch 1362/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 1.6162e-04 - val_loss: 3.9491e-04\n",
            "Epoch 1363/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3634e-04 - val_loss: 4.4726e-05\n",
            "Epoch 1364/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 1.2752e-04 - val_loss: 9.6440e-05\n",
            "Epoch 1365/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0360e-04 - val_loss: 1.4785e-04\n",
            "Epoch 1366/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 1.1296e-04 - val_loss: 5.0963e-05\n",
            "Epoch 1367/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.0175e-05 - val_loss: 4.3714e-05\n",
            "Epoch 1368/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 7.9028e-05 - val_loss: 2.4008e-04\n",
            "Epoch 1369/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 1.7911e-04 - val_loss: 2.9122e-04\n",
            "Epoch 1370/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0549e-04 - val_loss: 1.0375e-04\n",
            "Epoch 1371/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 1.7507e-04 - val_loss: 1.1591e-04\n",
            "Epoch 1372/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 1.1563e-04 - val_loss: 2.0946e-04\n",
            "Epoch 1373/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2795e-04 - val_loss: 3.6593e-05\n",
            "Epoch 1374/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 8.0147e-05 - val_loss: 3.2348e-05\n",
            "Epoch 1375/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 6.8961e-05 - val_loss: 1.3328e-04\n",
            "Epoch 1376/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 5.7265e-05 - val_loss: 1.3965e-05\n",
            "Epoch 1377/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 3.4868e-05 - val_loss: 5.4430e-05\n",
            "Epoch 1378/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 4.8649e-05 - val_loss: 1.5673e-04\n",
            "Epoch 1379/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 9.3144e-05 - val_loss: 5.1576e-05\n",
            "Epoch 1380/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 9.3052e-05 - val_loss: 8.0317e-05\n",
            "Epoch 1381/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 1.1190e-04 - val_loss: 1.5708e-04\n",
            "Epoch 1382/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 1.1782e-04 - val_loss: 1.8624e-05\n",
            "Epoch 1383/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 7.0063e-05 - val_loss: 2.7344e-05\n",
            "Epoch 1384/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 6.4320e-05 - val_loss: 1.1393e-04\n",
            "Epoch 1385/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 7.9558e-05 - val_loss: 6.6223e-05\n",
            "Epoch 1386/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 9.6885e-05 - val_loss: 7.5768e-05\n",
            "Epoch 1387/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.7042e-05 - val_loss: 1.1059e-04\n",
            "Epoch 1388/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.9014e-05 - val_loss: 6.8916e-05\n",
            "Epoch 1389/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.2120e-05 - val_loss: 3.0027e-05\n",
            "Epoch 1390/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 4.6214e-05 - val_loss: 3.4852e-05\n",
            "Epoch 1391/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 4.2928e-05 - val_loss: 2.7703e-05\n",
            "Epoch 1392/2000\n",
            "80/80 [==============================] - 0s 892us/step - loss: 4.7585e-05 - val_loss: 3.1662e-05\n",
            "Epoch 1393/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 4.0883e-05 - val_loss: 2.5242e-05\n",
            "Epoch 1394/2000\n",
            "80/80 [==============================] - 0s 851us/step - loss: 4.0637e-05 - val_loss: 1.4692e-05\n",
            "Epoch 1395/2000\n",
            "80/80 [==============================] - 0s 889us/step - loss: 2.7049e-05 - val_loss: 6.5967e-06\n",
            "Epoch 1396/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 2.3454e-05 - val_loss: 2.6377e-05\n",
            "Epoch 1397/2000\n",
            "80/80 [==============================] - 0s 863us/step - loss: 2.1132e-05 - val_loss: 3.7387e-05\n",
            "Epoch 1398/2000\n",
            "80/80 [==============================] - 0s 880us/step - loss: 3.1778e-05 - val_loss: 1.0806e-05\n",
            "Epoch 1399/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 2.3605e-05 - val_loss: 4.4591e-05\n",
            "Epoch 1400/2000\n",
            "80/80 [==============================] - 0s 894us/step - loss: 3.8479e-05 - val_loss: 9.4051e-05\n",
            "Epoch 1401/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 5.8218e-05 - val_loss: 2.1726e-05\n",
            "Epoch 1402/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 4.3112e-05 - val_loss: 3.0878e-05\n",
            "Epoch 1403/2000\n",
            "80/80 [==============================] - 0s 898us/step - loss: 3.3219e-05 - val_loss: 3.1926e-05\n",
            "Epoch 1404/2000\n",
            "80/80 [==============================] - 0s 838us/step - loss: 2.8284e-05 - val_loss: 6.9863e-05\n",
            "Epoch 1405/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 4.2057e-05 - val_loss: 2.0349e-05\n",
            "Epoch 1406/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 2.6735e-05 - val_loss: 2.7493e-05\n",
            "Epoch 1407/2000\n",
            "80/80 [==============================] - 0s 885us/step - loss: 2.3818e-05 - val_loss: 1.4867e-05\n",
            "Epoch 1408/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 1.2015e-05 - val_loss: 4.9624e-06\n",
            "Epoch 1409/2000\n",
            "80/80 [==============================] - 0s 880us/step - loss: 1.0995e-05 - val_loss: 7.2616e-06\n",
            "Epoch 1410/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 9.4365e-06 - val_loss: 2.0701e-05\n",
            "Epoch 1411/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 1.5307e-05 - val_loss: 1.6550e-05\n",
            "Epoch 1412/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 2.4045e-05 - val_loss: 2.0234e-05\n",
            "Epoch 1413/2000\n",
            "80/80 [==============================] - 0s 890us/step - loss: 2.0800e-05 - val_loss: 5.0235e-05\n",
            "Epoch 1414/2000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 2.3385e-05 - val_loss: 1.1448e-05\n",
            "Epoch 1415/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8854e-05 - val_loss: 9.5476e-06\n",
            "Epoch 1416/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 1.4510e-05 - val_loss: 2.8446e-05\n",
            "Epoch 1417/2000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 1.4611e-05 - val_loss: 6.0422e-06\n",
            "Epoch 1418/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 1.0488e-05 - val_loss: 1.2800e-05\n",
            "Epoch 1419/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 1.5119e-05 - val_loss: 3.6852e-06\n",
            "Epoch 1420/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 8.8794e-06 - val_loss: 2.8219e-05\n",
            "Epoch 1421/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4446e-05 - val_loss: 8.8883e-06\n",
            "Epoch 1422/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.9359e-06 - val_loss: 4.2329e-06\n",
            "Epoch 1423/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 5.5716e-06 - val_loss: 7.6063e-06\n",
            "Epoch 1424/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.5950e-06 - val_loss: 3.6403e-06\n",
            "Epoch 1425/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.5598e-06 - val_loss: 5.0015e-06\n",
            "Epoch 1426/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 4.0553e-06 - val_loss: 3.0833e-06\n",
            "Epoch 1427/2000\n",
            "80/80 [==============================] - 0s 979us/step - loss: 2.9205e-06 - val_loss: 4.5911e-06\n",
            "Epoch 1428/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 3.1718e-06 - val_loss: 5.7781e-06\n",
            "Epoch 1429/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 5.3590e-06 - val_loss: 6.1580e-06\n",
            "Epoch 1430/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.5452e-06 - val_loss: 1.7414e-05\n",
            "Epoch 1431/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 1.2501e-05 - val_loss: 7.0404e-06\n",
            "Epoch 1432/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 1.0335e-05 - val_loss: 2.3143e-05\n",
            "Epoch 1433/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 1.4001e-05 - val_loss: 1.1621e-05\n",
            "Epoch 1434/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 8.0813e-06 - val_loss: 5.8426e-06\n",
            "Epoch 1435/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 6.8378e-06 - val_loss: 6.6073e-06\n",
            "Epoch 1436/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.8923e-06 - val_loss: 1.2155e-05\n",
            "Epoch 1437/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.4429e-06 - val_loss: 3.1242e-06\n",
            "Epoch 1438/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 4.6930e-06 - val_loss: 7.8693e-06\n",
            "Epoch 1439/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 6.0127e-06 - val_loss: 6.6545e-06\n",
            "Epoch 1440/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 5.4079e-06 - val_loss: 7.9925e-06\n",
            "Epoch 1441/2000\n",
            "80/80 [==============================] - 0s 881us/step - loss: 6.5465e-06 - val_loss: 5.9150e-06\n",
            "Epoch 1442/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 6.2336e-06 - val_loss: 7.0343e-06\n",
            "Epoch 1443/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 5.2209e-06 - val_loss: 6.1423e-06\n",
            "Epoch 1444/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 3.2987e-06 - val_loss: 4.8094e-06\n",
            "Epoch 1445/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 3.3978e-06 - val_loss: 6.1810e-06\n",
            "Epoch 1446/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 3.4052e-06 - val_loss: 4.8207e-06\n",
            "Epoch 1447/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.0493e-06 - val_loss: 3.1428e-06\n",
            "Epoch 1448/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.4507e-06 - val_loss: 7.1813e-06\n",
            "Epoch 1449/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.9844e-06 - val_loss: 5.7025e-06\n",
            "Epoch 1450/2000\n",
            "80/80 [==============================] - 0s 994us/step - loss: 3.7874e-06 - val_loss: 3.2859e-06\n",
            "Epoch 1451/2000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 2.3679e-06 - val_loss: 3.2255e-06\n",
            "Epoch 1452/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 2.0350e-06 - val_loss: 3.2329e-06\n",
            "Epoch 1453/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 1.7765e-06 - val_loss: 3.2883e-06\n",
            "Epoch 1454/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 1.7472e-06 - val_loss: 3.8872e-06\n",
            "Epoch 1455/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 1.7795e-06 - val_loss: 6.4368e-06\n",
            "Epoch 1456/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 3.3414e-06 - val_loss: 3.4495e-06\n",
            "Epoch 1457/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 2.8463e-06 - val_loss: 2.6108e-06\n",
            "Epoch 1458/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 2.8783e-06 - val_loss: 4.6566e-06\n",
            "Epoch 1459/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 3.1904e-06 - val_loss: 2.5333e-06\n",
            "Epoch 1460/2000\n",
            "80/80 [==============================] - 0s 992us/step - loss: 7.0876e-06 - val_loss: 8.0103e-06\n",
            "Epoch 1461/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 5.7788e-06 - val_loss: 3.1763e-06\n",
            "Epoch 1462/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 3.6930e-06 - val_loss: 8.8930e-06\n",
            "Epoch 1463/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.9378e-06 - val_loss: 9.7717e-06\n",
            "Epoch 1464/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 4.2998e-06 - val_loss: 6.3850e-06\n",
            "Epoch 1465/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.8950e-06 - val_loss: 6.4588e-06\n",
            "Epoch 1466/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.7892e-06 - val_loss: 5.1796e-06\n",
            "Epoch 1467/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 2.9058e-06 - val_loss: 6.4407e-06\n",
            "Epoch 1468/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 5.3045e-06 - val_loss: 1.1483e-05\n",
            "Epoch 1469/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 6.4331e-06 - val_loss: 1.5643e-05\n",
            "Epoch 1470/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 7.7450e-06 - val_loss: 8.1211e-06\n",
            "Epoch 1471/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 6.1086e-06 - val_loss: 6.6720e-06\n",
            "Epoch 1472/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 5.0849e-06 - val_loss: 3.5571e-06\n",
            "Epoch 1473/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 2.4195e-06 - val_loss: 4.2993e-06\n",
            "Epoch 1474/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 2.1655e-06 - val_loss: 3.7102e-06\n",
            "Epoch 1475/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 1.7069e-06 - val_loss: 5.2249e-06\n",
            "Epoch 1476/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.2226e-06 - val_loss: 3.9228e-06\n",
            "Epoch 1477/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 2.3911e-06 - val_loss: 4.7199e-06\n",
            "Epoch 1478/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 2.7704e-06 - val_loss: 2.6094e-06\n",
            "Epoch 1479/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 3.0139e-06 - val_loss: 4.5987e-06\n",
            "Epoch 1480/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 2.1265e-06 - val_loss: 4.1256e-06\n",
            "Epoch 1481/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 2.4704e-06 - val_loss: 4.4742e-06\n",
            "Epoch 1482/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3826e-06 - val_loss: 2.9594e-06\n",
            "Epoch 1483/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3286e-06 - val_loss: 2.9621e-06\n",
            "Epoch 1484/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 1.4945e-06 - val_loss: 3.2219e-06\n",
            "Epoch 1485/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 1.2170e-06 - val_loss: 2.1813e-06\n",
            "Epoch 1486/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 1.4841e-06 - val_loss: 1.7836e-06\n",
            "Epoch 1487/2000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 1.1752e-06 - val_loss: 4.4586e-06\n",
            "Epoch 1488/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 1.8579e-06 - val_loss: 2.7558e-06\n",
            "Epoch 1489/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 2.0098e-06 - val_loss: 3.0374e-06\n",
            "Epoch 1490/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 2.1071e-06 - val_loss: 3.9638e-06\n",
            "Epoch 1491/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 3.0553e-06 - val_loss: 2.9000e-06\n",
            "Epoch 1492/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 1.3501e-06 - val_loss: 2.5881e-06\n",
            "Epoch 1493/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 1.1409e-06 - val_loss: 2.3414e-06\n",
            "Epoch 1494/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.6840e-06 - val_loss: 3.7822e-06\n",
            "Epoch 1495/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 1.9153e-06 - val_loss: 3.3952e-06\n",
            "Epoch 1496/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.6276e-06 - val_loss: 4.0710e-06\n",
            "Epoch 1497/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 1.5782e-06 - val_loss: 3.2002e-06\n",
            "Epoch 1498/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 1.5418e-06 - val_loss: 1.7593e-06\n",
            "Epoch 1499/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 1.1438e-06 - val_loss: 1.9620e-06\n",
            "Epoch 1500/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 1.1975e-06 - val_loss: 2.7051e-06\n",
            "Epoch 1501/2000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 9.0627e-07 - val_loss: 2.6181e-06\n",
            "Epoch 1502/2000\n",
            "80/80 [==============================] - 0s 992us/step - loss: 1.1269e-06 - val_loss: 2.6658e-06\n",
            "Epoch 1503/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 1.0425e-06 - val_loss: 2.8960e-06\n",
            "Epoch 1504/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 1.1837e-06 - val_loss: 2.6170e-06\n",
            "Epoch 1505/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4929e-06 - val_loss: 1.8057e-06\n",
            "Epoch 1506/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.5500e-06 - val_loss: 3.3489e-06\n",
            "Epoch 1507/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 1.2702e-06 - val_loss: 3.0553e-06\n",
            "Epoch 1508/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 1.1157e-06 - val_loss: 2.8508e-06\n",
            "Epoch 1509/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 1.1575e-06 - val_loss: 3.1129e-06\n",
            "Epoch 1510/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 2.5780e-06 - val_loss: 1.0222e-05\n",
            "Epoch 1511/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 1.0932e-05 - val_loss: 6.2464e-06\n",
            "Epoch 1512/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 8.1442e-06 - val_loss: 2.4999e-05\n",
            "Epoch 1513/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 1.2704e-05 - val_loss: 5.5556e-06\n",
            "Epoch 1514/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 1.1195e-05 - val_loss: 1.7535e-05\n",
            "Epoch 1515/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 1.5456e-05 - val_loss: 5.9156e-06\n",
            "Epoch 1516/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 1.1523e-05 - val_loss: 2.9221e-05\n",
            "Epoch 1517/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0320e-05 - val_loss: 2.5242e-06\n",
            "Epoch 1518/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 1.3961e-05 - val_loss: 5.0771e-06\n",
            "Epoch 1519/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 9.6668e-06 - val_loss: 1.6997e-05\n",
            "Epoch 1520/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 8.9421e-06 - val_loss: 4.3772e-06\n",
            "Epoch 1521/2000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 4.2851e-06 - val_loss: 1.1787e-05\n",
            "Epoch 1522/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 6.6241e-06 - val_loss: 4.7535e-06\n",
            "Epoch 1523/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 3.5655e-06 - val_loss: 6.1924e-06\n",
            "Epoch 1524/2000\n",
            "80/80 [==============================] - 0s 894us/step - loss: 3.8402e-06 - val_loss: 2.2067e-06\n",
            "Epoch 1525/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 2.7310e-06 - val_loss: 2.8445e-06\n",
            "Epoch 1526/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 2.3018e-06 - val_loss: 3.8230e-06\n",
            "Epoch 1527/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 2.0286e-06 - val_loss: 4.8561e-06\n",
            "Epoch 1528/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 6.5714e-06 - val_loss: 1.1718e-05\n",
            "Epoch 1529/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 1.2395e-05 - val_loss: 5.3156e-05\n",
            "Epoch 1530/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 2.9959e-05 - val_loss: 2.3968e-05\n",
            "Epoch 1531/2000\n",
            "80/80 [==============================] - 0s 981us/step - loss: 2.5296e-05 - val_loss: 1.2987e-05\n",
            "Epoch 1532/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 1.8309e-05 - val_loss: 2.9940e-05\n",
            "Epoch 1533/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 2.1055e-05 - val_loss: 3.8061e-05\n",
            "Epoch 1534/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 3.5598e-05 - val_loss: 5.6631e-05\n",
            "Epoch 1535/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 3.8368e-05 - val_loss: 4.0644e-05\n",
            "Epoch 1536/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 5.2929e-05 - val_loss: 7.2287e-05\n",
            "Epoch 1537/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.2764e-05 - val_loss: 2.0127e-05\n",
            "Epoch 1538/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.9304e-05 - val_loss: 2.8281e-04\n",
            "Epoch 1539/2000\n",
            "80/80 [==============================] - 0s 979us/step - loss: 1.4859e-04 - val_loss: 1.6454e-04\n",
            "Epoch 1540/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 1.9248e-04 - val_loss: 1.6845e-04\n",
            "Epoch 1541/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 1.7719e-04 - val_loss: 1.1130e-04\n",
            "Epoch 1542/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 1.9735e-04 - val_loss: 7.3923e-04\n",
            "Epoch 1543/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 3.4085e-04 - val_loss: 4.8581e-04\n",
            "Epoch 1544/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 3.9688e-04 - val_loss: 2.8807e-04\n",
            "Epoch 1545/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 3.0387e-04 - val_loss: 4.2267e-04\n",
            "Epoch 1546/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 2.2457e-04 - val_loss: 5.0915e-04\n",
            "Epoch 1547/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.1324e-04 - val_loss: 7.3205e-04\n",
            "Epoch 1548/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 5.1895e-04 - val_loss: 2.0426e-04\n",
            "Epoch 1549/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 2.9935e-04 - val_loss: 3.1609e-04\n",
            "Epoch 1550/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 2.1123e-04 - val_loss: 6.1181e-04\n",
            "Epoch 1551/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 4.9618e-04 - val_loss: 3.5936e-04\n",
            "Epoch 1552/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 4.2048e-04 - val_loss: 3.0449e-04\n",
            "Epoch 1553/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3659e-04 - val_loss: 3.7526e-05\n",
            "Epoch 1554/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 9.9542e-05 - val_loss: 2.5452e-04\n",
            "Epoch 1555/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 1.2158e-04 - val_loss: 5.6127e-05\n",
            "Epoch 1556/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 5.9026e-05 - val_loss: 6.5419e-05\n",
            "Epoch 1557/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 5.9494e-05 - val_loss: 1.8535e-04\n",
            "Epoch 1558/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 1.3706e-04 - val_loss: 5.0577e-05\n",
            "Epoch 1559/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.7452e-05 - val_loss: 1.8811e-04\n",
            "Epoch 1560/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 1.1762e-04 - val_loss: 1.4209e-05\n",
            "Epoch 1561/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 6.8928e-05 - val_loss: 4.3153e-05\n",
            "Epoch 1562/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 3.8992e-05 - val_loss: 6.1130e-05\n",
            "Epoch 1563/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 5.8270e-05 - val_loss: 1.4278e-04\n",
            "Epoch 1564/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 1.1958e-04 - val_loss: 1.4479e-05\n",
            "Epoch 1565/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 8.3894e-05 - val_loss: 5.3413e-04\n",
            "Epoch 1566/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.5120e-04 - val_loss: 1.9294e-04\n",
            "Epoch 1567/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 2.0810e-04 - val_loss: 1.9450e-04\n",
            "Epoch 1568/2000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 1.5885e-04 - val_loss: 4.9807e-05\n",
            "Epoch 1569/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 9.5444e-05 - val_loss: 9.9993e-05\n",
            "Epoch 1570/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 6.7429e-05 - val_loss: 3.1896e-05\n",
            "Epoch 1571/2000\n",
            "80/80 [==============================] - 0s 995us/step - loss: 3.2740e-05 - val_loss: 8.1572e-05\n",
            "Epoch 1572/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 5.7646e-05 - val_loss: 1.4038e-05\n",
            "Epoch 1573/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 3.5920e-05 - val_loss: 7.2239e-05\n",
            "Epoch 1574/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 5.3513e-05 - val_loss: 5.3723e-05\n",
            "Epoch 1575/2000\n",
            "80/80 [==============================] - 0s 884us/step - loss: 6.7571e-05 - val_loss: 1.2088e-04\n",
            "Epoch 1576/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.1473e-05 - val_loss: 1.6380e-05\n",
            "Epoch 1577/2000\n",
            "80/80 [==============================] - 0s 979us/step - loss: 5.9568e-05 - val_loss: 1.3563e-04\n",
            "Epoch 1578/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 1.0827e-04 - val_loss: 1.7830e-04\n",
            "Epoch 1579/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 1.0205e-04 - val_loss: 1.4350e-04\n",
            "Epoch 1580/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 8.7724e-05 - val_loss: 5.2900e-05\n",
            "Epoch 1581/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 6.0796e-05 - val_loss: 7.8287e-05\n",
            "Epoch 1582/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 5.8466e-05 - val_loss: 3.3255e-05\n",
            "Epoch 1583/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 6.0345e-05 - val_loss: 3.7898e-05\n",
            "Epoch 1584/2000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 5.6507e-05 - val_loss: 6.5558e-05\n",
            "Epoch 1585/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 4.6105e-05 - val_loss: 4.4008e-05\n",
            "Epoch 1586/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 3.4059e-05 - val_loss: 4.1036e-05\n",
            "Epoch 1587/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 4.1129e-05 - val_loss: 5.6812e-05\n",
            "Epoch 1588/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.9107e-05 - val_loss: 4.9193e-05\n",
            "Epoch 1589/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 3.6186e-05 - val_loss: 3.8599e-05\n",
            "Epoch 1590/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 3.1396e-05 - val_loss: 2.3445e-05\n",
            "Epoch 1591/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 3.5762e-05 - val_loss: 8.4850e-05\n",
            "Epoch 1592/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 3.7548e-05 - val_loss: 8.4016e-05\n",
            "Epoch 1593/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 6.7148e-05 - val_loss: 7.1046e-05\n",
            "Epoch 1594/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.2434e-05 - val_loss: 3.0609e-05\n",
            "Epoch 1595/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 9.1332e-05 - val_loss: 4.1857e-04\n",
            "Epoch 1596/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 2.0954e-04 - val_loss: 2.9954e-05\n",
            "Epoch 1597/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 1.3795e-04 - val_loss: 1.6694e-04\n",
            "Epoch 1598/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 1.2185e-04 - val_loss: 5.6579e-05\n",
            "Epoch 1599/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 4.7208e-05 - val_loss: 7.9159e-05\n",
            "Epoch 1600/2000\n",
            "80/80 [==============================] - 0s 981us/step - loss: 6.5825e-05 - val_loss: 6.4080e-05\n",
            "Epoch 1601/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 5.1623e-05 - val_loss: 3.6779e-05\n",
            "Epoch 1602/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 3.5176e-05 - val_loss: 3.5397e-05\n",
            "Epoch 1603/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 4.1599e-05 - val_loss: 4.7612e-05\n",
            "Epoch 1604/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.8238e-05 - val_loss: 5.9708e-05\n",
            "Epoch 1605/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.9678e-05 - val_loss: 3.8785e-05\n",
            "Epoch 1606/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 4.7311e-05 - val_loss: 7.2801e-05\n",
            "Epoch 1607/2000\n",
            "80/80 [==============================] - 0s 981us/step - loss: 5.9879e-05 - val_loss: 3.0172e-05\n",
            "Epoch 1608/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 4.5667e-05 - val_loss: 5.6603e-05\n",
            "Epoch 1609/2000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 4.8861e-05 - val_loss: 3.1415e-05\n",
            "Epoch 1610/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 4.0842e-05 - val_loss: 3.8703e-05\n",
            "Epoch 1611/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 3.8104e-05 - val_loss: 5.6159e-05\n",
            "Epoch 1612/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 5.4244e-05 - val_loss: 2.9789e-05\n",
            "Epoch 1613/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 4.6355e-05 - val_loss: 8.0589e-05\n",
            "Epoch 1614/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 5.6958e-05 - val_loss: 6.8762e-05\n",
            "Epoch 1615/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 6.7896e-05 - val_loss: 3.6241e-05\n",
            "Epoch 1616/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 4.8824e-05 - val_loss: 1.0783e-04\n",
            "Epoch 1617/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 7.2660e-05 - val_loss: 2.5842e-05\n",
            "Epoch 1618/2000\n",
            "80/80 [==============================] - 0s 886us/step - loss: 5.7090e-05 - val_loss: 5.0737e-05\n",
            "Epoch 1619/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 4.4914e-05 - val_loss: 3.9994e-05\n",
            "Epoch 1620/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 5.0540e-05 - val_loss: 5.7340e-05\n",
            "Epoch 1621/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 2.0225e-05 - val_loss: 2.4834e-05\n",
            "Epoch 1622/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7197e-05 - val_loss: 1.3714e-05\n",
            "Epoch 1623/2000\n",
            "80/80 [==============================] - 0s 995us/step - loss: 2.4693e-05 - val_loss: 1.8956e-05\n",
            "Epoch 1624/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 1.8079e-05 - val_loss: 2.9460e-05\n",
            "Epoch 1625/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 1.7432e-05 - val_loss: 9.9184e-06\n",
            "Epoch 1626/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 8.9126e-06 - val_loss: 1.9358e-05\n",
            "Epoch 1627/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3858e-05 - val_loss: 7.5841e-06\n",
            "Epoch 1628/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 6.8340e-06 - val_loss: 2.1787e-05\n",
            "Epoch 1629/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 1.4108e-05 - val_loss: 3.3506e-05\n",
            "Epoch 1630/2000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 2.5602e-05 - val_loss: 5.8071e-06\n",
            "Epoch 1631/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 1.6751e-05 - val_loss: 1.2320e-05\n",
            "Epoch 1632/2000\n",
            "80/80 [==============================] - 0s 977us/step - loss: 1.1064e-05 - val_loss: 1.1504e-05\n",
            "Epoch 1633/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 1.3863e-05 - val_loss: 3.8386e-05\n",
            "Epoch 1634/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 1.9618e-05 - val_loss: 1.2186e-05\n",
            "Epoch 1635/2000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 1.3148e-05 - val_loss: 1.4902e-05\n",
            "Epoch 1636/2000\n",
            "80/80 [==============================] - 0s 877us/step - loss: 1.5820e-05 - val_loss: 1.5987e-05\n",
            "Epoch 1637/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 1.1301e-05 - val_loss: 6.0358e-06\n",
            "Epoch 1638/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.8398e-06 - val_loss: 2.7733e-05\n",
            "Epoch 1639/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 1.6028e-05 - val_loss: 7.5789e-06\n",
            "Epoch 1640/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 1.7019e-05 - val_loss: 7.6489e-06\n",
            "Epoch 1641/2000\n",
            "80/80 [==============================] - 0s 892us/step - loss: 1.2543e-05 - val_loss: 3.2407e-05\n",
            "Epoch 1642/2000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 2.9164e-05 - val_loss: 7.8489e-06\n",
            "Epoch 1643/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 2.1230e-05 - val_loss: 8.6713e-06\n",
            "Epoch 1644/2000\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 1.3470e-05 - val_loss: 3.4453e-05\n",
            "Epoch 1645/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 2.6415e-05 - val_loss: 1.5435e-05\n",
            "Epoch 1646/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 2.8801e-05 - val_loss: 3.3140e-05\n",
            "Epoch 1647/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.4374e-05 - val_loss: 5.1825e-05\n",
            "Epoch 1648/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 2.9186e-05 - val_loss: 7.7491e-06\n",
            "Epoch 1649/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 1.6027e-05 - val_loss: 5.1137e-05\n",
            "Epoch 1650/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 3.2011e-05 - val_loss: 1.8914e-05\n",
            "Epoch 1651/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 2.0454e-05 - val_loss: 3.1036e-05\n",
            "Epoch 1652/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 1.2518e-05 - val_loss: 1.1127e-05\n",
            "Epoch 1653/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 1.0366e-05 - val_loss: 4.7953e-06\n",
            "Epoch 1654/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 4.9671e-06 - val_loss: 7.2343e-06\n",
            "Epoch 1655/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 4.4448e-06 - val_loss: 4.1584e-06\n",
            "Epoch 1656/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 3.1608e-06 - val_loss: 2.7388e-06\n",
            "Epoch 1657/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 2.4202e-06 - val_loss: 4.9827e-06\n",
            "Epoch 1658/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7025e-06 - val_loss: 2.8891e-06\n",
            "Epoch 1659/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.4532e-06 - val_loss: 4.3757e-06\n",
            "Epoch 1660/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 3.2625e-06 - val_loss: 3.5454e-06\n",
            "Epoch 1661/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.5893e-06 - val_loss: 5.7605e-06\n",
            "Epoch 1662/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 2.0775e-06 - val_loss: 3.5245e-06\n",
            "Epoch 1663/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 4.9416e-06 - val_loss: 1.1771e-05\n",
            "Epoch 1664/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 7.7566e-06 - val_loss: 4.1964e-06\n",
            "Epoch 1665/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 5.4188e-06 - val_loss: 1.0089e-05\n",
            "Epoch 1666/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 5.3813e-06 - val_loss: 1.3306e-05\n",
            "Epoch 1667/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 5.8309e-06 - val_loss: 3.3518e-06\n",
            "Epoch 1668/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 3.4619e-06 - val_loss: 7.5736e-06\n",
            "Epoch 1669/2000\n",
            "80/80 [==============================] - 0s 994us/step - loss: 6.8815e-06 - val_loss: 4.6853e-06\n",
            "Epoch 1670/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 4.8524e-06 - val_loss: 1.2239e-05\n",
            "Epoch 1671/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 5.5641e-06 - val_loss: 9.4584e-06\n",
            "Epoch 1672/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 3.9540e-06 - val_loss: 3.3114e-06\n",
            "Epoch 1673/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 3.7745e-06 - val_loss: 3.7034e-06\n",
            "Epoch 1674/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.5153e-06 - val_loss: 2.8698e-06\n",
            "Epoch 1675/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 2.2139e-06 - val_loss: 4.5605e-06\n",
            "Epoch 1676/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 2.8479e-06 - val_loss: 4.0108e-06\n",
            "Epoch 1677/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 1.7564e-06 - val_loss: 3.8129e-06\n",
            "Epoch 1678/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 1.8627e-06 - val_loss: 4.3520e-06\n",
            "Epoch 1679/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 1.6670e-06 - val_loss: 4.5396e-06\n",
            "Epoch 1680/2000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 2.3163e-06 - val_loss: 6.2045e-06\n",
            "Epoch 1681/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 2.8667e-06 - val_loss: 8.9463e-06\n",
            "Epoch 1682/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 4.6466e-06 - val_loss: 7.8836e-06\n",
            "Epoch 1683/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 6.0535e-06 - val_loss: 1.0677e-05\n",
            "Epoch 1684/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 1.0209e-05 - val_loss: 2.3852e-06\n",
            "Epoch 1685/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.1046e-06 - val_loss: 6.3452e-06\n",
            "Epoch 1686/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.6707e-06 - val_loss: 7.8847e-06\n",
            "Epoch 1687/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 4.3876e-06 - val_loss: 1.7462e-05\n",
            "Epoch 1688/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 7.9211e-06 - val_loss: 6.2747e-06\n",
            "Epoch 1689/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 4.6687e-06 - val_loss: 2.1399e-05\n",
            "Epoch 1690/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 1.4568e-05 - val_loss: 8.8417e-06\n",
            "Epoch 1691/2000\n",
            "80/80 [==============================] - 0s 981us/step - loss: 1.5463e-05 - val_loss: 7.8351e-06\n",
            "Epoch 1692/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 1.3660e-05 - val_loss: 3.4506e-05\n",
            "Epoch 1693/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 2.5527e-05 - val_loss: 4.7454e-05\n",
            "Epoch 1694/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 2.7377e-05 - val_loss: 8.4852e-05\n",
            "Epoch 1695/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 4.9594e-05 - val_loss: 9.0044e-06\n",
            "Epoch 1696/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0644e-05 - val_loss: 1.3769e-04\n",
            "Epoch 1697/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.9600e-05 - val_loss: 1.4936e-04\n",
            "Epoch 1698/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 1.0104e-04 - val_loss: 4.1233e-05\n",
            "Epoch 1699/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 5.6954e-05 - val_loss: 9.2437e-05\n",
            "Epoch 1700/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.7830e-05 - val_loss: 3.1268e-05\n",
            "Epoch 1701/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 2.2466e-05 - val_loss: 2.6089e-05\n",
            "Epoch 1702/2000\n",
            "80/80 [==============================] - 0s 981us/step - loss: 2.0358e-05 - val_loss: 1.7573e-05\n",
            "Epoch 1703/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 1.0479e-05 - val_loss: 2.0276e-05\n",
            "Epoch 1704/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 1.7701e-05 - val_loss: 9.4447e-06\n",
            "Epoch 1705/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 2.0898e-05 - val_loss: 5.2479e-06\n",
            "Epoch 1706/2000\n",
            "80/80 [==============================] - 0s 996us/step - loss: 1.9296e-05 - val_loss: 4.1976e-05\n",
            "Epoch 1707/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 2.7917e-05 - val_loss: 5.2371e-05\n",
            "Epoch 1708/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4793e-05 - val_loss: 6.2065e-06\n",
            "Epoch 1709/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 1.2894e-05 - val_loss: 3.8310e-05\n",
            "Epoch 1710/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 2.3552e-05 - val_loss: 9.7878e-06\n",
            "Epoch 1711/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 2.1184e-05 - val_loss: 9.0303e-06\n",
            "Epoch 1712/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 7.3116e-06 - val_loss: 3.0300e-05\n",
            "Epoch 1713/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 1.5337e-05 - val_loss: 1.3029e-05\n",
            "Epoch 1714/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 1.8412e-05 - val_loss: 6.8320e-06\n",
            "Epoch 1715/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 1.0943e-05 - val_loss: 1.6040e-05\n",
            "Epoch 1716/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 9.6980e-06 - val_loss: 7.4171e-06\n",
            "Epoch 1717/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 7.1798e-06 - val_loss: 5.0584e-06\n",
            "Epoch 1718/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 6.2294e-06 - val_loss: 1.2381e-05\n",
            "Epoch 1719/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 9.8528e-06 - val_loss: 1.1389e-05\n",
            "Epoch 1720/2000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 1.3957e-05 - val_loss: 6.7345e-06\n",
            "Epoch 1721/2000\n",
            "80/80 [==============================] - 0s 992us/step - loss: 1.5103e-05 - val_loss: 2.4567e-05\n",
            "Epoch 1722/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 1.5667e-05 - val_loss: 4.1901e-05\n",
            "Epoch 1723/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 2.4239e-05 - val_loss: 7.3021e-06\n",
            "Epoch 1724/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 1.0386e-05 - val_loss: 1.7432e-05\n",
            "Epoch 1725/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 8.6964e-06 - val_loss: 1.7780e-05\n",
            "Epoch 1726/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1094e-05 - val_loss: 2.8653e-06\n",
            "Epoch 1727/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.5518e-06 - val_loss: 6.7573e-06\n",
            "Epoch 1728/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.7224e-06 - val_loss: 1.5950e-05\n",
            "Epoch 1729/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 1.2687e-05 - val_loss: 1.0115e-05\n",
            "Epoch 1730/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 1.0837e-05 - val_loss: 7.0507e-06\n",
            "Epoch 1731/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 7.3080e-06 - val_loss: 1.4949e-05\n",
            "Epoch 1732/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 8.1526e-06 - val_loss: 8.5757e-06\n",
            "Epoch 1733/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 6.5030e-06 - val_loss: 2.7841e-06\n",
            "Epoch 1734/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 5.5381e-06 - val_loss: 3.7052e-06\n",
            "Epoch 1735/2000\n",
            "80/80 [==============================] - 0s 979us/step - loss: 9.4823e-06 - val_loss: 9.4339e-06\n",
            "Epoch 1736/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 5.8474e-06 - val_loss: 8.5801e-06\n",
            "Epoch 1737/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 1.3026e-05 - val_loss: 1.7513e-05\n",
            "Epoch 1738/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 1.6998e-05 - val_loss: 2.8285e-05\n",
            "Epoch 1739/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0092e-05 - val_loss: 6.4815e-06\n",
            "Epoch 1740/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 1.1401e-05 - val_loss: 3.9627e-06\n",
            "Epoch 1741/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 6.2633e-06 - val_loss: 5.6410e-06\n",
            "Epoch 1742/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 2.4684e-06 - val_loss: 3.3345e-06\n",
            "Epoch 1743/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 2.1954e-06 - val_loss: 7.0769e-06\n",
            "Epoch 1744/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 3.5609e-06 - val_loss: 4.0956e-06\n",
            "Epoch 1745/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 3.7754e-06 - val_loss: 4.6505e-06\n",
            "Epoch 1746/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 4.4224e-06 - val_loss: 4.7766e-06\n",
            "Epoch 1747/2000\n",
            "80/80 [==============================] - 0s 979us/step - loss: 4.0687e-06 - val_loss: 4.1703e-06\n",
            "Epoch 1748/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 5.2932e-06 - val_loss: 7.0906e-06\n",
            "Epoch 1749/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 1.0863e-05 - val_loss: 1.4250e-05\n",
            "Epoch 1750/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 9.7438e-06 - val_loss: 1.1062e-05\n",
            "Epoch 1751/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 9.8496e-06 - val_loss: 6.0560e-06\n",
            "Epoch 1752/2000\n",
            "80/80 [==============================] - 0s 979us/step - loss: 7.4762e-06 - val_loss: 7.3974e-06\n",
            "Epoch 1753/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 5.9423e-06 - val_loss: 1.2150e-05\n",
            "Epoch 1754/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 1.1727e-05 - val_loss: 1.9307e-05\n",
            "Epoch 1755/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 1.8621e-05 - val_loss: 1.2827e-05\n",
            "Epoch 1756/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 7.9716e-06 - val_loss: 7.0915e-06\n",
            "Epoch 1757/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.2173e-06 - val_loss: 5.3127e-06\n",
            "Epoch 1758/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 5.3172e-06 - val_loss: 7.6670e-06\n",
            "Epoch 1759/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 5.1092e-06 - val_loss: 1.2377e-05\n",
            "Epoch 1760/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 9.3387e-06 - val_loss: 1.6342e-05\n",
            "Epoch 1761/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 1.8398e-05 - val_loss: 1.9119e-05\n",
            "Epoch 1762/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 3.6191e-05 - val_loss: 3.0424e-05\n",
            "Epoch 1763/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.9502e-05 - val_loss: 2.5004e-05\n",
            "Epoch 1764/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 2.4716e-05 - val_loss: 1.6168e-05\n",
            "Epoch 1765/2000\n",
            "80/80 [==============================] - 0s 892us/step - loss: 3.7135e-05 - val_loss: 4.5762e-05\n",
            "Epoch 1766/2000\n",
            "80/80 [==============================] - 0s 867us/step - loss: 5.6274e-05 - val_loss: 1.4027e-05\n",
            "Epoch 1767/2000\n",
            "80/80 [==============================] - 0s 886us/step - loss: 1.9338e-05 - val_loss: 2.1335e-05\n",
            "Epoch 1768/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 1.3302e-05 - val_loss: 3.2226e-05\n",
            "Epoch 1769/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 1.6335e-05 - val_loss: 8.1739e-06\n",
            "Epoch 1770/2000\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 1.2016e-05 - val_loss: 1.0971e-05\n",
            "Epoch 1771/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 6.8429e-06 - val_loss: 1.0690e-05\n",
            "Epoch 1772/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 1.5783e-05 - val_loss: 1.4227e-05\n",
            "Epoch 1773/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 1.5445e-05 - val_loss: 1.7481e-05\n",
            "Epoch 1774/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.0328e-05 - val_loss: 2.0763e-05\n",
            "Epoch 1775/2000\n",
            "80/80 [==============================] - 0s 995us/step - loss: 7.4205e-05 - val_loss: 4.9241e-05\n",
            "Epoch 1776/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0327e-04 - val_loss: 8.3332e-05\n",
            "Epoch 1777/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 1.5205e-04 - val_loss: 2.3775e-04\n",
            "Epoch 1778/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 1.1163e-04 - val_loss: 9.5160e-05\n",
            "Epoch 1779/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 6.1092e-05 - val_loss: 4.2347e-05\n",
            "Epoch 1780/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.3685e-05 - val_loss: 2.0881e-05\n",
            "Epoch 1781/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 1.9545e-05 - val_loss: 2.1863e-05\n",
            "Epoch 1782/2000\n",
            "80/80 [==============================] - 0s 898us/step - loss: 2.5465e-05 - val_loss: 2.3974e-05\n",
            "Epoch 1783/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 2.4321e-05 - val_loss: 7.1929e-05\n",
            "Epoch 1784/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 6.3057e-05 - val_loss: 2.7204e-05\n",
            "Epoch 1785/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 5.2927e-05 - val_loss: 1.9570e-04\n",
            "Epoch 1786/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 1.1094e-04 - val_loss: 8.1087e-05\n",
            "Epoch 1787/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 9.4877e-05 - val_loss: 2.0890e-04\n",
            "Epoch 1788/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0619e-04 - val_loss: 1.1098e-04\n",
            "Epoch 1789/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 4.8411e-04 - val_loss: 0.0012\n",
            "Epoch 1790/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 9.3593e-04 - val_loss: 0.0016\n",
            "Epoch 1791/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 1792/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.5980e-04 - val_loss: 3.0994e-04\n",
            "Epoch 1793/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 3.2002e-04 - val_loss: 3.3325e-04\n",
            "Epoch 1794/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 3.6061e-04 - val_loss: 6.9529e-04\n",
            "Epoch 1795/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 3.0412e-04 - val_loss: 2.1395e-04\n",
            "Epoch 1796/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 2.7619e-04 - val_loss: 5.7105e-04\n",
            "Epoch 1797/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 8.5056e-04 - val_loss: 0.0010\n",
            "Epoch 1798/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 1799/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 8.1722e-04 - val_loss: 2.8506e-04\n",
            "Epoch 1800/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 4.6892e-04 - val_loss: 6.9297e-04\n",
            "Epoch 1801/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 4.7481e-04 - val_loss: 7.9453e-04\n",
            "Epoch 1802/2000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 4.0516e-04 - val_loss: 1.7204e-04\n",
            "Epoch 1803/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.3400e-04 - val_loss: 4.2307e-04\n",
            "Epoch 1804/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 3.8775e-04 - val_loss: 3.0171e-04\n",
            "Epoch 1805/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.6475e-04 - val_loss: 1.2018e-04\n",
            "Epoch 1806/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 1.4898e-04 - val_loss: 2.6260e-04\n",
            "Epoch 1807/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8423e-04 - val_loss: 6.1593e-04\n",
            "Epoch 1808/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.7509e-04 - val_loss: 7.3900e-04\n",
            "Epoch 1809/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.3757e-04 - val_loss: 0.0014\n",
            "Epoch 1810/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0028\n",
            "Epoch 1811/2000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 0.0047 - val_loss: 0.0084\n",
            "Epoch 1812/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0090\n",
            "Epoch 1813/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0070\n",
            "Epoch 1814/2000\n",
            "80/80 [==============================] - 0s 992us/step - loss: 0.0069 - val_loss: 0.0043\n",
            "Epoch 1815/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 0.0068 - val_loss: 0.0082\n",
            "Epoch 1816/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 0.0046 - val_loss: 0.0163\n",
            "Epoch 1817/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 0.0088 - val_loss: 0.0172\n",
            "Epoch 1818/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 0.0128 - val_loss: 0.0057\n",
            "Epoch 1819/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 0.0116 - val_loss: 0.0106\n",
            "Epoch 1820/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 0.0092 - val_loss: 0.0058\n",
            "Epoch 1821/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0033\n",
            "Epoch 1822/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 0.0048 - val_loss: 0.0016\n",
            "Epoch 1823/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 0.0044 - val_loss: 0.0027\n",
            "Epoch 1824/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 1825/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 0.0029 - val_loss: 0.0016\n",
            "Epoch 1826/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 1827/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 1828/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 0.0017 - val_loss: 0.0046\n",
            "Epoch 1829/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 0.0019 - val_loss: 0.0040\n",
            "Epoch 1830/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 0.0020 - val_loss: 0.0032\n",
            "Epoch 1831/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 1832/2000\n",
            "80/80 [==============================] - 0s 996us/step - loss: 0.0016 - val_loss: 0.0013\n",
            "Epoch 1833/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0011\n",
            "Epoch 1834/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 0.0014 - val_loss: 0.0015\n",
            "Epoch 1835/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.5380e-04 - val_loss: 4.1998e-04\n",
            "Epoch 1836/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 5.9697e-04 - val_loss: 1.7769e-04\n",
            "Epoch 1837/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.5456e-04 - val_loss: 4.7945e-04\n",
            "Epoch 1838/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3141e-04 - val_loss: 2.0525e-04\n",
            "Epoch 1839/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8370e-04 - val_loss: 3.8450e-04\n",
            "Epoch 1840/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 1.9999e-04 - val_loss: 1.3138e-04\n",
            "Epoch 1841/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 3.1524e-04 - val_loss: 4.9825e-04\n",
            "Epoch 1842/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 3.0439e-04 - val_loss: 2.7233e-04\n",
            "Epoch 1843/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 2.8217e-04 - val_loss: 3.9142e-04\n",
            "Epoch 1844/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 2.0967e-04 - val_loss: 3.6174e-04\n",
            "Epoch 1845/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 2.9094e-04 - val_loss: 4.6980e-04\n",
            "Epoch 1846/2000\n",
            "80/80 [==============================] - 0s 996us/step - loss: 1.3394e-04 - val_loss: 1.0348e-04\n",
            "Epoch 1847/2000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 8.9179e-05 - val_loss: 1.8767e-04\n",
            "Epoch 1848/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 8.7704e-05 - val_loss: 7.6675e-05\n",
            "Epoch 1849/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 1.0067e-04 - val_loss: 1.0879e-04\n",
            "Epoch 1850/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.4281e-05 - val_loss: 4.4959e-05\n",
            "Epoch 1851/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 6.8826e-05 - val_loss: 1.2480e-04\n",
            "Epoch 1852/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.9185e-05 - val_loss: 3.4863e-05\n",
            "Epoch 1853/2000\n",
            "80/80 [==============================] - 0s 993us/step - loss: 4.4415e-05 - val_loss: 1.7112e-04\n",
            "Epoch 1854/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 4.4271e-05 - val_loss: 3.5504e-05\n",
            "Epoch 1855/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 3.5801e-05 - val_loss: 1.3993e-04\n",
            "Epoch 1856/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 4.4565e-05 - val_loss: 2.6583e-05\n",
            "Epoch 1857/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.3304e-05 - val_loss: 6.6841e-05\n",
            "Epoch 1858/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 1.9994e-05 - val_loss: 2.7240e-05\n",
            "Epoch 1859/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 3.6853e-05 - val_loss: 6.6594e-05\n",
            "Epoch 1860/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4801e-05 - val_loss: 3.0698e-05\n",
            "Epoch 1861/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 4.1742e-05 - val_loss: 1.9181e-05\n",
            "Epoch 1862/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 2.9788e-05 - val_loss: 5.7806e-05\n",
            "Epoch 1863/2000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 3.6803e-05 - val_loss: 2.3471e-05\n",
            "Epoch 1864/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.9904e-05 - val_loss: 7.5189e-05\n",
            "Epoch 1865/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 2.8633e-05 - val_loss: 2.4140e-05\n",
            "Epoch 1866/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 4.0509e-05 - val_loss: 1.2953e-04\n",
            "Epoch 1867/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 5.2792e-05 - val_loss: 1.0522e-04\n",
            "Epoch 1868/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 6.0741e-05 - val_loss: 1.6271e-04\n",
            "Epoch 1869/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 6.7362e-05 - val_loss: 5.1732e-05\n",
            "Epoch 1870/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 7.0336e-05 - val_loss: 1.5395e-04\n",
            "Epoch 1871/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 8.4903e-05 - val_loss: 4.9590e-05\n",
            "Epoch 1872/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 7.8481e-05 - val_loss: 4.5286e-05\n",
            "Epoch 1873/2000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 5.9536e-05 - val_loss: 2.5253e-05\n",
            "Epoch 1874/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 5.0260e-05 - val_loss: 3.2963e-05\n",
            "Epoch 1875/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 4.9413e-05 - val_loss: 5.5926e-05\n",
            "Epoch 1876/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 3.7089e-05 - val_loss: 2.7161e-05\n",
            "Epoch 1877/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 3.1805e-05 - val_loss: 4.9978e-05\n",
            "Epoch 1878/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 2.1877e-05 - val_loss: 1.8740e-05\n",
            "Epoch 1879/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4448e-05 - val_loss: 3.9020e-05\n",
            "Epoch 1880/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 1.0712e-05 - val_loss: 1.6298e-05\n",
            "Epoch 1881/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 1.3258e-05 - val_loss: 3.6548e-05\n",
            "Epoch 1882/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 1.0373e-05 - val_loss: 1.6024e-05\n",
            "Epoch 1883/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 1.6683e-05 - val_loss: 5.0853e-05\n",
            "Epoch 1884/2000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 1.8741e-05 - val_loss: 2.2688e-05\n",
            "Epoch 1885/2000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 1.2562e-05 - val_loss: 2.2411e-05\n",
            "Epoch 1886/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1972e-05 - val_loss: 1.6819e-05\n",
            "Epoch 1887/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 1.1836e-05 - val_loss: 2.7315e-05\n",
            "Epoch 1888/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 8.8913e-06 - val_loss: 2.0418e-05\n",
            "Epoch 1889/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 1.2400e-05 - val_loss: 2.0275e-05\n",
            "Epoch 1890/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 1.1593e-05 - val_loss: 2.6680e-05\n",
            "Epoch 1891/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1935e-05 - val_loss: 1.3982e-05\n",
            "Epoch 1892/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 1.1204e-05 - val_loss: 3.6933e-05\n",
            "Epoch 1893/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 9.8353e-06 - val_loss: 1.6210e-05\n",
            "Epoch 1894/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 8.7770e-06 - val_loss: 2.5285e-05\n",
            "Epoch 1895/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 7.6960e-06 - val_loss: 1.4293e-05\n",
            "Epoch 1896/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 1.0028e-05 - val_loss: 1.7594e-05\n",
            "Epoch 1897/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 8.5560e-06 - val_loss: 2.5840e-05\n",
            "Epoch 1898/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2006e-05 - val_loss: 1.4265e-05\n",
            "Epoch 1899/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0964e-05 - val_loss: 3.8269e-05\n",
            "Epoch 1900/2000\n",
            "80/80 [==============================] - 0s 992us/step - loss: 1.3048e-05 - val_loss: 1.2635e-05\n",
            "Epoch 1901/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 7.4639e-06 - val_loss: 2.5804e-05\n",
            "Epoch 1902/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 6.9902e-06 - val_loss: 1.8859e-05\n",
            "Epoch 1903/2000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 6.8443e-06 - val_loss: 2.3622e-05\n",
            "Epoch 1904/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 7.5031e-06 - val_loss: 1.6599e-05\n",
            "Epoch 1905/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 7.4490e-06 - val_loss: 2.2400e-05\n",
            "Epoch 1906/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 6.0429e-06 - val_loss: 1.2697e-05\n",
            "Epoch 1907/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 7.1771e-06 - val_loss: 2.2681e-05\n",
            "Epoch 1908/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 7.5842e-06 - val_loss: 1.8175e-05\n",
            "Epoch 1909/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 6.2000e-06 - val_loss: 2.5875e-05\n",
            "Epoch 1910/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 9.1276e-06 - val_loss: 2.1457e-05\n",
            "Epoch 1911/2000\n",
            "80/80 [==============================] - 0s 989us/step - loss: 6.5590e-06 - val_loss: 1.4631e-05\n",
            "Epoch 1912/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 6.1553e-06 - val_loss: 1.3422e-05\n",
            "Epoch 1913/2000\n",
            "80/80 [==============================] - 0s 995us/step - loss: 6.6342e-06 - val_loss: 1.9506e-05\n",
            "Epoch 1914/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.8261e-06 - val_loss: 1.6275e-05\n",
            "Epoch 1915/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.7806e-06 - val_loss: 1.4832e-05\n",
            "Epoch 1916/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.0638e-06 - val_loss: 2.4994e-05\n",
            "Epoch 1917/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 6.6322e-06 - val_loss: 1.2441e-05\n",
            "Epoch 1918/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 5.7289e-06 - val_loss: 3.0699e-05\n",
            "Epoch 1919/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 8.8565e-06 - val_loss: 1.3351e-05\n",
            "Epoch 1920/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 6.1503e-06 - val_loss: 2.1843e-05\n",
            "Epoch 1921/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 6.8086e-06 - val_loss: 1.8723e-05\n",
            "Epoch 1922/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 7.1772e-06 - val_loss: 1.0572e-05\n",
            "Epoch 1923/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 6.2884e-06 - val_loss: 2.4078e-05\n",
            "Epoch 1924/2000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 6.5560e-06 - val_loss: 1.4775e-05\n",
            "Epoch 1925/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.4114e-06 - val_loss: 2.1874e-05\n",
            "Epoch 1926/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.1743e-06 - val_loss: 1.3754e-05\n",
            "Epoch 1927/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 4.7802e-06 - val_loss: 2.4508e-05\n",
            "Epoch 1928/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 6.0772e-06 - val_loss: 1.1317e-05\n",
            "Epoch 1929/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 5.7448e-06 - val_loss: 1.4880e-05\n",
            "Epoch 1930/2000\n",
            "80/80 [==============================] - 0s 870us/step - loss: 4.5119e-06 - val_loss: 1.2743e-05\n",
            "Epoch 1931/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.5172e-06 - val_loss: 1.8264e-05\n",
            "Epoch 1932/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 4.8408e-06 - val_loss: 1.6100e-05\n",
            "Epoch 1933/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.6214e-06 - val_loss: 1.5359e-05\n",
            "Epoch 1934/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.8122e-06 - val_loss: 1.4100e-05\n",
            "Epoch 1935/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 4.8275e-06 - val_loss: 1.0971e-05\n",
            "Epoch 1936/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 4.5960e-06 - val_loss: 1.7328e-05\n",
            "Epoch 1937/2000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 4.6772e-06 - val_loss: 1.4208e-05\n",
            "Epoch 1938/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 4.1260e-06 - val_loss: 1.6683e-05\n",
            "Epoch 1939/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 4.3096e-06 - val_loss: 1.1937e-05\n",
            "Epoch 1940/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 3.8473e-06 - val_loss: 1.7694e-05\n",
            "Epoch 1941/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 4.6852e-06 - val_loss: 8.9122e-06\n",
            "Epoch 1942/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 6.7756e-06 - val_loss: 2.4303e-05\n",
            "Epoch 1943/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 7.1504e-06 - val_loss: 1.1773e-05\n",
            "Epoch 1944/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 5.9516e-06 - val_loss: 1.8510e-05\n",
            "Epoch 1945/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 6.0090e-06 - val_loss: 1.5784e-05\n",
            "Epoch 1946/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 6.1076e-06 - val_loss: 9.1245e-06\n",
            "Epoch 1947/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 6.3984e-06 - val_loss: 2.6236e-05\n",
            "Epoch 1948/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 7.2797e-06 - val_loss: 1.1833e-05\n",
            "Epoch 1949/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 6.3660e-06 - val_loss: 1.1155e-05\n",
            "Epoch 1950/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.9038e-06 - val_loss: 2.2583e-05\n",
            "Epoch 1951/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 6.7587e-06 - val_loss: 8.9754e-06\n",
            "Epoch 1952/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 7.8001e-06 - val_loss: 2.0949e-05\n",
            "Epoch 1953/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 5.4719e-06 - val_loss: 9.4792e-06\n",
            "Epoch 1954/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 7.1362e-06 - val_loss: 1.0288e-05\n",
            "Epoch 1955/2000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 9.1208e-06 - val_loss: 2.9503e-05\n",
            "Epoch 1956/2000\n",
            "80/80 [==============================] - 0s 891us/step - loss: 8.2089e-06 - val_loss: 9.0014e-06\n",
            "Epoch 1957/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.7494e-06 - val_loss: 2.6154e-05\n",
            "Epoch 1958/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.3432e-06 - val_loss: 1.0005e-05\n",
            "Epoch 1959/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 5.2742e-06 - val_loss: 1.1304e-05\n",
            "Epoch 1960/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 6.4653e-06 - val_loss: 2.9936e-05\n",
            "Epoch 1961/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 7.7819e-06 - val_loss: 8.9404e-06\n",
            "Epoch 1962/2000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 5.6489e-06 - val_loss: 1.4260e-05\n",
            "Epoch 1963/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 4.3521e-06 - val_loss: 1.3934e-05\n",
            "Epoch 1964/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.5813e-06 - val_loss: 8.2417e-06\n",
            "Epoch 1965/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 7.5176e-06 - val_loss: 1.9360e-05\n",
            "Epoch 1966/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 3.6026e-06 - val_loss: 8.6457e-06\n",
            "Epoch 1967/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 6.2689e-06 - val_loss: 1.3170e-05\n",
            "Epoch 1968/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 6.1973e-06 - val_loss: 8.5570e-06\n",
            "Epoch 1969/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 6.8079e-06 - val_loss: 1.2136e-05\n",
            "Epoch 1970/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 4.3220e-06 - val_loss: 2.6002e-05\n",
            "Epoch 1971/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 6.1433e-06 - val_loss: 1.0573e-05\n",
            "Epoch 1972/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 7.4948e-06 - val_loss: 2.8347e-05\n",
            "Epoch 1973/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 1.1526e-05 - val_loss: 1.2572e-05\n",
            "Epoch 1974/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1419e-05 - val_loss: 8.4814e-06\n",
            "Epoch 1975/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.1013e-06 - val_loss: 3.4036e-05\n",
            "Epoch 1976/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 1.0807e-05 - val_loss: 1.4608e-05\n",
            "Epoch 1977/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 9.1484e-06 - val_loss: 3.3217e-05\n",
            "Epoch 1978/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0207e-05 - val_loss: 8.9960e-06\n",
            "Epoch 1979/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.3580e-06 - val_loss: 7.7594e-06\n",
            "Epoch 1980/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 5.7828e-06 - val_loss: 1.8952e-05\n",
            "Epoch 1981/2000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 8.3372e-06 - val_loss: 1.1375e-05\n",
            "Epoch 1982/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 3.4916e-06 - val_loss: 1.5491e-05\n",
            "Epoch 1983/2000\n",
            "80/80 [==============================] - 0s 892us/step - loss: 6.9214e-06 - val_loss: 1.5569e-05\n",
            "Epoch 1984/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 5.6065e-06 - val_loss: 1.1217e-05\n",
            "Epoch 1985/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 5.2146e-06 - val_loss: 1.4849e-05\n",
            "Epoch 1986/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 6.9106e-06 - val_loss: 1.5627e-05\n",
            "Epoch 1987/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 5.9149e-06 - val_loss: 8.0703e-06\n",
            "Epoch 1988/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.6027e-06 - val_loss: 1.7950e-05\n",
            "Epoch 1989/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 4.4413e-06 - val_loss: 9.9268e-06\n",
            "Epoch 1990/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 9.7892e-06 - val_loss: 1.7340e-05\n",
            "Epoch 1991/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 7.9411e-06 - val_loss: 1.5042e-05\n",
            "Epoch 1992/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 1.2418e-05 - val_loss: 9.8191e-06\n",
            "Epoch 1993/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 1.2868e-05 - val_loss: 2.9260e-05\n",
            "Epoch 1994/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 1.3361e-05 - val_loss: 8.5992e-06\n",
            "Epoch 1995/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 9.4820e-06 - val_loss: 7.5775e-06\n",
            "Epoch 1996/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 5.8736e-06 - val_loss: 2.5632e-05\n",
            "Epoch 1997/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 5.4075e-06 - val_loss: 1.0047e-05\n",
            "Epoch 1998/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 7.8960e-06 - val_loss: 2.9247e-05\n",
            "Epoch 1999/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.4951e-06 - val_loss: 7.8127e-06\n",
            "Epoch 2000/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.4091e-06 - val_loss: 1.3778e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCh_x4H_kzmc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "08359379-d348-4347-c2eb-3f83f8fef142"
      },
      "source": [
        "results = model.predict(x_test)\n",
        "results.shape\n",
        "y_test.shape\n",
        "plt.scatter(range(20),results,c='r')\n",
        "plt.scatter(range(20),y_test,c='g')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFlAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOdzNzBLkcDczS9D/B8wBB8WzKBH8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGUO1yHzll4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}