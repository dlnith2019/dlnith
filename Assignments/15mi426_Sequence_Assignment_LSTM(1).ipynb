{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15mi426 Sequence_Assignment_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUgRJd-JwE7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN, LSTM , Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlDC4VYCBRHh",
        "colab_type": "code",
        "outputId": "13b6ff24-20aa-4387-b6c2-0ef9ebd9ed4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "X = [[[(3**i)+j] for i in range (5)] for j in range(100)]\n",
        "print (X)\n",
        "Y = [(243+3*i) for i in range(100)]\n",
        "print (Y)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[1], [3], [9], [27], [81]], [[2], [4], [10], [28], [82]], [[3], [5], [11], [29], [83]], [[4], [6], [12], [30], [84]], [[5], [7], [13], [31], [85]], [[6], [8], [14], [32], [86]], [[7], [9], [15], [33], [87]], [[8], [10], [16], [34], [88]], [[9], [11], [17], [35], [89]], [[10], [12], [18], [36], [90]], [[11], [13], [19], [37], [91]], [[12], [14], [20], [38], [92]], [[13], [15], [21], [39], [93]], [[14], [16], [22], [40], [94]], [[15], [17], [23], [41], [95]], [[16], [18], [24], [42], [96]], [[17], [19], [25], [43], [97]], [[18], [20], [26], [44], [98]], [[19], [21], [27], [45], [99]], [[20], [22], [28], [46], [100]], [[21], [23], [29], [47], [101]], [[22], [24], [30], [48], [102]], [[23], [25], [31], [49], [103]], [[24], [26], [32], [50], [104]], [[25], [27], [33], [51], [105]], [[26], [28], [34], [52], [106]], [[27], [29], [35], [53], [107]], [[28], [30], [36], [54], [108]], [[29], [31], [37], [55], [109]], [[30], [32], [38], [56], [110]], [[31], [33], [39], [57], [111]], [[32], [34], [40], [58], [112]], [[33], [35], [41], [59], [113]], [[34], [36], [42], [60], [114]], [[35], [37], [43], [61], [115]], [[36], [38], [44], [62], [116]], [[37], [39], [45], [63], [117]], [[38], [40], [46], [64], [118]], [[39], [41], [47], [65], [119]], [[40], [42], [48], [66], [120]], [[41], [43], [49], [67], [121]], [[42], [44], [50], [68], [122]], [[43], [45], [51], [69], [123]], [[44], [46], [52], [70], [124]], [[45], [47], [53], [71], [125]], [[46], [48], [54], [72], [126]], [[47], [49], [55], [73], [127]], [[48], [50], [56], [74], [128]], [[49], [51], [57], [75], [129]], [[50], [52], [58], [76], [130]], [[51], [53], [59], [77], [131]], [[52], [54], [60], [78], [132]], [[53], [55], [61], [79], [133]], [[54], [56], [62], [80], [134]], [[55], [57], [63], [81], [135]], [[56], [58], [64], [82], [136]], [[57], [59], [65], [83], [137]], [[58], [60], [66], [84], [138]], [[59], [61], [67], [85], [139]], [[60], [62], [68], [86], [140]], [[61], [63], [69], [87], [141]], [[62], [64], [70], [88], [142]], [[63], [65], [71], [89], [143]], [[64], [66], [72], [90], [144]], [[65], [67], [73], [91], [145]], [[66], [68], [74], [92], [146]], [[67], [69], [75], [93], [147]], [[68], [70], [76], [94], [148]], [[69], [71], [77], [95], [149]], [[70], [72], [78], [96], [150]], [[71], [73], [79], [97], [151]], [[72], [74], [80], [98], [152]], [[73], [75], [81], [99], [153]], [[74], [76], [82], [100], [154]], [[75], [77], [83], [101], [155]], [[76], [78], [84], [102], [156]], [[77], [79], [85], [103], [157]], [[78], [80], [86], [104], [158]], [[79], [81], [87], [105], [159]], [[80], [82], [88], [106], [160]], [[81], [83], [89], [107], [161]], [[82], [84], [90], [108], [162]], [[83], [85], [91], [109], [163]], [[84], [86], [92], [110], [164]], [[85], [87], [93], [111], [165]], [[86], [88], [94], [112], [166]], [[87], [89], [95], [113], [167]], [[88], [90], [96], [114], [168]], [[89], [91], [97], [115], [169]], [[90], [92], [98], [116], [170]], [[91], [93], [99], [117], [171]], [[92], [94], [100], [118], [172]], [[93], [95], [101], [119], [173]], [[94], [96], [102], [120], [174]], [[95], [97], [103], [121], [175]], [[96], [98], [104], [122], [176]], [[97], [99], [105], [123], [177]], [[98], [100], [106], [124], [178]], [[99], [101], [107], [125], [179]], [[100], [102], [108], [126], [180]]]\n",
            "[243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309, 312, 315, 318, 321, 324, 327, 330, 333, 336, 339, 342, 345, 348, 351, 354, 357, 360, 363, 366, 369, 372, 375, 378, 381, 384, 387, 390, 393, 396, 399, 402, 405, 408, 411, 414, 417, 420, 423, 426, 429, 432, 435, 438, 441, 444, 447, 450, 453, 456, 459, 462, 465, 468, 471, 474, 477, 480, 483, 486, 489, 492, 495, 498, 501, 504, 507, 510, 513, 516, 519, 522, 525, 528, 531, 534, 537, 540]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKAoQeqSzFwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(X, dtype=\"float32\")\n",
        "Y = np.array(Y, dtype=\"float32\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nujWp20Edh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X /= 500\n",
        "Y /= 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdO2WW63Ejxv",
        "colab_type": "code",
        "outputId": "ae24f1c9-3056-49bb-eed9-c3cc06d13b79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaWPaPenEnV5",
        "colab_type": "code",
        "outputId": "364bb3e9-4ae0-4c34-9686-e7b4a24a1590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hFVg98QErgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2, \n",
        "                                                random_state=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtU_BMZEEu8E",
        "colab_type": "code",
        "outputId": "93ec0e20-d1f4-4455-957b-86faca72277a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.19 ],\n",
              "        [0.194],\n",
              "        [0.206],\n",
              "        [0.242],\n",
              "        [0.35 ]],\n",
              "\n",
              "       [[0.114],\n",
              "        [0.118],\n",
              "        [0.13 ],\n",
              "        [0.166],\n",
              "        [0.274]],\n",
              "\n",
              "       [[0.046],\n",
              "        [0.05 ],\n",
              "        [0.062],\n",
              "        [0.098],\n",
              "        [0.206]],\n",
              "\n",
              "       [[0.08 ],\n",
              "        [0.084],\n",
              "        [0.096],\n",
              "        [0.132],\n",
              "        [0.24 ]],\n",
              "\n",
              "       [[0.05 ],\n",
              "        [0.054],\n",
              "        [0.066],\n",
              "        [0.102],\n",
              "        [0.21 ]],\n",
              "\n",
              "       [[0.028],\n",
              "        [0.032],\n",
              "        [0.044],\n",
              "        [0.08 ],\n",
              "        [0.188]],\n",
              "\n",
              "       [[0.128],\n",
              "        [0.132],\n",
              "        [0.144],\n",
              "        [0.18 ],\n",
              "        [0.288]],\n",
              "\n",
              "       [[0.144],\n",
              "        [0.148],\n",
              "        [0.16 ],\n",
              "        [0.196],\n",
              "        [0.304]],\n",
              "\n",
              "       [[0.112],\n",
              "        [0.116],\n",
              "        [0.128],\n",
              "        [0.164],\n",
              "        [0.272]],\n",
              "\n",
              "       [[0.176],\n",
              "        [0.18 ],\n",
              "        [0.192],\n",
              "        [0.228],\n",
              "        [0.336]],\n",
              "\n",
              "       [[0.014],\n",
              "        [0.018],\n",
              "        [0.03 ],\n",
              "        [0.066],\n",
              "        [0.174]],\n",
              "\n",
              "       [[0.178],\n",
              "        [0.182],\n",
              "        [0.194],\n",
              "        [0.23 ],\n",
              "        [0.338]],\n",
              "\n",
              "       [[0.13 ],\n",
              "        [0.134],\n",
              "        [0.146],\n",
              "        [0.182],\n",
              "        [0.29 ]],\n",
              "\n",
              "       [[0.054],\n",
              "        [0.058],\n",
              "        [0.07 ],\n",
              "        [0.106],\n",
              "        [0.214]],\n",
              "\n",
              "       [[0.098],\n",
              "        [0.102],\n",
              "        [0.114],\n",
              "        [0.15 ],\n",
              "        [0.258]],\n",
              "\n",
              "       [[0.102],\n",
              "        [0.106],\n",
              "        [0.118],\n",
              "        [0.154],\n",
              "        [0.262]],\n",
              "\n",
              "       [[0.146],\n",
              "        [0.15 ],\n",
              "        [0.162],\n",
              "        [0.198],\n",
              "        [0.306]],\n",
              "\n",
              "       [[0.11 ],\n",
              "        [0.114],\n",
              "        [0.126],\n",
              "        [0.162],\n",
              "        [0.27 ]],\n",
              "\n",
              "       [[0.044],\n",
              "        [0.048],\n",
              "        [0.06 ],\n",
              "        [0.096],\n",
              "        [0.204]],\n",
              "\n",
              "       [[0.052],\n",
              "        [0.056],\n",
              "        [0.068],\n",
              "        [0.104],\n",
              "        [0.212]],\n",
              "\n",
              "       [[0.068],\n",
              "        [0.072],\n",
              "        [0.084],\n",
              "        [0.12 ],\n",
              "        [0.228]],\n",
              "\n",
              "       [[0.06 ],\n",
              "        [0.064],\n",
              "        [0.076],\n",
              "        [0.112],\n",
              "        [0.22 ]],\n",
              "\n",
              "       [[0.106],\n",
              "        [0.11 ],\n",
              "        [0.122],\n",
              "        [0.158],\n",
              "        [0.266]],\n",
              "\n",
              "       [[0.03 ],\n",
              "        [0.034],\n",
              "        [0.046],\n",
              "        [0.082],\n",
              "        [0.19 ]],\n",
              "\n",
              "       [[0.172],\n",
              "        [0.176],\n",
              "        [0.188],\n",
              "        [0.224],\n",
              "        [0.332]],\n",
              "\n",
              "       [[0.16 ],\n",
              "        [0.164],\n",
              "        [0.176],\n",
              "        [0.212],\n",
              "        [0.32 ]],\n",
              "\n",
              "       [[0.192],\n",
              "        [0.196],\n",
              "        [0.208],\n",
              "        [0.244],\n",
              "        [0.352]],\n",
              "\n",
              "       [[0.008],\n",
              "        [0.012],\n",
              "        [0.024],\n",
              "        [0.06 ],\n",
              "        [0.168]],\n",
              "\n",
              "       [[0.088],\n",
              "        [0.092],\n",
              "        [0.104],\n",
              "        [0.14 ],\n",
              "        [0.248]],\n",
              "\n",
              "       [[0.024],\n",
              "        [0.028],\n",
              "        [0.04 ],\n",
              "        [0.076],\n",
              "        [0.184]],\n",
              "\n",
              "       [[0.198],\n",
              "        [0.202],\n",
              "        [0.214],\n",
              "        [0.25 ],\n",
              "        [0.358]],\n",
              "\n",
              "       [[0.092],\n",
              "        [0.096],\n",
              "        [0.108],\n",
              "        [0.144],\n",
              "        [0.252]],\n",
              "\n",
              "       [[0.168],\n",
              "        [0.172],\n",
              "        [0.184],\n",
              "        [0.22 ],\n",
              "        [0.328]],\n",
              "\n",
              "       [[0.136],\n",
              "        [0.14 ],\n",
              "        [0.152],\n",
              "        [0.188],\n",
              "        [0.296]],\n",
              "\n",
              "       [[0.18 ],\n",
              "        [0.184],\n",
              "        [0.196],\n",
              "        [0.232],\n",
              "        [0.34 ]],\n",
              "\n",
              "       [[0.174],\n",
              "        [0.178],\n",
              "        [0.19 ],\n",
              "        [0.226],\n",
              "        [0.334]],\n",
              "\n",
              "       [[0.1  ],\n",
              "        [0.104],\n",
              "        [0.116],\n",
              "        [0.152],\n",
              "        [0.26 ]],\n",
              "\n",
              "       [[0.166],\n",
              "        [0.17 ],\n",
              "        [0.182],\n",
              "        [0.218],\n",
              "        [0.326]],\n",
              "\n",
              "       [[0.12 ],\n",
              "        [0.124],\n",
              "        [0.136],\n",
              "        [0.172],\n",
              "        [0.28 ]],\n",
              "\n",
              "       [[0.04 ],\n",
              "        [0.044],\n",
              "        [0.056],\n",
              "        [0.092],\n",
              "        [0.2  ]],\n",
              "\n",
              "       [[0.164],\n",
              "        [0.168],\n",
              "        [0.18 ],\n",
              "        [0.216],\n",
              "        [0.324]],\n",
              "\n",
              "       [[0.078],\n",
              "        [0.082],\n",
              "        [0.094],\n",
              "        [0.13 ],\n",
              "        [0.238]],\n",
              "\n",
              "       [[0.138],\n",
              "        [0.142],\n",
              "        [0.154],\n",
              "        [0.19 ],\n",
              "        [0.298]],\n",
              "\n",
              "       [[0.006],\n",
              "        [0.01 ],\n",
              "        [0.022],\n",
              "        [0.058],\n",
              "        [0.166]],\n",
              "\n",
              "       [[0.064],\n",
              "        [0.068],\n",
              "        [0.08 ],\n",
              "        [0.116],\n",
              "        [0.224]],\n",
              "\n",
              "       [[0.17 ],\n",
              "        [0.174],\n",
              "        [0.186],\n",
              "        [0.222],\n",
              "        [0.33 ]],\n",
              "\n",
              "       [[0.104],\n",
              "        [0.108],\n",
              "        [0.12 ],\n",
              "        [0.156],\n",
              "        [0.264]],\n",
              "\n",
              "       [[0.074],\n",
              "        [0.078],\n",
              "        [0.09 ],\n",
              "        [0.126],\n",
              "        [0.234]],\n",
              "\n",
              "       [[0.01 ],\n",
              "        [0.014],\n",
              "        [0.026],\n",
              "        [0.062],\n",
              "        [0.17 ]],\n",
              "\n",
              "       [[0.002],\n",
              "        [0.006],\n",
              "        [0.018],\n",
              "        [0.054],\n",
              "        [0.162]],\n",
              "\n",
              "       [[0.118],\n",
              "        [0.122],\n",
              "        [0.134],\n",
              "        [0.17 ],\n",
              "        [0.278]],\n",
              "\n",
              "       [[0.012],\n",
              "        [0.016],\n",
              "        [0.028],\n",
              "        [0.064],\n",
              "        [0.172]],\n",
              "\n",
              "       [[0.194],\n",
              "        [0.198],\n",
              "        [0.21 ],\n",
              "        [0.246],\n",
              "        [0.354]],\n",
              "\n",
              "       [[0.004],\n",
              "        [0.008],\n",
              "        [0.02 ],\n",
              "        [0.056],\n",
              "        [0.164]],\n",
              "\n",
              "       [[0.188],\n",
              "        [0.192],\n",
              "        [0.204],\n",
              "        [0.24 ],\n",
              "        [0.348]],\n",
              "\n",
              "       [[0.084],\n",
              "        [0.088],\n",
              "        [0.1  ],\n",
              "        [0.136],\n",
              "        [0.244]],\n",
              "\n",
              "       [[0.02 ],\n",
              "        [0.024],\n",
              "        [0.036],\n",
              "        [0.072],\n",
              "        [0.18 ]],\n",
              "\n",
              "       [[0.038],\n",
              "        [0.042],\n",
              "        [0.054],\n",
              "        [0.09 ],\n",
              "        [0.198]],\n",
              "\n",
              "       [[0.184],\n",
              "        [0.188],\n",
              "        [0.2  ],\n",
              "        [0.236],\n",
              "        [0.344]],\n",
              "\n",
              "       [[0.096],\n",
              "        [0.1  ],\n",
              "        [0.112],\n",
              "        [0.148],\n",
              "        [0.256]],\n",
              "\n",
              "       [[0.132],\n",
              "        [0.136],\n",
              "        [0.148],\n",
              "        [0.184],\n",
              "        [0.292]],\n",
              "\n",
              "       [[0.152],\n",
              "        [0.156],\n",
              "        [0.168],\n",
              "        [0.204],\n",
              "        [0.312]],\n",
              "\n",
              "       [[0.156],\n",
              "        [0.16 ],\n",
              "        [0.172],\n",
              "        [0.208],\n",
              "        [0.316]],\n",
              "\n",
              "       [[0.09 ],\n",
              "        [0.094],\n",
              "        [0.106],\n",
              "        [0.142],\n",
              "        [0.25 ]],\n",
              "\n",
              "       [[0.186],\n",
              "        [0.19 ],\n",
              "        [0.202],\n",
              "        [0.238],\n",
              "        [0.346]],\n",
              "\n",
              "       [[0.182],\n",
              "        [0.186],\n",
              "        [0.198],\n",
              "        [0.234],\n",
              "        [0.342]],\n",
              "\n",
              "       [[0.108],\n",
              "        [0.112],\n",
              "        [0.124],\n",
              "        [0.16 ],\n",
              "        [0.268]],\n",
              "\n",
              "       [[0.032],\n",
              "        [0.036],\n",
              "        [0.048],\n",
              "        [0.084],\n",
              "        [0.192]],\n",
              "\n",
              "       [[0.154],\n",
              "        [0.158],\n",
              "        [0.17 ],\n",
              "        [0.206],\n",
              "        [0.314]],\n",
              "\n",
              "       [[0.016],\n",
              "        [0.02 ],\n",
              "        [0.032],\n",
              "        [0.068],\n",
              "        [0.176]],\n",
              "\n",
              "       [[0.162],\n",
              "        [0.166],\n",
              "        [0.178],\n",
              "        [0.214],\n",
              "        [0.322]],\n",
              "\n",
              "       [[0.062],\n",
              "        [0.066],\n",
              "        [0.078],\n",
              "        [0.114],\n",
              "        [0.222]],\n",
              "\n",
              "       [[0.056],\n",
              "        [0.06 ],\n",
              "        [0.072],\n",
              "        [0.108],\n",
              "        [0.216]],\n",
              "\n",
              "       [[0.126],\n",
              "        [0.13 ],\n",
              "        [0.142],\n",
              "        [0.178],\n",
              "        [0.286]],\n",
              "\n",
              "       [[0.018],\n",
              "        [0.022],\n",
              "        [0.034],\n",
              "        [0.07 ],\n",
              "        [0.178]],\n",
              "\n",
              "       [[0.148],\n",
              "        [0.152],\n",
              "        [0.164],\n",
              "        [0.2  ],\n",
              "        [0.308]],\n",
              "\n",
              "       [[0.034],\n",
              "        [0.038],\n",
              "        [0.05 ],\n",
              "        [0.086],\n",
              "        [0.194]],\n",
              "\n",
              "       [[0.124],\n",
              "        [0.128],\n",
              "        [0.14 ],\n",
              "        [0.176],\n",
              "        [0.284]],\n",
              "\n",
              "       [[0.158],\n",
              "        [0.162],\n",
              "        [0.174],\n",
              "        [0.21 ],\n",
              "        [0.318]],\n",
              "\n",
              "       [[0.2  ],\n",
              "        [0.204],\n",
              "        [0.216],\n",
              "        [0.252],\n",
              "        [0.36 ]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnZRd-9HEx43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import SimpleRNN,LSTM,Flatten\n",
        "model = Sequential()\n",
        "model.add(LSTM((2),input_shape=(5,1),return_sequences=True))\n",
        "model.add(LSTM((3),input_shape=(5,1),return_sequences=True))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1,activation='relu'))\n",
        "#model.compile(optimizer='adam',loss='mae',metrics=['acc'])\n",
        "model.compile(optimizer='adam',loss='mae',metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXNvNbarE3ll",
        "colab_type": "code",
        "outputId": "6f779171-4c71-4eca-d922-b44676e5f183",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_9 (LSTM)                (None, 5, 2)              32        \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 5, 3)              72        \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 16        \n",
            "=================================================================\n",
            "Total params: 120\n",
            "Trainable params: 120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wuc_THFUE7JL",
        "colab_type": "code",
        "outputId": "ec62fcb4-6808-462b-cc53-307bf7437961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hist = model.fit(X_train, y_train, epochs=1000, batch_size=64, validation_data=(X_test, y_test))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/1000\n",
            "80/80 [==============================] - 2s 25ms/step - loss: 0.7847 - acc: 0.0000e+00 - val_loss: 0.7356 - val_acc: 0.0000e+00\n",
            "Epoch 2/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.7798 - acc: 0.0000e+00 - val_loss: 0.7307 - val_acc: 0.0000e+00\n",
            "Epoch 3/1000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.7748 - acc: 0.0000e+00 - val_loss: 0.7257 - val_acc: 0.0000e+00\n",
            "Epoch 4/1000\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.7697 - acc: 0.0000e+00 - val_loss: 0.7205 - val_acc: 0.0000e+00\n",
            "Epoch 5/1000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 0.7645 - acc: 0.0000e+00 - val_loss: 0.7152 - val_acc: 0.0000e+00\n",
            "Epoch 6/1000\n",
            "80/80 [==============================] - 0s 253us/step - loss: 0.7592 - acc: 0.0000e+00 - val_loss: 0.7098 - val_acc: 0.0000e+00\n",
            "Epoch 7/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.7537 - acc: 0.0000e+00 - val_loss: 0.7043 - val_acc: 0.0000e+00\n",
            "Epoch 8/1000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.7481 - acc: 0.0000e+00 - val_loss: 0.6986 - val_acc: 0.0000e+00\n",
            "Epoch 9/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.7424 - acc: 0.0000e+00 - val_loss: 0.6927 - val_acc: 0.0000e+00\n",
            "Epoch 10/1000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.7365 - acc: 0.0000e+00 - val_loss: 0.6867 - val_acc: 0.0000e+00\n",
            "Epoch 11/1000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.7304 - acc: 0.0000e+00 - val_loss: 0.6805 - val_acc: 0.0000e+00\n",
            "Epoch 12/1000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.7242 - acc: 0.0000e+00 - val_loss: 0.6742 - val_acc: 0.0000e+00\n",
            "Epoch 13/1000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.7178 - acc: 0.0000e+00 - val_loss: 0.6676 - val_acc: 0.0000e+00\n",
            "Epoch 14/1000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.7111 - acc: 0.0000e+00 - val_loss: 0.6608 - val_acc: 0.0000e+00\n",
            "Epoch 15/1000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.7043 - acc: 0.0000e+00 - val_loss: 0.6538 - val_acc: 0.0000e+00\n",
            "Epoch 16/1000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.6972 - acc: 0.0000e+00 - val_loss: 0.6466 - val_acc: 0.0000e+00\n",
            "Epoch 17/1000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.6899 - acc: 0.0000e+00 - val_loss: 0.6391 - val_acc: 0.0000e+00\n",
            "Epoch 18/1000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.6824 - acc: 0.0000e+00 - val_loss: 0.6314 - val_acc: 0.0000e+00\n",
            "Epoch 19/1000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.6746 - acc: 0.0000e+00 - val_loss: 0.6234 - val_acc: 0.0000e+00\n",
            "Epoch 20/1000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.6665 - acc: 0.0000e+00 - val_loss: 0.6152 - val_acc: 0.0000e+00\n",
            "Epoch 21/1000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.6582 - acc: 0.0000e+00 - val_loss: 0.6066 - val_acc: 0.0000e+00\n",
            "Epoch 22/1000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.6495 - acc: 0.0000e+00 - val_loss: 0.5978 - val_acc: 0.0000e+00\n",
            "Epoch 23/1000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.6406 - acc: 0.0000e+00 - val_loss: 0.5886 - val_acc: 0.0000e+00\n",
            "Epoch 24/1000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.6313 - acc: 0.0000e+00 - val_loss: 0.5791 - val_acc: 0.0000e+00\n",
            "Epoch 25/1000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.6217 - acc: 0.0000e+00 - val_loss: 0.5692 - val_acc: 0.0000e+00\n",
            "Epoch 26/1000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.6117 - acc: 0.0000e+00 - val_loss: 0.5590 - val_acc: 0.0000e+00\n",
            "Epoch 27/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.6014 - acc: 0.0000e+00 - val_loss: 0.5484 - val_acc: 0.0000e+00\n",
            "Epoch 28/1000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.5906 - acc: 0.0000e+00 - val_loss: 0.5374 - val_acc: 0.0000e+00\n",
            "Epoch 29/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.5795 - acc: 0.0000e+00 - val_loss: 0.5260 - val_acc: 0.0000e+00\n",
            "Epoch 30/1000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.5680 - acc: 0.0000e+00 - val_loss: 0.5142 - val_acc: 0.0000e+00\n",
            "Epoch 31/1000\n",
            "80/80 [==============================] - 0s 259us/step - loss: 0.5560 - acc: 0.0000e+00 - val_loss: 0.5019 - val_acc: 0.0000e+00\n",
            "Epoch 32/1000\n",
            "80/80 [==============================] - 0s 254us/step - loss: 0.5435 - acc: 0.0000e+00 - val_loss: 0.4891 - val_acc: 0.0000e+00\n",
            "Epoch 33/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.5306 - acc: 0.0000e+00 - val_loss: 0.4758 - val_acc: 0.0000e+00\n",
            "Epoch 34/1000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.5171 - acc: 0.0000e+00 - val_loss: 0.4620 - val_acc: 0.0000e+00\n",
            "Epoch 35/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.5032 - acc: 0.0000e+00 - val_loss: 0.4477 - val_acc: 0.0000e+00\n",
            "Epoch 36/1000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.4887 - acc: 0.0000e+00 - val_loss: 0.4328 - val_acc: 0.0000e+00\n",
            "Epoch 37/1000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.4736 - acc: 0.0000e+00 - val_loss: 0.4173 - val_acc: 0.0000e+00\n",
            "Epoch 38/1000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.4579 - acc: 0.0000e+00 - val_loss: 0.4012 - val_acc: 0.0000e+00\n",
            "Epoch 39/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.4415 - acc: 0.0000e+00 - val_loss: 0.3845 - val_acc: 0.0000e+00\n",
            "Epoch 40/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.4246 - acc: 0.0000e+00 - val_loss: 0.3670 - val_acc: 0.0000e+00\n",
            "Epoch 41/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.4069 - acc: 0.0000e+00 - val_loss: 0.3489 - val_acc: 0.0000e+00\n",
            "Epoch 42/1000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.3885 - acc: 0.0000e+00 - val_loss: 0.3301 - val_acc: 0.0000e+00\n",
            "Epoch 43/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.3695 - acc: 0.0000e+00 - val_loss: 0.3104 - val_acc: 0.0000e+00\n",
            "Epoch 44/1000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.3496 - acc: 0.0000e+00 - val_loss: 0.2900 - val_acc: 0.0000e+00\n",
            "Epoch 45/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.3288 - acc: 0.0000e+00 - val_loss: 0.2688 - val_acc: 0.0000e+00\n",
            "Epoch 46/1000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.3073 - acc: 0.0000e+00 - val_loss: 0.2467 - val_acc: 0.0000e+00\n",
            "Epoch 47/1000\n",
            "80/80 [==============================] - 0s 364us/step - loss: 0.2849 - acc: 0.0000e+00 - val_loss: 0.2237 - val_acc: 0.0000e+00\n",
            "Epoch 48/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.2618 - acc: 0.0000e+00 - val_loss: 0.1998 - val_acc: 0.0000e+00\n",
            "Epoch 49/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.2406 - acc: 0.0000e+00 - val_loss: 0.1756 - val_acc: 0.0000e+00\n",
            "Epoch 50/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.2206 - acc: 0.0000e+00 - val_loss: 0.1548 - val_acc: 0.0000e+00\n",
            "Epoch 51/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.2028 - acc: 0.0000e+00 - val_loss: 0.1360 - val_acc: 0.0000e+00\n",
            "Epoch 52/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.1869 - acc: 0.0000e+00 - val_loss: 0.1210 - val_acc: 0.0000e+00\n",
            "Epoch 53/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.1730 - acc: 0.0000e+00 - val_loss: 0.1087 - val_acc: 0.0000e+00\n",
            "Epoch 54/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.1615 - acc: 0.0000e+00 - val_loss: 0.0993 - val_acc: 0.0000e+00\n",
            "Epoch 55/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.1521 - acc: 0.0000e+00 - val_loss: 0.0946 - val_acc: 0.0000e+00\n",
            "Epoch 56/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.1438 - acc: 0.0000e+00 - val_loss: 0.0945 - val_acc: 0.0000e+00\n",
            "Epoch 57/1000\n",
            "80/80 [==============================] - 0s 378us/step - loss: 0.1366 - acc: 0.0000e+00 - val_loss: 0.0975 - val_acc: 0.0000e+00\n",
            "Epoch 58/1000\n",
            "80/80 [==============================] - 0s 385us/step - loss: 0.1323 - acc: 0.0000e+00 - val_loss: 0.1024 - val_acc: 0.0000e+00\n",
            "Epoch 59/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.1289 - acc: 0.0000e+00 - val_loss: 0.1073 - val_acc: 0.0000e+00\n",
            "Epoch 60/1000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.1284 - acc: 0.0000e+00 - val_loss: 0.1117 - val_acc: 0.0000e+00\n",
            "Epoch 61/1000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.1286 - acc: 0.0000e+00 - val_loss: 0.1159 - val_acc: 0.0000e+00\n",
            "Epoch 62/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.1293 - acc: 0.0000e+00 - val_loss: 0.1196 - val_acc: 0.0000e+00\n",
            "Epoch 63/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.1298 - acc: 0.0000e+00 - val_loss: 0.1224 - val_acc: 0.0000e+00\n",
            "Epoch 64/1000\n",
            "80/80 [==============================] - 0s 474us/step - loss: 0.1306 - acc: 0.0000e+00 - val_loss: 0.1245 - val_acc: 0.0000e+00\n",
            "Epoch 65/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.1313 - acc: 0.0000e+00 - val_loss: 0.1258 - val_acc: 0.0000e+00\n",
            "Epoch 66/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.1316 - acc: 0.0000e+00 - val_loss: 0.1263 - val_acc: 0.0000e+00\n",
            "Epoch 67/1000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.1317 - acc: 0.0000e+00 - val_loss: 0.1261 - val_acc: 0.0000e+00\n",
            "Epoch 68/1000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.1315 - acc: 0.0000e+00 - val_loss: 0.1253 - val_acc: 0.0000e+00\n",
            "Epoch 69/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.1310 - acc: 0.0000e+00 - val_loss: 0.1240 - val_acc: 0.0000e+00\n",
            "Epoch 70/1000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.1303 - acc: 0.0000e+00 - val_loss: 0.1222 - val_acc: 0.0000e+00\n",
            "Epoch 71/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.1293 - acc: 0.0000e+00 - val_loss: 0.1198 - val_acc: 0.0000e+00\n",
            "Epoch 72/1000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.1285 - acc: 0.0000e+00 - val_loss: 0.1169 - val_acc: 0.0000e+00\n",
            "Epoch 73/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.1274 - acc: 0.0000e+00 - val_loss: 0.1142 - val_acc: 0.0000e+00\n",
            "Epoch 74/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.1266 - acc: 0.0000e+00 - val_loss: 0.1117 - val_acc: 0.0000e+00\n",
            "Epoch 75/1000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.1258 - acc: 0.0000e+00 - val_loss: 0.1095 - val_acc: 0.0000e+00\n",
            "Epoch 76/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.1250 - acc: 0.0000e+00 - val_loss: 0.1079 - val_acc: 0.0000e+00\n",
            "Epoch 77/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.1247 - acc: 0.0000e+00 - val_loss: 0.1063 - val_acc: 0.0000e+00\n",
            "Epoch 78/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.1243 - acc: 0.0000e+00 - val_loss: 0.1050 - val_acc: 0.0000e+00\n",
            "Epoch 79/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.1240 - acc: 0.0000e+00 - val_loss: 0.1039 - val_acc: 0.0000e+00\n",
            "Epoch 80/1000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.1237 - acc: 0.0000e+00 - val_loss: 0.1030 - val_acc: 0.0000e+00\n",
            "Epoch 81/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.1236 - acc: 0.0000e+00 - val_loss: 0.1023 - val_acc: 0.0000e+00\n",
            "Epoch 82/1000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.1233 - acc: 0.0000e+00 - val_loss: 0.1020 - val_acc: 0.0000e+00\n",
            "Epoch 83/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.1230 - acc: 0.0000e+00 - val_loss: 0.1019 - val_acc: 0.0000e+00\n",
            "Epoch 84/1000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.1227 - acc: 0.0000e+00 - val_loss: 0.1020 - val_acc: 0.0000e+00\n",
            "Epoch 85/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.1224 - acc: 0.0000e+00 - val_loss: 0.1024 - val_acc: 0.0000e+00\n",
            "Epoch 86/1000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 0.1219 - acc: 0.0000e+00 - val_loss: 0.1027 - val_acc: 0.0000e+00\n",
            "Epoch 87/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.1217 - acc: 0.0000e+00 - val_loss: 0.1031 - val_acc: 0.0000e+00\n",
            "Epoch 88/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.1213 - acc: 0.0000e+00 - val_loss: 0.1034 - val_acc: 0.0000e+00\n",
            "Epoch 89/1000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.1210 - acc: 0.0000e+00 - val_loss: 0.1038 - val_acc: 0.0000e+00\n",
            "Epoch 90/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.1207 - acc: 0.0000e+00 - val_loss: 0.1042 - val_acc: 0.0000e+00\n",
            "Epoch 91/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.1204 - acc: 0.0000e+00 - val_loss: 0.1048 - val_acc: 0.0000e+00\n",
            "Epoch 92/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.1205 - acc: 0.0000e+00 - val_loss: 0.1050 - val_acc: 0.0000e+00\n",
            "Epoch 93/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.1201 - acc: 0.0000e+00 - val_loss: 0.1043 - val_acc: 0.0000e+00\n",
            "Epoch 94/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.1195 - acc: 0.0000e+00 - val_loss: 0.1029 - val_acc: 0.0000e+00\n",
            "Epoch 95/1000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.1191 - acc: 0.0000e+00 - val_loss: 0.1014 - val_acc: 0.0000e+00\n",
            "Epoch 96/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.1186 - acc: 0.0000e+00 - val_loss: 0.1000 - val_acc: 0.0000e+00\n",
            "Epoch 97/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.1184 - acc: 0.0000e+00 - val_loss: 0.0986 - val_acc: 0.0000e+00\n",
            "Epoch 98/1000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.1182 - acc: 0.0000e+00 - val_loss: 0.0976 - val_acc: 0.0000e+00\n",
            "Epoch 99/1000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.1180 - acc: 0.0000e+00 - val_loss: 0.0967 - val_acc: 0.0000e+00\n",
            "Epoch 100/1000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.1178 - acc: 0.0000e+00 - val_loss: 0.0960 - val_acc: 0.0000e+00\n",
            "Epoch 101/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.1176 - acc: 0.0000e+00 - val_loss: 0.0956 - val_acc: 0.0000e+00\n",
            "Epoch 102/1000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.1172 - acc: 0.0000e+00 - val_loss: 0.0955 - val_acc: 0.0000e+00\n",
            "Epoch 103/1000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.1168 - acc: 0.0000e+00 - val_loss: 0.0958 - val_acc: 0.0000e+00\n",
            "Epoch 104/1000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.1162 - acc: 0.0000e+00 - val_loss: 0.0965 - val_acc: 0.0000e+00\n",
            "Epoch 105/1000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 0.1156 - acc: 0.0000e+00 - val_loss: 0.0974 - val_acc: 0.0000e+00\n",
            "Epoch 106/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.1151 - acc: 0.0000e+00 - val_loss: 0.0983 - val_acc: 0.0000e+00\n",
            "Epoch 107/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.1146 - acc: 0.0000e+00 - val_loss: 0.0990 - val_acc: 0.0000e+00\n",
            "Epoch 108/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.1144 - acc: 0.0000e+00 - val_loss: 0.0997 - val_acc: 0.0000e+00\n",
            "Epoch 109/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.1143 - acc: 0.0000e+00 - val_loss: 0.1001 - val_acc: 0.0000e+00\n",
            "Epoch 110/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.1139 - acc: 0.0000e+00 - val_loss: 0.0997 - val_acc: 0.0000e+00\n",
            "Epoch 111/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.1134 - acc: 0.0000e+00 - val_loss: 0.0987 - val_acc: 0.0000e+00\n",
            "Epoch 112/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.1129 - acc: 0.0000e+00 - val_loss: 0.0975 - val_acc: 0.0000e+00\n",
            "Epoch 113/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.1123 - acc: 0.0000e+00 - val_loss: 0.0961 - val_acc: 0.0000e+00\n",
            "Epoch 114/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.1118 - acc: 0.0000e+00 - val_loss: 0.0945 - val_acc: 0.0000e+00\n",
            "Epoch 115/1000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.1117 - acc: 0.0000e+00 - val_loss: 0.0934 - val_acc: 0.0000e+00\n",
            "Epoch 116/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.1111 - acc: 0.0000e+00 - val_loss: 0.0930 - val_acc: 0.0000e+00\n",
            "Epoch 117/1000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.1107 - acc: 0.0000e+00 - val_loss: 0.0926 - val_acc: 0.0000e+00\n",
            "Epoch 118/1000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.1102 - acc: 0.0000e+00 - val_loss: 0.0924 - val_acc: 0.0000e+00\n",
            "Epoch 119/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.1097 - acc: 0.0000e+00 - val_loss: 0.0923 - val_acc: 0.0000e+00\n",
            "Epoch 120/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.1092 - acc: 0.0000e+00 - val_loss: 0.0923 - val_acc: 0.0000e+00\n",
            "Epoch 121/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.1087 - acc: 0.0000e+00 - val_loss: 0.0921 - val_acc: 0.0000e+00\n",
            "Epoch 122/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.1082 - acc: 0.0000e+00 - val_loss: 0.0918 - val_acc: 0.0000e+00\n",
            "Epoch 123/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.1077 - acc: 0.0000e+00 - val_loss: 0.0914 - val_acc: 0.0000e+00\n",
            "Epoch 124/1000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.1072 - acc: 0.0000e+00 - val_loss: 0.0911 - val_acc: 0.0000e+00\n",
            "Epoch 125/1000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.1067 - acc: 0.0000e+00 - val_loss: 0.0909 - val_acc: 0.0000e+00\n",
            "Epoch 126/1000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.1062 - acc: 0.0000e+00 - val_loss: 0.0908 - val_acc: 0.0000e+00\n",
            "Epoch 127/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.1057 - acc: 0.0000e+00 - val_loss: 0.0904 - val_acc: 0.0000e+00\n",
            "Epoch 128/1000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.1053 - acc: 0.0000e+00 - val_loss: 0.0898 - val_acc: 0.0000e+00\n",
            "Epoch 129/1000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.1046 - acc: 0.0000e+00 - val_loss: 0.0899 - val_acc: 0.0000e+00\n",
            "Epoch 130/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.1041 - acc: 0.0000e+00 - val_loss: 0.0900 - val_acc: 0.0000e+00\n",
            "Epoch 131/1000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.1036 - acc: 0.0000e+00 - val_loss: 0.0899 - val_acc: 0.0000e+00\n",
            "Epoch 132/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.1031 - acc: 0.0000e+00 - val_loss: 0.0893 - val_acc: 0.0000e+00\n",
            "Epoch 133/1000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.1025 - acc: 0.0000e+00 - val_loss: 0.0886 - val_acc: 0.0000e+00\n",
            "Epoch 134/1000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.1018 - acc: 0.0000e+00 - val_loss: 0.0877 - val_acc: 0.0000e+00\n",
            "Epoch 135/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.1012 - acc: 0.0000e+00 - val_loss: 0.0867 - val_acc: 0.0000e+00\n",
            "Epoch 136/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.1005 - acc: 0.0000e+00 - val_loss: 0.0855 - val_acc: 0.0000e+00\n",
            "Epoch 137/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0999 - acc: 0.0000e+00 - val_loss: 0.0844 - val_acc: 0.0000e+00\n",
            "Epoch 138/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0993 - acc: 0.0000e+00 - val_loss: 0.0833 - val_acc: 0.0000e+00\n",
            "Epoch 139/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0988 - acc: 0.0000e+00 - val_loss: 0.0823 - val_acc: 0.0000e+00\n",
            "Epoch 140/1000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.0982 - acc: 0.0000e+00 - val_loss: 0.0818 - val_acc: 0.0000e+00\n",
            "Epoch 141/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0975 - acc: 0.0000e+00 - val_loss: 0.0816 - val_acc: 0.0000e+00\n",
            "Epoch 142/1000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0967 - acc: 0.0000e+00 - val_loss: 0.0813 - val_acc: 0.0000e+00\n",
            "Epoch 143/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0960 - acc: 0.0000e+00 - val_loss: 0.0811 - val_acc: 0.0000e+00\n",
            "Epoch 144/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0952 - acc: 0.0000e+00 - val_loss: 0.0807 - val_acc: 0.0000e+00\n",
            "Epoch 145/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0944 - acc: 0.0000e+00 - val_loss: 0.0805 - val_acc: 0.0000e+00\n",
            "Epoch 146/1000\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.0938 - acc: 0.0000e+00 - val_loss: 0.0802 - val_acc: 0.0000e+00\n",
            "Epoch 147/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0930 - acc: 0.0000e+00 - val_loss: 0.0796 - val_acc: 0.0000e+00\n",
            "Epoch 148/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0921 - acc: 0.0000e+00 - val_loss: 0.0794 - val_acc: 0.0000e+00\n",
            "Epoch 149/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0914 - acc: 0.0000e+00 - val_loss: 0.0790 - val_acc: 0.0000e+00\n",
            "Epoch 150/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0906 - acc: 0.0000e+00 - val_loss: 0.0783 - val_acc: 0.0000e+00\n",
            "Epoch 151/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0898 - acc: 0.0000e+00 - val_loss: 0.0773 - val_acc: 0.0000e+00\n",
            "Epoch 152/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0889 - acc: 0.0000e+00 - val_loss: 0.0763 - val_acc: 0.0000e+00\n",
            "Epoch 153/1000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0881 - acc: 0.0000e+00 - val_loss: 0.0756 - val_acc: 0.0000e+00\n",
            "Epoch 154/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0872 - acc: 0.0000e+00 - val_loss: 0.0751 - val_acc: 0.0000e+00\n",
            "Epoch 155/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0864 - acc: 0.0000e+00 - val_loss: 0.0744 - val_acc: 0.0000e+00\n",
            "Epoch 156/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0854 - acc: 0.0000e+00 - val_loss: 0.0731 - val_acc: 0.0000e+00\n",
            "Epoch 157/1000\n",
            "80/80 [==============================] - 0s 367us/step - loss: 0.0845 - acc: 0.0000e+00 - val_loss: 0.0715 - val_acc: 0.0000e+00\n",
            "Epoch 158/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0836 - acc: 0.0000e+00 - val_loss: 0.0698 - val_acc: 0.0000e+00\n",
            "Epoch 159/1000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.0829 - acc: 0.0000e+00 - val_loss: 0.0681 - val_acc: 0.0000e+00\n",
            "Epoch 160/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0823 - acc: 0.0000e+00 - val_loss: 0.0667 - val_acc: 0.0000e+00\n",
            "Epoch 161/1000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0817 - acc: 0.0000e+00 - val_loss: 0.0658 - val_acc: 0.0000e+00\n",
            "Epoch 162/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0808 - acc: 0.0000e+00 - val_loss: 0.0650 - val_acc: 0.0000e+00\n",
            "Epoch 163/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0799 - acc: 0.0000e+00 - val_loss: 0.0642 - val_acc: 0.0000e+00\n",
            "Epoch 164/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0788 - acc: 0.0000e+00 - val_loss: 0.0641 - val_acc: 0.0000e+00\n",
            "Epoch 165/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0776 - acc: 0.0000e+00 - val_loss: 0.0644 - val_acc: 0.0000e+00\n",
            "Epoch 166/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0763 - acc: 0.0000e+00 - val_loss: 0.0643 - val_acc: 0.0000e+00\n",
            "Epoch 167/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0750 - acc: 0.0000e+00 - val_loss: 0.0638 - val_acc: 0.0000e+00\n",
            "Epoch 168/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0739 - acc: 0.0000e+00 - val_loss: 0.0632 - val_acc: 0.0000e+00\n",
            "Epoch 169/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0728 - acc: 0.0000e+00 - val_loss: 0.0627 - val_acc: 0.0000e+00\n",
            "Epoch 170/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0718 - acc: 0.0000e+00 - val_loss: 0.0618 - val_acc: 0.0000e+00\n",
            "Epoch 171/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0706 - acc: 0.0000e+00 - val_loss: 0.0602 - val_acc: 0.0000e+00\n",
            "Epoch 172/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0693 - acc: 0.0000e+00 - val_loss: 0.0582 - val_acc: 0.0000e+00\n",
            "Epoch 173/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0684 - acc: 0.0000e+00 - val_loss: 0.0564 - val_acc: 0.0000e+00\n",
            "Epoch 174/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0675 - acc: 0.0000e+00 - val_loss: 0.0554 - val_acc: 0.0000e+00\n",
            "Epoch 175/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0662 - acc: 0.0000e+00 - val_loss: 0.0551 - val_acc: 0.0000e+00\n",
            "Epoch 176/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0649 - acc: 0.0000e+00 - val_loss: 0.0549 - val_acc: 0.0000e+00\n",
            "Epoch 177/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0633 - acc: 0.0000e+00 - val_loss: 0.0544 - val_acc: 0.0000e+00\n",
            "Epoch 178/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0621 - acc: 0.0000e+00 - val_loss: 0.0537 - val_acc: 0.0000e+00\n",
            "Epoch 179/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0606 - acc: 0.0000e+00 - val_loss: 0.0527 - val_acc: 0.0000e+00\n",
            "Epoch 180/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0593 - acc: 0.0000e+00 - val_loss: 0.0517 - val_acc: 0.0000e+00\n",
            "Epoch 181/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0578 - acc: 0.0000e+00 - val_loss: 0.0507 - val_acc: 0.0000e+00\n",
            "Epoch 182/1000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.0564 - acc: 0.0000e+00 - val_loss: 0.0496 - val_acc: 0.0000e+00\n",
            "Epoch 183/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0549 - acc: 0.0000e+00 - val_loss: 0.0480 - val_acc: 0.0000e+00\n",
            "Epoch 184/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0533 - acc: 0.0000e+00 - val_loss: 0.0467 - val_acc: 0.0000e+00\n",
            "Epoch 185/1000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0517 - acc: 0.0000e+00 - val_loss: 0.0454 - val_acc: 0.0000e+00\n",
            "Epoch 186/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0501 - acc: 0.0000e+00 - val_loss: 0.0437 - val_acc: 0.0000e+00\n",
            "Epoch 187/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0484 - acc: 0.0000e+00 - val_loss: 0.0417 - val_acc: 0.0000e+00\n",
            "Epoch 188/1000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0468 - acc: 0.0000e+00 - val_loss: 0.0402 - val_acc: 0.0000e+00\n",
            "Epoch 189/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0449 - acc: 0.0000e+00 - val_loss: 0.0394 - val_acc: 0.0000e+00\n",
            "Epoch 190/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0432 - acc: 0.0000e+00 - val_loss: 0.0393 - val_acc: 0.0000e+00\n",
            "Epoch 191/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0417 - acc: 0.0000e+00 - val_loss: 0.0389 - val_acc: 0.0000e+00\n",
            "Epoch 192/1000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.0402 - acc: 0.0000e+00 - val_loss: 0.0370 - val_acc: 0.0000e+00\n",
            "Epoch 193/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0382 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
            "Epoch 194/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0362 - acc: 0.0000e+00 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
            "Epoch 195/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0338 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0000e+00\n",
            "Epoch 196/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0319 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0000e+00\n",
            "Epoch 197/1000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.0299 - acc: 0.0000e+00 - val_loss: 0.0237 - val_acc: 0.0000e+00\n",
            "Epoch 198/1000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0222 - val_acc: 0.0000e+00\n",
            "Epoch 199/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0255 - acc: 0.0000e+00 - val_loss: 0.0210 - val_acc: 0.0000e+00\n",
            "Epoch 200/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0230 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0000e+00\n",
            "Epoch 201/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.0212 - acc: 0.0000e+00 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
            "Epoch 202/1000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.0190 - acc: 0.0000e+00 - val_loss: 0.0151 - val_acc: 0.0000e+00\n",
            "Epoch 203/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.0162 - acc: 0.0000e+00 - val_loss: 0.0124 - val_acc: 0.0000e+00\n",
            "Epoch 204/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0139 - acc: 0.0000e+00 - val_loss: 0.0108 - val_acc: 0.0000e+00\n",
            "Epoch 205/1000\n",
            "80/80 [==============================] - 0s 349us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
            "Epoch 206/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0089 - acc: 0.0000e+00 - val_loss: 0.0063 - val_acc: 0.0000e+00\n",
            "Epoch 207/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0076 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
            "Epoch 208/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0069 - acc: 0.0000e+00 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
            "Epoch 209/1000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.0065 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
            "Epoch 210/1000\n",
            "80/80 [==============================] - 0s 361us/step - loss: 0.0075 - acc: 0.0000e+00 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
            "Epoch 211/1000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.0069 - acc: 0.0000e+00 - val_loss: 0.0088 - val_acc: 0.0000e+00\n",
            "Epoch 212/1000\n",
            "80/80 [==============================] - 0s 412us/step - loss: 0.0076 - acc: 0.0000e+00 - val_loss: 0.0067 - val_acc: 0.0000e+00\n",
            "Epoch 213/1000\n",
            "80/80 [==============================] - 0s 358us/step - loss: 0.0069 - acc: 0.0000e+00 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
            "Epoch 214/1000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.0077 - acc: 0.0000e+00 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
            "Epoch 215/1000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.0071 - acc: 0.0000e+00 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
            "Epoch 216/1000\n",
            "80/80 [==============================] - 0s 380us/step - loss: 0.0081 - acc: 0.0000e+00 - val_loss: 0.0083 - val_acc: 0.0000e+00\n",
            "Epoch 217/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0071 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
            "Epoch 218/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
            "Epoch 219/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0067 - acc: 0.0000e+00 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
            "Epoch 220/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0085 - acc: 0.0000e+00 - val_loss: 0.0090 - val_acc: 0.0000e+00\n",
            "Epoch 221/1000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0070 - acc: 0.0000e+00 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
            "Epoch 222/1000\n",
            "80/80 [==============================] - 0s 356us/step - loss: 0.0088 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
            "Epoch 223/1000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.0075 - acc: 0.0000e+00 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
            "Epoch 224/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0071 - acc: 0.0000e+00 - val_loss: 0.0060 - val_acc: 0.0000e+00\n",
            "Epoch 225/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0061 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
            "Epoch 226/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0066 - acc: 0.0000e+00 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
            "Epoch 227/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0061 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
            "Epoch 228/1000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0060 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
            "Epoch 229/1000\n",
            "80/80 [==============================] - 0s 371us/step - loss: 0.0064 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
            "Epoch 230/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0065 - acc: 0.0000e+00 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
            "Epoch 231/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0060 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
            "Epoch 232/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0059 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
            "Epoch 233/1000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0061 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
            "Epoch 234/1000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0061 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
            "Epoch 235/1000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0060 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
            "Epoch 236/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0058 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
            "Epoch 237/1000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0063 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
            "Epoch 238/1000\n",
            "80/80 [==============================] - 0s 390us/step - loss: 0.0063 - acc: 0.0000e+00 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
            "Epoch 239/1000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0058 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
            "Epoch 240/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0058 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
            "Epoch 241/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0058 - acc: 0.0000e+00 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
            "Epoch 242/1000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0056 - acc: 0.0000e+00 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
            "Epoch 243/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0056 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
            "Epoch 244/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0059 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
            "Epoch 245/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0058 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
            "Epoch 246/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0058 - acc: 0.0000e+00 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
            "Epoch 247/1000\n",
            "80/80 [==============================] - 0s 354us/step - loss: 0.0056 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
            "Epoch 248/1000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0061 - acc: 0.0000e+00 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
            "Epoch 249/1000\n",
            "80/80 [==============================] - 0s 342us/step - loss: 0.0057 - acc: 0.0000e+00 - val_loss: 0.0061 - val_acc: 0.0000e+00\n",
            "Epoch 250/1000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0060 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
            "Epoch 251/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0061 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
            "Epoch 252/1000\n",
            "80/80 [==============================] - 0s 381us/step - loss: 0.0058 - acc: 0.0000e+00 - val_loss: 0.0060 - val_acc: 0.0000e+00\n",
            "Epoch 253/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0062 - acc: 0.0000e+00 - val_loss: 0.0060 - val_acc: 0.0000e+00\n",
            "Epoch 254/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0059 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
            "Epoch 255/1000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0056 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
            "Epoch 256/1000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0056 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
            "Epoch 257/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0053 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
            "Epoch 258/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0053 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
            "Epoch 259/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0053 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
            "Epoch 260/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0055 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
            "Epoch 261/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0055 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
            "Epoch 262/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0054 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 263/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0057 - acc: 0.0000e+00 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
            "Epoch 264/1000\n",
            "80/80 [==============================] - 0s 428us/step - loss: 0.0053 - acc: 0.0000e+00 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
            "Epoch 265/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0059 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
            "Epoch 266/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0055 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 267/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0052 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
            "Epoch 268/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0054 - acc: 0.0000e+00 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
            "Epoch 269/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0051 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
            "Epoch 270/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0051 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
            "Epoch 271/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0051 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
            "Epoch 272/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0050 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
            "Epoch 273/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0051 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
            "Epoch 274/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0048 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
            "Epoch 275/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0053 - acc: 0.0000e+00 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
            "Epoch 276/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0050 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
            "Epoch 277/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0048 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
            "Epoch 278/1000\n",
            "80/80 [==============================] - 0s 372us/step - loss: 0.0048 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
            "Epoch 279/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0049 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
            "Epoch 280/1000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0048 - acc: 0.0000e+00 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
            "Epoch 281/1000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0049 - acc: 0.0000e+00 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
            "Epoch 282/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0051 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 283/1000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
            "Epoch 284/1000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.0048 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
            "Epoch 285/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0048 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 286/1000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0049 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
            "Epoch 287/1000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
            "Epoch 288/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 289/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0049 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 290/1000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
            "Epoch 291/1000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 292/1000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0045 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
            "Epoch 293/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
            "Epoch 294/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0046 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
            "Epoch 295/1000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0046 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
            "Epoch 296/1000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
            "Epoch 297/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0056 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
            "Epoch 298/1000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0045 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
            "Epoch 299/1000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0056 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
            "Epoch 300/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0056 - acc: 0.0000e+00 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
            "Epoch 301/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0042 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
            "Epoch 302/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0059 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
            "Epoch 303/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0044 - acc: 0.0000e+00 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
            "Epoch 304/1000\n",
            "80/80 [==============================] - 0s 361us/step - loss: 0.0053 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 305/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0053 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 306/1000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0051 - acc: 0.0000e+00 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
            "Epoch 307/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 308/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0046 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 309/1000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.0043 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
            "Epoch 310/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0043 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
            "Epoch 311/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0041 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 312/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0042 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 313/1000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0040 - acc: 0.0000e+00 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
            "Epoch 314/1000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
            "Epoch 315/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0042 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
            "Epoch 316/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0040 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
            "Epoch 317/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0041 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
            "Epoch 318/1000\n",
            "80/80 [==============================] - 0s 389us/step - loss: 0.0040 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 319/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0040 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
            "Epoch 320/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0041 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
            "Epoch 321/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0039 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 322/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0042 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 323/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0038 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
            "Epoch 324/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0043 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 325/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0041 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 326/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0041 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
            "Epoch 327/1000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.0040 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 328/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 329/1000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0038 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
            "Epoch 330/1000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.0038 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 331/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0039 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
            "Epoch 332/1000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0038 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 333/1000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.0038 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 334/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
            "Epoch 335/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0041 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 336/1000\n",
            "80/80 [==============================] - 0s 382us/step - loss: 0.0038 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 337/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 338/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 339/1000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
            "Epoch 340/1000\n",
            "80/80 [==============================] - 0s 378us/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 341/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
            "Epoch 342/1000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
            "Epoch 343/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 344/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
            "Epoch 345/1000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.0040 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 346/1000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 347/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 348/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 349/1000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 350/1000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
            "Epoch 351/1000\n",
            "80/80 [==============================] - 0s 368us/step - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 352/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0038 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 353/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0032 - acc: 0.0000e+00 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
            "Epoch 354/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0043 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 355/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 356/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0038 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
            "Epoch 357/1000\n",
            "80/80 [==============================] - 0s 384us/step - loss: 0.0041 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 358/1000\n",
            "80/80 [==============================] - 0s 412us/step - loss: 0.0040 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 359/1000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
            "Epoch 360/1000\n",
            "80/80 [==============================] - 0s 382us/step - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 361/1000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0041 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 362/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
            "Epoch 363/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0032 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 364/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0040 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 365/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0031 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
            "Epoch 366/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0031 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 367/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0031 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 368/1000\n",
            "80/80 [==============================] - 0s 409us/step - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 369/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 370/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 371/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 372/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 373/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 374/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 375/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 376/1000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 377/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 378/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 379/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 380/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 381/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 382/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 383/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 384/1000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 385/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 386/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 387/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 388/1000\n",
            "80/80 [==============================] - 0s 356us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 389/1000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 390/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
            "Epoch 391/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0039 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 392/1000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 393/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
            "Epoch 394/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 395/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 396/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 397/1000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 398/1000\n",
            "80/80 [==============================] - 0s 397us/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 399/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 400/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 401/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 402/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 403/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 404/1000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 405/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
            "Epoch 406/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 407/1000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
            "Epoch 408/1000\n",
            "80/80 [==============================] - 0s 258us/step - loss: 0.0031 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 409/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0032 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 410/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
            "Epoch 411/1000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.0038 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 412/1000\n",
            "80/80 [==============================] - 0s 372us/step - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 413/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
            "Epoch 414/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 415/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 416/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 417/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 418/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 419/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 420/1000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 421/1000\n",
            "80/80 [==============================] - 0s 364us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 422/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 423/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 424/1000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.0032 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 425/1000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 426/1000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
            "Epoch 427/1000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0059 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
            "Epoch 428/1000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0042 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
            "Epoch 429/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0043 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 430/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0040 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 431/1000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
            "Epoch 432/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0040 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 433/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 434/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
            "Epoch 435/1000\n",
            "80/80 [==============================] - 0s 382us/step - loss: 0.0046 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
            "Epoch 436/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 437/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
            "Epoch 438/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 439/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 440/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
            "Epoch 441/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 442/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 443/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 444/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 445/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 446/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 447/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 448/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 449/1000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 450/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 451/1000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 452/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 453/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 454/1000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 455/1000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 456/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 457/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 458/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 459/1000\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 460/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 461/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 462/1000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 463/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 464/1000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 465/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 466/1000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
            "Epoch 467/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0032 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 468/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 469/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
            "Epoch 470/1000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 471/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 472/1000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 473/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 474/1000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 475/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 476/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 477/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 478/1000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 479/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 480/1000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 481/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 482/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 483/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 484/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 485/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 486/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 487/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 488/1000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 489/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 490/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 491/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 492/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 493/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 494/1000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 495/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 496/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 497/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 498/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 499/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 500/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 501/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 502/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 503/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 504/1000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 505/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 506/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 507/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 508/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 509/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 510/1000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 511/1000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 512/1000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 513/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 514/1000\n",
            "80/80 [==============================] - 0s 360us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 515/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 516/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0032 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 517/1000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
            "Epoch 518/1000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 519/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 520/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 521/1000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 522/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 523/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 524/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 525/1000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 526/1000\n",
            "80/80 [==============================] - 0s 403us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 527/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 528/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 529/1000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 530/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 531/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 532/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 533/1000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 534/1000\n",
            "80/80 [==============================] - 0s 256us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 535/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 536/1000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 537/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 538/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 539/1000\n",
            "80/80 [==============================] - 0s 349us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
            "Epoch 540/1000\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 541/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 542/1000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
            "Epoch 543/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0032 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 544/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 545/1000\n",
            "80/80 [==============================] - 0s 364us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 546/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 547/1000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 548/1000\n",
            "80/80 [==============================] - 0s 399us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 549/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 550/1000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 551/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 552/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 553/1000\n",
            "80/80 [==============================] - 0s 372us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 554/1000\n",
            "80/80 [==============================] - 0s 384us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 555/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 556/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 557/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 558/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 559/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 560/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 561/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 562/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 563/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 564/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 565/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 566/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 567/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 568/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 569/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 570/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 571/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 572/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0032 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 573/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
            "Epoch 574/1000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
            "Epoch 575/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
            "Epoch 576/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 577/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 578/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
            "Epoch 579/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 580/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 581/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
            "Epoch 582/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 583/1000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 584/1000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 585/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 586/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 587/1000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 588/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 589/1000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 590/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 591/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 592/1000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 593/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 594/1000\n",
            "80/80 [==============================] - 0s 389us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 595/1000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 596/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 597/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 598/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 599/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 600/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 601/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 602/1000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 603/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 604/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 605/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 606/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 607/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 608/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 609/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 610/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 611/1000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 612/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 613/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 614/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 615/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 616/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 617/1000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 618/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 619/1000\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 620/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 621/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 622/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 623/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 624/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 625/1000\n",
            "80/80 [==============================] - 0s 349us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 626/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
            "Epoch 627/1000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 628/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 629/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
            "Epoch 630/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 631/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 632/1000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 633/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 634/1000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 635/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 636/1000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 637/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 638/1000\n",
            "80/80 [==============================] - 0s 349us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 639/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 640/1000\n",
            "80/80 [==============================] - 0s 271us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 641/1000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 642/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 643/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 644/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 645/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 646/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 647/1000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 648/1000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 649/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 650/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 651/1000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 652/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 653/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 654/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
            "Epoch 655/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 656/1000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 657/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 658/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 659/1000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 660/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 661/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 662/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 663/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 664/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 665/1000\n",
            "80/80 [==============================] - 0s 371us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 666/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 667/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 668/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 669/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 670/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 671/1000\n",
            "80/80 [==============================] - 0s 325us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 672/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 673/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 674/1000\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 675/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 676/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 677/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 678/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 679/1000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 680/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 681/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 682/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 683/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 684/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 685/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 686/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 687/1000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 688/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 689/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 690/1000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 691/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 692/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 693/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 694/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 695/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 696/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
            "Epoch 697/1000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 698/1000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 699/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 700/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 701/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 702/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 703/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 704/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 705/1000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 706/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 707/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 708/1000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 709/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 710/1000\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 711/1000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 712/1000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 713/1000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 714/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 715/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 716/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 717/1000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 718/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 719/1000\n",
            "80/80 [==============================] - 0s 363us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 720/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 721/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 722/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 723/1000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 724/1000\n",
            "80/80 [==============================] - 0s 378us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 725/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 726/1000\n",
            "80/80 [==============================] - 0s 358us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 727/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 728/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 729/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 730/1000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 731/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 732/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 733/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 734/1000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 735/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 736/1000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 737/1000\n",
            "80/80 [==============================] - 0s 343us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 738/1000\n",
            "80/80 [==============================] - 0s 353us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 739/1000\n",
            "80/80 [==============================] - 0s 401us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 740/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 741/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 742/1000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 743/1000\n",
            "80/80 [==============================] - 0s 372us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 744/1000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 745/1000\n",
            "80/80 [==============================] - 0s 346us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 746/1000\n",
            "80/80 [==============================] - 0s 336us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 747/1000\n",
            "80/80 [==============================] - 0s 394us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 748/1000\n",
            "80/80 [==============================] - 0s 335us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 749/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 750/1000\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 751/1000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 752/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 753/1000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 754/1000\n",
            "80/80 [==============================] - 0s 357us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 755/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 756/1000\n",
            "80/80 [==============================] - 0s 499us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 757/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 758/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 759/1000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 760/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 761/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 762/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 763/1000\n",
            "80/80 [==============================] - 0s 373us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 764/1000\n",
            "80/80 [==============================] - 0s 320us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 765/1000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 766/1000\n",
            "80/80 [==============================] - 0s 397us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 767/1000\n",
            "80/80 [==============================] - 0s 406us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 768/1000\n",
            "80/80 [==============================] - 0s 363us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 769/1000\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 770/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 771/1000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 772/1000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 773/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 774/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 775/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 776/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 777/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 778/1000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 779/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 780/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 781/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 782/1000\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 783/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 784/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 785/1000\n",
            "80/80 [==============================] - 0s 317us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 786/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 787/1000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 788/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 789/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 790/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 791/1000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 792/1000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 793/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 794/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 795/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 796/1000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 797/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 798/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 799/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 800/1000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 801/1000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 802/1000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 803/1000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 804/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 805/1000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 806/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 807/1000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 808/1000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 809/1000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 810/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 811/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 812/1000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 813/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 814/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 815/1000\n",
            "80/80 [==============================] - 0s 375us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 816/1000\n",
            "80/80 [==============================] - 0s 331us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 817/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 818/1000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 819/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 820/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 821/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 822/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 823/1000\n",
            "80/80 [==============================] - 0s 311us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 824/1000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 825/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 826/1000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 827/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 828/1000\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 829/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 830/1000\n",
            "80/80 [==============================] - 0s 355us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 831/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 832/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 833/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 834/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 835/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 836/1000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 837/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 838/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 839/1000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 840/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 841/1000\n",
            "80/80 [==============================] - 0s 372us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 842/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 843/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 844/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 845/1000\n",
            "80/80 [==============================] - 0s 323us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 846/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 847/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 848/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 849/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 850/1000\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 851/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 852/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 9.9412e-04 - val_acc: 0.0000e+00\n",
            "Epoch 853/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 854/1000\n",
            "80/80 [==============================] - 0s 329us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 855/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 856/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 857/1000\n",
            "80/80 [==============================] - 0s 314us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 858/1000\n",
            "80/80 [==============================] - 0s 310us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 859/1000\n",
            "80/80 [==============================] - 0s 307us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 860/1000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 861/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 862/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 863/1000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 864/1000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 865/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 866/1000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 867/1000\n",
            "80/80 [==============================] - 0s 420us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 868/1000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 869/1000\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 870/1000\n",
            "80/80 [==============================] - 0s 333us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 871/1000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 872/1000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 873/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 874/1000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 875/1000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 876/1000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 877/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 878/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 879/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 880/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 881/1000\n",
            "80/80 [==============================] - 0s 326us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 882/1000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 883/1000\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 884/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 885/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 886/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 887/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 888/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 889/1000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 9.7073e-04 - val_acc: 0.0000e+00\n",
            "Epoch 890/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 891/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 9.9452e-04 - val_acc: 0.0000e+00\n",
            "Epoch 892/1000\n",
            "80/80 [==============================] - 0s 340us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 893/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 894/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 895/1000\n",
            "80/80 [==============================] - 0s 321us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 896/1000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 897/1000\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 898/1000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 899/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 900/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 901/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 902/1000\n",
            "80/80 [==============================] - 0s 316us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 903/1000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 904/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 905/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 906/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 907/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 908/1000\n",
            "80/80 [==============================] - 0s 269us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 909/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 910/1000\n",
            "80/80 [==============================] - 0s 303us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 911/1000\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 912/1000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 913/1000\n",
            "80/80 [==============================] - 0s 287us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 914/1000\n",
            "80/80 [==============================] - 0s 305us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 915/1000\n",
            "80/80 [==============================] - 0s 339us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 916/1000\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 917/1000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 918/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 919/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 920/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 921/1000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 922/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 923/1000\n",
            "80/80 [==============================] - 0s 330us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 924/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 925/1000\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 926/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 927/1000\n",
            "80/80 [==============================] - 0s 327us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 928/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 929/1000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 930/1000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 931/1000\n",
            "80/80 [==============================] - 0s 301us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 932/1000\n",
            "80/80 [==============================] - 0s 362us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 933/1000\n",
            "80/80 [==============================] - 0s 283us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 934/1000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 935/1000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 936/1000\n",
            "80/80 [==============================] - 0s 277us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 937/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 938/1000\n",
            "80/80 [==============================] - 0s 276us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 939/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 940/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 941/1000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 942/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 943/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 944/1000\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 945/1000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 946/1000\n",
            "80/80 [==============================] - 0s 270us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 947/1000\n",
            "80/80 [==============================] - 0s 265us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 948/1000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 949/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 950/1000\n",
            "80/80 [==============================] - 0s 387us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 951/1000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 952/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 953/1000\n",
            "80/80 [==============================] - 0s 280us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 954/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 955/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 956/1000\n",
            "80/80 [==============================] - 0s 328us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 957/1000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 958/1000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 959/1000\n",
            "80/80 [==============================] - 0s 322us/step - loss: 0.0017 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 960/1000\n",
            "80/80 [==============================] - 0s 313us/step - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 961/1000\n",
            "80/80 [==============================] - 0s 344us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 962/1000\n",
            "80/80 [==============================] - 0s 302us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 963/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 964/1000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 965/1000\n",
            "80/80 [==============================] - 0s 292us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 966/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 967/1000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 968/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 969/1000\n",
            "80/80 [==============================] - 0s 306us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 970/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 971/1000\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 972/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 973/1000\n",
            "80/80 [==============================] - 0s 298us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 974/1000\n",
            "80/80 [==============================] - 0s 350us/step - loss: 0.0016 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 975/1000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 976/1000\n",
            "80/80 [==============================] - 0s 295us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 977/1000\n",
            "80/80 [==============================] - 0s 296us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 978/1000\n",
            "80/80 [==============================] - 0s 309us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 979/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 980/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 981/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 982/1000\n",
            "80/80 [==============================] - 0s 304us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 983/1000\n",
            "80/80 [==============================] - 0s 308us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 984/1000\n",
            "80/80 [==============================] - 0s 300us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 985/1000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 986/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 987/1000\n",
            "80/80 [==============================] - 0s 291us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 988/1000\n",
            "80/80 [==============================] - 0s 341us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 989/1000\n",
            "80/80 [==============================] - 0s 281us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 990/1000\n",
            "80/80 [==============================] - 0s 293us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 991/1000\n",
            "80/80 [==============================] - 0s 319us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 992/1000\n",
            "80/80 [==============================] - 0s 312us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 993/1000\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 994/1000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 995/1000\n",
            "80/80 [==============================] - 0s 315us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 996/1000\n",
            "80/80 [==============================] - 0s 290us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 997/1000\n",
            "80/80 [==============================] - 0s 297us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 998/1000\n",
            "80/80 [==============================] - 0s 324us/step - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 999/1000\n",
            "80/80 [==============================] - 0s 286us/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 1000/1000\n",
            "80/80 [==============================] - 0s 462us/step - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1lJMvLFE-if",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predict = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PyZBrWfFTWo",
        "colab_type": "code",
        "outputId": "0ea3fce6-9a5a-40a1-a3ce-3b029d5dd568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "np.round(y_predict*500)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[442.],\n",
              "       [339.],\n",
              "       [382.],\n",
              "       [327.],\n",
              "       [466.],\n",
              "       [312.],\n",
              "       [274.],\n",
              "       [303.],\n",
              "       [294.],\n",
              "       [348.],\n",
              "       [533.],\n",
              "       [354.],\n",
              "       [454.],\n",
              "       [363.],\n",
              "       [424.],\n",
              "       [345.],\n",
              "       [369.],\n",
              "       [415.],\n",
              "       [280.],\n",
              "       [451.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uuk0EKEaFXgu",
        "colab_type": "code",
        "outputId": "c1d98ed7-f818-4624-e4e6-87695453ab20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "np.round(y_test*500)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([441., 339., 381., 327., 465., 312., 273., 303., 294., 348., 534.,\n",
              "       354., 453., 363., 423., 345., 369., 414., 279., 450.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mE29TU-FazF",
        "colab_type": "code",
        "outputId": "7be631c4-0195-43e3-f0bf-5a59741d85a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.scatter(range(20),y_predict,c = 'r')\n",
        "plt.scatter(range(20),y_test ,c='g')\n",
        "plt.show()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqSIMfEmqCANfkiri/wPkn5kjpQxzRQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMfYIQiOFdwq",
        "colab_type": "code",
        "outputId": "1cadcf52-7181-46d8-d982-15b1e69c4405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsy5UwhiFh_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}