{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multiple_layers_Assignment_15MI402.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UUtIRHSOfrt",
        "colab_type": "text"
      },
      "source": [
        "Assignment-1:Generating two series of multiples of 2 and 3 respectively and combining them to form a single data matrix .The target matrix predicts the product of elements of a particular row of the data matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DafZCPi6nshV",
        "colab_type": "code",
        "outputId": "30233f82-ae41-493a-bc10-2f41ab7e4efb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,LSTM\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPvPrGGxn3P9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1 = [((x+1)*2)/100 for x in range(100)]\n",
        "X2 = [((x+1)*3)/100for x in range(100)]\n",
        "Data = np.column_stack((X1, X2))\n",
        "target = [x1*x2 for x1,x2 in zip(X1,X2)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohVNB670oePU",
        "colab_type": "code",
        "outputId": "3395c615-1201-40a9-f565-5bfb9b476f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02, 0.03],\n",
              "       [0.04, 0.06],\n",
              "       [0.06, 0.09],\n",
              "       [0.08, 0.12],\n",
              "       [0.1 , 0.15],\n",
              "       [0.12, 0.18],\n",
              "       [0.14, 0.21],\n",
              "       [0.16, 0.24],\n",
              "       [0.18, 0.27],\n",
              "       [0.2 , 0.3 ],\n",
              "       [0.22, 0.33],\n",
              "       [0.24, 0.36],\n",
              "       [0.26, 0.39],\n",
              "       [0.28, 0.42],\n",
              "       [0.3 , 0.45],\n",
              "       [0.32, 0.48],\n",
              "       [0.34, 0.51],\n",
              "       [0.36, 0.54],\n",
              "       [0.38, 0.57],\n",
              "       [0.4 , 0.6 ],\n",
              "       [0.42, 0.63],\n",
              "       [0.44, 0.66],\n",
              "       [0.46, 0.69],\n",
              "       [0.48, 0.72],\n",
              "       [0.5 , 0.75],\n",
              "       [0.52, 0.78],\n",
              "       [0.54, 0.81],\n",
              "       [0.56, 0.84],\n",
              "       [0.58, 0.87],\n",
              "       [0.6 , 0.9 ],\n",
              "       [0.62, 0.93],\n",
              "       [0.64, 0.96],\n",
              "       [0.66, 0.99],\n",
              "       [0.68, 1.02],\n",
              "       [0.7 , 1.05],\n",
              "       [0.72, 1.08],\n",
              "       [0.74, 1.11],\n",
              "       [0.76, 1.14],\n",
              "       [0.78, 1.17],\n",
              "       [0.8 , 1.2 ],\n",
              "       [0.82, 1.23],\n",
              "       [0.84, 1.26],\n",
              "       [0.86, 1.29],\n",
              "       [0.88, 1.32],\n",
              "       [0.9 , 1.35],\n",
              "       [0.92, 1.38],\n",
              "       [0.94, 1.41],\n",
              "       [0.96, 1.44],\n",
              "       [0.98, 1.47],\n",
              "       [1.  , 1.5 ],\n",
              "       [1.02, 1.53],\n",
              "       [1.04, 1.56],\n",
              "       [1.06, 1.59],\n",
              "       [1.08, 1.62],\n",
              "       [1.1 , 1.65],\n",
              "       [1.12, 1.68],\n",
              "       [1.14, 1.71],\n",
              "       [1.16, 1.74],\n",
              "       [1.18, 1.77],\n",
              "       [1.2 , 1.8 ],\n",
              "       [1.22, 1.83],\n",
              "       [1.24, 1.86],\n",
              "       [1.26, 1.89],\n",
              "       [1.28, 1.92],\n",
              "       [1.3 , 1.95],\n",
              "       [1.32, 1.98],\n",
              "       [1.34, 2.01],\n",
              "       [1.36, 2.04],\n",
              "       [1.38, 2.07],\n",
              "       [1.4 , 2.1 ],\n",
              "       [1.42, 2.13],\n",
              "       [1.44, 2.16],\n",
              "       [1.46, 2.19],\n",
              "       [1.48, 2.22],\n",
              "       [1.5 , 2.25],\n",
              "       [1.52, 2.28],\n",
              "       [1.54, 2.31],\n",
              "       [1.56, 2.34],\n",
              "       [1.58, 2.37],\n",
              "       [1.6 , 2.4 ],\n",
              "       [1.62, 2.43],\n",
              "       [1.64, 2.46],\n",
              "       [1.66, 2.49],\n",
              "       [1.68, 2.52],\n",
              "       [1.7 , 2.55],\n",
              "       [1.72, 2.58],\n",
              "       [1.74, 2.61],\n",
              "       [1.76, 2.64],\n",
              "       [1.78, 2.67],\n",
              "       [1.8 , 2.7 ],\n",
              "       [1.82, 2.73],\n",
              "       [1.84, 2.76],\n",
              "       [1.86, 2.79],\n",
              "       [1.88, 2.82],\n",
              "       [1.9 , 2.85],\n",
              "       [1.92, 2.88],\n",
              "       [1.94, 2.91],\n",
              "       [1.96, 2.94],\n",
              "       [1.98, 2.97],\n",
              "       [2.  , 3.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Raq9vvlbof7v",
        "colab_type": "code",
        "outputId": "6992a809-8b89-4006-87e4-35716e02191e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "target"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0006,\n",
              " 0.0024,\n",
              " 0.005399999999999999,\n",
              " 0.0096,\n",
              " 0.015,\n",
              " 0.021599999999999998,\n",
              " 0.029400000000000003,\n",
              " 0.0384,\n",
              " 0.048600000000000004,\n",
              " 0.06,\n",
              " 0.0726,\n",
              " 0.08639999999999999,\n",
              " 0.1014,\n",
              " 0.11760000000000001,\n",
              " 0.135,\n",
              " 0.1536,\n",
              " 0.17340000000000003,\n",
              " 0.19440000000000002,\n",
              " 0.2166,\n",
              " 0.24,\n",
              " 0.2646,\n",
              " 0.2904,\n",
              " 0.3174,\n",
              " 0.34559999999999996,\n",
              " 0.375,\n",
              " 0.4056,\n",
              " 0.43740000000000007,\n",
              " 0.47040000000000004,\n",
              " 0.5045999999999999,\n",
              " 0.54,\n",
              " 0.5766,\n",
              " 0.6144,\n",
              " 0.6534,\n",
              " 0.6936000000000001,\n",
              " 0.735,\n",
              " 0.7776000000000001,\n",
              " 0.8214,\n",
              " 0.8664,\n",
              " 0.9126,\n",
              " 0.96,\n",
              " 1.0086,\n",
              " 1.0584,\n",
              " 1.1094,\n",
              " 1.1616,\n",
              " 1.215,\n",
              " 1.2696,\n",
              " 1.3254,\n",
              " 1.3823999999999999,\n",
              " 1.4405999999999999,\n",
              " 1.5,\n",
              " 1.5606,\n",
              " 1.6224,\n",
              " 1.6854000000000002,\n",
              " 1.7496000000000003,\n",
              " 1.815,\n",
              " 1.8816000000000002,\n",
              " 1.9493999999999998,\n",
              " 2.0183999999999997,\n",
              " 2.0886,\n",
              " 2.16,\n",
              " 2.2326,\n",
              " 2.3064,\n",
              " 2.3813999999999997,\n",
              " 2.4576,\n",
              " 2.535,\n",
              " 2.6136,\n",
              " 2.6934,\n",
              " 2.7744000000000004,\n",
              " 2.8565999999999994,\n",
              " 2.94,\n",
              " 3.0245999999999995,\n",
              " 3.1104000000000003,\n",
              " 3.1974,\n",
              " 3.2856,\n",
              " 3.375,\n",
              " 3.4656,\n",
              " 3.5574000000000003,\n",
              " 3.6504,\n",
              " 3.7446,\n",
              " 3.84,\n",
              " 3.9366000000000003,\n",
              " 4.0344,\n",
              " 4.1334,\n",
              " 4.2336,\n",
              " 4.335,\n",
              " 4.4376,\n",
              " 4.541399999999999,\n",
              " 4.6464,\n",
              " 4.7526,\n",
              " 4.86,\n",
              " 4.9686,\n",
              " 5.0784,\n",
              " 5.1894,\n",
              " 5.3016,\n",
              " 5.415,\n",
              " 5.529599999999999,\n",
              " 5.6454,\n",
              " 5.7623999999999995,\n",
              " 5.8806,\n",
              " 6.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DigCJAh5ohxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.array(Data,dtype=float)\n",
        "target = np.array(target,dtype=float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQhxV8L2o2Jy",
        "colab_type": "code",
        "outputId": "2fed163e-c8aa-4c77-83f7-03dbf33016c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = np.array(data).reshape(100, 2,1)\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 2, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_8P1_nmo6Gl",
        "colab_type": "code",
        "outputId": "1cbe9a2f-071a-4265-f84a-4664381caeb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_93Sdcoo8cO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(data,target,test_size=0.2,random_state=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko77mK6jpaLk",
        "colab_type": "code",
        "outputId": "1e95f9cc-5948-4a7a-8058-a08eeaa672a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(2,1)))\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(25, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 2, 200)            161600    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 2, 100)            120400    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 2, 50)             30200     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 25)                7600      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                520       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                210       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 320,541\n",
            "Trainable params: 320,541\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsoTncmqp5vC",
        "colab_type": "code",
        "outputId": "17cae9c2-5b5d-4a0c-b012-a8b10ad670a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(x_train,y_train,epochs=2000,validation_data=(x_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/2000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "80/80 [==============================] - 4s 45ms/step - loss: 7.7760 - val_loss: 5.6791\n",
            "Epoch 2/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.7036 - val_loss: 5.6239\n",
            "Epoch 3/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 7.6251 - val_loss: 5.5647\n",
            "Epoch 4/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 7.5404 - val_loss: 5.5001\n",
            "Epoch 5/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 7.4422 - val_loss: 5.4297\n",
            "Epoch 6/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 7.3414 - val_loss: 5.3504\n",
            "Epoch 7/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.2211 - val_loss: 5.2585\n",
            "Epoch 8/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 7.0816 - val_loss: 5.1502\n",
            "Epoch 9/2000\n",
            "80/80 [==============================] - 0s 989us/step - loss: 6.9118 - val_loss: 5.0148\n",
            "Epoch 10/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 6.6954 - val_loss: 4.8351\n",
            "Epoch 11/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 6.3988 - val_loss: 4.5838\n",
            "Epoch 12/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 6.0085 - val_loss: 4.2027\n",
            "Epoch 13/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.3882 - val_loss: 3.5679\n",
            "Epoch 14/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 4.3884 - val_loss: 2.4246\n",
            "Epoch 15/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7020 - val_loss: 0.5927\n",
            "Epoch 16/2000\n",
            "80/80 [==============================] - 0s 994us/step - loss: 0.5440 - val_loss: 2.6213\n",
            "Epoch 17/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 1.5794 - val_loss: 0.4208\n",
            "Epoch 18/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 0.2643 - val_loss: 0.4423\n",
            "Epoch 19/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 0.5998 - val_loss: 0.5943\n",
            "Epoch 20/2000\n",
            "80/80 [==============================] - 0s 992us/step - loss: 0.6860 - val_loss: 0.4545\n",
            "Epoch 21/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 0.4452 - val_loss: 0.3328\n",
            "Epoch 22/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 0.2507 - val_loss: 0.5499\n",
            "Epoch 23/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 0.3717 - val_loss: 0.5114\n",
            "Epoch 24/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 0.2759 - val_loss: 0.3225\n",
            "Epoch 25/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.2361 - val_loss: 0.3101\n",
            "Epoch 26/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 0.2805 - val_loss: 0.2914\n",
            "Epoch 27/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 0.2392 - val_loss: 0.2896\n",
            "Epoch 28/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 0.2048 - val_loss: 0.3515\n",
            "Epoch 29/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 0.2165 - val_loss: 0.3157\n",
            "Epoch 30/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 0.1899 - val_loss: 0.2491\n",
            "Epoch 31/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 0.1765 - val_loss: 0.2207\n",
            "Epoch 32/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 0.1775 - val_loss: 0.2139\n",
            "Epoch 33/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 0.1621 - val_loss: 0.2305\n",
            "Epoch 34/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 0.1529 - val_loss: 0.2295\n",
            "Epoch 35/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1473 - val_loss: 0.2022\n",
            "Epoch 36/2000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 0.1399 - val_loss: 0.1774\n",
            "Epoch 37/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 0.1333 - val_loss: 0.1743\n",
            "Epoch 38/2000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 0.1261 - val_loss: 0.1746\n",
            "Epoch 39/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 0.1200 - val_loss: 0.1692\n",
            "Epoch 40/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 0.1145 - val_loss: 0.1581\n",
            "Epoch 41/2000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 0.1086 - val_loss: 0.1415\n",
            "Epoch 42/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 0.1024 - val_loss: 0.1244\n",
            "Epoch 43/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 0.0995 - val_loss: 0.1164\n",
            "Epoch 44/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 0.0926 - val_loss: 0.1241\n",
            "Epoch 45/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0867 - val_loss: 0.1229\n",
            "Epoch 46/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 0.0832 - val_loss: 0.1040\n",
            "Epoch 47/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 0.0765 - val_loss: 0.0966\n",
            "Epoch 48/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 0.0717 - val_loss: 0.0929\n",
            "Epoch 49/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0650 - val_loss: 0.0746\n",
            "Epoch 50/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0615 - val_loss: 0.0696\n",
            "Epoch 51/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0556 - val_loss: 0.0745\n",
            "Epoch 52/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0486 - val_loss: 0.0529\n",
            "Epoch 53/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 0.0429 - val_loss: 0.0477\n",
            "Epoch 54/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0391 - val_loss: 0.0502\n",
            "Epoch 55/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 0.0316 - val_loss: 0.0307\n",
            "Epoch 56/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0291 - val_loss: 0.0194\n",
            "Epoch 57/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 0.0239 - val_loss: 0.0282\n",
            "Epoch 58/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.0325\n",
            "Epoch 59/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0123\n",
            "Epoch 60/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 0.0159 - val_loss: 0.0125\n",
            "Epoch 61/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 0.0122 - val_loss: 0.0196\n",
            "Epoch 62/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 0.0116 - val_loss: 0.0156\n",
            "Epoch 63/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 0.0097 - val_loss: 0.0082\n",
            "Epoch 64/2000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 0.0096 - val_loss: 0.0041\n",
            "Epoch 65/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 0.0087 - val_loss: 0.0079\n",
            "Epoch 66/2000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 0.0070 - val_loss: 0.0141\n",
            "Epoch 67/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 0.0076 - val_loss: 0.0093\n",
            "Epoch 68/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0039\n",
            "Epoch 69/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 0.0052 - val_loss: 0.0040\n",
            "Epoch 70/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 0.0041 - val_loss: 0.0068\n",
            "Epoch 71/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 0.0043 - val_loss: 0.0057\n",
            "Epoch 72/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 0.0037 - val_loss: 0.0042\n",
            "Epoch 73/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 0.0035 - val_loss: 0.0040\n",
            "Epoch 74/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 0.0033 - val_loss: 0.0036\n",
            "Epoch 75/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 0.0030 - val_loss: 0.0038\n",
            "Epoch 76/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 0.0028 - val_loss: 0.0030\n",
            "Epoch 77/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 0.0025 - val_loss: 0.0026\n",
            "Epoch 78/2000\n",
            "80/80 [==============================] - 0s 894us/step - loss: 0.0025 - val_loss: 0.0027\n",
            "Epoch 79/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 80/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 0.0022 - val_loss: 0.0029\n",
            "Epoch 81/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 0.0020 - val_loss: 0.0024\n",
            "Epoch 82/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 83/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 84/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 0.0017 - val_loss: 0.0023\n",
            "Epoch 85/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 0.0016 - val_loss: 0.0019\n",
            "Epoch 86/2000\n",
            "80/80 [==============================] - 0s 883us/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 87/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 88/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 0.0014 - val_loss: 7.6083e-04\n",
            "Epoch 89/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 0.0013 - val_loss: 0.0016\n",
            "Epoch 90/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 91/2000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 0.0011 - val_loss: 8.0946e-04\n",
            "Epoch 92/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 0.0015 - val_loss: 5.5733e-04\n",
            "Epoch 93/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 94/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 95/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.5405e-04 - val_loss: 0.0012\n",
            "Epoch 96/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 9.3526e-04 - val_loss: 0.0012\n",
            "Epoch 97/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 9.4918e-04 - val_loss: 8.2805e-04\n",
            "Epoch 98/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 7.1744e-04 - val_loss: 1.4466e-04\n",
            "Epoch 99/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 0.0011 - val_loss: 4.3449e-04\n",
            "Epoch 100/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 8.6342e-04 - val_loss: 0.0014\n",
            "Epoch 101/2000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 8.8547e-04 - val_loss: 9.8961e-04\n",
            "Epoch 102/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 7.9410e-04 - val_loss: 2.6628e-04\n",
            "Epoch 103/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 7.7264e-04 - val_loss: 6.4814e-04\n",
            "Epoch 104/2000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 7.7511e-04 - val_loss: 3.2225e-04\n",
            "Epoch 105/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 6.9384e-04 - val_loss: 2.9994e-04\n",
            "Epoch 106/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 6.8023e-04 - val_loss: 9.2545e-04\n",
            "Epoch 107/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 6.1247e-04 - val_loss: 6.3044e-04\n",
            "Epoch 108/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 4.4695e-04 - val_loss: 1.5361e-04\n",
            "Epoch 109/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 6.4968e-04 - val_loss: 1.2027e-04\n",
            "Epoch 110/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 6.2773e-04 - val_loss: 2.9800e-04\n",
            "Epoch 111/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 5.1526e-04 - val_loss: 7.8582e-04\n",
            "Epoch 112/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 5.4302e-04 - val_loss: 4.8392e-04\n",
            "Epoch 113/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 5.2064e-04 - val_loss: 2.1257e-04\n",
            "Epoch 114/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 4.2032e-04 - val_loss: 3.5789e-04\n",
            "Epoch 115/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 5.0213e-04 - val_loss: 2.2763e-04\n",
            "Epoch 116/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 3.2370e-04 - val_loss: 6.2161e-04\n",
            "Epoch 117/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 4.5106e-04 - val_loss: 6.1906e-04\n",
            "Epoch 118/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 4.6926e-04 - val_loss: 1.2295e-04\n",
            "Epoch 119/2000\n",
            "80/80 [==============================] - 0s 996us/step - loss: 3.9818e-04 - val_loss: 2.8530e-04\n",
            "Epoch 120/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 3.5860e-04 - val_loss: 1.3157e-04\n",
            "Epoch 121/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 2.8773e-04 - val_loss: 3.7710e-04\n",
            "Epoch 122/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 3.7255e-04 - val_loss: 3.5783e-04\n",
            "Epoch 123/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 3.0008e-04 - val_loss: 1.3576e-04\n",
            "Epoch 124/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 2.7126e-04 - val_loss: 1.9838e-04\n",
            "Epoch 125/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 2.9009e-04 - val_loss: 1.6974e-04\n",
            "Epoch 126/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 2.4418e-04 - val_loss: 1.0674e-04\n",
            "Epoch 127/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 2.5384e-04 - val_loss: 1.9934e-04\n",
            "Epoch 128/2000\n",
            "80/80 [==============================] - 0s 983us/step - loss: 2.4602e-04 - val_loss: 1.7055e-04\n",
            "Epoch 129/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2533e-04 - val_loss: 1.3006e-04\n",
            "Epoch 130/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 2.2938e-04 - val_loss: 1.5146e-04\n",
            "Epoch 131/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 2.1496e-04 - val_loss: 1.4043e-04\n",
            "Epoch 132/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 2.0754e-04 - val_loss: 1.1779e-04\n",
            "Epoch 133/2000\n",
            "80/80 [==============================] - 0s 983us/step - loss: 2.2168e-04 - val_loss: 1.0293e-04\n",
            "Epoch 134/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 2.0113e-04 - val_loss: 1.8146e-04\n",
            "Epoch 135/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 2.1142e-04 - val_loss: 1.6172e-04\n",
            "Epoch 136/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 2.3108e-04 - val_loss: 1.2831e-04\n",
            "Epoch 137/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 2.1216e-04 - val_loss: 1.6969e-04\n",
            "Epoch 138/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 1.8800e-04 - val_loss: 4.1279e-05\n",
            "Epoch 139/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 2.0772e-04 - val_loss: 1.4570e-04\n",
            "Epoch 140/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 2.1594e-04 - val_loss: 1.2663e-04\n",
            "Epoch 141/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 1.6700e-04 - val_loss: 5.9535e-05\n",
            "Epoch 142/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0129e-04 - val_loss: 1.2965e-04\n",
            "Epoch 143/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 1.9947e-04 - val_loss: 9.7784e-05\n",
            "Epoch 144/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7258e-04 - val_loss: 1.1559e-04\n",
            "Epoch 145/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 2.1229e-04 - val_loss: 4.2485e-05\n",
            "Epoch 146/2000\n",
            "80/80 [==============================] - 0s 892us/step - loss: 1.9545e-04 - val_loss: 1.3595e-04\n",
            "Epoch 147/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 1.9970e-04 - val_loss: 4.8054e-05\n",
            "Epoch 148/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 1.9257e-04 - val_loss: 1.0140e-04\n",
            "Epoch 149/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 1.4029e-04 - val_loss: 3.6592e-05\n",
            "Epoch 150/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 1.3328e-04 - val_loss: 5.2745e-05\n",
            "Epoch 151/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 1.8366e-04 - val_loss: 6.6841e-05\n",
            "Epoch 152/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7944e-04 - val_loss: 2.4441e-05\n",
            "Epoch 153/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3706e-04 - val_loss: 1.3845e-04\n",
            "Epoch 154/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 1.4602e-04 - val_loss: 6.9101e-05\n",
            "Epoch 155/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 1.5826e-04 - val_loss: 3.6292e-05\n",
            "Epoch 156/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 1.5001e-04 - val_loss: 8.3715e-05\n",
            "Epoch 157/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 1.1178e-04 - val_loss: 3.2998e-05\n",
            "Epoch 158/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 1.3571e-04 - val_loss: 5.4990e-05\n",
            "Epoch 159/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2071e-04 - val_loss: 6.2221e-05\n",
            "Epoch 160/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 9.9821e-05 - val_loss: 3.9582e-05\n",
            "Epoch 161/2000\n",
            "80/80 [==============================] - 0s 877us/step - loss: 1.0334e-04 - val_loss: 3.8987e-05\n",
            "Epoch 162/2000\n",
            "80/80 [==============================] - 0s 880us/step - loss: 1.1759e-04 - val_loss: 2.3598e-05\n",
            "Epoch 163/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 1.0862e-04 - val_loss: 2.0866e-05\n",
            "Epoch 164/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 1.0008e-04 - val_loss: 6.4209e-05\n",
            "Epoch 165/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2363e-04 - val_loss: 5.3499e-05\n",
            "Epoch 166/2000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 1.5373e-04 - val_loss: 1.8789e-05\n",
            "Epoch 167/2000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 1.2063e-04 - val_loss: 1.0526e-04\n",
            "Epoch 168/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 1.2225e-04 - val_loss: 6.2625e-05\n",
            "Epoch 169/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 1.0486e-04 - val_loss: 7.3231e-05\n",
            "Epoch 170/2000\n",
            "80/80 [==============================] - 0s 871us/step - loss: 1.4696e-04 - val_loss: 2.3391e-05\n",
            "Epoch 171/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 1.4217e-04 - val_loss: 3.0527e-05\n",
            "Epoch 172/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 1.1308e-04 - val_loss: 1.2301e-04\n",
            "Epoch 173/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 1.1938e-04 - val_loss: 9.6464e-05\n",
            "Epoch 174/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 1.5030e-04 - val_loss: 2.4902e-05\n",
            "Epoch 175/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 1.1239e-04 - val_loss: 4.2681e-05\n",
            "Epoch 176/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 8.3218e-05 - val_loss: 2.9290e-05\n",
            "Epoch 177/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 7.6645e-05 - val_loss: 6.4875e-05\n",
            "Epoch 178/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 8.8451e-05 - val_loss: 2.2215e-05\n",
            "Epoch 179/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.4610e-05 - val_loss: 1.4738e-05\n",
            "Epoch 180/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 6.4331e-05 - val_loss: 5.1228e-05\n",
            "Epoch 181/2000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 7.3034e-05 - val_loss: 3.1193e-05\n",
            "Epoch 182/2000\n",
            "80/80 [==============================] - 0s 892us/step - loss: 6.8744e-05 - val_loss: 2.0068e-05\n",
            "Epoch 183/2000\n",
            "80/80 [==============================] - 0s 893us/step - loss: 5.9511e-05 - val_loss: 2.3769e-05\n",
            "Epoch 184/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 6.4119e-05 - val_loss: 2.8066e-05\n",
            "Epoch 185/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 8.4566e-05 - val_loss: 1.7648e-05\n",
            "Epoch 186/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 1.0661e-04 - val_loss: 4.3067e-05\n",
            "Epoch 187/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 8.8138e-05 - val_loss: 1.7935e-05\n",
            "Epoch 188/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 6.7565e-05 - val_loss: 7.1062e-05\n",
            "Epoch 189/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 6.8838e-05 - val_loss: 2.6403e-05\n",
            "Epoch 190/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 7.6126e-05 - val_loss: 2.4801e-05\n",
            "Epoch 191/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 5.3123e-05 - val_loss: 1.5631e-05\n",
            "Epoch 192/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 5.3922e-05 - val_loss: 2.9838e-05\n",
            "Epoch 193/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 5.5181e-05 - val_loss: 2.4546e-05\n",
            "Epoch 194/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.9031e-05 - val_loss: 3.3718e-05\n",
            "Epoch 195/2000\n",
            "80/80 [==============================] - 0s 893us/step - loss: 6.6123e-05 - val_loss: 1.1058e-05\n",
            "Epoch 196/2000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 5.3399e-05 - val_loss: 3.0698e-05\n",
            "Epoch 197/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 5.9929e-05 - val_loss: 1.3529e-05\n",
            "Epoch 198/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 4.0501e-05 - val_loss: 3.0038e-05\n",
            "Epoch 199/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 5.0825e-05 - val_loss: 1.6091e-05\n",
            "Epoch 200/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 4.4506e-05 - val_loss: 1.8350e-05\n",
            "Epoch 201/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 4.5688e-05 - val_loss: 1.0507e-05\n",
            "Epoch 202/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 3.8117e-05 - val_loss: 1.4334e-05\n",
            "Epoch 203/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 3.9459e-05 - val_loss: 1.6765e-05\n",
            "Epoch 204/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 3.7867e-05 - val_loss: 9.3234e-06\n",
            "Epoch 205/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 4.4167e-05 - val_loss: 1.0014e-05\n",
            "Epoch 206/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.2883e-05 - val_loss: 9.9096e-06\n",
            "Epoch 207/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 3.3577e-05 - val_loss: 8.7416e-06\n",
            "Epoch 208/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 3.2694e-05 - val_loss: 1.2424e-05\n",
            "Epoch 209/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 3.3828e-05 - val_loss: 8.9627e-06\n",
            "Epoch 210/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.9929e-05 - val_loss: 8.9902e-06\n",
            "Epoch 211/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 3.4675e-05 - val_loss: 9.4977e-06\n",
            "Epoch 212/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 3.2711e-05 - val_loss: 1.0293e-05\n",
            "Epoch 213/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 3.0428e-05 - val_loss: 1.3774e-05\n",
            "Epoch 214/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 3.3303e-05 - val_loss: 1.0969e-05\n",
            "Epoch 215/2000\n",
            "80/80 [==============================] - 0s 979us/step - loss: 5.1005e-05 - val_loss: 1.1410e-05\n",
            "Epoch 216/2000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 5.0700e-05 - val_loss: 9.3470e-06\n",
            "Epoch 217/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 3.4046e-05 - val_loss: 1.6212e-05\n",
            "Epoch 218/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 3.7241e-05 - val_loss: 1.9514e-05\n",
            "Epoch 219/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 3.4870e-05 - val_loss: 1.4279e-05\n",
            "Epoch 220/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 3.1824e-05 - val_loss: 1.2836e-05\n",
            "Epoch 221/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 3.7957e-05 - val_loss: 8.9046e-06\n",
            "Epoch 222/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 3.5536e-05 - val_loss: 9.4808e-06\n",
            "Epoch 223/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 3.7090e-05 - val_loss: 1.1330e-05\n",
            "Epoch 224/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 3.4419e-05 - val_loss: 1.6264e-05\n",
            "Epoch 225/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 2.2447e-05 - val_loss: 2.8852e-05\n",
            "Epoch 226/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 5.2018e-05 - val_loss: 2.2727e-05\n",
            "Epoch 227/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 3.8554e-05 - val_loss: 1.5732e-05\n",
            "Epoch 228/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 3.4132e-05 - val_loss: 1.5383e-05\n",
            "Epoch 229/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 3.8184e-05 - val_loss: 1.2320e-05\n",
            "Epoch 230/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 2.3788e-05 - val_loss: 7.6447e-06\n",
            "Epoch 231/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 2.5351e-05 - val_loss: 1.2551e-05\n",
            "Epoch 232/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 2.2476e-05 - val_loss: 1.4482e-05\n",
            "Epoch 233/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 2.7076e-05 - val_loss: 9.1165e-06\n",
            "Epoch 234/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7874e-05 - val_loss: 6.6177e-06\n",
            "Epoch 235/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 2.1219e-05 - val_loss: 6.1785e-06\n",
            "Epoch 236/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 1.9081e-05 - val_loss: 1.3277e-05\n",
            "Epoch 237/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 3.6589e-05 - val_loss: 2.3181e-05\n",
            "Epoch 238/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 4.8729e-05 - val_loss: 1.0360e-05\n",
            "Epoch 239/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 4.8488e-05 - val_loss: 6.4265e-06\n",
            "Epoch 240/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 4.6353e-05 - val_loss: 6.9583e-06\n",
            "Epoch 241/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 4.0694e-05 - val_loss: 4.7647e-05\n",
            "Epoch 242/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 4.5455e-05 - val_loss: 2.1370e-05\n",
            "Epoch 243/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.8770e-05 - val_loss: 3.7241e-05\n",
            "Epoch 244/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.4631e-05 - val_loss: 2.1347e-05\n",
            "Epoch 245/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 3.5035e-05 - val_loss: 2.3154e-05\n",
            "Epoch 246/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 2.6629e-05 - val_loss: 7.1714e-06\n",
            "Epoch 247/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 2.1504e-05 - val_loss: 1.9680e-05\n",
            "Epoch 248/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3041e-05 - val_loss: 1.0185e-05\n",
            "Epoch 249/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 2.7091e-05 - val_loss: 7.9004e-06\n",
            "Epoch 250/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 1.8794e-05 - val_loss: 5.9827e-06\n",
            "Epoch 251/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 1.7964e-05 - val_loss: 5.3618e-06\n",
            "Epoch 252/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 1.3406e-05 - val_loss: 1.2862e-05\n",
            "Epoch 253/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 1.9923e-05 - val_loss: 8.8576e-06\n",
            "Epoch 254/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4620e-05 - val_loss: 7.4622e-06\n",
            "Epoch 255/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 1.3705e-05 - val_loss: 5.8289e-06\n",
            "Epoch 256/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 1.5071e-05 - val_loss: 1.0672e-05\n",
            "Epoch 257/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 1.4954e-05 - val_loss: 1.3988e-05\n",
            "Epoch 258/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.6635e-05 - val_loss: 7.3191e-06\n",
            "Epoch 259/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 1.4953e-05 - val_loss: 1.0452e-05\n",
            "Epoch 260/2000\n",
            "80/80 [==============================] - 0s 882us/step - loss: 1.3631e-05 - val_loss: 1.0928e-05\n",
            "Epoch 261/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 1.8854e-05 - val_loss: 1.1760e-05\n",
            "Epoch 262/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 1.9775e-05 - val_loss: 7.4128e-06\n",
            "Epoch 263/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 1.8389e-05 - val_loss: 1.2782e-05\n",
            "Epoch 264/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 2.0040e-05 - val_loss: 9.8948e-06\n",
            "Epoch 265/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 1.3844e-05 - val_loss: 4.7004e-06\n",
            "Epoch 266/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 1.2196e-05 - val_loss: 9.2239e-06\n",
            "Epoch 267/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 1.2960e-05 - val_loss: 1.1841e-05\n",
            "Epoch 268/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 1.3222e-05 - val_loss: 1.2058e-05\n",
            "Epoch 269/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3899e-05 - val_loss: 4.8370e-06\n",
            "Epoch 270/2000\n",
            "80/80 [==============================] - 0s 883us/step - loss: 1.2989e-05 - val_loss: 1.2747e-05\n",
            "Epoch 271/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 1.1785e-05 - val_loss: 8.0112e-06\n",
            "Epoch 272/2000\n",
            "80/80 [==============================] - 0s 883us/step - loss: 1.2831e-05 - val_loss: 4.4702e-06\n",
            "Epoch 273/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 1.3975e-05 - val_loss: 3.6844e-06\n",
            "Epoch 274/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 1.4751e-05 - val_loss: 5.2927e-06\n",
            "Epoch 275/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 1.3217e-05 - val_loss: 5.5839e-06\n",
            "Epoch 276/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 1.1110e-05 - val_loss: 7.6529e-06\n",
            "Epoch 277/2000\n",
            "80/80 [==============================] - 0s 884us/step - loss: 1.2420e-05 - val_loss: 5.3753e-06\n",
            "Epoch 278/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1665e-05 - val_loss: 5.2640e-06\n",
            "Epoch 279/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 1.0878e-05 - val_loss: 3.4164e-06\n",
            "Epoch 280/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 9.4531e-06 - val_loss: 8.0196e-06\n",
            "Epoch 281/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 9.4568e-06 - val_loss: 8.9608e-06\n",
            "Epoch 282/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 1.0241e-05 - val_loss: 1.0287e-05\n",
            "Epoch 283/2000\n",
            "80/80 [==============================] - 0s 995us/step - loss: 1.2400e-05 - val_loss: 6.3082e-06\n",
            "Epoch 284/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 9.5256e-06 - val_loss: 1.0510e-05\n",
            "Epoch 285/2000\n",
            "80/80 [==============================] - 0s 877us/step - loss: 9.0558e-06 - val_loss: 5.4359e-06\n",
            "Epoch 286/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 8.5607e-06 - val_loss: 5.5617e-06\n",
            "Epoch 287/2000\n",
            "80/80 [==============================] - 0s 890us/step - loss: 9.4425e-06 - val_loss: 4.4954e-06\n",
            "Epoch 288/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.2110e-06 - val_loss: 7.4292e-06\n",
            "Epoch 289/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 8.1423e-06 - val_loss: 1.6032e-05\n",
            "Epoch 290/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 1.0173e-05 - val_loss: 9.6855e-06\n",
            "Epoch 291/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 8.7155e-06 - val_loss: 6.3960e-06\n",
            "Epoch 292/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 8.9244e-06 - val_loss: 1.1044e-05\n",
            "Epoch 293/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 1.1591e-05 - val_loss: 1.1905e-05\n",
            "Epoch 294/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 1.0991e-05 - val_loss: 4.1407e-06\n",
            "Epoch 295/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 1.3713e-05 - val_loss: 4.2500e-06\n",
            "Epoch 296/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0528e-05 - val_loss: 1.1090e-05\n",
            "Epoch 297/2000\n",
            "80/80 [==============================] - 0s 886us/step - loss: 7.6825e-06 - val_loss: 4.7230e-06\n",
            "Epoch 298/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 1.1087e-05 - val_loss: 5.6657e-06\n",
            "Epoch 299/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 6.0927e-06 - val_loss: 2.3197e-05\n",
            "Epoch 300/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 1.1723e-05 - val_loss: 8.6892e-06\n",
            "Epoch 301/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 1.2212e-05 - val_loss: 2.0237e-05\n",
            "Epoch 302/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 1.7216e-05 - val_loss: 2.2185e-05\n",
            "Epoch 303/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 1.9040e-05 - val_loss: 8.7608e-06\n",
            "Epoch 304/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 9.9196e-06 - val_loss: 2.9302e-06\n",
            "Epoch 305/2000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 1.1716e-05 - val_loss: 9.6634e-06\n",
            "Epoch 306/2000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 9.2468e-06 - val_loss: 9.4101e-06\n",
            "Epoch 307/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 7.8388e-06 - val_loss: 7.6510e-06\n",
            "Epoch 308/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 9.4190e-06 - val_loss: 4.2418e-06\n",
            "Epoch 309/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 8.5709e-06 - val_loss: 1.7187e-05\n",
            "Epoch 310/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 1.0187e-05 - val_loss: 3.3875e-06\n",
            "Epoch 311/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 1.0096e-05 - val_loss: 6.4307e-06\n",
            "Epoch 312/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 8.6911e-06 - val_loss: 5.6003e-06\n",
            "Epoch 313/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 7.2162e-06 - val_loss: 6.3262e-06\n",
            "Epoch 314/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 5.9977e-06 - val_loss: 4.8038e-06\n",
            "Epoch 315/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 5.8115e-06 - val_loss: 6.8067e-06\n",
            "Epoch 316/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 5.6261e-06 - val_loss: 1.0432e-05\n",
            "Epoch 317/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.3840e-06 - val_loss: 1.1094e-05\n",
            "Epoch 318/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 5.7628e-06 - val_loss: 7.1982e-06\n",
            "Epoch 319/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 7.2570e-06 - val_loss: 7.3011e-06\n",
            "Epoch 320/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 8.1274e-06 - val_loss: 1.3481e-05\n",
            "Epoch 321/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 6.7147e-06 - val_loss: 5.5323e-06\n",
            "Epoch 322/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 6.8143e-06 - val_loss: 3.3230e-06\n",
            "Epoch 323/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 6.3316e-06 - val_loss: 1.2755e-05\n",
            "Epoch 324/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 6.5048e-06 - val_loss: 6.8915e-06\n",
            "Epoch 325/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 5.5512e-06 - val_loss: 6.4281e-06\n",
            "Epoch 326/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.0980e-06 - val_loss: 6.8555e-06\n",
            "Epoch 327/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 5.9849e-06 - val_loss: 1.2453e-05\n",
            "Epoch 328/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 6.4061e-06 - val_loss: 4.3110e-06\n",
            "Epoch 329/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 7.6434e-06 - val_loss: 4.2433e-06\n",
            "Epoch 330/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 5.9975e-06 - val_loss: 8.2713e-06\n",
            "Epoch 331/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 7.3135e-06 - val_loss: 2.0905e-05\n",
            "Epoch 332/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 1.1955e-05 - val_loss: 5.8633e-06\n",
            "Epoch 333/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 2.1199e-05 - val_loss: 2.6315e-05\n",
            "Epoch 334/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 2.3281e-05 - val_loss: 1.9967e-05\n",
            "Epoch 335/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 2.0651e-05 - val_loss: 2.4692e-05\n",
            "Epoch 336/2000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 2.0281e-05 - val_loss: 7.3917e-06\n",
            "Epoch 337/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 2.0994e-05 - val_loss: 2.3612e-05\n",
            "Epoch 338/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 1.4176e-05 - val_loss: 1.2483e-05\n",
            "Epoch 339/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 1.9249e-05 - val_loss: 2.0914e-05\n",
            "Epoch 340/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 1.6663e-05 - val_loss: 1.3641e-05\n",
            "Epoch 341/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 1.4731e-05 - val_loss: 2.0550e-05\n",
            "Epoch 342/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 1.1304e-05 - val_loss: 4.4430e-06\n",
            "Epoch 343/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 4.7951e-06 - val_loss: 1.5919e-05\n",
            "Epoch 344/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 6.0200e-06 - val_loss: 5.0744e-06\n",
            "Epoch 345/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 6.1060e-06 - val_loss: 8.7943e-06\n",
            "Epoch 346/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 5.7791e-06 - val_loss: 8.6342e-06\n",
            "Epoch 347/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 4.1932e-06 - val_loss: 1.1292e-05\n",
            "Epoch 348/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 6.5407e-06 - val_loss: 9.7231e-06\n",
            "Epoch 349/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 5.6659e-06 - val_loss: 1.2485e-05\n",
            "Epoch 350/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 9.4052e-06 - val_loss: 1.0447e-05\n",
            "Epoch 351/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.0483e-06 - val_loss: 1.2148e-05\n",
            "Epoch 352/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 1.0904e-05 - val_loss: 1.6657e-05\n",
            "Epoch 353/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 9.4907e-06 - val_loss: 5.3215e-06\n",
            "Epoch 354/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 7.5425e-06 - val_loss: 1.3738e-05\n",
            "Epoch 355/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 5.0876e-06 - val_loss: 6.7428e-06\n",
            "Epoch 356/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 4.1248e-06 - val_loss: 1.1554e-05\n",
            "Epoch 357/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 3.8921e-06 - val_loss: 4.0309e-06\n",
            "Epoch 358/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 5.1794e-06 - val_loss: 7.3775e-06\n",
            "Epoch 359/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 4.0703e-06 - val_loss: 6.2074e-06\n",
            "Epoch 360/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 4.8853e-06 - val_loss: 6.7416e-06\n",
            "Epoch 361/2000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 4.3077e-06 - val_loss: 4.1706e-06\n",
            "Epoch 362/2000\n",
            "80/80 [==============================] - 0s 996us/step - loss: 5.2034e-06 - val_loss: 1.2061e-05\n",
            "Epoch 363/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 4.8191e-06 - val_loss: 4.3000e-06\n",
            "Epoch 364/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 6.0972e-06 - val_loss: 1.3270e-05\n",
            "Epoch 365/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 5.7613e-06 - val_loss: 4.8161e-06\n",
            "Epoch 366/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 6.5719e-06 - val_loss: 8.3014e-06\n",
            "Epoch 367/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.7153e-06 - val_loss: 3.6660e-06\n",
            "Epoch 368/2000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 3.4288e-06 - val_loss: 1.0758e-05\n",
            "Epoch 369/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.7805e-06 - val_loss: 6.7345e-06\n",
            "Epoch 370/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 4.1748e-06 - val_loss: 5.3463e-06\n",
            "Epoch 371/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.7423e-06 - val_loss: 8.4982e-06\n",
            "Epoch 372/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 5.0237e-06 - val_loss: 6.3218e-06\n",
            "Epoch 373/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 4.4623e-06 - val_loss: 6.3351e-06\n",
            "Epoch 374/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 3.5552e-06 - val_loss: 4.0319e-06\n",
            "Epoch 375/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 5.4330e-06 - val_loss: 1.4637e-05\n",
            "Epoch 376/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 5.3121e-06 - val_loss: 5.8029e-06\n",
            "Epoch 377/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 6.1111e-06 - val_loss: 1.1266e-05\n",
            "Epoch 378/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 5.2125e-06 - val_loss: 5.4878e-06\n",
            "Epoch 379/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 3.8398e-06 - val_loss: 7.1700e-06\n",
            "Epoch 380/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.2568e-06 - val_loss: 4.4992e-06\n",
            "Epoch 381/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.5119e-06 - val_loss: 8.4985e-06\n",
            "Epoch 382/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 3.0211e-06 - val_loss: 4.2517e-06\n",
            "Epoch 383/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 4.4403e-06 - val_loss: 6.5918e-06\n",
            "Epoch 384/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 2.7831e-06 - val_loss: 3.8667e-06\n",
            "Epoch 385/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 3.5582e-06 - val_loss: 4.4745e-06\n",
            "Epoch 386/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 3.3257e-06 - val_loss: 6.5661e-06\n",
            "Epoch 387/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7098e-06 - val_loss: 6.0233e-06\n",
            "Epoch 388/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 3.1873e-06 - val_loss: 4.9171e-06\n",
            "Epoch 389/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 2.6680e-06 - val_loss: 1.1239e-05\n",
            "Epoch 390/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 5.1933e-06 - val_loss: 8.0321e-06\n",
            "Epoch 391/2000\n",
            "80/80 [==============================] - 0s 994us/step - loss: 3.5457e-06 - val_loss: 4.4015e-06\n",
            "Epoch 392/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 4.4128e-06 - val_loss: 6.3493e-06\n",
            "Epoch 393/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 2.7370e-06 - val_loss: 3.8448e-06\n",
            "Epoch 394/2000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 4.3750e-06 - val_loss: 9.9485e-06\n",
            "Epoch 395/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 4.8501e-06 - val_loss: 6.2121e-06\n",
            "Epoch 396/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.0291e-06 - val_loss: 1.2120e-05\n",
            "Epoch 397/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 3.0130e-06 - val_loss: 1.5808e-06\n",
            "Epoch 398/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 4.7654e-06 - val_loss: 5.5449e-06\n",
            "Epoch 399/2000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 4.1809e-06 - val_loss: 3.7038e-06\n",
            "Epoch 400/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 3.4821e-06 - val_loss: 3.8682e-06\n",
            "Epoch 401/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 3.3730e-06 - val_loss: 1.0908e-05\n",
            "Epoch 402/2000\n",
            "80/80 [==============================] - 0s 880us/step - loss: 5.6435e-06 - val_loss: 6.2870e-06\n",
            "Epoch 403/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 7.1390e-06 - val_loss: 1.5081e-05\n",
            "Epoch 404/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 8.1621e-06 - val_loss: 1.0562e-05\n",
            "Epoch 405/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.3881e-06 - val_loss: 1.7005e-05\n",
            "Epoch 406/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 5.2218e-06 - val_loss: 2.7173e-06\n",
            "Epoch 407/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 4.0029e-06 - val_loss: 1.4060e-05\n",
            "Epoch 408/2000\n",
            "80/80 [==============================] - 0s 891us/step - loss: 5.6757e-06 - val_loss: 4.9380e-06\n",
            "Epoch 409/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 3.3488e-06 - val_loss: 6.1225e-06\n",
            "Epoch 410/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 3.2017e-06 - val_loss: 7.1095e-06\n",
            "Epoch 411/2000\n",
            "80/80 [==============================] - 0s 983us/step - loss: 4.6657e-06 - val_loss: 6.2750e-06\n",
            "Epoch 412/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 2.5704e-06 - val_loss: 2.2802e-06\n",
            "Epoch 413/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 2.8702e-06 - val_loss: 5.8803e-06\n",
            "Epoch 414/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 2.2540e-06 - val_loss: 7.7882e-06\n",
            "Epoch 415/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8298e-06 - val_loss: 3.8797e-06\n",
            "Epoch 416/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0519e-06 - val_loss: 5.8021e-06\n",
            "Epoch 417/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 2.7094e-06 - val_loss: 5.1391e-06\n",
            "Epoch 418/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 2.9291e-06 - val_loss: 7.2186e-06\n",
            "Epoch 419/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 2.3180e-06 - val_loss: 4.9220e-06\n",
            "Epoch 420/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 2.3328e-06 - val_loss: 3.8136e-06\n",
            "Epoch 421/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 2.1704e-06 - val_loss: 3.7514e-06\n",
            "Epoch 422/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 2.1210e-06 - val_loss: 5.4104e-06\n",
            "Epoch 423/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 3.1215e-06 - val_loss: 5.7979e-06\n",
            "Epoch 424/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 2.2483e-06 - val_loss: 2.5626e-06\n",
            "Epoch 425/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 1.9856e-06 - val_loss: 7.1300e-06\n",
            "Epoch 426/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 2.7902e-06 - val_loss: 2.4946e-06\n",
            "Epoch 427/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 2.3873e-06 - val_loss: 3.6486e-06\n",
            "Epoch 428/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 2.2641e-06 - val_loss: 8.1009e-06\n",
            "Epoch 429/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 2.7444e-06 - val_loss: 6.0652e-06\n",
            "Epoch 430/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 2.8917e-06 - val_loss: 5.8080e-06\n",
            "Epoch 431/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 2.3260e-06 - val_loss: 7.9805e-06\n",
            "Epoch 432/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 2.2975e-06 - val_loss: 5.2823e-06\n",
            "Epoch 433/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 2.1696e-06 - val_loss: 6.6537e-06\n",
            "Epoch 434/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 2.2976e-06 - val_loss: 5.3307e-06\n",
            "Epoch 435/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7627e-06 - val_loss: 4.9480e-06\n",
            "Epoch 436/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 1.8645e-06 - val_loss: 5.3773e-06\n",
            "Epoch 437/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 1.7494e-06 - val_loss: 5.9986e-06\n",
            "Epoch 438/2000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 1.7855e-06 - val_loss: 2.5162e-06\n",
            "Epoch 439/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 1.6332e-06 - val_loss: 9.3397e-06\n",
            "Epoch 440/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 3.3667e-06 - val_loss: 5.0813e-06\n",
            "Epoch 441/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3374e-06 - val_loss: 4.0720e-06\n",
            "Epoch 442/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0378e-06 - val_loss: 6.0009e-06\n",
            "Epoch 443/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8851e-06 - val_loss: 4.3003e-06\n",
            "Epoch 444/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0961e-06 - val_loss: 5.9992e-06\n",
            "Epoch 445/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 1.7746e-06 - val_loss: 2.1193e-06\n",
            "Epoch 446/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 2.4542e-06 - val_loss: 6.5788e-06\n",
            "Epoch 447/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 2.2835e-06 - val_loss: 6.6140e-06\n",
            "Epoch 448/2000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 3.4340e-06 - val_loss: 2.6303e-06\n",
            "Epoch 449/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.0499e-06 - val_loss: 1.0176e-05\n",
            "Epoch 450/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 2.9990e-06 - val_loss: 2.1620e-06\n",
            "Epoch 451/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 5.8083e-06 - val_loss: 3.8739e-06\n",
            "Epoch 452/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 4.7949e-06 - val_loss: 1.4549e-05\n",
            "Epoch 453/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 5.2492e-06 - val_loss: 1.8301e-06\n",
            "Epoch 454/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 3.7348e-06 - val_loss: 1.0916e-05\n",
            "Epoch 455/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 5.3333e-06 - val_loss: 6.9679e-06\n",
            "Epoch 456/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 5.4710e-06 - val_loss: 5.3341e-06\n",
            "Epoch 457/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 3.5586e-06 - val_loss: 3.8456e-06\n",
            "Epoch 458/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 4.5270e-06 - val_loss: 4.7346e-06\n",
            "Epoch 459/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 2.4207e-06 - val_loss: 4.0944e-06\n",
            "Epoch 460/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 2.2600e-06 - val_loss: 9.1834e-06\n",
            "Epoch 461/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 1.9588e-06 - val_loss: 3.9655e-06\n",
            "Epoch 462/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.1451e-06 - val_loss: 4.8966e-06\n",
            "Epoch 463/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3027e-06 - val_loss: 3.7853e-06\n",
            "Epoch 464/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3308e-06 - val_loss: 2.7954e-06\n",
            "Epoch 465/2000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 2.4565e-06 - val_loss: 9.3149e-06\n",
            "Epoch 466/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 2.6787e-06 - val_loss: 2.7326e-06\n",
            "Epoch 467/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 3.8533e-06 - val_loss: 5.2730e-06\n",
            "Epoch 468/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 2.9867e-06 - val_loss: 6.2220e-06\n",
            "Epoch 469/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 2.3046e-06 - val_loss: 5.3793e-06\n",
            "Epoch 470/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8102e-06 - val_loss: 8.0802e-06\n",
            "Epoch 471/2000\n",
            "80/80 [==============================] - 0s 983us/step - loss: 1.9320e-06 - val_loss: 2.5311e-06\n",
            "Epoch 472/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 3.1568e-06 - val_loss: 4.3996e-06\n",
            "Epoch 473/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 1.8807e-06 - val_loss: 4.5918e-06\n",
            "Epoch 474/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8673e-06 - val_loss: 3.4502e-06\n",
            "Epoch 475/2000\n",
            "80/80 [==============================] - 0s 995us/step - loss: 1.9640e-06 - val_loss: 2.4646e-06\n",
            "Epoch 476/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 1.9295e-06 - val_loss: 5.0979e-06\n",
            "Epoch 477/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 1.8763e-06 - val_loss: 3.8361e-06\n",
            "Epoch 478/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 1.6898e-06 - val_loss: 2.7406e-06\n",
            "Epoch 479/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 1.5349e-06 - val_loss: 3.0049e-06\n",
            "Epoch 480/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4584e-06 - val_loss: 3.7379e-06\n",
            "Epoch 481/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 1.4702e-06 - val_loss: 2.9053e-06\n",
            "Epoch 482/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 1.2933e-06 - val_loss: 3.8741e-06\n",
            "Epoch 483/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 1.3673e-06 - val_loss: 3.6433e-06\n",
            "Epoch 484/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 1.6300e-06 - val_loss: 9.4455e-06\n",
            "Epoch 485/2000\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 2.7382e-06 - val_loss: 2.6120e-06\n",
            "Epoch 486/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 2.1359e-06 - val_loss: 9.8353e-06\n",
            "Epoch 487/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 3.6447e-06 - val_loss: 6.2108e-06\n",
            "Epoch 488/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 2.3459e-06 - val_loss: 2.4939e-06\n",
            "Epoch 489/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 2.1096e-06 - val_loss: 6.7190e-06\n",
            "Epoch 490/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 1.6181e-06 - val_loss: 3.5877e-06\n",
            "Epoch 491/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 2.4001e-06 - val_loss: 7.5655e-06\n",
            "Epoch 492/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 2.0209e-06 - val_loss: 6.3472e-06\n",
            "Epoch 493/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 1.6524e-06 - val_loss: 4.1381e-06\n",
            "Epoch 494/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.1466e-06 - val_loss: 1.0074e-05\n",
            "Epoch 495/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 3.1057e-06 - val_loss: 5.9684e-06\n",
            "Epoch 496/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 2.0919e-06 - val_loss: 1.5809e-06\n",
            "Epoch 497/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 2.4696e-06 - val_loss: 6.3162e-06\n",
            "Epoch 498/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 1.5721e-06 - val_loss: 4.5816e-06\n",
            "Epoch 499/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 1.4842e-06 - val_loss: 5.7603e-06\n",
            "Epoch 500/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0016e-06 - val_loss: 7.0852e-06\n",
            "Epoch 501/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.5454e-06 - val_loss: 2.7223e-06\n",
            "Epoch 502/2000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 1.9417e-06 - val_loss: 4.6963e-06\n",
            "Epoch 503/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 2.0628e-06 - val_loss: 6.1904e-06\n",
            "Epoch 504/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 2.0731e-06 - val_loss: 2.2398e-06\n",
            "Epoch 505/2000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 4.5592e-06 - val_loss: 5.7884e-06\n",
            "Epoch 506/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 2.9170e-06 - val_loss: 8.6808e-06\n",
            "Epoch 507/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 2.4938e-06 - val_loss: 3.0126e-06\n",
            "Epoch 508/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 3.3286e-06 - val_loss: 3.5126e-06\n",
            "Epoch 509/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 2.0134e-06 - val_loss: 2.8724e-06\n",
            "Epoch 510/2000\n",
            "80/80 [==============================] - 0s 894us/step - loss: 1.3546e-06 - val_loss: 5.5039e-06\n",
            "Epoch 511/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 1.5264e-06 - val_loss: 3.6259e-06\n",
            "Epoch 512/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 1.4899e-06 - val_loss: 2.7304e-06\n",
            "Epoch 513/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 1.3143e-06 - val_loss: 8.2176e-06\n",
            "Epoch 514/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0408e-06 - val_loss: 4.3941e-06\n",
            "Epoch 515/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 1.7571e-06 - val_loss: 3.7774e-06\n",
            "Epoch 516/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 1.6327e-06 - val_loss: 5.9393e-06\n",
            "Epoch 517/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0143e-06 - val_loss: 4.7527e-06\n",
            "Epoch 518/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 1.7298e-06 - val_loss: 4.2614e-06\n",
            "Epoch 519/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 2.7992e-06 - val_loss: 2.8439e-06\n",
            "Epoch 520/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 2.0992e-06 - val_loss: 6.4657e-06\n",
            "Epoch 521/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 3.4428e-06 - val_loss: 4.5608e-06\n",
            "Epoch 522/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 2.4213e-06 - val_loss: 3.9645e-06\n",
            "Epoch 523/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 3.7107e-06 - val_loss: 1.5082e-05\n",
            "Epoch 524/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 3.6953e-06 - val_loss: 2.9931e-06\n",
            "Epoch 525/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 2.0804e-06 - val_loss: 6.8267e-06\n",
            "Epoch 526/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4538e-06 - val_loss: 5.4639e-06\n",
            "Epoch 527/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 2.7726e-06 - val_loss: 1.4588e-06\n",
            "Epoch 528/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 2.0089e-06 - val_loss: 7.9050e-06\n",
            "Epoch 529/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 2.4313e-06 - val_loss: 5.1947e-06\n",
            "Epoch 530/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 1.9671e-06 - val_loss: 2.2078e-06\n",
            "Epoch 531/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 1.9803e-06 - val_loss: 9.3868e-06\n",
            "Epoch 532/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.1863e-06 - val_loss: 1.6309e-06\n",
            "Epoch 533/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 5.6297e-06 - val_loss: 6.6070e-06\n",
            "Epoch 534/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 4.9633e-06 - val_loss: 1.0863e-05\n",
            "Epoch 535/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 6.5202e-06 - val_loss: 3.6857e-06\n",
            "Epoch 536/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 8.7527e-06 - val_loss: 1.2546e-05\n",
            "Epoch 537/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 8.2479e-06 - val_loss: 5.5890e-06\n",
            "Epoch 538/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 6.2760e-06 - val_loss: 1.5969e-06\n",
            "Epoch 539/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 3.4309e-06 - val_loss: 1.2008e-05\n",
            "Epoch 540/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 3.0996e-06 - val_loss: 4.4057e-06\n",
            "Epoch 541/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.5492e-06 - val_loss: 2.6613e-06\n",
            "Epoch 542/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 2.5030e-06 - val_loss: 4.8779e-06\n",
            "Epoch 543/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 2.6565e-06 - val_loss: 5.5880e-06\n",
            "Epoch 544/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 2.8644e-06 - val_loss: 4.2442e-06\n",
            "Epoch 545/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 4.4954e-06 - val_loss: 5.7502e-06\n",
            "Epoch 546/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8708e-06 - val_loss: 1.0402e-05\n",
            "Epoch 547/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 2.6500e-06 - val_loss: 2.8203e-06\n",
            "Epoch 548/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 2.4134e-06 - val_loss: 6.3929e-06\n",
            "Epoch 549/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 1.9967e-06 - val_loss: 9.2562e-06\n",
            "Epoch 550/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3799e-06 - val_loss: 2.9284e-06\n",
            "Epoch 551/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 3.3517e-06 - val_loss: 8.2359e-06\n",
            "Epoch 552/2000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 3.9906e-06 - val_loss: 7.4637e-06\n",
            "Epoch 553/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.6220e-06 - val_loss: 2.0202e-05\n",
            "Epoch 554/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1445e-05 - val_loss: 1.5048e-05\n",
            "Epoch 555/2000\n",
            "80/80 [==============================] - 0s 883us/step - loss: 1.4563e-05 - val_loss: 1.8081e-06\n",
            "Epoch 556/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 1.1130e-05 - val_loss: 1.7910e-05\n",
            "Epoch 557/2000\n",
            "80/80 [==============================] - 0s 993us/step - loss: 1.0471e-05 - val_loss: 1.3662e-05\n",
            "Epoch 558/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 6.5512e-06 - val_loss: 3.6175e-06\n",
            "Epoch 559/2000\n",
            "80/80 [==============================] - 0s 876us/step - loss: 4.4799e-06 - val_loss: 1.0821e-05\n",
            "Epoch 560/2000\n",
            "80/80 [==============================] - 0s 891us/step - loss: 4.2951e-06 - val_loss: 3.4561e-06\n",
            "Epoch 561/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 2.5970e-06 - val_loss: 4.1915e-06\n",
            "Epoch 562/2000\n",
            "80/80 [==============================] - 0s 989us/step - loss: 3.0392e-06 - val_loss: 1.7189e-05\n",
            "Epoch 563/2000\n",
            "80/80 [==============================] - 0s 889us/step - loss: 4.4106e-06 - val_loss: 2.8304e-06\n",
            "Epoch 564/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 2.5203e-06 - val_loss: 3.6103e-06\n",
            "Epoch 565/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 1.5988e-06 - val_loss: 5.6535e-06\n",
            "Epoch 566/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 1.8092e-06 - val_loss: 2.4438e-06\n",
            "Epoch 567/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 1.7046e-06 - val_loss: 5.7554e-06\n",
            "Epoch 568/2000\n",
            "80/80 [==============================] - 0s 882us/step - loss: 1.5076e-06 - val_loss: 6.0383e-06\n",
            "Epoch 569/2000\n",
            "80/80 [==============================] - 0s 889us/step - loss: 2.1556e-06 - val_loss: 1.9707e-06\n",
            "Epoch 570/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 2.8074e-06 - val_loss: 1.0584e-05\n",
            "Epoch 571/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8782e-06 - val_loss: 5.3545e-06\n",
            "Epoch 572/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 2.0182e-06 - val_loss: 2.5710e-06\n",
            "Epoch 573/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 1.3749e-06 - val_loss: 4.1846e-06\n",
            "Epoch 574/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 1.2514e-06 - val_loss: 1.7998e-06\n",
            "Epoch 575/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7269e-06 - val_loss: 3.9075e-06\n",
            "Epoch 576/2000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 1.5453e-06 - val_loss: 5.5634e-06\n",
            "Epoch 577/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 1.7057e-06 - val_loss: 3.0423e-06\n",
            "Epoch 578/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1691e-06 - val_loss: 2.3764e-06\n",
            "Epoch 579/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 1.1268e-06 - val_loss: 2.1070e-06\n",
            "Epoch 580/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 1.0723e-06 - val_loss: 3.7244e-06\n",
            "Epoch 581/2000\n",
            "80/80 [==============================] - 0s 894us/step - loss: 1.0859e-06 - val_loss: 2.1696e-06\n",
            "Epoch 582/2000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 1.1233e-06 - val_loss: 6.0722e-06\n",
            "Epoch 583/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8381e-06 - val_loss: 3.7046e-06\n",
            "Epoch 584/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 1.4444e-06 - val_loss: 1.8982e-06\n",
            "Epoch 585/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 2.9738e-06 - val_loss: 5.0819e-06\n",
            "Epoch 586/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 1.2934e-06 - val_loss: 3.0634e-06\n",
            "Epoch 587/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4522e-06 - val_loss: 3.2833e-06\n",
            "Epoch 588/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 1.6410e-06 - val_loss: 8.6128e-06\n",
            "Epoch 589/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 2.0478e-06 - val_loss: 2.7613e-06\n",
            "Epoch 590/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 1.7370e-06 - val_loss: 3.0012e-06\n",
            "Epoch 591/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 1.4771e-06 - val_loss: 4.0373e-06\n",
            "Epoch 592/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3127e-06 - val_loss: 3.1360e-06\n",
            "Epoch 593/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 1.2850e-06 - val_loss: 3.1379e-06\n",
            "Epoch 594/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0537e-06 - val_loss: 2.7840e-06\n",
            "Epoch 595/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7206e-06 - val_loss: 1.0090e-06\n",
            "Epoch 596/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.1649e-06 - val_loss: 4.6494e-06\n",
            "Epoch 597/2000\n",
            "80/80 [==============================] - 0s 983us/step - loss: 1.9503e-06 - val_loss: 4.5934e-06\n",
            "Epoch 598/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 2.0303e-06 - val_loss: 1.7997e-06\n",
            "Epoch 599/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3810e-06 - val_loss: 2.0738e-06\n",
            "Epoch 600/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 1.2091e-06 - val_loss: 3.1624e-06\n",
            "Epoch 601/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 1.3359e-06 - val_loss: 2.7888e-06\n",
            "Epoch 602/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 1.1408e-06 - val_loss: 3.5549e-06\n",
            "Epoch 603/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 1.0814e-06 - val_loss: 2.6053e-06\n",
            "Epoch 604/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 1.3163e-06 - val_loss: 4.1016e-06\n",
            "Epoch 605/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 1.2011e-06 - val_loss: 3.1617e-06\n",
            "Epoch 606/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8142e-06 - val_loss: 1.6873e-06\n",
            "Epoch 607/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 2.1408e-06 - val_loss: 4.5708e-06\n",
            "Epoch 608/2000\n",
            "80/80 [==============================] - 0s 890us/step - loss: 1.0655e-06 - val_loss: 2.3116e-06\n",
            "Epoch 609/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 1.3682e-06 - val_loss: 4.2959e-06\n",
            "Epoch 610/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1994e-06 - val_loss: 5.4246e-06\n",
            "Epoch 611/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 1.3884e-06 - val_loss: 2.2201e-06\n",
            "Epoch 612/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 1.6155e-06 - val_loss: 5.1328e-06\n",
            "Epoch 613/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 1.2232e-06 - val_loss: 2.8385e-06\n",
            "Epoch 614/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 1.1849e-06 - val_loss: 1.8058e-06\n",
            "Epoch 615/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.5346e-06 - val_loss: 2.4793e-06\n",
            "Epoch 616/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 1.7081e-06 - val_loss: 9.0478e-06\n",
            "Epoch 617/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 3.9816e-06 - val_loss: 3.1721e-06\n",
            "Epoch 618/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 3.0065e-06 - val_loss: 1.7379e-06\n",
            "Epoch 619/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 2.5134e-06 - val_loss: 1.0042e-05\n",
            "Epoch 620/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 4.5180e-06 - val_loss: 7.6405e-07\n",
            "Epoch 621/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 3.4615e-06 - val_loss: 1.8923e-06\n",
            "Epoch 622/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 3.9671e-06 - val_loss: 8.3931e-06\n",
            "Epoch 623/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.5366e-06 - val_loss: 7.6030e-06\n",
            "Epoch 624/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 3.8902e-06 - val_loss: 4.6503e-06\n",
            "Epoch 625/2000\n",
            "80/80 [==============================] - 0s 898us/step - loss: 7.1417e-06 - val_loss: 9.2538e-07\n",
            "Epoch 626/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 5.2981e-06 - val_loss: 1.8710e-05\n",
            "Epoch 627/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 8.6790e-06 - val_loss: 3.5270e-06\n",
            "Epoch 628/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 1.1818e-05 - val_loss: 1.8716e-06\n",
            "Epoch 629/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 7.2405e-06 - val_loss: 6.3073e-06\n",
            "Epoch 630/2000\n",
            "80/80 [==============================] - 0s 992us/step - loss: 3.9766e-06 - val_loss: 2.1676e-06\n",
            "Epoch 631/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 2.6540e-06 - val_loss: 7.6919e-06\n",
            "Epoch 632/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.5378e-06 - val_loss: 6.1189e-06\n",
            "Epoch 633/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 4.2704e-06 - val_loss: 3.0824e-06\n",
            "Epoch 634/2000\n",
            "80/80 [==============================] - 0s 983us/step - loss: 2.3059e-06 - val_loss: 5.6256e-06\n",
            "Epoch 635/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 1.4593e-06 - val_loss: 1.8041e-06\n",
            "Epoch 636/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 2.0917e-06 - val_loss: 4.4633e-06\n",
            "Epoch 637/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 2.2081e-06 - val_loss: 2.1936e-06\n",
            "Epoch 638/2000\n",
            "80/80 [==============================] - 0s 992us/step - loss: 1.6901e-06 - val_loss: 8.0156e-06\n",
            "Epoch 639/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3170e-06 - val_loss: 3.4143e-06\n",
            "Epoch 640/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 3.9092e-06 - val_loss: 1.1423e-06\n",
            "Epoch 641/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 3.4183e-06 - val_loss: 1.2127e-05\n",
            "Epoch 642/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 3.3136e-06 - val_loss: 4.1219e-06\n",
            "Epoch 643/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.1277e-06 - val_loss: 2.4189e-06\n",
            "Epoch 644/2000\n",
            "80/80 [==============================] - 0s 884us/step - loss: 2.5374e-06 - val_loss: 5.0169e-06\n",
            "Epoch 645/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 3.0967e-06 - val_loss: 1.1679e-06\n",
            "Epoch 646/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 2.6773e-06 - val_loss: 1.3556e-05\n",
            "Epoch 647/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.8033e-06 - val_loss: 1.3642e-05\n",
            "Epoch 648/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 5.9457e-06 - val_loss: 1.1767e-05\n",
            "Epoch 649/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 5.1710e-06 - val_loss: 4.7407e-06\n",
            "Epoch 650/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 1.0780e-05 - val_loss: 6.0511e-06\n",
            "Epoch 651/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 7.2386e-06 - val_loss: 1.7620e-05\n",
            "Epoch 652/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 5.2844e-06 - val_loss: 2.9134e-06\n",
            "Epoch 653/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 6.2102e-06 - val_loss: 8.3082e-06\n",
            "Epoch 654/2000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 9.2563e-06 - val_loss: 4.5308e-06\n",
            "Epoch 655/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 5.9396e-06 - val_loss: 8.5320e-06\n",
            "Epoch 656/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 5.3829e-06 - val_loss: 7.6143e-06\n",
            "Epoch 657/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.8726e-06 - val_loss: 9.3361e-07\n",
            "Epoch 658/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 4.3410e-06 - val_loss: 1.3394e-05\n",
            "Epoch 659/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 5.2357e-06 - val_loss: 2.2325e-06\n",
            "Epoch 660/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 4.1263e-06 - val_loss: 6.5185e-06\n",
            "Epoch 661/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 3.0049e-06 - val_loss: 2.5798e-06\n",
            "Epoch 662/2000\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 4.7515e-06 - val_loss: 6.1316e-06\n",
            "Epoch 663/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 2.4400e-06 - val_loss: 5.7037e-06\n",
            "Epoch 664/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 3.1782e-06 - val_loss: 1.0572e-06\n",
            "Epoch 665/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 1.6444e-06 - val_loss: 5.8228e-06\n",
            "Epoch 666/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 4.5669e-06 - val_loss: 2.0453e-06\n",
            "Epoch 667/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 4.3609e-06 - val_loss: 6.3849e-06\n",
            "Epoch 668/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 4.2926e-06 - val_loss: 3.6185e-06\n",
            "Epoch 669/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 3.4789e-06 - val_loss: 4.7503e-06\n",
            "Epoch 670/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 3.9891e-06 - val_loss: 2.9702e-06\n",
            "Epoch 671/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.1831e-06 - val_loss: 2.0447e-06\n",
            "Epoch 672/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 3.7822e-06 - val_loss: 5.9724e-06\n",
            "Epoch 673/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 2.1617e-06 - val_loss: 6.6633e-06\n",
            "Epoch 674/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 2.9621e-06 - val_loss: 8.5912e-06\n",
            "Epoch 675/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 5.2275e-06 - val_loss: 2.0903e-06\n",
            "Epoch 676/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 4.3886e-06 - val_loss: 2.5303e-06\n",
            "Epoch 677/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 3.3600e-06 - val_loss: 1.0906e-05\n",
            "Epoch 678/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 4.3857e-06 - val_loss: 1.1731e-06\n",
            "Epoch 679/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 2.0775e-06 - val_loss: 1.2199e-05\n",
            "Epoch 680/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 4.5383e-06 - val_loss: 4.9228e-06\n",
            "Epoch 681/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 3.9879e-06 - val_loss: 4.4360e-06\n",
            "Epoch 682/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 8.1512e-06 - val_loss: 8.2327e-06\n",
            "Epoch 683/2000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 9.3382e-06 - val_loss: 1.7116e-05\n",
            "Epoch 684/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 8.0995e-06 - val_loss: 7.2541e-06\n",
            "Epoch 685/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 9.6877e-06 - val_loss: 3.9418e-06\n",
            "Epoch 686/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1853e-05 - val_loss: 1.5184e-05\n",
            "Epoch 687/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.9921e-06 - val_loss: 9.4233e-06\n",
            "Epoch 688/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.1021e-06 - val_loss: 1.0595e-06\n",
            "Epoch 689/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 2.8535e-06 - val_loss: 1.5306e-05\n",
            "Epoch 690/2000\n",
            "80/80 [==============================] - 0s 883us/step - loss: 7.3117e-06 - val_loss: 1.5133e-05\n",
            "Epoch 691/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 6.5665e-06 - val_loss: 8.5540e-06\n",
            "Epoch 692/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 6.8377e-06 - val_loss: 1.5909e-06\n",
            "Epoch 693/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 5.7420e-06 - val_loss: 3.3612e-06\n",
            "Epoch 694/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 5.8357e-06 - val_loss: 1.1838e-05\n",
            "Epoch 695/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.1292e-06 - val_loss: 2.3616e-06\n",
            "Epoch 696/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 3.4916e-06 - val_loss: 3.7790e-06\n",
            "Epoch 697/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 1.8364e-06 - val_loss: 1.0086e-05\n",
            "Epoch 698/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 3.4652e-06 - val_loss: 3.4000e-06\n",
            "Epoch 699/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 2.4673e-06 - val_loss: 1.5761e-06\n",
            "Epoch 700/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 4.6582e-06 - val_loss: 2.2125e-06\n",
            "Epoch 701/2000\n",
            "80/80 [==============================] - 0s 891us/step - loss: 3.1259e-06 - val_loss: 1.1537e-05\n",
            "Epoch 702/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 3.3173e-06 - val_loss: 1.0714e-06\n",
            "Epoch 703/2000\n",
            "80/80 [==============================] - 0s 977us/step - loss: 2.3054e-06 - val_loss: 3.1435e-06\n",
            "Epoch 704/2000\n",
            "80/80 [==============================] - 0s 889us/step - loss: 4.0522e-06 - val_loss: 3.1288e-06\n",
            "Epoch 705/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 2.0833e-06 - val_loss: 9.1588e-06\n",
            "Epoch 706/2000\n",
            "80/80 [==============================] - 0s 983us/step - loss: 4.8419e-06 - val_loss: 7.6552e-06\n",
            "Epoch 707/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 3.8321e-06 - val_loss: 1.7156e-06\n",
            "Epoch 708/2000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 6.2033e-06 - val_loss: 1.6888e-06\n",
            "Epoch 709/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 5.0647e-06 - val_loss: 8.3745e-06\n",
            "Epoch 710/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 6.0658e-06 - val_loss: 5.0325e-06\n",
            "Epoch 711/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.1926e-06 - val_loss: 5.5025e-06\n",
            "Epoch 712/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.2820e-06 - val_loss: 1.0014e-06\n",
            "Epoch 713/2000\n",
            "80/80 [==============================] - 0s 992us/step - loss: 5.9988e-06 - val_loss: 8.9760e-06\n",
            "Epoch 714/2000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 4.9799e-06 - val_loss: 1.4101e-06\n",
            "Epoch 715/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 4.0731e-06 - val_loss: 4.5393e-06\n",
            "Epoch 716/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 7.7517e-06 - val_loss: 3.2851e-06\n",
            "Epoch 717/2000\n",
            "80/80 [==============================] - 0s 977us/step - loss: 5.3490e-06 - val_loss: 9.7039e-06\n",
            "Epoch 718/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.6645e-06 - val_loss: 3.6102e-06\n",
            "Epoch 719/2000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 4.7364e-06 - val_loss: 1.4737e-06\n",
            "Epoch 720/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 8.3806e-06 - val_loss: 6.0674e-06\n",
            "Epoch 721/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 9.2455e-06 - val_loss: 1.7140e-05\n",
            "Epoch 722/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 1.2699e-05 - val_loss: 1.5294e-05\n",
            "Epoch 723/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3473e-05 - val_loss: 1.0658e-05\n",
            "Epoch 724/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 2.8514e-05 - val_loss: 3.1406e-06\n",
            "Epoch 725/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 2.2636e-05 - val_loss: 2.2725e-05\n",
            "Epoch 726/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 2.2618e-05 - val_loss: 2.4821e-06\n",
            "Epoch 727/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 1.6882e-05 - val_loss: 2.0662e-05\n",
            "Epoch 728/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 1.9594e-05 - val_loss: 1.9360e-05\n",
            "Epoch 729/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 1.9557e-05 - val_loss: 6.2291e-05\n",
            "Epoch 730/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 2.2271e-05 - val_loss: 2.1728e-06\n",
            "Epoch 731/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 9.6616e-06 - val_loss: 7.3665e-06\n",
            "Epoch 732/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 1.1624e-05 - val_loss: 5.7550e-06\n",
            "Epoch 733/2000\n",
            "80/80 [==============================] - 0s 898us/step - loss: 4.9814e-06 - val_loss: 4.4676e-05\n",
            "Epoch 734/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 1.7752e-05 - val_loss: 3.8125e-05\n",
            "Epoch 735/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4972e-05 - val_loss: 7.9379e-06\n",
            "Epoch 736/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 1.1529e-05 - val_loss: 8.1292e-06\n",
            "Epoch 737/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 6.4328e-06 - val_loss: 7.1894e-06\n",
            "Epoch 738/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 3.2361e-06 - val_loss: 2.7204e-06\n",
            "Epoch 739/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 2.3870e-06 - val_loss: 7.0015e-06\n",
            "Epoch 740/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 3.6019e-06 - val_loss: 3.2451e-06\n",
            "Epoch 741/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 2.9125e-06 - val_loss: 6.2856e-06\n",
            "Epoch 742/2000\n",
            "80/80 [==============================] - 0s 892us/step - loss: 1.7450e-06 - val_loss: 2.7212e-06\n",
            "Epoch 743/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 1.9778e-06 - val_loss: 8.8070e-06\n",
            "Epoch 744/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.5003e-06 - val_loss: 3.4656e-06\n",
            "Epoch 745/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.0177e-06 - val_loss: 1.2061e-06\n",
            "Epoch 746/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 2.5971e-06 - val_loss: 4.8877e-06\n",
            "Epoch 747/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 1.9158e-06 - val_loss: 1.0961e-05\n",
            "Epoch 748/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 4.0688e-06 - val_loss: 3.6003e-06\n",
            "Epoch 749/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2880e-06 - val_loss: 1.6586e-06\n",
            "Epoch 750/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 2.8109e-06 - val_loss: 1.2173e-06\n",
            "Epoch 751/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 2.6096e-06 - val_loss: 2.6994e-06\n",
            "Epoch 752/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 1.3928e-06 - val_loss: 4.5010e-06\n",
            "Epoch 753/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 1.1191e-06 - val_loss: 1.3990e-06\n",
            "Epoch 754/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 2.1390e-06 - val_loss: 3.9212e-06\n",
            "Epoch 755/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 1.5211e-06 - val_loss: 2.8707e-06\n",
            "Epoch 756/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 1.3701e-06 - val_loss: 1.4327e-06\n",
            "Epoch 757/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.8494e-07 - val_loss: 3.4946e-06\n",
            "Epoch 758/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 1.3105e-06 - val_loss: 5.4995e-06\n",
            "Epoch 759/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8712e-06 - val_loss: 8.0590e-07\n",
            "Epoch 760/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 1.5608e-06 - val_loss: 4.7149e-06\n",
            "Epoch 761/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 1.7804e-06 - val_loss: 1.0977e-05\n",
            "Epoch 762/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 3.4758e-06 - val_loss: 4.3246e-06\n",
            "Epoch 763/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 1.8240e-06 - val_loss: 1.4232e-06\n",
            "Epoch 764/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 3.8352e-06 - val_loss: 2.4985e-06\n",
            "Epoch 765/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 2.2450e-06 - val_loss: 8.7617e-06\n",
            "Epoch 766/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 3.2572e-06 - val_loss: 4.7709e-06\n",
            "Epoch 767/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 2.3463e-06 - val_loss: 5.3543e-06\n",
            "Epoch 768/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 1.9443e-06 - val_loss: 1.3296e-06\n",
            "Epoch 769/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 3.3189e-06 - val_loss: 2.7237e-06\n",
            "Epoch 770/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 2.3828e-06 - val_loss: 8.1611e-07\n",
            "Epoch 771/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 2.1020e-06 - val_loss: 1.1289e-06\n",
            "Epoch 772/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 2.1695e-06 - val_loss: 3.4874e-06\n",
            "Epoch 773/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 3.0753e-06 - val_loss: 9.7060e-06\n",
            "Epoch 774/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 4.7819e-06 - val_loss: 8.7147e-06\n",
            "Epoch 775/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 3.5228e-06 - val_loss: 1.3357e-06\n",
            "Epoch 776/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.5983e-06 - val_loss: 7.8667e-06\n",
            "Epoch 777/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 4.9077e-06 - val_loss: 2.1168e-06\n",
            "Epoch 778/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 5.4322e-06 - val_loss: 6.9019e-06\n",
            "Epoch 779/2000\n",
            "80/80 [==============================] - 0s 874us/step - loss: 3.0331e-06 - val_loss: 1.3178e-06\n",
            "Epoch 780/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 2.2382e-06 - val_loss: 2.0289e-06\n",
            "Epoch 781/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7666e-06 - val_loss: 1.0977e-06\n",
            "Epoch 782/2000\n",
            "80/80 [==============================] - 0s 882us/step - loss: 2.1933e-06 - val_loss: 9.8423e-06\n",
            "Epoch 783/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 4.9741e-06 - val_loss: 2.6427e-06\n",
            "Epoch 784/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 7.6709e-06 - val_loss: 5.3832e-06\n",
            "Epoch 785/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 1.1039e-05 - val_loss: 1.1128e-05\n",
            "Epoch 786/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 1.2986e-05 - val_loss: 2.9517e-05\n",
            "Epoch 787/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 1.8266e-05 - val_loss: 1.5754e-05\n",
            "Epoch 788/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 3.2445e-05 - val_loss: 5.7174e-06\n",
            "Epoch 789/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 4.9521e-05 - val_loss: 6.6336e-05\n",
            "Epoch 790/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.6264e-05 - val_loss: 1.9992e-05\n",
            "Epoch 791/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 3.8291e-05 - val_loss: 4.9674e-05\n",
            "Epoch 792/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 5.6014e-05 - val_loss: 4.1818e-05\n",
            "Epoch 793/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 2.7383e-05 - val_loss: 7.6231e-06\n",
            "Epoch 794/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 2.3169e-05 - val_loss: 1.3458e-05\n",
            "Epoch 795/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 1.7828e-05 - val_loss: 1.8636e-05\n",
            "Epoch 796/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 1.4686e-05 - val_loss: 1.8478e-05\n",
            "Epoch 797/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 1.5454e-05 - val_loss: 7.9686e-06\n",
            "Epoch 798/2000\n",
            "80/80 [==============================] - 0s 983us/step - loss: 9.6297e-06 - val_loss: 2.7987e-05\n",
            "Epoch 799/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1385e-05 - val_loss: 2.3589e-05\n",
            "Epoch 800/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 1.1154e-05 - val_loss: 1.5080e-05\n",
            "Epoch 801/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 7.6207e-06 - val_loss: 1.4788e-06\n",
            "Epoch 802/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 5.7798e-06 - val_loss: 3.1892e-05\n",
            "Epoch 803/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 1.7702e-05 - val_loss: 1.0665e-05\n",
            "Epoch 804/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 8.3841e-06 - val_loss: 1.7313e-06\n",
            "Epoch 805/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 3.1797e-06 - val_loss: 1.1973e-05\n",
            "Epoch 806/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 5.1262e-06 - val_loss: 1.5787e-05\n",
            "Epoch 807/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 6.3282e-06 - val_loss: 5.4329e-06\n",
            "Epoch 808/2000\n",
            "80/80 [==============================] - 0s 885us/step - loss: 4.0665e-06 - val_loss: 2.8657e-06\n",
            "Epoch 809/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.9329e-06 - val_loss: 1.0206e-05\n",
            "Epoch 810/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 2.5251e-06 - val_loss: 8.2890e-06\n",
            "Epoch 811/2000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 4.9231e-06 - val_loss: 9.4377e-06\n",
            "Epoch 812/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 4.0828e-06 - val_loss: 1.9531e-06\n",
            "Epoch 813/2000\n",
            "80/80 [==============================] - 0s 993us/step - loss: 8.4748e-06 - val_loss: 7.7029e-06\n",
            "Epoch 814/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 7.0096e-06 - val_loss: 2.1283e-06\n",
            "Epoch 815/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 5.2893e-06 - val_loss: 1.2807e-05\n",
            "Epoch 816/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 1.2057e-05 - val_loss: 2.1780e-05\n",
            "Epoch 817/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 1.6259e-05 - val_loss: 3.8269e-06\n",
            "Epoch 818/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 2.1424e-05 - val_loss: 4.7498e-05\n",
            "Epoch 819/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 3.4242e-05 - val_loss: 6.8945e-06\n",
            "Epoch 820/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 2.7894e-05 - val_loss: 7.2824e-05\n",
            "Epoch 821/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 5.6375e-05 - val_loss: 1.0165e-04\n",
            "Epoch 822/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 5.5749e-05 - val_loss: 2.5787e-06\n",
            "Epoch 823/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 2.8452e-05 - val_loss: 5.4945e-05\n",
            "Epoch 824/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 7.9036e-05 - val_loss: 8.8324e-05\n",
            "Epoch 825/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 5.3887e-05 - val_loss: 8.3192e-05\n",
            "Epoch 826/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.1275e-05 - val_loss: 9.6568e-05\n",
            "Epoch 827/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 5.7429e-05 - val_loss: 8.2653e-05\n",
            "Epoch 828/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 6.3463e-05 - val_loss: 6.0896e-05\n",
            "Epoch 829/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 5.4659e-05 - val_loss: 1.9555e-05\n",
            "Epoch 830/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 4.7384e-05 - val_loss: 3.5754e-05\n",
            "Epoch 831/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 4.8818e-05 - val_loss: 3.9533e-05\n",
            "Epoch 832/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 2.2130e-05 - val_loss: 1.3751e-05\n",
            "Epoch 833/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 2.7411e-05 - val_loss: 1.5978e-05\n",
            "Epoch 834/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 2.7623e-05 - val_loss: 3.5054e-05\n",
            "Epoch 835/2000\n",
            "80/80 [==============================] - 0s 878us/step - loss: 3.6288e-05 - val_loss: 3.3220e-05\n",
            "Epoch 836/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 4.2467e-05 - val_loss: 5.6900e-06\n",
            "Epoch 837/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 3.2570e-05 - val_loss: 5.5754e-05\n",
            "Epoch 838/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 8.9222e-05 - val_loss: 3.0359e-06\n",
            "Epoch 839/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 5.0350e-05 - val_loss: 6.9581e-05\n",
            "Epoch 840/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 4.7837e-05 - val_loss: 4.8196e-06\n",
            "Epoch 841/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 3.3285e-05 - val_loss: 8.5418e-05\n",
            "Epoch 842/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 8.1902e-05 - val_loss: 5.7448e-06\n",
            "Epoch 843/2000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 5.9219e-05 - val_loss: 1.8614e-04\n",
            "Epoch 844/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 1.2075e-04 - val_loss: 3.6880e-06\n",
            "Epoch 845/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 4.8663e-05 - val_loss: 3.2386e-05\n",
            "Epoch 846/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 2.5230e-05 - val_loss: 6.3005e-06\n",
            "Epoch 847/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.5254e-05 - val_loss: 3.7740e-05\n",
            "Epoch 848/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 1.7181e-05 - val_loss: 3.8852e-06\n",
            "Epoch 849/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3670e-05 - val_loss: 2.6077e-06\n",
            "Epoch 850/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.5829e-06 - val_loss: 3.1688e-06\n",
            "Epoch 851/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.4568e-06 - val_loss: 1.7088e-06\n",
            "Epoch 852/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 3.3507e-06 - val_loss: 4.4004e-06\n",
            "Epoch 853/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 2.7415e-06 - val_loss: 4.9281e-06\n",
            "Epoch 854/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 3.4596e-06 - val_loss: 1.4453e-05\n",
            "Epoch 855/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 3.5902e-06 - val_loss: 3.7829e-06\n",
            "Epoch 856/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7074e-06 - val_loss: 3.0076e-06\n",
            "Epoch 857/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.7324e-06 - val_loss: 1.2349e-05\n",
            "Epoch 858/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 4.5580e-06 - val_loss: 6.4981e-06\n",
            "Epoch 859/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 4.3552e-06 - val_loss: 2.1396e-06\n",
            "Epoch 860/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 3.0596e-06 - val_loss: 3.5242e-06\n",
            "Epoch 861/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.7736e-06 - val_loss: 1.1202e-05\n",
            "Epoch 862/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 6.0309e-06 - val_loss: 4.4725e-06\n",
            "Epoch 863/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 4.4697e-06 - val_loss: 3.7818e-06\n",
            "Epoch 864/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 7.4568e-06 - val_loss: 2.4161e-06\n",
            "Epoch 865/2000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 3.8018e-06 - val_loss: 4.8577e-06\n",
            "Epoch 866/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 2.6456e-06 - val_loss: 7.0096e-06\n",
            "Epoch 867/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 2.3905e-06 - val_loss: 4.3578e-06\n",
            "Epoch 868/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.9015e-06 - val_loss: 6.3334e-06\n",
            "Epoch 869/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 1.8250e-06 - val_loss: 4.7253e-06\n",
            "Epoch 870/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 2.1622e-06 - val_loss: 6.5481e-06\n",
            "Epoch 871/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 3.3947e-06 - val_loss: 5.4467e-06\n",
            "Epoch 872/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 3.7855e-06 - val_loss: 4.2823e-06\n",
            "Epoch 873/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 4.9553e-06 - val_loss: 3.4822e-06\n",
            "Epoch 874/2000\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 6.4076e-06 - val_loss: 1.9169e-06\n",
            "Epoch 875/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 2.9450e-06 - val_loss: 2.3093e-05\n",
            "Epoch 876/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 9.1113e-06 - val_loss: 3.3409e-06\n",
            "Epoch 877/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 7.6407e-06 - val_loss: 9.8202e-06\n",
            "Epoch 878/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 7.6281e-06 - val_loss: 2.7626e-06\n",
            "Epoch 879/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 6.2336e-06 - val_loss: 2.5270e-05\n",
            "Epoch 880/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 1.5041e-05 - val_loss: 1.4467e-05\n",
            "Epoch 881/2000\n",
            "80/80 [==============================] - 0s 995us/step - loss: 1.6467e-05 - val_loss: 6.3902e-06\n",
            "Epoch 882/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 1.1771e-05 - val_loss: 4.6494e-06\n",
            "Epoch 883/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.2000e-06 - val_loss: 8.9169e-06\n",
            "Epoch 884/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 6.6057e-06 - val_loss: 8.6598e-07\n",
            "Epoch 885/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 5.6619e-06 - val_loss: 9.6382e-06\n",
            "Epoch 886/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 4.7998e-06 - val_loss: 8.3450e-06\n",
            "Epoch 887/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 4.5276e-06 - val_loss: 5.2038e-06\n",
            "Epoch 888/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.0696e-06 - val_loss: 4.5922e-06\n",
            "Epoch 889/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 6.1379e-06 - val_loss: 9.3220e-07\n",
            "Epoch 890/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 2.4260e-06 - val_loss: 4.2370e-06\n",
            "Epoch 891/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 2.1655e-06 - val_loss: 4.9629e-06\n",
            "Epoch 892/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 3.9570e-06 - val_loss: 4.4152e-06\n",
            "Epoch 893/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 1.2028e-05 - val_loss: 5.8924e-06\n",
            "Epoch 894/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0530e-05 - val_loss: 2.8228e-05\n",
            "Epoch 895/2000\n",
            "80/80 [==============================] - 0s 977us/step - loss: 7.9788e-06 - val_loss: 1.3965e-05\n",
            "Epoch 896/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 6.1497e-06 - val_loss: 1.1241e-06\n",
            "Epoch 897/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 4.2976e-06 - val_loss: 1.0324e-05\n",
            "Epoch 898/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.3689e-06 - val_loss: 1.1894e-05\n",
            "Epoch 899/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 4.2603e-06 - val_loss: 1.1681e-05\n",
            "Epoch 900/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 8.1060e-06 - val_loss: 1.1472e-05\n",
            "Epoch 901/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 5.7308e-06 - val_loss: 2.9078e-06\n",
            "Epoch 902/2000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 1.0288e-05 - val_loss: 6.6736e-06\n",
            "Epoch 903/2000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 9.5516e-06 - val_loss: 3.0537e-06\n",
            "Epoch 904/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 7.4953e-06 - val_loss: 1.4934e-05\n",
            "Epoch 905/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 8.4897e-06 - val_loss: 1.1654e-05\n",
            "Epoch 906/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 6.0598e-06 - val_loss: 5.5750e-06\n",
            "Epoch 907/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 7.3466e-06 - val_loss: 1.3969e-05\n",
            "Epoch 908/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 7.3130e-06 - val_loss: 6.8492e-06\n",
            "Epoch 909/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 8.4423e-06 - val_loss: 3.0774e-05\n",
            "Epoch 910/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 1.3593e-05 - val_loss: 9.8989e-06\n",
            "Epoch 911/2000\n",
            "80/80 [==============================] - 0s 877us/step - loss: 9.4564e-06 - val_loss: 3.5296e-06\n",
            "Epoch 912/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 8.9967e-06 - val_loss: 9.9448e-06\n",
            "Epoch 913/2000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 8.9288e-06 - val_loss: 8.0141e-06\n",
            "Epoch 914/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 7.0182e-06 - val_loss: 1.1103e-05\n",
            "Epoch 915/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 6.7276e-06 - val_loss: 9.1797e-06\n",
            "Epoch 916/2000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 5.7943e-06 - val_loss: 1.4803e-05\n",
            "Epoch 917/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 6.7642e-06 - val_loss: 5.2200e-06\n",
            "Epoch 918/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 6.4174e-06 - val_loss: 1.0224e-05\n",
            "Epoch 919/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 6.5402e-06 - val_loss: 1.2846e-05\n",
            "Epoch 920/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 5.6687e-06 - val_loss: 1.0400e-05\n",
            "Epoch 921/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 5.5211e-06 - val_loss: 9.6232e-07\n",
            "Epoch 922/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 4.0428e-06 - val_loss: 5.1428e-06\n",
            "Epoch 923/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 4.4230e-06 - val_loss: 9.3958e-06\n",
            "Epoch 924/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 1.2616e-05 - val_loss: 2.0174e-05\n",
            "Epoch 925/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 9.6980e-06 - val_loss: 3.9523e-06\n",
            "Epoch 926/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.0363e-06 - val_loss: 9.6906e-07\n",
            "Epoch 927/2000\n",
            "80/80 [==============================] - 0s 994us/step - loss: 3.4081e-06 - val_loss: 8.1649e-06\n",
            "Epoch 928/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 2.4633e-06 - val_loss: 5.0371e-06\n",
            "Epoch 929/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 4.2793e-06 - val_loss: 8.9469e-06\n",
            "Epoch 930/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 6.7351e-06 - val_loss: 7.2065e-06\n",
            "Epoch 931/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 4.8859e-06 - val_loss: 1.0198e-05\n",
            "Epoch 932/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 4.9213e-06 - val_loss: 7.5476e-06\n",
            "Epoch 933/2000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 1.8472e-05 - val_loss: 5.8939e-06\n",
            "Epoch 934/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 7.0464e-06 - val_loss: 1.6395e-05\n",
            "Epoch 935/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 1.0387e-05 - val_loss: 1.9377e-05\n",
            "Epoch 936/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 7.1843e-06 - val_loss: 2.3186e-06\n",
            "Epoch 937/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 2.9965e-06 - val_loss: 3.0927e-06\n",
            "Epoch 938/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.6235e-06 - val_loss: 3.4872e-06\n",
            "Epoch 939/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 4.9132e-06 - val_loss: 8.1057e-06\n",
            "Epoch 940/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 3.7542e-06 - val_loss: 7.0689e-06\n",
            "Epoch 941/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 3.3826e-06 - val_loss: 3.1735e-06\n",
            "Epoch 942/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 3.1458e-06 - val_loss: 2.5249e-06\n",
            "Epoch 943/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 7.6977e-06 - val_loss: 4.9450e-06\n",
            "Epoch 944/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 5.7685e-06 - val_loss: 2.8361e-06\n",
            "Epoch 945/2000\n",
            "80/80 [==============================] - 0s 894us/step - loss: 5.7449e-06 - val_loss: 9.3951e-06\n",
            "Epoch 946/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 4.9113e-06 - val_loss: 2.5704e-06\n",
            "Epoch 947/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 1.8214e-06 - val_loss: 3.2404e-06\n",
            "Epoch 948/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 1.9199e-06 - val_loss: 5.4172e-06\n",
            "Epoch 949/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 2.4770e-06 - val_loss: 1.2937e-05\n",
            "Epoch 950/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 4.6459e-06 - val_loss: 1.4441e-06\n",
            "Epoch 951/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 2.9828e-06 - val_loss: 2.9575e-06\n",
            "Epoch 952/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.6844e-06 - val_loss: 3.9758e-06\n",
            "Epoch 953/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 7.7772e-06 - val_loss: 3.6130e-06\n",
            "Epoch 954/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3176e-05 - val_loss: 1.0234e-05\n",
            "Epoch 955/2000\n",
            "80/80 [==============================] - 0s 886us/step - loss: 1.7832e-05 - val_loss: 4.4870e-05\n",
            "Epoch 956/2000\n",
            "80/80 [==============================] - 0s 993us/step - loss: 3.5387e-05 - val_loss: 5.1028e-06\n",
            "Epoch 957/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 1.3778e-05 - val_loss: 8.3725e-06\n",
            "Epoch 958/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 1.0862e-05 - val_loss: 2.9264e-06\n",
            "Epoch 959/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 4.1879e-06 - val_loss: 3.3236e-06\n",
            "Epoch 960/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 5.7538e-06 - val_loss: 1.7867e-05\n",
            "Epoch 961/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 1.3558e-05 - val_loss: 3.8024e-05\n",
            "Epoch 962/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 2.3551e-05 - val_loss: 9.2346e-06\n",
            "Epoch 963/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 1.3089e-05 - val_loss: 2.1178e-05\n",
            "Epoch 964/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 3.1950e-05 - val_loss: 6.9308e-05\n",
            "Epoch 965/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 5.6082e-05 - val_loss: 3.8460e-05\n",
            "Epoch 966/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 3.5700e-05 - val_loss: 9.6857e-05\n",
            "Epoch 967/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 4.6310e-05 - val_loss: 5.0823e-05\n",
            "Epoch 968/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 4.6626e-05 - val_loss: 4.6902e-05\n",
            "Epoch 969/2000\n",
            "80/80 [==============================] - 0s 857us/step - loss: 9.8240e-05 - val_loss: 3.8343e-05\n",
            "Epoch 970/2000\n",
            "80/80 [==============================] - 0s 876us/step - loss: 3.9685e-05 - val_loss: 8.7730e-06\n",
            "Epoch 971/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 1.7965e-05 - val_loss: 2.9651e-05\n",
            "Epoch 972/2000\n",
            "80/80 [==============================] - 0s 889us/step - loss: 2.0838e-05 - val_loss: 4.8523e-05\n",
            "Epoch 973/2000\n",
            "80/80 [==============================] - 0s 892us/step - loss: 3.1305e-05 - val_loss: 1.8021e-05\n",
            "Epoch 974/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 2.1178e-05 - val_loss: 1.2749e-05\n",
            "Epoch 975/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 2.4527e-05 - val_loss: 8.8773e-06\n",
            "Epoch 976/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3425e-05 - val_loss: 4.1214e-05\n",
            "Epoch 977/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 2.3824e-05 - val_loss: 5.1080e-05\n",
            "Epoch 978/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 2.2166e-05 - val_loss: 3.8247e-05\n",
            "Epoch 979/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 1.4488e-05 - val_loss: 3.1320e-05\n",
            "Epoch 980/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 2.3139e-05 - val_loss: 4.5086e-05\n",
            "Epoch 981/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 2.5241e-05 - val_loss: 1.8359e-05\n",
            "Epoch 982/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 2.2194e-05 - val_loss: 4.1011e-05\n",
            "Epoch 983/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.2064e-05 - val_loss: 6.0158e-06\n",
            "Epoch 984/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8989e-05 - val_loss: 3.8426e-05\n",
            "Epoch 985/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.6120e-05 - val_loss: 1.5228e-05\n",
            "Epoch 986/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 2.3602e-05 - val_loss: 3.5988e-05\n",
            "Epoch 987/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.1210e-05 - val_loss: 4.2830e-05\n",
            "Epoch 988/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 2.1765e-05 - val_loss: 1.6996e-05\n",
            "Epoch 989/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 2.6030e-05 - val_loss: 9.8257e-06\n",
            "Epoch 990/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 2.6675e-05 - val_loss: 2.9685e-05\n",
            "Epoch 991/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 2.2609e-05 - val_loss: 3.1706e-06\n",
            "Epoch 992/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 2.4945e-05 - val_loss: 1.3239e-05\n",
            "Epoch 993/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 7.1231e-06 - val_loss: 1.4779e-05\n",
            "Epoch 994/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 9.5338e-06 - val_loss: 2.3027e-05\n",
            "Epoch 995/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 1.1502e-05 - val_loss: 3.8134e-06\n",
            "Epoch 996/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 1.2479e-05 - val_loss: 1.2862e-05\n",
            "Epoch 997/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 1.3524e-05 - val_loss: 9.6459e-06\n",
            "Epoch 998/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 2.8946e-05 - val_loss: 3.9116e-06\n",
            "Epoch 999/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 4.3739e-05 - val_loss: 6.3953e-05\n",
            "Epoch 1000/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 9.3723e-05 - val_loss: 2.1991e-04\n",
            "Epoch 1001/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 2.0482e-04 - val_loss: 4.8003e-05\n",
            "Epoch 1002/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 1.6540e-04 - val_loss: 8.9006e-05\n",
            "Epoch 1003/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 1.4144e-04 - val_loss: 8.2693e-05\n",
            "Epoch 1004/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 1.6379e-04 - val_loss: 2.7566e-04\n",
            "Epoch 1005/2000\n",
            "80/80 [==============================] - 0s 892us/step - loss: 4.3562e-04 - val_loss: 7.8842e-04\n",
            "Epoch 1006/2000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 9.6708e-04 - val_loss: 4.6861e-04\n",
            "Epoch 1007/2000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 0.0014 - val_loss: 9.7390e-04\n",
            "Epoch 1008/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 1009/2000\n",
            "80/80 [==============================] - 0s 893us/step - loss: 0.0025 - val_loss: 0.0017\n",
            "Epoch 1010/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 0.0014 - val_loss: 0.0025\n",
            "Epoch 1011/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 0.0021 - val_loss: 3.4821e-04\n",
            "Epoch 1012/2000\n",
            "80/80 [==============================] - 0s 979us/step - loss: 8.1780e-04 - val_loss: 0.0041\n",
            "Epoch 1013/2000\n",
            "80/80 [==============================] - 0s 870us/step - loss: 0.0037 - val_loss: 5.0463e-04\n",
            "Epoch 1014/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 0.0041 - val_loss: 0.0055\n",
            "Epoch 1015/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 0.0065 - val_loss: 0.0128\n",
            "Epoch 1016/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 0.0189 - val_loss: 0.0124\n",
            "Epoch 1017/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 0.0209 - val_loss: 0.0353\n",
            "Epoch 1018/2000\n",
            "80/80 [==============================] - 0s 882us/step - loss: 0.0298 - val_loss: 0.0058\n",
            "Epoch 1019/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 0.0155 - val_loss: 6.0938e-04\n",
            "Epoch 1020/2000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 0.0162 - val_loss: 0.0191\n",
            "Epoch 1021/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 0.0157 - val_loss: 0.0118\n",
            "Epoch 1022/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 0.0120 - val_loss: 0.0088\n",
            "Epoch 1023/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 0.0057 - val_loss: 7.5535e-04\n",
            "Epoch 1024/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 0.0018 - val_loss: 0.0013\n",
            "Epoch 1025/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 0.0032 - val_loss: 0.0028\n",
            "Epoch 1026/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 0.0046 - val_loss: 0.0042\n",
            "Epoch 1027/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 2.8950e-04\n",
            "Epoch 1028/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 0.0010 - val_loss: 2.2545e-04\n",
            "Epoch 1029/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 5.7189e-04 - val_loss: 6.4020e-04\n",
            "Epoch 1030/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.0778e-04 - val_loss: 0.0016\n",
            "Epoch 1031/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 9.5402e-04 - val_loss: 1.9050e-04\n",
            "Epoch 1032/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 4.9967e-04 - val_loss: 1.6965e-04\n",
            "Epoch 1033/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 2.6005e-04 - val_loss: 2.3448e-05\n",
            "Epoch 1034/2000\n",
            "80/80 [==============================] - 0s 983us/step - loss: 7.0324e-05 - val_loss: 2.1883e-05\n",
            "Epoch 1035/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 4.0275e-05 - val_loss: 3.4983e-05\n",
            "Epoch 1036/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 3.4126e-05 - val_loss: 1.2662e-05\n",
            "Epoch 1037/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 3.4925e-05 - val_loss: 1.2259e-05\n",
            "Epoch 1038/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 2.3578e-05 - val_loss: 1.3989e-05\n",
            "Epoch 1039/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 2.2962e-05 - val_loss: 1.1423e-05\n",
            "Epoch 1040/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 1.5992e-05 - val_loss: 5.4943e-06\n",
            "Epoch 1041/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 1.9129e-05 - val_loss: 4.5175e-05\n",
            "Epoch 1042/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 4.2377e-05 - val_loss: 4.1315e-05\n",
            "Epoch 1043/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 6.2294e-05 - val_loss: 1.1703e-04\n",
            "Epoch 1044/2000\n",
            "80/80 [==============================] - 0s 890us/step - loss: 7.0942e-05 - val_loss: 1.0569e-05\n",
            "Epoch 1045/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 4.5513e-05 - val_loss: 4.5559e-05\n",
            "Epoch 1046/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 3.3751e-05 - val_loss: 1.4362e-05\n",
            "Epoch 1047/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 3.4289e-05 - val_loss: 9.7280e-06\n",
            "Epoch 1048/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 3.2300e-05 - val_loss: 6.0795e-05\n",
            "Epoch 1049/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 3.4539e-05 - val_loss: 2.5908e-05\n",
            "Epoch 1050/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 2.6596e-05 - val_loss: 6.7629e-06\n",
            "Epoch 1051/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7709e-05 - val_loss: 1.9428e-05\n",
            "Epoch 1052/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 2.4974e-05 - val_loss: 2.1822e-05\n",
            "Epoch 1053/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 3.0824e-05 - val_loss: 5.4058e-05\n",
            "Epoch 1054/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 3.1868e-05 - val_loss: 5.7276e-06\n",
            "Epoch 1055/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 1.5234e-05 - val_loss: 3.6295e-06\n",
            "Epoch 1056/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.2839e-06 - val_loss: 1.5189e-05\n",
            "Epoch 1057/2000\n",
            "80/80 [==============================] - 0s 876us/step - loss: 7.9254e-06 - val_loss: 5.8371e-06\n",
            "Epoch 1058/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 2.5387e-05 - val_loss: 6.4265e-05\n",
            "Epoch 1059/2000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 2.7871e-05 - val_loss: 1.3123e-05\n",
            "Epoch 1060/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4744e-05 - val_loss: 9.0726e-06\n",
            "Epoch 1061/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7972e-05 - val_loss: 2.0575e-05\n",
            "Epoch 1062/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 1.4872e-05 - val_loss: 7.1866e-06\n",
            "Epoch 1063/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 1.7247e-05 - val_loss: 4.5108e-05\n",
            "Epoch 1064/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 2.0386e-05 - val_loss: 1.6677e-05\n",
            "Epoch 1065/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 3.4275e-05 - val_loss: 5.1020e-05\n",
            "Epoch 1066/2000\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 3.5048e-05 - val_loss: 2.9985e-05\n",
            "Epoch 1067/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 2.7824e-05 - val_loss: 3.1357e-06\n",
            "Epoch 1068/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 2.9664e-05 - val_loss: 1.0325e-04\n",
            "Epoch 1069/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 4.0477e-05 - val_loss: 3.7887e-05\n",
            "Epoch 1070/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.3563e-05 - val_loss: 1.0130e-05\n",
            "Epoch 1071/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 2.8134e-05 - val_loss: 2.6618e-05\n",
            "Epoch 1072/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 2.2859e-05 - val_loss: 1.8436e-05\n",
            "Epoch 1073/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 1.9411e-05 - val_loss: 4.1291e-05\n",
            "Epoch 1074/2000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 1.8585e-05 - val_loss: 2.4297e-06\n",
            "Epoch 1075/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 5.1254e-06 - val_loss: 9.5210e-06\n",
            "Epoch 1076/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 6.9824e-06 - val_loss: 4.9304e-06\n",
            "Epoch 1077/2000\n",
            "80/80 [==============================] - 0s 886us/step - loss: 4.0490e-06 - val_loss: 1.7952e-06\n",
            "Epoch 1078/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 5.1804e-06 - val_loss: 2.0737e-05\n",
            "Epoch 1079/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 9.5285e-06 - val_loss: 3.7863e-06\n",
            "Epoch 1080/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 9.8413e-06 - val_loss: 7.3499e-06\n",
            "Epoch 1081/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 5.0337e-06 - val_loss: 9.5872e-06\n",
            "Epoch 1082/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 4.3311e-06 - val_loss: 6.1969e-06\n",
            "Epoch 1083/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 2.9181e-06 - val_loss: 8.3909e-06\n",
            "Epoch 1084/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.0226e-06 - val_loss: 7.2261e-06\n",
            "Epoch 1085/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 3.6214e-06 - val_loss: 1.3319e-05\n",
            "Epoch 1086/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 3.6883e-06 - val_loss: 3.0698e-06\n",
            "Epoch 1087/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 5.1492e-06 - val_loss: 6.7324e-06\n",
            "Epoch 1088/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 2.5911e-06 - val_loss: 5.3416e-06\n",
            "Epoch 1089/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.5439e-06 - val_loss: 6.4425e-06\n",
            "Epoch 1090/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 2.5406e-06 - val_loss: 3.7367e-06\n",
            "Epoch 1091/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 3.1507e-06 - val_loss: 1.4041e-05\n",
            "Epoch 1092/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 4.1631e-06 - val_loss: 2.2771e-06\n",
            "Epoch 1093/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 4.2043e-06 - val_loss: 1.0550e-05\n",
            "Epoch 1094/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.9075e-06 - val_loss: 6.2008e-06\n",
            "Epoch 1095/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 4.6094e-06 - val_loss: 3.3708e-06\n",
            "Epoch 1096/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 4.6934e-06 - val_loss: 1.2916e-05\n",
            "Epoch 1097/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 4.5469e-06 - val_loss: 1.6993e-06\n",
            "Epoch 1098/2000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 5.4695e-06 - val_loss: 1.4694e-05\n",
            "Epoch 1099/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 4.5294e-06 - val_loss: 6.2666e-06\n",
            "Epoch 1100/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 7.0102e-06 - val_loss: 2.4889e-06\n",
            "Epoch 1101/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 1.1854e-05 - val_loss: 4.5421e-05\n",
            "Epoch 1102/2000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 1.3275e-05 - val_loss: 4.2958e-06\n",
            "Epoch 1103/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 1.1501e-05 - val_loss: 3.4059e-05\n",
            "Epoch 1104/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 1.4700e-05 - val_loss: 1.1711e-05\n",
            "Epoch 1105/2000\n",
            "80/80 [==============================] - 0s 885us/step - loss: 4.3417e-06 - val_loss: 6.6588e-06\n",
            "Epoch 1106/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 5.8528e-06 - val_loss: 2.4189e-05\n",
            "Epoch 1107/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 9.5857e-06 - val_loss: 1.0777e-05\n",
            "Epoch 1108/2000\n",
            "80/80 [==============================] - 0s 993us/step - loss: 3.8787e-06 - val_loss: 5.1582e-06\n",
            "Epoch 1109/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8354e-06 - val_loss: 1.5445e-05\n",
            "Epoch 1110/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 4.7751e-06 - val_loss: 5.8529e-06\n",
            "Epoch 1111/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 2.9139e-06 - val_loss: 1.5614e-05\n",
            "Epoch 1112/2000\n",
            "80/80 [==============================] - 0s 981us/step - loss: 6.9088e-06 - val_loss: 1.2814e-05\n",
            "Epoch 1113/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 7.5363e-06 - val_loss: 3.4904e-06\n",
            "Epoch 1114/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.0935e-06 - val_loss: 3.9614e-05\n",
            "Epoch 1115/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 1.2657e-05 - val_loss: 5.2064e-06\n",
            "Epoch 1116/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 8.4582e-06 - val_loss: 8.1087e-06\n",
            "Epoch 1117/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 8.2602e-06 - val_loss: 3.7837e-05\n",
            "Epoch 1118/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2869e-05 - val_loss: 6.3982e-06\n",
            "Epoch 1119/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2104e-05 - val_loss: 2.3446e-05\n",
            "Epoch 1120/2000\n",
            "80/80 [==============================] - 0s 996us/step - loss: 1.6667e-05 - val_loss: 1.6749e-05\n",
            "Epoch 1121/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 1.6569e-05 - val_loss: 7.2600e-06\n",
            "Epoch 1122/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1141e-05 - val_loss: 3.1927e-05\n",
            "Epoch 1123/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 1.5913e-05 - val_loss: 1.5677e-05\n",
            "Epoch 1124/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1335e-05 - val_loss: 5.1613e-06\n",
            "Epoch 1125/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 1.4282e-05 - val_loss: 4.6453e-05\n",
            "Epoch 1126/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 1.5869e-05 - val_loss: 1.5328e-06\n",
            "Epoch 1127/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 7.1189e-06 - val_loss: 1.9067e-06\n",
            "Epoch 1128/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 1.1159e-05 - val_loss: 1.4855e-05\n",
            "Epoch 1129/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 9.4065e-06 - val_loss: 1.0032e-05\n",
            "Epoch 1130/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 1.4778e-05 - val_loss: 4.6780e-06\n",
            "Epoch 1131/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 1.3351e-05 - val_loss: 3.0868e-05\n",
            "Epoch 1132/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 1.0656e-05 - val_loss: 1.5868e-05\n",
            "Epoch 1133/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 1.0214e-05 - val_loss: 1.8147e-06\n",
            "Epoch 1134/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 4.8652e-06 - val_loss: 1.3221e-05\n",
            "Epoch 1135/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 6.3104e-06 - val_loss: 1.1289e-06\n",
            "Epoch 1136/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 5.5577e-06 - val_loss: 5.6994e-06\n",
            "Epoch 1137/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 5.2425e-06 - val_loss: 2.2448e-06\n",
            "Epoch 1138/2000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 3.6221e-06 - val_loss: 1.9289e-06\n",
            "Epoch 1139/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 2.6917e-06 - val_loss: 6.4267e-06\n",
            "Epoch 1140/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 2.1436e-06 - val_loss: 4.3116e-06\n",
            "Epoch 1141/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 2.9279e-06 - val_loss: 1.0550e-05\n",
            "Epoch 1142/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 3.8297e-06 - val_loss: 9.0476e-06\n",
            "Epoch 1143/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 2.3767e-06 - val_loss: 3.4582e-06\n",
            "Epoch 1144/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.0415e-06 - val_loss: 6.3202e-06\n",
            "Epoch 1145/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 2.5387e-06 - val_loss: 7.2185e-06\n",
            "Epoch 1146/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 2.8122e-06 - val_loss: 4.9083e-06\n",
            "Epoch 1147/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 1.8042e-06 - val_loss: 1.0797e-05\n",
            "Epoch 1148/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 2.4414e-06 - val_loss: 2.2228e-06\n",
            "Epoch 1149/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 3.6329e-06 - val_loss: 5.2050e-06\n",
            "Epoch 1150/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 2.4371e-06 - val_loss: 1.3343e-05\n",
            "Epoch 1151/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 3.1881e-06 - val_loss: 1.5415e-06\n",
            "Epoch 1152/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.2550e-06 - val_loss: 4.4541e-06\n",
            "Epoch 1153/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 4.7469e-06 - val_loss: 1.8084e-05\n",
            "Epoch 1154/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 4.6312e-06 - val_loss: 2.7193e-06\n",
            "Epoch 1155/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 6.9203e-06 - val_loss: 1.7930e-05\n",
            "Epoch 1156/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 7.3094e-06 - val_loss: 8.0386e-06\n",
            "Epoch 1157/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 7.4425e-06 - val_loss: 3.0642e-06\n",
            "Epoch 1158/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7288e-05 - val_loss: 4.7416e-05\n",
            "Epoch 1159/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 2.9946e-05 - val_loss: 1.5100e-06\n",
            "Epoch 1160/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 2.2345e-05 - val_loss: 7.4650e-06\n",
            "Epoch 1161/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 1.7528e-05 - val_loss: 3.8400e-05\n",
            "Epoch 1162/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 2.6215e-05 - val_loss: 1.8146e-05\n",
            "Epoch 1163/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 1.9720e-05 - val_loss: 2.0040e-05\n",
            "Epoch 1164/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 3.0505e-05 - val_loss: 1.7076e-05\n",
            "Epoch 1165/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 2.3167e-05 - val_loss: 1.1546e-05\n",
            "Epoch 1166/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 1.6622e-05 - val_loss: 1.2324e-05\n",
            "Epoch 1167/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 2.1368e-05 - val_loss: 7.9375e-05\n",
            "Epoch 1168/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.9629e-05 - val_loss: 1.0510e-04\n",
            "Epoch 1169/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 2.5986e-04 - val_loss: 7.8197e-05\n",
            "Epoch 1170/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 4.9674e-04 - val_loss: 0.0012\n",
            "Epoch 1171/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 7.9863e-04 - val_loss: 4.5168e-05\n",
            "Epoch 1172/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 4.0839e-04 - val_loss: 7.3397e-04\n",
            "Epoch 1173/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 7.1269e-04 - val_loss: 7.6742e-04\n",
            "Epoch 1174/2000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 4.5483e-04 - val_loss: 4.4374e-04\n",
            "Epoch 1175/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 4.0714e-04 - val_loss: 1.4122e-04\n",
            "Epoch 1176/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 3.9402e-04 - val_loss: 6.0922e-04\n",
            "Epoch 1177/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.0577e-04 - val_loss: 2.5250e-04\n",
            "Epoch 1178/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 4.4676e-04 - val_loss: 2.0861e-05\n",
            "Epoch 1179/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 4.3362e-04 - val_loss: 2.4665e-04\n",
            "Epoch 1180/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 3.7012e-04 - val_loss: 1.0950e-04\n",
            "Epoch 1181/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 1.3031e-04 - val_loss: 4.3675e-05\n",
            "Epoch 1182/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 4.1446e-05 - val_loss: 9.4999e-05\n",
            "Epoch 1183/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 4.6147e-05 - val_loss: 1.9469e-05\n",
            "Epoch 1184/2000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 3.7898e-05 - val_loss: 3.8338e-05\n",
            "Epoch 1185/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 4.7042e-05 - val_loss: 6.0199e-05\n",
            "Epoch 1186/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 6.6319e-05 - val_loss: 1.4963e-04\n",
            "Epoch 1187/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 1.2807e-04 - val_loss: 9.8528e-06\n",
            "Epoch 1188/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 6.6415e-05 - val_loss: 1.0141e-04\n",
            "Epoch 1189/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 9.8479e-05 - val_loss: 9.6166e-05\n",
            "Epoch 1190/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 1.1703e-04 - val_loss: 4.7496e-05\n",
            "Epoch 1191/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 1.0343e-04 - val_loss: 5.7467e-05\n",
            "Epoch 1192/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 1.5585e-04 - val_loss: 1.6484e-04\n",
            "Epoch 1193/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.9814e-05 - val_loss: 1.1508e-04\n",
            "Epoch 1194/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 1.1426e-04 - val_loss: 1.2178e-05\n",
            "Epoch 1195/2000\n",
            "80/80 [==============================] - 0s 891us/step - loss: 5.1504e-05 - val_loss: 2.5642e-05\n",
            "Epoch 1196/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 3.3759e-05 - val_loss: 7.4591e-05\n",
            "Epoch 1197/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.1491e-05 - val_loss: 5.9032e-06\n",
            "Epoch 1198/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 3.2633e-05 - val_loss: 1.7058e-06\n",
            "Epoch 1199/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 4.8351e-05 - val_loss: 1.9380e-04\n",
            "Epoch 1200/2000\n",
            "80/80 [==============================] - 0s 891us/step - loss: 8.2351e-05 - val_loss: 4.0498e-05\n",
            "Epoch 1201/2000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 3.5269e-05 - val_loss: 1.1745e-05\n",
            "Epoch 1202/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.6147e-05 - val_loss: 1.9079e-05\n",
            "Epoch 1203/2000\n",
            "80/80 [==============================] - 0s 889us/step - loss: 1.4734e-05 - val_loss: 3.0019e-05\n",
            "Epoch 1204/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 2.6425e-05 - val_loss: 1.2302e-05\n",
            "Epoch 1205/2000\n",
            "80/80 [==============================] - 0s 876us/step - loss: 1.7094e-05 - val_loss: 1.0990e-05\n",
            "Epoch 1206/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 8.7390e-06 - val_loss: 9.1692e-06\n",
            "Epoch 1207/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 5.3394e-06 - val_loss: 8.6705e-06\n",
            "Epoch 1208/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 5.6170e-06 - val_loss: 1.7477e-05\n",
            "Epoch 1209/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 7.4212e-06 - val_loss: 2.2862e-06\n",
            "Epoch 1210/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 9.8796e-06 - val_loss: 1.2176e-05\n",
            "Epoch 1211/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 6.5831e-06 - val_loss: 3.3312e-05\n",
            "Epoch 1212/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 1.2599e-05 - val_loss: 2.7276e-06\n",
            "Epoch 1213/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 1.6058e-05 - val_loss: 4.3322e-06\n",
            "Epoch 1214/2000\n",
            "80/80 [==============================] - 0s 995us/step - loss: 6.2279e-06 - val_loss: 5.3975e-06\n",
            "Epoch 1215/2000\n",
            "80/80 [==============================] - 0s 883us/step - loss: 7.7009e-06 - val_loss: 2.2299e-06\n",
            "Epoch 1216/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 6.4159e-06 - val_loss: 3.7883e-06\n",
            "Epoch 1217/2000\n",
            "80/80 [==============================] - 0s 885us/step - loss: 4.9765e-06 - val_loss: 2.0088e-05\n",
            "Epoch 1218/2000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 5.2537e-06 - val_loss: 3.1942e-06\n",
            "Epoch 1219/2000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 4.8203e-06 - val_loss: 4.4536e-06\n",
            "Epoch 1220/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 4.9890e-06 - val_loss: 1.6999e-05\n",
            "Epoch 1221/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 3.9960e-06 - val_loss: 3.3375e-06\n",
            "Epoch 1222/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 3.1999e-06 - val_loss: 5.1717e-06\n",
            "Epoch 1223/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 2.3306e-06 - val_loss: 1.3782e-05\n",
            "Epoch 1224/2000\n",
            "80/80 [==============================] - 0s 981us/step - loss: 5.4286e-06 - val_loss: 2.0833e-06\n",
            "Epoch 1225/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 4.9490e-06 - val_loss: 1.4261e-06\n",
            "Epoch 1226/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 4.4272e-06 - val_loss: 2.1665e-05\n",
            "Epoch 1227/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 1.1312e-05 - val_loss: 1.4055e-06\n",
            "Epoch 1228/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 6.0843e-06 - val_loss: 2.1059e-06\n",
            "Epoch 1229/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 6.7264e-06 - val_loss: 1.5411e-05\n",
            "Epoch 1230/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 4.7101e-06 - val_loss: 1.0858e-05\n",
            "Epoch 1231/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 3.2250e-06 - val_loss: 1.5223e-06\n",
            "Epoch 1232/2000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 2.3999e-06 - val_loss: 3.6373e-06\n",
            "Epoch 1233/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 2.4380e-06 - val_loss: 1.8336e-05\n",
            "Epoch 1234/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 7.0813e-06 - val_loss: 2.0985e-06\n",
            "Epoch 1235/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 4.5444e-06 - val_loss: 3.2251e-06\n",
            "Epoch 1236/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 3.5594e-06 - val_loss: 2.5847e-05\n",
            "Epoch 1237/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 6.5189e-06 - val_loss: 1.3404e-06\n",
            "Epoch 1238/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 1.0387e-05 - val_loss: 3.7828e-06\n",
            "Epoch 1239/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 8.6583e-06 - val_loss: 2.8562e-05\n",
            "Epoch 1240/2000\n",
            "80/80 [==============================] - 0s 873us/step - loss: 8.3470e-06 - val_loss: 3.6186e-06\n",
            "Epoch 1241/2000\n",
            "80/80 [==============================] - 0s 865us/step - loss: 6.0997e-06 - val_loss: 1.5632e-06\n",
            "Epoch 1242/2000\n",
            "80/80 [==============================] - 0s 864us/step - loss: 5.3686e-06 - val_loss: 9.1886e-06\n",
            "Epoch 1243/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.7097e-06 - val_loss: 3.7520e-06\n",
            "Epoch 1244/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 1.5674e-06 - val_loss: 1.8816e-06\n",
            "Epoch 1245/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 1.7082e-06 - val_loss: 7.9443e-06\n",
            "Epoch 1246/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 2.1797e-06 - val_loss: 1.1132e-05\n",
            "Epoch 1247/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 2.4876e-06 - val_loss: 1.3698e-06\n",
            "Epoch 1248/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 3.0816e-06 - val_loss: 6.0960e-06\n",
            "Epoch 1249/2000\n",
            "80/80 [==============================] - 0s 898us/step - loss: 2.8240e-06 - val_loss: 7.2046e-06\n",
            "Epoch 1250/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.5329e-06 - val_loss: 1.6317e-06\n",
            "Epoch 1251/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 2.2691e-06 - val_loss: 3.7276e-06\n",
            "Epoch 1252/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 1.3855e-06 - val_loss: 1.0424e-05\n",
            "Epoch 1253/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 2.2299e-06 - val_loss: 2.8314e-06\n",
            "Epoch 1254/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.6366e-06 - val_loss: 1.6483e-06\n",
            "Epoch 1255/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 2.6243e-06 - val_loss: 5.7743e-06\n",
            "Epoch 1256/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 2.2433e-06 - val_loss: 5.8963e-06\n",
            "Epoch 1257/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4871e-06 - val_loss: 1.0777e-06\n",
            "Epoch 1258/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2367e-06 - val_loss: 2.6648e-06\n",
            "Epoch 1259/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.6064e-06 - val_loss: 7.2871e-06\n",
            "Epoch 1260/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.6619e-06 - val_loss: 1.5694e-06\n",
            "Epoch 1261/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 3.4726e-06 - val_loss: 6.8114e-06\n",
            "Epoch 1262/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 3.7300e-06 - val_loss: 1.4325e-05\n",
            "Epoch 1263/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 5.5149e-06 - val_loss: 1.7149e-06\n",
            "Epoch 1264/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 8.1593e-06 - val_loss: 1.9552e-06\n",
            "Epoch 1265/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 8.5549e-06 - val_loss: 2.7281e-05\n",
            "Epoch 1266/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 1.2329e-05 - val_loss: 8.8425e-07\n",
            "Epoch 1267/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 7.6054e-06 - val_loss: 5.3505e-06\n",
            "Epoch 1268/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 8.6041e-06 - val_loss: 1.5570e-06\n",
            "Epoch 1269/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 2.4666e-06 - val_loss: 5.2395e-06\n",
            "Epoch 1270/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 2.1692e-06 - val_loss: 1.2044e-06\n",
            "Epoch 1271/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 3.2439e-06 - val_loss: 2.6601e-06\n",
            "Epoch 1272/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 2.5999e-06 - val_loss: 7.8943e-06\n",
            "Epoch 1273/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 4.0443e-06 - val_loss: 1.4304e-05\n",
            "Epoch 1274/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.0867e-06 - val_loss: 3.1485e-06\n",
            "Epoch 1275/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 9.2604e-06 - val_loss: 7.8218e-07\n",
            "Epoch 1276/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.5007e-06 - val_loss: 2.0644e-05\n",
            "Epoch 1277/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 8.8956e-06 - val_loss: 2.2983e-06\n",
            "Epoch 1278/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.0322e-06 - val_loss: 1.6188e-06\n",
            "Epoch 1279/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 4.8026e-06 - val_loss: 4.0909e-06\n",
            "Epoch 1280/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 1.8819e-06 - val_loss: 8.4805e-06\n",
            "Epoch 1281/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 1.6585e-06 - val_loss: 2.0208e-06\n",
            "Epoch 1282/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 1.5685e-06 - val_loss: 5.1018e-06\n",
            "Epoch 1283/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 2.1574e-06 - val_loss: 9.9506e-06\n",
            "Epoch 1284/2000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 2.8378e-06 - val_loss: 1.3664e-06\n",
            "Epoch 1285/2000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 3.5291e-06 - val_loss: 2.0398e-06\n",
            "Epoch 1286/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 3.5498e-06 - val_loss: 1.1576e-05\n",
            "Epoch 1287/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 3.5365e-06 - val_loss: 6.5673e-06\n",
            "Epoch 1288/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 1.3351e-06 - val_loss: 1.2769e-06\n",
            "Epoch 1289/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 2.6117e-06 - val_loss: 5.0432e-06\n",
            "Epoch 1290/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.6953e-06 - val_loss: 1.0767e-05\n",
            "Epoch 1291/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 2.6182e-06 - val_loss: 1.7204e-06\n",
            "Epoch 1292/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 2.6233e-06 - val_loss: 1.6293e-06\n",
            "Epoch 1293/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 1.8579e-06 - val_loss: 5.1815e-06\n",
            "Epoch 1294/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 1.6308e-06 - val_loss: 3.9147e-06\n",
            "Epoch 1295/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.5558e-06 - val_loss: 5.4720e-06\n",
            "Epoch 1296/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 1.6840e-06 - val_loss: 1.7006e-06\n",
            "Epoch 1297/2000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 3.3675e-06 - val_loss: 1.3184e-06\n",
            "Epoch 1298/2000\n",
            "80/80 [==============================] - 0s 859us/step - loss: 6.4065e-06 - val_loss: 1.1788e-05\n",
            "Epoch 1299/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 4.1921e-06 - val_loss: 2.9621e-06\n",
            "Epoch 1300/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7804e-06 - val_loss: 1.4923e-06\n",
            "Epoch 1301/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 4.1193e-06 - val_loss: 8.0667e-06\n",
            "Epoch 1302/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 2.6238e-06 - val_loss: 1.1735e-05\n",
            "Epoch 1303/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 2.4308e-06 - val_loss: 2.7025e-06\n",
            "Epoch 1304/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 1.8806e-06 - val_loss: 1.9242e-06\n",
            "Epoch 1305/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 3.9282e-06 - val_loss: 1.9438e-06\n",
            "Epoch 1306/2000\n",
            "80/80 [==============================] - 0s 981us/step - loss: 1.8408e-06 - val_loss: 3.4404e-06\n",
            "Epoch 1307/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 1.4025e-06 - val_loss: 3.3693e-06\n",
            "Epoch 1308/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 1.2008e-06 - val_loss: 2.9194e-06\n",
            "Epoch 1309/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 1.5682e-06 - val_loss: 3.4961e-06\n",
            "Epoch 1310/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 1.4839e-06 - val_loss: 7.8619e-06\n",
            "Epoch 1311/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 2.2074e-06 - val_loss: 3.3810e-06\n",
            "Epoch 1312/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 9.6530e-07 - val_loss: 3.3210e-06\n",
            "Epoch 1313/2000\n",
            "80/80 [==============================] - 0s 893us/step - loss: 1.2002e-06 - val_loss: 5.5873e-06\n",
            "Epoch 1314/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 1.3920e-06 - val_loss: 1.8487e-06\n",
            "Epoch 1315/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.6760e-06 - val_loss: 1.7371e-06\n",
            "Epoch 1316/2000\n",
            "80/80 [==============================] - 0s 898us/step - loss: 2.2316e-06 - val_loss: 3.1288e-06\n",
            "Epoch 1317/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 9.9448e-07 - val_loss: 2.8366e-06\n",
            "Epoch 1318/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 1.1263e-06 - val_loss: 2.7121e-06\n",
            "Epoch 1319/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 1.0618e-06 - val_loss: 5.3448e-06\n",
            "Epoch 1320/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 1.9775e-06 - val_loss: 1.0296e-06\n",
            "Epoch 1321/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 2.3447e-06 - val_loss: 2.9836e-06\n",
            "Epoch 1322/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 2.2328e-06 - val_loss: 4.7993e-06\n",
            "Epoch 1323/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 1.2692e-06 - val_loss: 3.5981e-06\n",
            "Epoch 1324/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 1.0708e-06 - val_loss: 1.2047e-06\n",
            "Epoch 1325/2000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 1.8388e-06 - val_loss: 3.4598e-06\n",
            "Epoch 1326/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 1.3833e-06 - val_loss: 3.4215e-06\n",
            "Epoch 1327/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 1.0770e-06 - val_loss: 1.8083e-06\n",
            "Epoch 1328/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 2.4928e-06 - val_loss: 2.0876e-06\n",
            "Epoch 1329/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 1.5919e-06 - val_loss: 6.3412e-06\n",
            "Epoch 1330/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0934e-06 - val_loss: 1.8878e-06\n",
            "Epoch 1331/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3778e-06 - val_loss: 1.9198e-06\n",
            "Epoch 1332/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 1.1344e-06 - val_loss: 6.6412e-06\n",
            "Epoch 1333/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 2.8763e-06 - val_loss: 1.5773e-06\n",
            "Epoch 1334/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 2.3892e-06 - val_loss: 1.7378e-06\n",
            "Epoch 1335/2000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 1.5765e-06 - val_loss: 4.7555e-06\n",
            "Epoch 1336/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 2.4213e-06 - val_loss: 5.9924e-06\n",
            "Epoch 1337/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 2.7268e-06 - val_loss: 8.8584e-06\n",
            "Epoch 1338/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 4.0015e-06 - val_loss: 2.8942e-06\n",
            "Epoch 1339/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 2.4817e-06 - val_loss: 2.2347e-06\n",
            "Epoch 1340/2000\n",
            "80/80 [==============================] - 0s 893us/step - loss: 1.2694e-06 - val_loss: 6.7171e-06\n",
            "Epoch 1341/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 1.5421e-06 - val_loss: 9.8263e-07\n",
            "Epoch 1342/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 2.5160e-06 - val_loss: 1.4725e-06\n",
            "Epoch 1343/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 3.7821e-06 - val_loss: 4.2861e-06\n",
            "Epoch 1344/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8699e-06 - val_loss: 5.5594e-06\n",
            "Epoch 1345/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 2.9773e-06 - val_loss: 3.2148e-06\n",
            "Epoch 1346/2000\n",
            "80/80 [==============================] - 0s 868us/step - loss: 1.5636e-06 - val_loss: 4.7510e-06\n",
            "Epoch 1347/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 1.5754e-06 - val_loss: 1.3345e-06\n",
            "Epoch 1348/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 2.0180e-06 - val_loss: 6.3390e-06\n",
            "Epoch 1349/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 1.4860e-06 - val_loss: 7.2809e-06\n",
            "Epoch 1350/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 1.9073e-06 - val_loss: 3.3137e-06\n",
            "Epoch 1351/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 1.3674e-06 - val_loss: 2.5867e-06\n",
            "Epoch 1352/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 9.5317e-07 - val_loss: 4.0053e-06\n",
            "Epoch 1353/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0534e-06 - val_loss: 5.6478e-06\n",
            "Epoch 1354/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 1.2407e-06 - val_loss: 2.3568e-06\n",
            "Epoch 1355/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 1.1264e-06 - val_loss: 3.9403e-06\n",
            "Epoch 1356/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 1.8586e-06 - val_loss: 1.8437e-06\n",
            "Epoch 1357/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 9.9901e-07 - val_loss: 4.7279e-06\n",
            "Epoch 1358/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 1.4385e-06 - val_loss: 1.1976e-06\n",
            "Epoch 1359/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2739e-06 - val_loss: 8.5176e-07\n",
            "Epoch 1360/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 1.4171e-06 - val_loss: 1.3508e-05\n",
            "Epoch 1361/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 4.6067e-06 - val_loss: 7.4341e-06\n",
            "Epoch 1362/2000\n",
            "80/80 [==============================] - 0s 852us/step - loss: 2.3039e-06 - val_loss: 7.3246e-07\n",
            "Epoch 1363/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 4.7228e-06 - val_loss: 4.0262e-06\n",
            "Epoch 1364/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 5.7864e-06 - val_loss: 9.0864e-06\n",
            "Epoch 1365/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 4.9185e-06 - val_loss: 3.1656e-05\n",
            "Epoch 1366/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 1.1306e-05 - val_loss: 1.2146e-06\n",
            "Epoch 1367/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 7.7864e-06 - val_loss: 1.8282e-06\n",
            "Epoch 1368/2000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 5.7004e-06 - val_loss: 6.9519e-06\n",
            "Epoch 1369/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 3.9428e-06 - val_loss: 1.5713e-05\n",
            "Epoch 1370/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 6.1191e-06 - val_loss: 1.6675e-06\n",
            "Epoch 1371/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 8.4995e-06 - val_loss: 6.0112e-06\n",
            "Epoch 1372/2000\n",
            "80/80 [==============================] - 0s 894us/step - loss: 1.2951e-05 - val_loss: 8.8231e-06\n",
            "Epoch 1373/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.2377e-06 - val_loss: 1.7800e-05\n",
            "Epoch 1374/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 4.0830e-06 - val_loss: 7.4886e-06\n",
            "Epoch 1375/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 1.7488e-06 - val_loss: 2.7166e-06\n",
            "Epoch 1376/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 1.5454e-06 - val_loss: 1.8551e-06\n",
            "Epoch 1377/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 1.3716e-06 - val_loss: 4.0461e-06\n",
            "Epoch 1378/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 1.0875e-06 - val_loss: 2.2774e-06\n",
            "Epoch 1379/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 1.0879e-06 - val_loss: 2.6254e-06\n",
            "Epoch 1380/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 1.0023e-06 - val_loss: 2.9199e-06\n",
            "Epoch 1381/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 9.0390e-07 - val_loss: 1.8555e-06\n",
            "Epoch 1382/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 9.1703e-07 - val_loss: 5.1071e-06\n",
            "Epoch 1383/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 1.3890e-06 - val_loss: 1.8948e-06\n",
            "Epoch 1384/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 2.5140e-06 - val_loss: 1.2644e-06\n",
            "Epoch 1385/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.5152e-06 - val_loss: 4.7056e-06\n",
            "Epoch 1386/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8508e-06 - val_loss: 1.1658e-05\n",
            "Epoch 1387/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 2.7911e-06 - val_loss: 3.8705e-06\n",
            "Epoch 1388/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 2.4646e-06 - val_loss: 1.4158e-06\n",
            "Epoch 1389/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 2.3984e-06 - val_loss: 7.8010e-07\n",
            "Epoch 1390/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 2.9581e-06 - val_loss: 4.2484e-06\n",
            "Epoch 1391/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 5.2914e-06 - val_loss: 3.5418e-05\n",
            "Epoch 1392/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 1.4910e-05 - val_loss: 2.8660e-05\n",
            "Epoch 1393/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 1.8520e-05 - val_loss: 8.5562e-06\n",
            "Epoch 1394/2000\n",
            "80/80 [==============================] - 0s 871us/step - loss: 3.2180e-05 - val_loss: 3.2515e-05\n",
            "Epoch 1395/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.1537e-05 - val_loss: 7.1742e-06\n",
            "Epoch 1396/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4850e-05 - val_loss: 2.5373e-05\n",
            "Epoch 1397/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 1.7284e-05 - val_loss: 1.2277e-05\n",
            "Epoch 1398/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 1.1492e-05 - val_loss: 4.7534e-06\n",
            "Epoch 1399/2000\n",
            "80/80 [==============================] - 0s 868us/step - loss: 7.4631e-06 - val_loss: 7.4781e-06\n",
            "Epoch 1400/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 1.5446e-05 - val_loss: 1.1495e-05\n",
            "Epoch 1401/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 1.5290e-05 - val_loss: 1.0707e-05\n",
            "Epoch 1402/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 5.4786e-06 - val_loss: 2.2028e-05\n",
            "Epoch 1403/2000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 7.5252e-06 - val_loss: 3.2443e-05\n",
            "Epoch 1404/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 1.3017e-05 - val_loss: 1.0416e-05\n",
            "Epoch 1405/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 3.8090e-06 - val_loss: 3.0667e-06\n",
            "Epoch 1406/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 3.2949e-06 - val_loss: 1.7488e-05\n",
            "Epoch 1407/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 6.4684e-06 - val_loss: 1.7857e-05\n",
            "Epoch 1408/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2265e-05 - val_loss: 3.2207e-06\n",
            "Epoch 1409/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 1.4385e-05 - val_loss: 2.7121e-05\n",
            "Epoch 1410/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 1.5123e-04 - val_loss: 1.8545e-04\n",
            "Epoch 1411/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 1.4675e-04 - val_loss: 8.5737e-06\n",
            "Epoch 1412/2000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 5.2856e-05 - val_loss: 1.8053e-05\n",
            "Epoch 1413/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 3.6953e-05 - val_loss: 6.2524e-05\n",
            "Epoch 1414/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 4.2636e-05 - val_loss: 1.6031e-04\n",
            "Epoch 1415/2000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 5.3135e-05 - val_loss: 2.5379e-05\n",
            "Epoch 1416/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4038e-05 - val_loss: 1.5589e-05\n",
            "Epoch 1417/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 1.7640e-05 - val_loss: 2.4827e-06\n",
            "Epoch 1418/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 1.3156e-05 - val_loss: 1.8586e-05\n",
            "Epoch 1419/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 1.9979e-05 - val_loss: 1.4848e-05\n",
            "Epoch 1420/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 1.0787e-05 - val_loss: 9.1713e-07\n",
            "Epoch 1421/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 8.3954e-06 - val_loss: 9.3044e-06\n",
            "Epoch 1422/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 1.1212e-05 - val_loss: 1.7120e-06\n",
            "Epoch 1423/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 7.5550e-06 - val_loss: 1.8718e-05\n",
            "Epoch 1424/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 1.0924e-05 - val_loss: 3.7204e-05\n",
            "Epoch 1425/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7621e-05 - val_loss: 1.9918e-05\n",
            "Epoch 1426/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 1.1083e-05 - val_loss: 7.6501e-06\n",
            "Epoch 1427/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 3.3630e-05 - val_loss: 1.4538e-05\n",
            "Epoch 1428/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 2.4255e-05 - val_loss: 1.4154e-05\n",
            "Epoch 1429/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 1.6979e-05 - val_loss: 4.8636e-05\n",
            "Epoch 1430/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 1.7032e-05 - val_loss: 2.0294e-05\n",
            "Epoch 1431/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.3161e-06 - val_loss: 8.1230e-07\n",
            "Epoch 1432/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 5.4667e-06 - val_loss: 3.2165e-06\n",
            "Epoch 1433/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 5.8823e-06 - val_loss: 1.7844e-05\n",
            "Epoch 1434/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 1.5876e-05 - val_loss: 2.7440e-05\n",
            "Epoch 1435/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 3.0396e-05 - val_loss: 6.6709e-05\n",
            "Epoch 1436/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.1122e-05 - val_loss: 2.1044e-05\n",
            "Epoch 1437/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 1.1891e-05 - val_loss: 2.3324e-05\n",
            "Epoch 1438/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 2.2090e-05 - val_loss: 1.0044e-05\n",
            "Epoch 1439/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 2.0515e-05 - val_loss: 3.8454e-06\n",
            "Epoch 1440/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 1.5560e-05 - val_loss: 3.4600e-05\n",
            "Epoch 1441/2000\n",
            "80/80 [==============================] - 0s 892us/step - loss: 1.4339e-05 - val_loss: 1.0065e-05\n",
            "Epoch 1442/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 9.7455e-06 - val_loss: 3.6033e-06\n",
            "Epoch 1443/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 1.6775e-05 - val_loss: 1.4437e-05\n",
            "Epoch 1444/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 1.7832e-05 - val_loss: 2.4607e-06\n",
            "Epoch 1445/2000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 4.9170e-06 - val_loss: 2.6930e-06\n",
            "Epoch 1446/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 2.5099e-06 - val_loss: 3.2352e-06\n",
            "Epoch 1447/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 2.0098e-06 - val_loss: 5.5348e-06\n",
            "Epoch 1448/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 1.5179e-06 - val_loss: 8.1194e-06\n",
            "Epoch 1449/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.5758e-06 - val_loss: 8.9152e-06\n",
            "Epoch 1450/2000\n",
            "80/80 [==============================] - 0s 977us/step - loss: 2.5443e-06 - val_loss: 1.6154e-06\n",
            "Epoch 1451/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 2.7287e-06 - val_loss: 1.3321e-06\n",
            "Epoch 1452/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 2.4755e-06 - val_loss: 1.5146e-06\n",
            "Epoch 1453/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 5.6171e-06 - val_loss: 4.7165e-05\n",
            "Epoch 1454/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 6.7205e-05 - val_loss: 2.7641e-04\n",
            "Epoch 1455/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 1.8553e-04 - val_loss: 1.6744e-04\n",
            "Epoch 1456/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 2.4633e-04 - val_loss: 2.3537e-04\n",
            "Epoch 1457/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 1.5606e-04 - val_loss: 1.9673e-05\n",
            "Epoch 1458/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 8.8405e-05 - val_loss: 1.4386e-04\n",
            "Epoch 1459/2000\n",
            "80/80 [==============================] - 0s 977us/step - loss: 1.2879e-04 - val_loss: 4.2194e-04\n",
            "Epoch 1460/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.2497e-04 - val_loss: 1.6779e-04\n",
            "Epoch 1461/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 2.1126e-04 - val_loss: 2.1185e-05\n",
            "Epoch 1462/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 1.3238e-04 - val_loss: 2.3722e-04\n",
            "Epoch 1463/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 5.3103e-04 - val_loss: 6.1181e-04\n",
            "Epoch 1464/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 4.8145e-04 - val_loss: 3.8246e-04\n",
            "Epoch 1465/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 2.2167e-04 - val_loss: 3.4664e-05\n",
            "Epoch 1466/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 1.6279e-04 - val_loss: 5.2082e-05\n",
            "Epoch 1467/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 2.7079e-04 - val_loss: 1.1543e-04\n",
            "Epoch 1468/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 1.3858e-04 - val_loss: 3.0373e-05\n",
            "Epoch 1469/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 1.2401e-04 - val_loss: 2.4156e-04\n",
            "Epoch 1470/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 1.9839e-04 - val_loss: 2.4912e-04\n",
            "Epoch 1471/2000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 1.0880e-04 - val_loss: 5.2127e-05\n",
            "Epoch 1472/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 6.2799e-05 - val_loss: 2.9111e-05\n",
            "Epoch 1473/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 4.4281e-05 - val_loss: 5.1731e-05\n",
            "Epoch 1474/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 3.0632e-05 - val_loss: 6.3209e-05\n",
            "Epoch 1475/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 4.8315e-05 - val_loss: 2.1952e-05\n",
            "Epoch 1476/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 3.3931e-05 - val_loss: 1.1920e-04\n",
            "Epoch 1477/2000\n",
            "80/80 [==============================] - 0s 890us/step - loss: 8.5096e-05 - val_loss: 6.3255e-05\n",
            "Epoch 1478/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 3.4364e-05 - val_loss: 2.8206e-05\n",
            "Epoch 1479/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 1.9561e-05 - val_loss: 9.8585e-06\n",
            "Epoch 1480/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2488e-05 - val_loss: 3.1830e-06\n",
            "Epoch 1481/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 6.4669e-06 - val_loss: 1.3866e-05\n",
            "Epoch 1482/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 8.5508e-06 - val_loss: 6.3336e-06\n",
            "Epoch 1483/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 4.0121e-06 - val_loss: 1.5884e-05\n",
            "Epoch 1484/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 5.5475e-06 - val_loss: 3.7905e-06\n",
            "Epoch 1485/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 8.6309e-06 - val_loss: 3.6263e-06\n",
            "Epoch 1486/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 1.0173e-05 - val_loss: 2.3090e-06\n",
            "Epoch 1487/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.0101e-06 - val_loss: 1.3691e-05\n",
            "Epoch 1488/2000\n",
            "80/80 [==============================] - 0s 889us/step - loss: 1.0312e-05 - val_loss: 3.0499e-05\n",
            "Epoch 1489/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 2.3765e-05 - val_loss: 8.2382e-05\n",
            "Epoch 1490/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 6.7313e-05 - val_loss: 2.5873e-04\n",
            "Epoch 1491/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 1.5077e-04 - val_loss: 5.7195e-05\n",
            "Epoch 1492/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 7.1065e-05 - val_loss: 2.8604e-05\n",
            "Epoch 1493/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 5.9750e-05 - val_loss: 1.1540e-04\n",
            "Epoch 1494/2000\n",
            "80/80 [==============================] - 0s 892us/step - loss: 7.4701e-05 - val_loss: 1.8874e-05\n",
            "Epoch 1495/2000\n",
            "80/80 [==============================] - 0s 871us/step - loss: 2.2917e-05 - val_loss: 8.1411e-06\n",
            "Epoch 1496/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3069e-05 - val_loss: 1.2040e-05\n",
            "Epoch 1497/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 2.7710e-05 - val_loss: 5.2528e-05\n",
            "Epoch 1498/2000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 4.6961e-05 - val_loss: 5.8431e-05\n",
            "Epoch 1499/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 3.6773e-05 - val_loss: 5.7799e-05\n",
            "Epoch 1500/2000\n",
            "80/80 [==============================] - 0s 898us/step - loss: 2.7162e-05 - val_loss: 1.3245e-05\n",
            "Epoch 1501/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 5.8318e-05 - val_loss: 6.5627e-06\n",
            "Epoch 1502/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 7.7919e-05 - val_loss: 1.6415e-04\n",
            "Epoch 1503/2000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 1.8061e-04 - val_loss: 1.1700e-04\n",
            "Epoch 1504/2000\n",
            "80/80 [==============================] - 0s 889us/step - loss: 8.2162e-05 - val_loss: 1.1237e-05\n",
            "Epoch 1505/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 1.9484e-05 - val_loss: 2.3923e-06\n",
            "Epoch 1506/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3187e-05 - val_loss: 1.6364e-05\n",
            "Epoch 1507/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 1.0144e-05 - val_loss: 2.1727e-05\n",
            "Epoch 1508/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 1.3791e-05 - val_loss: 6.4375e-06\n",
            "Epoch 1509/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 7.6817e-06 - val_loss: 1.8930e-06\n",
            "Epoch 1510/2000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 1.8893e-05 - val_loss: 4.0591e-05\n",
            "Epoch 1511/2000\n",
            "80/80 [==============================] - 0s 889us/step - loss: 3.4030e-05 - val_loss: 2.0926e-06\n",
            "Epoch 1512/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 1.1438e-05 - val_loss: 2.7056e-05\n",
            "Epoch 1513/2000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 2.1570e-05 - val_loss: 5.7845e-05\n",
            "Epoch 1514/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 3.3461e-05 - val_loss: 1.1281e-04\n",
            "Epoch 1515/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 5.4826e-05 - val_loss: 2.5075e-05\n",
            "Epoch 1516/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 6.0399e-05 - val_loss: 5.0432e-06\n",
            "Epoch 1517/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 4.7709e-05 - val_loss: 1.9551e-05\n",
            "Epoch 1518/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.2161e-05 - val_loss: 6.7228e-06\n",
            "Epoch 1519/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 2.1498e-05 - val_loss: 3.7019e-05\n",
            "Epoch 1520/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 9.2249e-05 - val_loss: 2.3965e-05\n",
            "Epoch 1521/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 8.4113e-05 - val_loss: 1.2784e-04\n",
            "Epoch 1522/2000\n",
            "80/80 [==============================] - 0s 989us/step - loss: 1.8292e-04 - val_loss: 4.4346e-04\n",
            "Epoch 1523/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 1.7236e-04 - val_loss: 2.7552e-04\n",
            "Epoch 1524/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 1.1275e-04 - val_loss: 1.0070e-05\n",
            "Epoch 1525/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 5.4174e-05 - val_loss: 1.2965e-04\n",
            "Epoch 1526/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 1.8089e-04 - val_loss: 1.1518e-05\n",
            "Epoch 1527/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 2.5829e-04 - val_loss: 3.3736e-05\n",
            "Epoch 1528/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 1.1419e-04 - val_loss: 1.6164e-04\n",
            "Epoch 1529/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 2.5301e-04 - val_loss: 6.7739e-04\n",
            "Epoch 1530/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 6.8856e-04 - val_loss: 7.2251e-05\n",
            "Epoch 1531/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.5801e-04 - val_loss: 9.8632e-05\n",
            "Epoch 1532/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 9.9871e-05 - val_loss: 5.3505e-05\n",
            "Epoch 1533/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.7959e-05 - val_loss: 9.1407e-05\n",
            "Epoch 1534/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 8.3216e-05 - val_loss: 2.2363e-04\n",
            "Epoch 1535/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 2.6376e-04 - val_loss: 5.0403e-04\n",
            "Epoch 1536/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 3.2999e-04 - val_loss: 3.1890e-04\n",
            "Epoch 1537/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 2.3369e-04 - val_loss: 7.4338e-05\n",
            "Epoch 1538/2000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 2.6040e-04 - val_loss: 1.4289e-04\n",
            "Epoch 1539/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 2.2550e-04 - val_loss: 0.0020\n",
            "Epoch 1540/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 0.0015 - val_loss: 0.0033\n",
            "Epoch 1541/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 0.0027 - val_loss: 0.0021\n",
            "Epoch 1542/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0032\n",
            "Epoch 1543/2000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 0.0035 - val_loss: 0.0167\n",
            "Epoch 1544/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 0.0076 - val_loss: 2.2307e-04\n",
            "Epoch 1545/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 0.0027 - val_loss: 0.0024\n",
            "Epoch 1546/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0050\n",
            "Epoch 1547/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0038\n",
            "Epoch 1548/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 0.0066 - val_loss: 0.0020\n",
            "Epoch 1549/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 0.0066 - val_loss: 0.0104\n",
            "Epoch 1550/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 0.0060 - val_loss: 0.0033\n",
            "Epoch 1551/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 8.6733e-04\n",
            "Epoch 1552/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 1553/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 0.0021 - val_loss: 1.9168e-04\n",
            "Epoch 1554/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 9.7459e-04 - val_loss: 6.5332e-04\n",
            "Epoch 1555/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 0.0013 - val_loss: 2.8818e-04\n",
            "Epoch 1556/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 9.0964e-04 - val_loss: 7.0654e-05\n",
            "Epoch 1557/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 3.3129e-04 - val_loss: 1.3542e-04\n",
            "Epoch 1558/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 2.6452e-04 - val_loss: 2.6187e-04\n",
            "Epoch 1559/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 1.9945e-04 - val_loss: 5.4383e-05\n",
            "Epoch 1560/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 1.3091e-04 - val_loss: 2.0789e-04\n",
            "Epoch 1561/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 1.5808e-04 - val_loss: 4.6690e-04\n",
            "Epoch 1562/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.2549e-04 - val_loss: 1.4149e-04\n",
            "Epoch 1563/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 1.7094e-04 - val_loss: 9.2531e-05\n",
            "Epoch 1564/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 8.1725e-05 - val_loss: 2.3605e-04\n",
            "Epoch 1565/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 8.4159e-05 - val_loss: 3.1311e-05\n",
            "Epoch 1566/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 6.6424e-05 - val_loss: 9.2964e-05\n",
            "Epoch 1567/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 1.4278e-04 - val_loss: 1.3730e-05\n",
            "Epoch 1568/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4940e-05 - val_loss: 1.3817e-05\n",
            "Epoch 1569/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 1.6706e-05 - val_loss: 4.4437e-05\n",
            "Epoch 1570/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 1.9932e-05 - val_loss: 4.8072e-06\n",
            "Epoch 1571/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 1.7732e-05 - val_loss: 4.2969e-06\n",
            "Epoch 1572/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 9.7052e-06 - val_loss: 1.0903e-05\n",
            "Epoch 1573/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 9.1444e-06 - val_loss: 3.0903e-05\n",
            "Epoch 1574/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 1.0734e-05 - val_loss: 1.0702e-05\n",
            "Epoch 1575/2000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 4.9965e-06 - val_loss: 1.2030e-05\n",
            "Epoch 1576/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.0130e-06 - val_loss: 9.1891e-06\n",
            "Epoch 1577/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 4.2740e-06 - val_loss: 3.9559e-06\n",
            "Epoch 1578/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.5364e-06 - val_loss: 3.7915e-06\n",
            "Epoch 1579/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 5.7629e-06 - val_loss: 5.9401e-06\n",
            "Epoch 1580/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 3.6882e-06 - val_loss: 4.7641e-06\n",
            "Epoch 1581/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 1.0243e-05 - val_loss: 8.1325e-06\n",
            "Epoch 1582/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 7.2491e-06 - val_loss: 6.2025e-05\n",
            "Epoch 1583/2000\n",
            "80/80 [==============================] - 0s 906us/step - loss: 4.3594e-05 - val_loss: 1.3806e-05\n",
            "Epoch 1584/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 8.8210e-05 - val_loss: 6.1841e-05\n",
            "Epoch 1585/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 7.7855e-05 - val_loss: 4.1411e-06\n",
            "Epoch 1586/2000\n",
            "80/80 [==============================] - 0s 891us/step - loss: 5.2821e-05 - val_loss: 1.6729e-04\n",
            "Epoch 1587/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 1.2408e-04 - val_loss: 7.6328e-05\n",
            "Epoch 1588/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 6.0911e-05 - val_loss: 1.7942e-05\n",
            "Epoch 1589/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 4.7249e-05 - val_loss: 5.2188e-06\n",
            "Epoch 1590/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 2.0467e-05 - val_loss: 3.8123e-05\n",
            "Epoch 1591/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 2.5839e-05 - val_loss: 1.0167e-05\n",
            "Epoch 1592/2000\n",
            "80/80 [==============================] - 0s 898us/step - loss: 3.6084e-05 - val_loss: 1.0233e-05\n",
            "Epoch 1593/2000\n",
            "80/80 [==============================] - 0s 995us/step - loss: 2.2033e-05 - val_loss: 1.0974e-04\n",
            "Epoch 1594/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 8.4893e-05 - val_loss: 5.9870e-06\n",
            "Epoch 1595/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 6.1197e-05 - val_loss: 1.4793e-04\n",
            "Epoch 1596/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 2.1573e-04 - val_loss: 1.5308e-04\n",
            "Epoch 1597/2000\n",
            "80/80 [==============================] - 0s 892us/step - loss: 1.9089e-04 - val_loss: 6.3723e-04\n",
            "Epoch 1598/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 3.1008e-04 - val_loss: 6.1428e-06\n",
            "Epoch 1599/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 9.6074e-05 - val_loss: 1.4587e-04\n",
            "Epoch 1600/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 9.5195e-05 - val_loss: 2.2040e-05\n",
            "Epoch 1601/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 5.2899e-05 - val_loss: 6.9862e-05\n",
            "Epoch 1602/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 5.6093e-05 - val_loss: 1.1170e-04\n",
            "Epoch 1603/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 9.8843e-05 - val_loss: 2.0978e-04\n",
            "Epoch 1604/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 1.1128e-04 - val_loss: 1.6012e-04\n",
            "Epoch 1605/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2013e-04 - val_loss: 6.9263e-05\n",
            "Epoch 1606/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 1.1584e-04 - val_loss: 2.7901e-04\n",
            "Epoch 1607/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 3.5284e-04 - val_loss: 5.1097e-05\n",
            "Epoch 1608/2000\n",
            "80/80 [==============================] - 0s 992us/step - loss: 1.1414e-04 - val_loss: 1.4301e-04\n",
            "Epoch 1609/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 1.0047e-04 - val_loss: 2.5638e-05\n",
            "Epoch 1610/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 5.7582e-05 - val_loss: 3.6995e-05\n",
            "Epoch 1611/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 4.5581e-05 - val_loss: 1.3061e-04\n",
            "Epoch 1612/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 7.7162e-05 - val_loss: 1.5199e-04\n",
            "Epoch 1613/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 1.5968e-04 - val_loss: 2.2504e-04\n",
            "Epoch 1614/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 1.0576e-04 - val_loss: 3.0246e-05\n",
            "Epoch 1615/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 3.7639e-05 - val_loss: 1.0525e-05\n",
            "Epoch 1616/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 1.3866e-05 - val_loss: 3.5475e-06\n",
            "Epoch 1617/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 8.6386e-06 - val_loss: 7.7762e-06\n",
            "Epoch 1618/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 1.7418e-05 - val_loss: 2.7993e-05\n",
            "Epoch 1619/2000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 2.7244e-05 - val_loss: 3.2558e-05\n",
            "Epoch 1620/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 1.8612e-05 - val_loss: 9.4778e-06\n",
            "Epoch 1621/2000\n",
            "80/80 [==============================] - 0s 977us/step - loss: 5.5424e-06 - val_loss: 1.6157e-05\n",
            "Epoch 1622/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.4228e-06 - val_loss: 4.9367e-05\n",
            "Epoch 1623/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 1.1282e-05 - val_loss: 9.4429e-06\n",
            "Epoch 1624/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 7.6832e-06 - val_loss: 1.9500e-06\n",
            "Epoch 1625/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 7.8886e-06 - val_loss: 5.2089e-06\n",
            "Epoch 1626/2000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 1.0533e-05 - val_loss: 7.6256e-06\n",
            "Epoch 1627/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 4.3819e-06 - val_loss: 2.8464e-06\n",
            "Epoch 1628/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 5.3548e-06 - val_loss: 7.3328e-06\n",
            "Epoch 1629/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 6.2228e-06 - val_loss: 1.9448e-05\n",
            "Epoch 1630/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 4.8878e-06 - val_loss: 1.2222e-05\n",
            "Epoch 1631/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 3.7662e-06 - val_loss: 2.1510e-06\n",
            "Epoch 1632/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 4.3196e-06 - val_loss: 4.2614e-06\n",
            "Epoch 1633/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.6225e-06 - val_loss: 5.5621e-06\n",
            "Epoch 1634/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 3.7581e-06 - val_loss: 7.0718e-06\n",
            "Epoch 1635/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 4.1194e-06 - val_loss: 2.1226e-05\n",
            "Epoch 1636/2000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 6.5490e-06 - val_loss: 7.3942e-06\n",
            "Epoch 1637/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 1.0221e-05 - val_loss: 1.0018e-05\n",
            "Epoch 1638/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 1.6490e-05 - val_loss: 2.9392e-06\n",
            "Epoch 1639/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 1.5111e-05 - val_loss: 1.9043e-05\n",
            "Epoch 1640/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 2.7516e-05 - val_loss: 7.5202e-06\n",
            "Epoch 1641/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 1.3030e-05 - val_loss: 3.3698e-06\n",
            "Epoch 1642/2000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 5.8453e-06 - val_loss: 4.6801e-06\n",
            "Epoch 1643/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 2.7104e-06 - val_loss: 3.9296e-06\n",
            "Epoch 1644/2000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 2.2129e-06 - val_loss: 3.3282e-06\n",
            "Epoch 1645/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 1.6624e-06 - val_loss: 8.1550e-06\n",
            "Epoch 1646/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 2.4162e-06 - val_loss: 7.0962e-06\n",
            "Epoch 1647/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7060e-06 - val_loss: 2.0011e-06\n",
            "Epoch 1648/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 2.3718e-06 - val_loss: 2.9650e-06\n",
            "Epoch 1649/2000\n",
            "80/80 [==============================] - 0s 894us/step - loss: 1.7559e-06 - val_loss: 1.2211e-05\n",
            "Epoch 1650/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 4.0818e-06 - val_loss: 6.6092e-06\n",
            "Epoch 1651/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 6.2042e-06 - val_loss: 9.8522e-07\n",
            "Epoch 1652/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 5.0144e-06 - val_loss: 5.8012e-06\n",
            "Epoch 1653/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.2482e-06 - val_loss: 1.7675e-06\n",
            "Epoch 1654/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 1.0504e-05 - val_loss: 5.6161e-06\n",
            "Epoch 1655/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 1.1065e-05 - val_loss: 2.2958e-05\n",
            "Epoch 1656/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 2.1006e-05 - val_loss: 5.1215e-05\n",
            "Epoch 1657/2000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 1.6837e-05 - val_loss: 2.3597e-05\n",
            "Epoch 1658/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 1.3021e-05 - val_loss: 6.1232e-06\n",
            "Epoch 1659/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 1.8558e-05 - val_loss: 1.0302e-05\n",
            "Epoch 1660/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 1.4386e-05 - val_loss: 4.0436e-06\n",
            "Epoch 1661/2000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 1.0078e-05 - val_loss: 3.5732e-06\n",
            "Epoch 1662/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 7.3580e-06 - val_loss: 3.5854e-05\n",
            "Epoch 1663/2000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 1.3520e-05 - val_loss: 3.6686e-05\n",
            "Epoch 1664/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 1.1579e-05 - val_loss: 3.4401e-06\n",
            "Epoch 1665/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 8.9036e-06 - val_loss: 1.0922e-05\n",
            "Epoch 1666/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 1.2915e-05 - val_loss: 6.9293e-06\n",
            "Epoch 1667/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 2.3125e-05 - val_loss: 2.9595e-05\n",
            "Epoch 1668/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 2.5864e-05 - val_loss: 3.3223e-06\n",
            "Epoch 1669/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 1.4160e-05 - val_loss: 1.0196e-04\n",
            "Epoch 1670/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.6294e-05 - val_loss: 5.2579e-05\n",
            "Epoch 1671/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.5293e-05 - val_loss: 6.1210e-06\n",
            "Epoch 1672/2000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 1.2473e-05 - val_loss: 1.2790e-05\n",
            "Epoch 1673/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4899e-05 - val_loss: 1.8103e-05\n",
            "Epoch 1674/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 2.0378e-05 - val_loss: 5.1299e-06\n",
            "Epoch 1675/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 1.0119e-05 - val_loss: 1.1839e-05\n",
            "Epoch 1676/2000\n",
            "80/80 [==============================] - 0s 894us/step - loss: 1.0321e-05 - val_loss: 2.0898e-05\n",
            "Epoch 1677/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 1.1109e-05 - val_loss: 4.0854e-05\n",
            "Epoch 1678/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3886e-05 - val_loss: 6.2016e-05\n",
            "Epoch 1679/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 4.3351e-05 - val_loss: 1.5225e-04\n",
            "Epoch 1680/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 1.0565e-04 - val_loss: 3.7633e-05\n",
            "Epoch 1681/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 5.5713e-05 - val_loss: 6.7782e-05\n",
            "Epoch 1682/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 5.1250e-05 - val_loss: 1.2190e-05\n",
            "Epoch 1683/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 3.0489e-05 - val_loss: 2.2274e-05\n",
            "Epoch 1684/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 6.9119e-05 - val_loss: 1.2318e-04\n",
            "Epoch 1685/2000\n",
            "80/80 [==============================] - 0s 893us/step - loss: 1.2304e-04 - val_loss: 4.6420e-05\n",
            "Epoch 1686/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 1.0192e-04 - val_loss: 2.1381e-05\n",
            "Epoch 1687/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 4.9396e-05 - val_loss: 6.2769e-05\n",
            "Epoch 1688/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 1.6631e-05 - val_loss: 3.5798e-05\n",
            "Epoch 1689/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 1.6718e-05 - val_loss: 2.1051e-05\n",
            "Epoch 1690/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 9.1851e-06 - val_loss: 3.0656e-05\n",
            "Epoch 1691/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 5.7721e-05 - val_loss: 1.1157e-05\n",
            "Epoch 1692/2000\n",
            "80/80 [==============================] - 0s 992us/step - loss: 2.5246e-05 - val_loss: 9.2167e-06\n",
            "Epoch 1693/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 1.9244e-05 - val_loss: 4.3978e-06\n",
            "Epoch 1694/2000\n",
            "80/80 [==============================] - 0s 929us/step - loss: 6.4732e-05 - val_loss: 9.9722e-05\n",
            "Epoch 1695/2000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 1.1368e-04 - val_loss: 3.8668e-04\n",
            "Epoch 1696/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 3.3918e-04 - val_loss: 0.0016\n",
            "Epoch 1697/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 9.8112e-04 - val_loss: 4.0574e-04\n",
            "Epoch 1698/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.3017e-04 - val_loss: 3.4221e-05\n",
            "Epoch 1699/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 1700/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 0.0022 - val_loss: 0.0041\n",
            "Epoch 1701/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 0.0026 - val_loss: 0.0016\n",
            "Epoch 1702/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0090\n",
            "Epoch 1703/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.0301\n",
            "Epoch 1704/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 0.0223 - val_loss: 0.0026\n",
            "Epoch 1705/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 0.0058 - val_loss: 0.0157\n",
            "Epoch 1706/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 0.0294 - val_loss: 0.0147\n",
            "Epoch 1707/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0312 - val_loss: 0.1074\n",
            "Epoch 1708/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 0.0678 - val_loss: 0.0067\n",
            "Epoch 1709/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 0.0356 - val_loss: 0.0144\n",
            "Epoch 1710/2000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 0.0367 - val_loss: 0.0716\n",
            "Epoch 1711/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 0.0557 - val_loss: 0.0222\n",
            "Epoch 1712/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 0.0222 - val_loss: 0.0053\n",
            "Epoch 1713/2000\n",
            "80/80 [==============================] - 0s 979us/step - loss: 0.0133 - val_loss: 0.0076\n",
            "Epoch 1714/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 0.0103 - val_loss: 0.0019\n",
            "Epoch 1715/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 0.0046 - val_loss: 0.0048\n",
            "Epoch 1716/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 0.0032 - val_loss: 4.4285e-04\n",
            "Epoch 1717/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0020\n",
            "Epoch 1718/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 9.7114e-04 - val_loss: 7.7689e-04\n",
            "Epoch 1719/2000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 8.8815e-04 - val_loss: 6.8730e-04\n",
            "Epoch 1720/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 8.9159e-04 - val_loss: 9.4913e-04\n",
            "Epoch 1721/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 7.9656e-04 - val_loss: 7.2298e-04\n",
            "Epoch 1722/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 0.0010 - val_loss: 8.9572e-04\n",
            "Epoch 1723/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 1724/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 1725/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 7.6682e-04 - val_loss: 1.1495e-04\n",
            "Epoch 1726/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.9329e-04 - val_loss: 1.9291e-04\n",
            "Epoch 1727/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 3.4775e-04 - val_loss: 2.0080e-04\n",
            "Epoch 1728/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 3.5755e-04 - val_loss: 3.0126e-04\n",
            "Epoch 1729/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 2.9674e-04 - val_loss: 3.7824e-04\n",
            "Epoch 1730/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 3.0321e-04 - val_loss: 1.9282e-04\n",
            "Epoch 1731/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.6991e-04 - val_loss: 2.3066e-05\n",
            "Epoch 1732/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 7.5824e-05 - val_loss: 3.2896e-05\n",
            "Epoch 1733/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 9.3649e-05 - val_loss: 5.8056e-05\n",
            "Epoch 1734/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 9.8956e-05 - val_loss: 1.1878e-04\n",
            "Epoch 1735/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 6.7750e-05 - val_loss: 2.1128e-05\n",
            "Epoch 1736/2000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 3.4338e-05 - val_loss: 1.2687e-05\n",
            "Epoch 1737/2000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 2.4589e-05 - val_loss: 6.7226e-05\n",
            "Epoch 1738/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 5.7251e-05 - val_loss: 4.4812e-05\n",
            "Epoch 1739/2000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 5.7049e-05 - val_loss: 1.1666e-04\n",
            "Epoch 1740/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.6475e-05 - val_loss: 2.7738e-05\n",
            "Epoch 1741/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 5.0284e-05 - val_loss: 5.6142e-05\n",
            "Epoch 1742/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 4.3420e-05 - val_loss: 9.3334e-06\n",
            "Epoch 1743/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 4.0309e-05 - val_loss: 1.5294e-05\n",
            "Epoch 1744/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 6.2910e-05 - val_loss: 7.6201e-05\n",
            "Epoch 1745/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 9.5976e-05 - val_loss: 1.5992e-04\n",
            "Epoch 1746/2000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 1.1001e-04 - val_loss: 2.3903e-05\n",
            "Epoch 1747/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 3.7311e-05 - val_loss: 5.3352e-06\n",
            "Epoch 1748/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 2.9565e-05 - val_loss: 1.1967e-05\n",
            "Epoch 1749/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 1.6310e-05 - val_loss: 2.9913e-05\n",
            "Epoch 1750/2000\n",
            "80/80 [==============================] - 0s 996us/step - loss: 2.1099e-05 - val_loss: 1.5903e-05\n",
            "Epoch 1751/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 1.5336e-05 - val_loss: 2.7816e-05\n",
            "Epoch 1752/2000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 1.8040e-05 - val_loss: 1.5645e-05\n",
            "Epoch 1753/2000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 2.6555e-05 - val_loss: 8.7260e-06\n",
            "Epoch 1754/2000\n",
            "80/80 [==============================] - 0s 912us/step - loss: 1.5115e-05 - val_loss: 1.5563e-05\n",
            "Epoch 1755/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 1.6646e-05 - val_loss: 1.6611e-05\n",
            "Epoch 1756/2000\n",
            "80/80 [==============================] - 0s 996us/step - loss: 1.4026e-05 - val_loss: 1.8499e-05\n",
            "Epoch 1757/2000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 1.0743e-05 - val_loss: 1.5144e-05\n",
            "Epoch 1758/2000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 1.3070e-05 - val_loss: 1.5142e-05\n",
            "Epoch 1759/2000\n",
            "80/80 [==============================] - 0s 979us/step - loss: 8.1141e-06 - val_loss: 4.5055e-06\n",
            "Epoch 1760/2000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 5.8570e-06 - val_loss: 4.9322e-06\n",
            "Epoch 1761/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 7.6752e-06 - val_loss: 9.5893e-06\n",
            "Epoch 1762/2000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 8.1066e-06 - val_loss: 7.0229e-06\n",
            "Epoch 1763/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 6.5549e-06 - val_loss: 1.5058e-05\n",
            "Epoch 1764/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2802e-05 - val_loss: 1.0379e-05\n",
            "Epoch 1765/2000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 1.2205e-05 - val_loss: 9.5251e-06\n",
            "Epoch 1766/2000\n",
            "80/80 [==============================] - 0s 992us/step - loss: 1.5322e-05 - val_loss: 2.0475e-05\n",
            "Epoch 1767/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 8.2713e-06 - val_loss: 4.1925e-06\n",
            "Epoch 1768/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.3450e-06 - val_loss: 8.3699e-06\n",
            "Epoch 1769/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 3.6636e-06 - val_loss: 4.5416e-06\n",
            "Epoch 1770/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 3.3621e-06 - val_loss: 3.8316e-06\n",
            "Epoch 1771/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 3.2333e-06 - val_loss: 4.8136e-06\n",
            "Epoch 1772/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 2.8174e-06 - val_loss: 6.5922e-06\n",
            "Epoch 1773/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 2.7595e-06 - val_loss: 4.2123e-06\n",
            "Epoch 1774/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.9653e-06 - val_loss: 7.1932e-06\n",
            "Epoch 1775/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 3.5512e-06 - val_loss: 7.7233e-06\n",
            "Epoch 1776/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 3.1064e-06 - val_loss: 3.9463e-06\n",
            "Epoch 1777/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 3.2438e-06 - val_loss: 6.4922e-06\n",
            "Epoch 1778/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 2.9189e-06 - val_loss: 5.4004e-06\n",
            "Epoch 1779/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 3.2058e-06 - val_loss: 2.9759e-06\n",
            "Epoch 1780/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 4.7160e-06 - val_loss: 9.8264e-06\n",
            "Epoch 1781/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 4.2127e-06 - val_loss: 3.6882e-06\n",
            "Epoch 1782/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 5.2671e-06 - val_loss: 4.6981e-06\n",
            "Epoch 1783/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.9917e-06 - val_loss: 6.0742e-06\n",
            "Epoch 1784/2000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 3.7030e-06 - val_loss: 3.0411e-06\n",
            "Epoch 1785/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 2.9099e-06 - val_loss: 8.4934e-06\n",
            "Epoch 1786/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 2.3749e-06 - val_loss: 4.0624e-06\n",
            "Epoch 1787/2000\n",
            "80/80 [==============================] - 0s 988us/step - loss: 3.3266e-06 - val_loss: 3.3237e-06\n",
            "Epoch 1788/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 2.8175e-06 - val_loss: 4.4685e-06\n",
            "Epoch 1789/2000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 2.2540e-06 - val_loss: 3.6171e-06\n",
            "Epoch 1790/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 2.2693e-06 - val_loss: 7.1776e-06\n",
            "Epoch 1791/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 2.6135e-06 - val_loss: 3.5226e-06\n",
            "Epoch 1792/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 4.3708e-06 - val_loss: 1.6713e-05\n",
            "Epoch 1793/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 7.2349e-06 - val_loss: 4.6336e-06\n",
            "Epoch 1794/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 2.4819e-06 - val_loss: 6.6661e-06\n",
            "Epoch 1795/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.1514e-06 - val_loss: 3.8364e-06\n",
            "Epoch 1796/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0627e-06 - val_loss: 3.9847e-06\n",
            "Epoch 1797/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.9788e-06 - val_loss: 3.3934e-06\n",
            "Epoch 1798/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0973e-06 - val_loss: 7.3888e-06\n",
            "Epoch 1799/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 2.2135e-06 - val_loss: 3.9264e-06\n",
            "Epoch 1800/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.6437e-06 - val_loss: 5.6363e-06\n",
            "Epoch 1801/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2959e-06 - val_loss: 5.7233e-06\n",
            "Epoch 1802/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0960e-06 - val_loss: 3.6742e-06\n",
            "Epoch 1803/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8850e-06 - val_loss: 3.6454e-06\n",
            "Epoch 1804/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 2.0586e-06 - val_loss: 2.8363e-06\n",
            "Epoch 1805/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 2.5632e-06 - val_loss: 5.3309e-06\n",
            "Epoch 1806/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.1583e-06 - val_loss: 8.2288e-06\n",
            "Epoch 1807/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.9977e-06 - val_loss: 2.9883e-06\n",
            "Epoch 1808/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.2197e-06 - val_loss: 1.3272e-05\n",
            "Epoch 1809/2000\n",
            "80/80 [==============================] - 0s 992us/step - loss: 3.4605e-06 - val_loss: 2.7710e-06\n",
            "Epoch 1810/2000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 3.1864e-06 - val_loss: 4.3109e-06\n",
            "Epoch 1811/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 2.0550e-06 - val_loss: 3.8700e-06\n",
            "Epoch 1812/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 2.2555e-06 - val_loss: 3.2747e-06\n",
            "Epoch 1813/2000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 2.5423e-06 - val_loss: 9.7427e-06\n",
            "Epoch 1814/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 2.3576e-06 - val_loss: 1.9614e-06\n",
            "Epoch 1815/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.2249e-06 - val_loss: 7.4279e-06\n",
            "Epoch 1816/2000\n",
            "80/80 [==============================] - 0s 977us/step - loss: 2.8928e-06 - val_loss: 8.0148e-06\n",
            "Epoch 1817/2000\n",
            "80/80 [==============================] - 0s 994us/step - loss: 4.3437e-06 - val_loss: 4.3595e-06\n",
            "Epoch 1818/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 6.6906e-06 - val_loss: 1.1322e-05\n",
            "Epoch 1819/2000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 4.1078e-06 - val_loss: 3.3978e-06\n",
            "Epoch 1820/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8336e-06 - val_loss: 2.6864e-06\n",
            "Epoch 1821/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.5960e-06 - val_loss: 1.9487e-05\n",
            "Epoch 1822/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 4.9291e-06 - val_loss: 3.9479e-06\n",
            "Epoch 1823/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 7.5763e-06 - val_loss: 1.1947e-05\n",
            "Epoch 1824/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.6565e-06 - val_loss: 1.9439e-06\n",
            "Epoch 1825/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.5577e-06 - val_loss: 5.6140e-06\n",
            "Epoch 1826/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 1.2361e-05 - val_loss: 3.1517e-05\n",
            "Epoch 1827/2000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 1.3453e-05 - val_loss: 5.1129e-06\n",
            "Epoch 1828/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 7.3046e-06 - val_loss: 1.1206e-05\n",
            "Epoch 1829/2000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 5.5646e-06 - val_loss: 5.2474e-06\n",
            "Epoch 1830/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.6518e-06 - val_loss: 3.9134e-06\n",
            "Epoch 1831/2000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 2.2452e-06 - val_loss: 8.2231e-06\n",
            "Epoch 1832/2000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 2.2504e-06 - val_loss: 6.1947e-06\n",
            "Epoch 1833/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8337e-06 - val_loss: 5.1362e-06\n",
            "Epoch 1834/2000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 1.6189e-06 - val_loss: 8.2062e-06\n",
            "Epoch 1835/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8812e-06 - val_loss: 2.8069e-06\n",
            "Epoch 1836/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 4.1329e-06 - val_loss: 8.7081e-06\n",
            "Epoch 1837/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8332e-06 - val_loss: 1.9467e-06\n",
            "Epoch 1838/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.1891e-06 - val_loss: 3.6059e-06\n",
            "Epoch 1839/2000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 2.1117e-06 - val_loss: 8.6549e-06\n",
            "Epoch 1840/2000\n",
            "80/80 [==============================] - 0s 989us/step - loss: 2.2437e-06 - val_loss: 2.6524e-06\n",
            "Epoch 1841/2000\n",
            "80/80 [==============================] - 0s 981us/step - loss: 1.8904e-06 - val_loss: 3.5138e-06\n",
            "Epoch 1842/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.6774e-06 - val_loss: 1.0549e-05\n",
            "Epoch 1843/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.0708e-06 - val_loss: 2.7827e-06\n",
            "Epoch 1844/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 6.9498e-06 - val_loss: 6.1947e-06\n",
            "Epoch 1845/2000\n",
            "80/80 [==============================] - 0s 989us/step - loss: 2.7600e-06 - val_loss: 3.8364e-06\n",
            "Epoch 1846/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 1.9408e-06 - val_loss: 2.6511e-06\n",
            "Epoch 1847/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4697e-06 - val_loss: 2.2821e-06\n",
            "Epoch 1848/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7774e-06 - val_loss: 6.6334e-06\n",
            "Epoch 1849/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7788e-06 - val_loss: 2.1026e-06\n",
            "Epoch 1850/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.9088e-06 - val_loss: 3.9759e-06\n",
            "Epoch 1851/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 2.4216e-06 - val_loss: 8.8243e-06\n",
            "Epoch 1852/2000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 3.3017e-06 - val_loss: 3.9613e-06\n",
            "Epoch 1853/2000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 1.9361e-06 - val_loss: 5.7640e-06\n",
            "Epoch 1854/2000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 2.6302e-06 - val_loss: 5.1833e-06\n",
            "Epoch 1855/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4115e-06 - val_loss: 2.6411e-06\n",
            "Epoch 1856/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4553e-06 - val_loss: 9.5447e-06\n",
            "Epoch 1857/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0353e-06 - val_loss: 2.1800e-06\n",
            "Epoch 1858/2000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 2.2574e-06 - val_loss: 4.5430e-06\n",
            "Epoch 1859/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7518e-06 - val_loss: 4.0273e-06\n",
            "Epoch 1860/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 1.5613e-06 - val_loss: 7.4644e-06\n",
            "Epoch 1861/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 1.9500e-06 - val_loss: 3.1167e-06\n",
            "Epoch 1862/2000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 2.1150e-06 - val_loss: 5.6970e-06\n",
            "Epoch 1863/2000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 1.2179e-06 - val_loss: 2.4868e-06\n",
            "Epoch 1864/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3649e-06 - val_loss: 5.2672e-06\n",
            "Epoch 1865/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4820e-06 - val_loss: 3.4668e-06\n",
            "Epoch 1866/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 1.7001e-06 - val_loss: 5.1301e-06\n",
            "Epoch 1867/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 1.3919e-06 - val_loss: 2.8701e-06\n",
            "Epoch 1868/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4651e-06 - val_loss: 3.5800e-06\n",
            "Epoch 1869/2000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 1.6641e-06 - val_loss: 8.8841e-06\n",
            "Epoch 1870/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8531e-06 - val_loss: 4.7490e-06\n",
            "Epoch 1871/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 2.1133e-06 - val_loss: 2.3469e-06\n",
            "Epoch 1872/2000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 3.3885e-06 - val_loss: 2.6908e-05\n",
            "Epoch 1873/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.7664e-06 - val_loss: 2.3313e-06\n",
            "Epoch 1874/2000\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 3.9833e-06 - val_loss: 1.8983e-06\n",
            "Epoch 1875/2000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 3.9132e-06 - val_loss: 6.9138e-06\n",
            "Epoch 1876/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.9500e-06 - val_loss: 2.9973e-06\n",
            "Epoch 1877/2000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 7.3523e-06 - val_loss: 3.1517e-06\n",
            "Epoch 1878/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 4.4723e-06 - val_loss: 1.0201e-05\n",
            "Epoch 1879/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.2778e-06 - val_loss: 2.0191e-06\n",
            "Epoch 1880/2000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 6.4997e-06 - val_loss: 2.3271e-06\n",
            "Epoch 1881/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.3298e-06 - val_loss: 1.5568e-05\n",
            "Epoch 1882/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.1304e-06 - val_loss: 3.0848e-06\n",
            "Epoch 1883/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.2215e-06 - val_loss: 1.9217e-06\n",
            "Epoch 1884/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 3.6561e-06 - val_loss: 1.4044e-05\n",
            "Epoch 1885/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.1663e-06 - val_loss: 6.3911e-06\n",
            "Epoch 1886/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 1.2251e-05 - val_loss: 3.0428e-06\n",
            "Epoch 1887/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 7.4347e-06 - val_loss: 2.5394e-05\n",
            "Epoch 1888/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.9081e-06 - val_loss: 3.8727e-06\n",
            "Epoch 1889/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.4021e-06 - val_loss: 8.0360e-06\n",
            "Epoch 1890/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.2284e-06 - val_loss: 1.6323e-05\n",
            "Epoch 1891/2000\n",
            "80/80 [==============================] - 0s 904us/step - loss: 6.9460e-06 - val_loss: 3.3408e-06\n",
            "Epoch 1892/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.5311e-06 - val_loss: 1.7704e-05\n",
            "Epoch 1893/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.8259e-06 - val_loss: 2.0844e-05\n",
            "Epoch 1894/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2632e-05 - val_loss: 1.2634e-05\n",
            "Epoch 1895/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 3.0603e-05 - val_loss: 8.2683e-06\n",
            "Epoch 1896/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 4.5872e-05 - val_loss: 8.9345e-05\n",
            "Epoch 1897/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 5.0631e-05 - val_loss: 2.6246e-05\n",
            "Epoch 1898/2000\n",
            "80/80 [==============================] - 0s 992us/step - loss: 4.4916e-05 - val_loss: 1.1623e-05\n",
            "Epoch 1899/2000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 3.1662e-05 - val_loss: 3.1812e-05\n",
            "Epoch 1900/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3783e-05 - val_loss: 2.8870e-06\n",
            "Epoch 1901/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0412e-05 - val_loss: 2.1746e-05\n",
            "Epoch 1902/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.8197e-05 - val_loss: 6.1239e-05\n",
            "Epoch 1903/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.3702e-05 - val_loss: 2.5703e-05\n",
            "Epoch 1904/2000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 1.8834e-05 - val_loss: 5.8507e-06\n",
            "Epoch 1905/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 1.2382e-05 - val_loss: 2.3113e-05\n",
            "Epoch 1906/2000\n",
            "80/80 [==============================] - 0s 993us/step - loss: 1.5770e-05 - val_loss: 6.4420e-06\n",
            "Epoch 1907/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.9179e-06 - val_loss: 8.4384e-06\n",
            "Epoch 1908/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0739e-05 - val_loss: 8.9318e-06\n",
            "Epoch 1909/2000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 4.8188e-06 - val_loss: 4.1323e-06\n",
            "Epoch 1910/2000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 8.5979e-06 - val_loss: 1.6067e-06\n",
            "Epoch 1911/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 6.1604e-06 - val_loss: 1.4134e-05\n",
            "Epoch 1912/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.4123e-06 - val_loss: 1.9610e-06\n",
            "Epoch 1913/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 3.0505e-06 - val_loss: 2.1972e-06\n",
            "Epoch 1914/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7007e-06 - val_loss: 4.2451e-06\n",
            "Epoch 1915/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 1.6673e-06 - val_loss: 2.9313e-06\n",
            "Epoch 1916/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 1.3532e-06 - val_loss: 3.6094e-06\n",
            "Epoch 1917/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2897e-06 - val_loss: 2.2395e-06\n",
            "Epoch 1918/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.6883e-06 - val_loss: 1.8998e-06\n",
            "Epoch 1919/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 1.9911e-06 - val_loss: 8.5805e-06\n",
            "Epoch 1920/2000\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 2.5620e-06 - val_loss: 7.0282e-06\n",
            "Epoch 1921/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.9099e-06 - val_loss: 3.0340e-06\n",
            "Epoch 1922/2000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 5.2668e-06 - val_loss: 1.0643e-05\n",
            "Epoch 1923/2000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 2.4392e-06 - val_loss: 1.0147e-05\n",
            "Epoch 1924/2000\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 2.9100e-06 - val_loss: 2.9848e-06\n",
            "Epoch 1925/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 6.0127e-06 - val_loss: 1.2897e-06\n",
            "Epoch 1926/2000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 4.1254e-06 - val_loss: 1.6743e-05\n",
            "Epoch 1927/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.6645e-06 - val_loss: 2.9564e-06\n",
            "Epoch 1928/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 4.0438e-06 - val_loss: 2.1852e-06\n",
            "Epoch 1929/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 5.5353e-06 - val_loss: 1.3800e-05\n",
            "Epoch 1930/2000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 1.4781e-05 - val_loss: 2.1819e-05\n",
            "Epoch 1931/2000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 1.4175e-05 - val_loss: 8.7491e-06\n",
            "Epoch 1932/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3754e-05 - val_loss: 2.8656e-06\n",
            "Epoch 1933/2000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 2.1306e-05 - val_loss: 5.0807e-05\n",
            "Epoch 1934/2000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 2.2432e-05 - val_loss: 1.7088e-05\n",
            "Epoch 1935/2000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 3.6897e-05 - val_loss: 2.0835e-06\n",
            "Epoch 1936/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0959e-05 - val_loss: 3.9676e-05\n",
            "Epoch 1937/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4893e-05 - val_loss: 2.6997e-06\n",
            "Epoch 1938/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 9.5159e-06 - val_loss: 3.5734e-06\n",
            "Epoch 1939/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 1.8164e-05 - val_loss: 6.1819e-05\n",
            "Epoch 1940/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 2.6062e-05 - val_loss: 9.3744e-06\n",
            "Epoch 1941/2000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 1.7235e-05 - val_loss: 1.0544e-05\n",
            "Epoch 1942/2000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 2.8805e-05 - val_loss: 2.6432e-05\n",
            "Epoch 1943/2000\n",
            "80/80 [==============================] - 0s 894us/step - loss: 1.3074e-05 - val_loss: 2.5557e-06\n",
            "Epoch 1944/2000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 9.3148e-06 - val_loss: 1.5584e-05\n",
            "Epoch 1945/2000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 1.5603e-05 - val_loss: 1.7818e-05\n",
            "Epoch 1946/2000\n",
            "80/80 [==============================] - 0s 876us/step - loss: 6.3941e-06 - val_loss: 6.7074e-06\n",
            "Epoch 1947/2000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 6.9820e-06 - val_loss: 8.0770e-06\n",
            "Epoch 1948/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 1.1449e-05 - val_loss: 7.1675e-06\n",
            "Epoch 1949/2000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 5.7537e-06 - val_loss: 4.1005e-06\n",
            "Epoch 1950/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 3.6929e-06 - val_loss: 1.3019e-06\n",
            "Epoch 1951/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 3.4285e-06 - val_loss: 2.5246e-06\n",
            "Epoch 1952/2000\n",
            "80/80 [==============================] - 0s 995us/step - loss: 3.2596e-06 - val_loss: 2.0088e-05\n",
            "Epoch 1953/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4805e-05 - val_loss: 1.5395e-06\n",
            "Epoch 1954/2000\n",
            "80/80 [==============================] - 0s 963us/step - loss: 1.0639e-05 - val_loss: 2.7324e-05\n",
            "Epoch 1955/2000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 4.1333e-05 - val_loss: 2.9277e-05\n",
            "Epoch 1956/2000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 2.4999e-05 - val_loss: 5.0934e-05\n",
            "Epoch 1957/2000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 3.4730e-05 - val_loss: 1.9912e-05\n",
            "Epoch 1958/2000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 4.1361e-05 - val_loss: 3.6589e-06\n",
            "Epoch 1959/2000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 3.3651e-05 - val_loss: 1.2447e-04\n",
            "Epoch 1960/2000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 4.7816e-05 - val_loss: 5.2414e-06\n",
            "Epoch 1961/2000\n",
            "80/80 [==============================] - 0s 885us/step - loss: 2.8631e-05 - val_loss: 4.7891e-06\n",
            "Epoch 1962/2000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 1.5199e-05 - val_loss: 3.6679e-05\n",
            "Epoch 1963/2000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 1.5966e-05 - val_loss: 8.5314e-06\n",
            "Epoch 1964/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 7.7204e-06 - val_loss: 3.0488e-06\n",
            "Epoch 1965/2000\n",
            "80/80 [==============================] - 0s 918us/step - loss: 8.5858e-06 - val_loss: 3.2529e-05\n",
            "Epoch 1966/2000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 1.5358e-05 - val_loss: 8.8595e-06\n",
            "Epoch 1967/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3709e-05 - val_loss: 1.1402e-05\n",
            "Epoch 1968/2000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 1.2498e-05 - val_loss: 2.1528e-05\n",
            "Epoch 1969/2000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 1.4492e-05 - val_loss: 1.2600e-05\n",
            "Epoch 1970/2000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 7.0888e-06 - val_loss: 2.6856e-06\n",
            "Epoch 1971/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 6.6346e-06 - val_loss: 2.0506e-06\n",
            "Epoch 1972/2000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 2.9538e-06 - val_loss: 6.3239e-06\n",
            "Epoch 1973/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2608e-06 - val_loss: 3.1092e-06\n",
            "Epoch 1974/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 1.6693e-06 - val_loss: 1.2965e-06\n",
            "Epoch 1975/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 2.8645e-06 - val_loss: 3.1231e-06\n",
            "Epoch 1976/2000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 3.1709e-06 - val_loss: 8.4092e-06\n",
            "Epoch 1977/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 2.7089e-06 - val_loss: 4.4083e-06\n",
            "Epoch 1978/2000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 1.1141e-06 - val_loss: 7.8911e-06\n",
            "Epoch 1979/2000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 1.9368e-06 - val_loss: 3.1267e-06\n",
            "Epoch 1980/2000\n",
            "80/80 [==============================] - 0s 932us/step - loss: 1.3483e-06 - val_loss: 2.7219e-06\n",
            "Epoch 1981/2000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 1.4935e-06 - val_loss: 5.4347e-06\n",
            "Epoch 1982/2000\n",
            "80/80 [==============================] - 0s 959us/step - loss: 1.4347e-06 - val_loss: 1.3240e-06\n",
            "Epoch 1983/2000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 2.7414e-06 - val_loss: 1.4775e-06\n",
            "Epoch 1984/2000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 7.3021e-06 - val_loss: 6.3149e-06\n",
            "Epoch 1985/2000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 3.0994e-06 - val_loss: 1.2563e-05\n",
            "Epoch 1986/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 3.5339e-06 - val_loss: 2.3207e-06\n",
            "Epoch 1987/2000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 2.1828e-06 - val_loss: 1.6804e-06\n",
            "Epoch 1988/2000\n",
            "80/80 [==============================] - 0s 973us/step - loss: 1.5657e-06 - val_loss: 5.7270e-06\n",
            "Epoch 1989/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 1.5757e-06 - val_loss: 1.5134e-06\n",
            "Epoch 1990/2000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 2.2694e-06 - val_loss: 8.9052e-07\n",
            "Epoch 1991/2000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 2.2210e-06 - val_loss: 5.1831e-06\n",
            "Epoch 1992/2000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 2.5755e-06 - val_loss: 7.7287e-06\n",
            "Epoch 1993/2000\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 1.7243e-06 - val_loss: 1.9335e-06\n",
            "Epoch 1994/2000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 1.9530e-06 - val_loss: 1.2847e-06\n",
            "Epoch 1995/2000\n",
            "80/80 [==============================] - 0s 983us/step - loss: 1.3883e-06 - val_loss: 2.7809e-06\n",
            "Epoch 1996/2000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 1.0201e-06 - val_loss: 3.1255e-06\n",
            "Epoch 1997/2000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 1.2550e-06 - val_loss: 1.2536e-06\n",
            "Epoch 1998/2000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.3787e-06 - val_loss: 2.3192e-06\n",
            "Epoch 1999/2000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 1.4550e-06 - val_loss: 4.8203e-06\n",
            "Epoch 2000/2000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 1.6690e-06 - val_loss: 3.3572e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVgFQ54hqWr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHYE2M2ayeub",
        "colab_type": "code",
        "outputId": "85fbce14-5f56-4fa6-84a1-8091fbdb4102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "results.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scPNXOzuylCP",
        "colab_type": "code",
        "outputId": "53046150-8625-4fdc-ba25-17f838eea5de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF8S_FG3qeUI",
        "colab_type": "code",
        "outputId": "f416b2b7-11b7-4fe9-b911-f59274cf84b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.scatter(range(20),results,c='r')\n",
        "plt.scatter(range(20),y_test,c='g')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAD8CAYAAACFK0QrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFwqDijUqr30",
        "colab_type": "code",
        "outputId": "17ce5594-85ef-450a-a99b-b84639b1784b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuAGgzxDcANBnCG4A6DMENwD0mf8HpmoTquTGYoMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_Q6_evfrfRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}