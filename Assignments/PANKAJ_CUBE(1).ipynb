{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=[[[(i+j)*(i+j)*(i+j)/100000] for i in range(5)] for j in range(100)]\n",
    "target=[(i+5)*(i+5)*(i+5)/100000 for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.0], [1e-05], [8e-05], [0.00027], [0.00064]],\n",
       " [[1e-05], [8e-05], [0.00027], [0.00064], [0.00125]],\n",
       " [[8e-05], [0.00027], [0.00064], [0.00125], [0.00216]],\n",
       " [[0.00027], [0.00064], [0.00125], [0.00216], [0.00343]],\n",
       " [[0.00064], [0.00125], [0.00216], [0.00343], [0.00512]],\n",
       " [[0.00125], [0.00216], [0.00343], [0.00512], [0.00729]],\n",
       " [[0.00216], [0.00343], [0.00512], [0.00729], [0.01]],\n",
       " [[0.00343], [0.00512], [0.00729], [0.01], [0.01331]],\n",
       " [[0.00512], [0.00729], [0.01], [0.01331], [0.01728]],\n",
       " [[0.00729], [0.01], [0.01331], [0.01728], [0.02197]],\n",
       " [[0.01], [0.01331], [0.01728], [0.02197], [0.02744]],\n",
       " [[0.01331], [0.01728], [0.02197], [0.02744], [0.03375]],\n",
       " [[0.01728], [0.02197], [0.02744], [0.03375], [0.04096]],\n",
       " [[0.02197], [0.02744], [0.03375], [0.04096], [0.04913]],\n",
       " [[0.02744], [0.03375], [0.04096], [0.04913], [0.05832]],\n",
       " [[0.03375], [0.04096], [0.04913], [0.05832], [0.06859]],\n",
       " [[0.04096], [0.04913], [0.05832], [0.06859], [0.08]],\n",
       " [[0.04913], [0.05832], [0.06859], [0.08], [0.09261]],\n",
       " [[0.05832], [0.06859], [0.08], [0.09261], [0.10648]],\n",
       " [[0.06859], [0.08], [0.09261], [0.10648], [0.12167]],\n",
       " [[0.08], [0.09261], [0.10648], [0.12167], [0.13824]],\n",
       " [[0.09261], [0.10648], [0.12167], [0.13824], [0.15625]],\n",
       " [[0.10648], [0.12167], [0.13824], [0.15625], [0.17576]],\n",
       " [[0.12167], [0.13824], [0.15625], [0.17576], [0.19683]],\n",
       " [[0.13824], [0.15625], [0.17576], [0.19683], [0.21952]],\n",
       " [[0.15625], [0.17576], [0.19683], [0.21952], [0.24389]],\n",
       " [[0.17576], [0.19683], [0.21952], [0.24389], [0.27]],\n",
       " [[0.19683], [0.21952], [0.24389], [0.27], [0.29791]],\n",
       " [[0.21952], [0.24389], [0.27], [0.29791], [0.32768]],\n",
       " [[0.24389], [0.27], [0.29791], [0.32768], [0.35937]],\n",
       " [[0.27], [0.29791], [0.32768], [0.35937], [0.39304]],\n",
       " [[0.29791], [0.32768], [0.35937], [0.39304], [0.42875]],\n",
       " [[0.32768], [0.35937], [0.39304], [0.42875], [0.46656]],\n",
       " [[0.35937], [0.39304], [0.42875], [0.46656], [0.50653]],\n",
       " [[0.39304], [0.42875], [0.46656], [0.50653], [0.54872]],\n",
       " [[0.42875], [0.46656], [0.50653], [0.54872], [0.59319]],\n",
       " [[0.46656], [0.50653], [0.54872], [0.59319], [0.64]],\n",
       " [[0.50653], [0.54872], [0.59319], [0.64], [0.68921]],\n",
       " [[0.54872], [0.59319], [0.64], [0.68921], [0.74088]],\n",
       " [[0.59319], [0.64], [0.68921], [0.74088], [0.79507]],\n",
       " [[0.64], [0.68921], [0.74088], [0.79507], [0.85184]],\n",
       " [[0.68921], [0.74088], [0.79507], [0.85184], [0.91125]],\n",
       " [[0.74088], [0.79507], [0.85184], [0.91125], [0.97336]],\n",
       " [[0.79507], [0.85184], [0.91125], [0.97336], [1.03823]],\n",
       " [[0.85184], [0.91125], [0.97336], [1.03823], [1.10592]],\n",
       " [[0.91125], [0.97336], [1.03823], [1.10592], [1.17649]],\n",
       " [[0.97336], [1.03823], [1.10592], [1.17649], [1.25]],\n",
       " [[1.03823], [1.10592], [1.17649], [1.25], [1.32651]],\n",
       " [[1.10592], [1.17649], [1.25], [1.32651], [1.40608]],\n",
       " [[1.17649], [1.25], [1.32651], [1.40608], [1.48877]],\n",
       " [[1.25], [1.32651], [1.40608], [1.48877], [1.57464]],\n",
       " [[1.32651], [1.40608], [1.48877], [1.57464], [1.66375]],\n",
       " [[1.40608], [1.48877], [1.57464], [1.66375], [1.75616]],\n",
       " [[1.48877], [1.57464], [1.66375], [1.75616], [1.85193]],\n",
       " [[1.57464], [1.66375], [1.75616], [1.85193], [1.95112]],\n",
       " [[1.66375], [1.75616], [1.85193], [1.95112], [2.05379]],\n",
       " [[1.75616], [1.85193], [1.95112], [2.05379], [2.16]],\n",
       " [[1.85193], [1.95112], [2.05379], [2.16], [2.26981]],\n",
       " [[1.95112], [2.05379], [2.16], [2.26981], [2.38328]],\n",
       " [[2.05379], [2.16], [2.26981], [2.38328], [2.50047]],\n",
       " [[2.16], [2.26981], [2.38328], [2.50047], [2.62144]],\n",
       " [[2.26981], [2.38328], [2.50047], [2.62144], [2.74625]],\n",
       " [[2.38328], [2.50047], [2.62144], [2.74625], [2.87496]],\n",
       " [[2.50047], [2.62144], [2.74625], [2.87496], [3.00763]],\n",
       " [[2.62144], [2.74625], [2.87496], [3.00763], [3.14432]],\n",
       " [[2.74625], [2.87496], [3.00763], [3.14432], [3.28509]],\n",
       " [[2.87496], [3.00763], [3.14432], [3.28509], [3.43]],\n",
       " [[3.00763], [3.14432], [3.28509], [3.43], [3.57911]],\n",
       " [[3.14432], [3.28509], [3.43], [3.57911], [3.73248]],\n",
       " [[3.28509], [3.43], [3.57911], [3.73248], [3.89017]],\n",
       " [[3.43], [3.57911], [3.73248], [3.89017], [4.05224]],\n",
       " [[3.57911], [3.73248], [3.89017], [4.05224], [4.21875]],\n",
       " [[3.73248], [3.89017], [4.05224], [4.21875], [4.38976]],\n",
       " [[3.89017], [4.05224], [4.21875], [4.38976], [4.56533]],\n",
       " [[4.05224], [4.21875], [4.38976], [4.56533], [4.74552]],\n",
       " [[4.21875], [4.38976], [4.56533], [4.74552], [4.93039]],\n",
       " [[4.38976], [4.56533], [4.74552], [4.93039], [5.12]],\n",
       " [[4.56533], [4.74552], [4.93039], [5.12], [5.31441]],\n",
       " [[4.74552], [4.93039], [5.12], [5.31441], [5.51368]],\n",
       " [[4.93039], [5.12], [5.31441], [5.51368], [5.71787]],\n",
       " [[5.12], [5.31441], [5.51368], [5.71787], [5.92704]],\n",
       " [[5.31441], [5.51368], [5.71787], [5.92704], [6.14125]],\n",
       " [[5.51368], [5.71787], [5.92704], [6.14125], [6.36056]],\n",
       " [[5.71787], [5.92704], [6.14125], [6.36056], [6.58503]],\n",
       " [[5.92704], [6.14125], [6.36056], [6.58503], [6.81472]],\n",
       " [[6.14125], [6.36056], [6.58503], [6.81472], [7.04969]],\n",
       " [[6.36056], [6.58503], [6.81472], [7.04969], [7.29]],\n",
       " [[6.58503], [6.81472], [7.04969], [7.29], [7.53571]],\n",
       " [[6.81472], [7.04969], [7.29], [7.53571], [7.78688]],\n",
       " [[7.04969], [7.29], [7.53571], [7.78688], [8.04357]],\n",
       " [[7.29], [7.53571], [7.78688], [8.04357], [8.30584]],\n",
       " [[7.53571], [7.78688], [8.04357], [8.30584], [8.57375]],\n",
       " [[7.78688], [8.04357], [8.30584], [8.57375], [8.84736]],\n",
       " [[8.04357], [8.30584], [8.57375], [8.84736], [9.12673]],\n",
       " [[8.30584], [8.57375], [8.84736], [9.12673], [9.41192]],\n",
       " [[8.57375], [8.84736], [9.12673], [9.41192], [9.70299]],\n",
       " [[8.84736], [9.12673], [9.41192], [9.70299], [10.0]],\n",
       " [[9.12673], [9.41192], [9.70299], [10.0], [10.30301]],\n",
       " [[9.41192], [9.70299], [10.0], [10.30301], [10.61208]],\n",
       " [[9.70299], [10.0], [10.30301], [10.61208], [10.92727]]]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.array(Data,dtype=float)\n",
    "target=np.array(target,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.250000e-03, 2.160000e-03, 3.430000e-03, 5.120000e-03,\n",
       "       7.290000e-03, 1.000000e-02, 1.331000e-02, 1.728000e-02,\n",
       "       2.197000e-02, 2.744000e-02, 3.375000e-02, 4.096000e-02,\n",
       "       4.913000e-02, 5.832000e-02, 6.859000e-02, 8.000000e-02,\n",
       "       9.261000e-02, 1.064800e-01, 1.216700e-01, 1.382400e-01,\n",
       "       1.562500e-01, 1.757600e-01, 1.968300e-01, 2.195200e-01,\n",
       "       2.438900e-01, 2.700000e-01, 2.979100e-01, 3.276800e-01,\n",
       "       3.593700e-01, 3.930400e-01, 4.287500e-01, 4.665600e-01,\n",
       "       5.065300e-01, 5.487200e-01, 5.931900e-01, 6.400000e-01,\n",
       "       6.892100e-01, 7.408800e-01, 7.950700e-01, 8.518400e-01,\n",
       "       9.112500e-01, 9.733600e-01, 1.038230e+00, 1.105920e+00,\n",
       "       1.176490e+00, 1.250000e+00, 1.326510e+00, 1.406080e+00,\n",
       "       1.488770e+00, 1.574640e+00, 1.663750e+00, 1.756160e+00,\n",
       "       1.851930e+00, 1.951120e+00, 2.053790e+00, 2.160000e+00,\n",
       "       2.269810e+00, 2.383280e+00, 2.500470e+00, 2.621440e+00,\n",
       "       2.746250e+00, 2.874960e+00, 3.007630e+00, 3.144320e+00,\n",
       "       3.285090e+00, 3.430000e+00, 3.579110e+00, 3.732480e+00,\n",
       "       3.890170e+00, 4.052240e+00, 4.218750e+00, 4.389760e+00,\n",
       "       4.565330e+00, 4.745520e+00, 4.930390e+00, 5.120000e+00,\n",
       "       5.314410e+00, 5.513680e+00, 5.717870e+00, 5.927040e+00,\n",
       "       6.141250e+00, 6.360560e+00, 6.585030e+00, 6.814720e+00,\n",
       "       7.049690e+00, 7.290000e+00, 7.535710e+00, 7.786880e+00,\n",
       "       8.043570e+00, 8.305840e+00, 8.573750e+00, 8.847360e+00,\n",
       "       9.126730e+00, 9.411920e+00, 9.702990e+00, 1.000000e+01,\n",
       "       1.030301e+01, 1.061208e+01, 1.092727e+01, 1.124864e+01])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(data,target,test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00064],\n",
       "       [0.00125],\n",
       "       [0.00216],\n",
       "       [0.00343],\n",
       "       [0.00512]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM((1),batch_input_shape=(None,5,1),return_sequences=True))\n",
    "model.add(LSTM((1),return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='mean_absolute_error',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_22 (LSTM)               (None, 5, 1)              12        \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 24\n",
      "Trainable params: 24\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 22s 279ms/step - loss: 3.4560 - acc: 0.0000e+00 - val_loss: 2.3604 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.4499 - acc: 0.0000e+00 - val_loss: 2.3556 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.4436 - acc: 0.0000e+00 - val_loss: 2.3510 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.4376 - acc: 0.0000e+00 - val_loss: 2.3465 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.4316 - acc: 0.0000e+00 - val_loss: 2.3421 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.4256 - acc: 0.0000e+00 - val_loss: 2.3377 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.4196 - acc: 0.0000e+00 - val_loss: 2.3334 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.4134 - acc: 0.0000e+00 - val_loss: 2.3292 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.4076 - acc: 0.0000e+00 - val_loss: 2.3251 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.4015 - acc: 0.0000e+00 - val_loss: 2.3209 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3958 - acc: 0.0000e+00 - val_loss: 2.3168 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3896 - acc: 0.0000e+00 - val_loss: 2.3128 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3837 - acc: 0.0000e+00 - val_loss: 2.3088 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3778 - acc: 0.0000e+00 - val_loss: 2.3048 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3717 - acc: 0.0000e+00 - val_loss: 2.3009 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3655 - acc: 0.0000e+00 - val_loss: 2.2971 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3590 - acc: 0.0000e+00 - val_loss: 2.2935 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3528 - acc: 0.0000e+00 - val_loss: 2.2899 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - ETA: 0s - loss: 3.3386 - acc: 0.0000e+0 - 0s 1ms/step - loss: 3.3464 - acc: 0.0000e+00 - val_loss: 2.2863 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3400 - acc: 0.0000e+00 - val_loss: 2.2826 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3334 - acc: 0.0000e+00 - val_loss: 2.2790 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3264 - acc: 0.0000e+00 - val_loss: 2.2755 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3196 - acc: 0.0000e+00 - val_loss: 2.2720 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3131 - acc: 0.0000e+00 - val_loss: 2.2685 - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3056 - acc: 0.0000e+00 - val_loss: 2.2649 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.2984 - acc: 0.0000e+00 - val_loss: 2.2614 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - ETA: 0s - loss: 4.0863 - acc: 0.0000e+0 - 0s 1ms/step - loss: 3.2911 - acc: 0.0000e+00 - val_loss: 2.2578 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.2833 - acc: 0.0000e+00 - val_loss: 2.2541 - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.2754 - acc: 0.0000e+00 - val_loss: 2.2503 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.2675 - acc: 0.0000e+00 - val_loss: 2.2465 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.2588 - acc: 0.0000e+00 - val_loss: 2.2425 - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.2505 - acc: 0.0000e+00 - val_loss: 2.2383 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.2412 - acc: 0.0000e+00 - val_loss: 2.2338 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.2317 - acc: 0.0000e+00 - val_loss: 2.2290 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.2225 - acc: 0.0000e+00 - val_loss: 2.2236 - val_acc: 0.0000e+00\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.2123 - acc: 0.0000e+00 - val_loss: 2.2180 - val_acc: 0.0000e+00\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.2021 - acc: 0.0000e+00 - val_loss: 2.2120 - val_acc: 0.0000e+00\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.1919 - acc: 0.0000e+00 - val_loss: 2.2056 - val_acc: 0.0000e+00\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - ETA: 0s - loss: 3.9398 - acc: 0.0000e+0 - 0s 1ms/step - loss: 3.1820 - acc: 0.0000e+00 - val_loss: 2.1989 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.1713 - acc: 0.0000e+00 - val_loss: 2.1919 - val_acc: 0.0000e+00\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.1611 - acc: 0.0000e+00 - val_loss: 2.1849 - val_acc: 0.0000e+00\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.1511 - acc: 0.0000e+00 - val_loss: 2.1779 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.1417 - acc: 0.0000e+00 - val_loss: 2.1711 - val_acc: 0.0000e+00\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.1334 - acc: 0.0000e+00 - val_loss: 2.1646 - val_acc: 0.0000e+00\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.1243 - acc: 0.0000e+00 - val_loss: 2.1586 - val_acc: 0.0000e+00\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.1169 - acc: 0.0000e+00 - val_loss: 2.1529 - val_acc: 0.0000e+00\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.1100 - acc: 0.0000e+00 - val_loss: 2.1478 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.1032 - acc: 0.0000e+00 - val_loss: 2.1433 - val_acc: 0.0000e+00\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0974 - acc: 0.0000e+00 - val_loss: 2.1392 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0921 - acc: 0.0000e+00 - val_loss: 2.1355 - val_acc: 0.0000e+00\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0872 - acc: 0.0000e+00 - val_loss: 2.1324 - val_acc: 0.0000e+00\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0830 - acc: 0.0000e+00 - val_loss: 2.1296 - val_acc: 0.0000e+00\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0792 - acc: 0.0000e+00 - val_loss: 2.1271 - val_acc: 0.0000e+00\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0755 - acc: 0.0000e+00 - val_loss: 2.1250 - val_acc: 0.0000e+00\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 962us/step - loss: 3.0725 - acc: 0.0000e+00 - val_loss: 2.1230 - val_acc: 0.0000e+00\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0695 - acc: 0.0000e+00 - val_loss: 2.1212 - val_acc: 0.0000e+00\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 1000us/step - loss: 3.0668 - acc: 0.0000e+00 - val_loss: 2.1196 - val_acc: 0.0000e+00\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0645 - acc: 0.0000e+00 - val_loss: 2.1180 - val_acc: 0.0000e+00\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0622 - acc: 0.0000e+00 - val_loss: 2.1167 - val_acc: 0.0000e+00\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0600 - acc: 0.0000e+00 - val_loss: 2.1154 - val_acc: 0.0000e+00\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0581 - acc: 0.0000e+00 - val_loss: 2.1142 - val_acc: 0.0000e+00\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0563 - acc: 0.0000e+00 - val_loss: 2.1130 - val_acc: 0.0000e+00\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0546 - acc: 0.0000e+00 - val_loss: 2.1119 - val_acc: 0.0000e+00\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0529 - acc: 0.0000e+00 - val_loss: 2.1108 - val_acc: 0.0000e+00\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0514 - acc: 0.0000e+00 - val_loss: 2.1098 - val_acc: 0.0000e+00\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0498 - acc: 0.0000e+00 - val_loss: 2.1088 - val_acc: 0.0000e+00\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0484 - acc: 0.0000e+00 - val_loss: 2.1079 - val_acc: 0.0000e+00\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0469 - acc: 0.0000e+00 - val_loss: 2.1069 - val_acc: 0.0000e+00\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0455 - acc: 0.0000e+00 - val_loss: 2.1059 - val_acc: 0.0000e+00\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0441 - acc: 0.0000e+00 - val_loss: 2.1050 - val_acc: 0.0000e+00\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0428 - acc: 0.0000e+00 - val_loss: 2.1041 - val_acc: 0.0000e+00\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0414 - acc: 0.0000e+00 - val_loss: 2.1032 - val_acc: 0.0000e+00\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0402 - acc: 0.0000e+00 - val_loss: 2.1023 - val_acc: 0.0000e+00\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0389 - acc: 0.0000e+00 - val_loss: 2.1014 - val_acc: 0.0000e+00\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 1000us/step - loss: 3.0376 - acc: 0.0000e+00 - val_loss: 2.1005 - val_acc: 0.0000e+00\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0364 - acc: 0.0000e+00 - val_loss: 2.0996 - val_acc: 0.0000e+00\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0352 - acc: 0.0000e+00 - val_loss: 2.0987 - val_acc: 0.0000e+00\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0339 - acc: 0.0000e+00 - val_loss: 2.0978 - val_acc: 0.0000e+00\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0327 - acc: 0.0000e+00 - val_loss: 2.0969 - val_acc: 0.0000e+00\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0315 - acc: 0.0000e+00 - val_loss: 2.0960 - val_acc: 0.0000e+00\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0302 - acc: 0.0000e+00 - val_loss: 2.0951 - val_acc: 0.0000e+00\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0290 - acc: 0.0000e+00 - val_loss: 2.0942 - val_acc: 0.0000e+00\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0279 - acc: 0.0000e+00 - val_loss: 2.0933 - val_acc: 0.0000e+00\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0266 - acc: 0.0000e+00 - val_loss: 2.0924 - val_acc: 0.0000e+00\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0256 - acc: 0.0000e+00 - val_loss: 2.0915 - val_acc: 0.0000e+00\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0243 - acc: 0.0000e+00 - val_loss: 2.0906 - val_acc: 0.0000e+00\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0231 - acc: 0.0000e+00 - val_loss: 2.0897 - val_acc: 0.0000e+00\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0219 - acc: 0.0000e+00 - val_loss: 2.0888 - val_acc: 0.0000e+00\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0207 - acc: 0.0000e+00 - val_loss: 2.0878 - val_acc: 0.0000e+00\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0195 - acc: 0.0000e+00 - val_loss: 2.0869 - val_acc: 0.0000e+00\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0183 - acc: 0.0000e+00 - val_loss: 2.0859 - val_acc: 0.0000e+00\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0170 - acc: 0.0000e+00 - val_loss: 2.0850 - val_acc: 0.0000e+00\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0158 - acc: 0.0000e+00 - val_loss: 2.0842 - val_acc: 0.0000e+00\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0145 - acc: 0.0000e+00 - val_loss: 2.0834 - val_acc: 0.0000e+00\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0133 - acc: 0.0000e+00 - val_loss: 2.0826 - val_acc: 0.0000e+00\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0120 - acc: 0.0000e+00 - val_loss: 2.0817 - val_acc: 0.0000e+00\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0107 - acc: 0.0000e+00 - val_loss: 2.0809 - val_acc: 0.0000e+00\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0095 - acc: 0.0000e+00 - val_loss: 2.0801 - val_acc: 0.0000e+00\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0081 - acc: 0.0000e+00 - val_loss: 2.0793 - val_acc: 0.0000e+00\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0069 - acc: 0.0000e+00 - val_loss: 2.0784 - val_acc: 0.0000e+00\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0057 - acc: 0.0000e+00 - val_loss: 2.0775 - val_acc: 0.0000e+00\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0043 - acc: 0.0000e+00 - val_loss: 2.0767 - val_acc: 0.0000e+00\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0030 - acc: 0.0000e+00 - val_loss: 2.0758 - val_acc: 0.0000e+00\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0017 - acc: 0.0000e+00 - val_loss: 2.0750 - val_acc: 0.0000e+00\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.0004 - acc: 0.0000e+00 - val_loss: 2.0742 - val_acc: 0.0000e+00\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9992 - acc: 0.0000e+00 - val_loss: 2.0733 - val_acc: 0.0000e+00\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9979 - acc: 0.0000e+00 - val_loss: 2.0724 - val_acc: 0.0000e+00\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9966 - acc: 0.0000e+00 - val_loss: 2.0716 - val_acc: 0.0000e+00\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9953 - acc: 0.0000e+00 - val_loss: 2.0707 - val_acc: 0.0000e+00\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9940 - acc: 0.0000e+00 - val_loss: 2.0698 - val_acc: 0.0000e+00\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9927 - acc: 0.0000e+00 - val_loss: 2.0689 - val_acc: 0.0000e+00\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - ETA: 0s - loss: 2.9427 - acc: 0.0000e+0 - 0s 1ms/step - loss: 2.9913 - acc: 0.0000e+00 - val_loss: 2.0680 - val_acc: 0.0000e+00\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9900 - acc: 0.0000e+00 - val_loss: 2.0671 - val_acc: 0.0000e+00\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9886 - acc: 0.0000e+00 - val_loss: 2.0662 - val_acc: 0.0000e+00\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9873 - acc: 0.0000e+00 - val_loss: 2.0653 - val_acc: 0.0000e+00\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9859 - acc: 0.0000e+00 - val_loss: 2.0643 - val_acc: 0.0000e+00\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9845 - acc: 0.0000e+00 - val_loss: 2.0634 - val_acc: 0.0000e+00\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9832 - acc: 0.0000e+00 - val_loss: 2.0625 - val_acc: 0.0000e+00\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9819 - acc: 0.0000e+00 - val_loss: 2.0615 - val_acc: 0.0000e+00\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9807 - acc: 0.0000e+00 - val_loss: 2.0606 - val_acc: 0.0000e+00\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9792 - acc: 0.0000e+00 - val_loss: 2.0597 - val_acc: 0.0000e+00\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9779 - acc: 0.0000e+00 - val_loss: 2.0588 - val_acc: 0.0000e+00\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9766 - acc: 0.0000e+00 - val_loss: 2.0579 - val_acc: 0.0000e+00\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9752 - acc: 0.0000e+00 - val_loss: 2.0569 - val_acc: 0.0000e+00\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9739 - acc: 0.0000e+00 - val_loss: 2.0560 - val_acc: 0.0000e+00\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9726 - acc: 0.0000e+00 - val_loss: 2.0550 - val_acc: 0.0000e+00\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9712 - acc: 0.0000e+00 - val_loss: 2.0540 - val_acc: 0.0000e+00\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9698 - acc: 0.0000e+00 - val_loss: 2.0530 - val_acc: 0.0000e+00\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9683 - acc: 0.0000e+00 - val_loss: 2.0521 - val_acc: 0.0000e+00\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9670 - acc: 0.0000e+00 - val_loss: 2.0511 - val_acc: 0.0000e+00\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9657 - acc: 0.0000e+00 - val_loss: 2.0501 - val_acc: 0.0000e+00\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9642 - acc: 0.0000e+00 - val_loss: 2.0492 - val_acc: 0.0000e+00\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9630 - acc: 0.0000e+00 - val_loss: 2.0482 - val_acc: 0.0000e+00\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9616 - acc: 0.0000e+00 - val_loss: 2.0472 - val_acc: 0.0000e+00\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9603 - acc: 0.0000e+00 - val_loss: 2.0462 - val_acc: 0.0000e+00\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9589 - acc: 0.0000e+00 - val_loss: 2.0452 - val_acc: 0.0000e+00\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9575 - acc: 0.0000e+00 - val_loss: 2.0442 - val_acc: 0.0000e+00\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - ETA: 0s - loss: 2.0956 - acc: 0.0000e+0 - 0s 1ms/step - loss: 2.9561 - acc: 0.0000e+00 - val_loss: 2.0433 - val_acc: 0.0000e+00\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9548 - acc: 0.0000e+00 - val_loss: 2.0423 - val_acc: 0.0000e+00\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9534 - acc: 0.0000e+00 - val_loss: 2.0413 - val_acc: 0.0000e+00\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - ETA: 0s - loss: 2.7028 - acc: 0.0000e+0 - 0s 1ms/step - loss: 2.9520 - acc: 0.0000e+00 - val_loss: 2.0403 - val_acc: 0.0000e+00\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9507 - acc: 0.0000e+00 - val_loss: 2.0394 - val_acc: 0.0000e+00\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9492 - acc: 0.0000e+00 - val_loss: 2.0386 - val_acc: 0.0000e+00\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9478 - acc: 0.0000e+00 - val_loss: 2.0377 - val_acc: 0.0000e+00\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9463 - acc: 0.0000e+00 - val_loss: 2.0369 - val_acc: 0.0000e+00\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9449 - acc: 0.0000e+00 - val_loss: 2.0360 - val_acc: 0.0000e+00\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9435 - acc: 0.0000e+00 - val_loss: 2.0351 - val_acc: 0.0000e+00\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9420 - acc: 0.0000e+00 - val_loss: 2.0343 - val_acc: 0.0000e+00\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9405 - acc: 0.0000e+00 - val_loss: 2.0334 - val_acc: 0.0000e+00\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9390 - acc: 0.0000e+00 - val_loss: 2.0326 - val_acc: 0.0000e+00\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9376 - acc: 0.0000e+00 - val_loss: 2.0317 - val_acc: 0.0000e+00\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9362 - acc: 0.0000e+00 - val_loss: 2.0308 - val_acc: 0.0000e+00\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9347 - acc: 0.0000e+00 - val_loss: 2.0300 - val_acc: 0.0000e+00\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9332 - acc: 0.0000e+00 - val_loss: 2.0291 - val_acc: 0.0000e+00\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9318 - acc: 0.0000e+00 - val_loss: 2.0282 - val_acc: 0.0000e+00\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9303 - acc: 0.0000e+00 - val_loss: 2.0273 - val_acc: 0.0000e+00\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9288 - acc: 0.0000e+00 - val_loss: 2.0265 - val_acc: 0.0000e+00\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9275 - acc: 0.0000e+00 - val_loss: 2.0256 - val_acc: 0.0000e+00\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9260 - acc: 0.0000e+00 - val_loss: 2.0247 - val_acc: 0.0000e+00\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9245 - acc: 0.0000e+00 - val_loss: 2.0238 - val_acc: 0.0000e+00\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9232 - acc: 0.0000e+00 - val_loss: 2.0229 - val_acc: 0.0000e+00\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9217 - acc: 0.0000e+00 - val_loss: 2.0220 - val_acc: 0.0000e+00\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9202 - acc: 0.0000e+00 - val_loss: 2.0212 - val_acc: 0.0000e+00\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9188 - acc: 0.0000e+00 - val_loss: 2.0203 - val_acc: 0.0000e+00\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9174 - acc: 0.0000e+00 - val_loss: 2.0194 - val_acc: 0.0000e+00\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9159 - acc: 0.0000e+00 - val_loss: 2.0185 - val_acc: 0.0000e+00\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9144 - acc: 0.0000e+00 - val_loss: 2.0176 - val_acc: 0.0000e+00\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9130 - acc: 0.0000e+00 - val_loss: 2.0167 - val_acc: 0.0000e+00\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9115 - acc: 0.0000e+00 - val_loss: 2.0160 - val_acc: 0.0000e+00\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9100 - acc: 0.0000e+00 - val_loss: 2.0153 - val_acc: 0.0000e+00\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9085 - acc: 0.0000e+00 - val_loss: 2.0146 - val_acc: 0.0000e+00\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9071 - acc: 0.0000e+00 - val_loss: 2.0138 - val_acc: 0.0000e+00\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9057 - acc: 0.0000e+00 - val_loss: 2.0131 - val_acc: 0.0000e+00\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9042 - acc: 0.0000e+00 - val_loss: 2.0124 - val_acc: 0.0000e+00\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.9026 - acc: 0.0000e+00 - val_loss: 2.0117 - val_acc: 0.0000e+00\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.9013 - acc: 0.0000e+00 - val_loss: 2.0110 - val_acc: 0.0000e+00\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8997 - acc: 0.0000e+00 - val_loss: 2.0102 - val_acc: 0.0000e+00\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8982 - acc: 0.0000e+00 - val_loss: 2.0095 - val_acc: 0.0000e+00\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8968 - acc: 0.0000e+00 - val_loss: 2.0088 - val_acc: 0.0000e+00\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8953 - acc: 0.0000e+00 - val_loss: 2.0081 - val_acc: 0.0000e+00\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8938 - acc: 0.0000e+00 - val_loss: 2.0073 - val_acc: 0.0000e+00\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8922 - acc: 0.0000e+00 - val_loss: 2.0066 - val_acc: 0.0000e+00\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8908 - acc: 0.0000e+00 - val_loss: 2.0059 - val_acc: 0.0000e+00\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8892 - acc: 0.0000e+00 - val_loss: 2.0051 - val_acc: 0.0000e+00\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8878 - acc: 0.0000e+00 - val_loss: 2.0044 - val_acc: 0.0000e+00\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8863 - acc: 0.0000e+00 - val_loss: 2.0036 - val_acc: 0.0000e+00\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8849 - acc: 0.0000e+00 - val_loss: 2.0029 - val_acc: 0.0000e+00\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8834 - acc: 0.0000e+00 - val_loss: 2.0021 - val_acc: 0.0000e+00\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8819 - acc: 0.0000e+00 - val_loss: 2.0014 - val_acc: 0.0000e+00\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8805 - acc: 0.0000e+00 - val_loss: 2.0007 - val_acc: 0.0000e+00\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 1000us/step - loss: 2.8790 - acc: 0.0000e+00 - val_loss: 1.9999 - val_acc: 0.0000e+00\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8776 - acc: 0.0000e+00 - val_loss: 1.9992 - val_acc: 0.0000e+00\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8762 - acc: 0.0000e+00 - val_loss: 1.9984 - val_acc: 0.0000e+00\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8748 - acc: 0.0000e+00 - val_loss: 1.9976 - val_acc: 0.0000e+00\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8732 - acc: 0.0000e+00 - val_loss: 1.9969 - val_acc: 0.0000e+00\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8718 - acc: 0.0000e+00 - val_loss: 1.9961 - val_acc: 0.0000e+00\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8704 - acc: 0.0000e+00 - val_loss: 1.9953 - val_acc: 0.0000e+00\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8689 - acc: 0.0000e+00 - val_loss: 1.9946 - val_acc: 0.0000e+00\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8673 - acc: 0.0000e+00 - val_loss: 1.9938 - val_acc: 0.0000e+00\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8660 - acc: 0.0000e+00 - val_loss: 1.9930 - val_acc: 0.0000e+00\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8645 - acc: 0.0000e+00 - val_loss: 1.9923 - val_acc: 0.0000e+00\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8631 - acc: 0.0000e+00 - val_loss: 1.9915 - val_acc: 0.0000e+00\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8617 - acc: 0.0000e+00 - val_loss: 1.9907 - val_acc: 0.0000e+00\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8604 - acc: 0.0000e+00 - val_loss: 1.9899 - val_acc: 0.0000e+00\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8589 - acc: 0.0000e+00 - val_loss: 1.9892 - val_acc: 0.0000e+00\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8575 - acc: 0.0000e+00 - val_loss: 1.9884 - val_acc: 0.0000e+00\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8561 - acc: 0.0000e+00 - val_loss: 1.9876 - val_acc: 0.0000e+00\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8547 - acc: 0.0000e+00 - val_loss: 1.9868 - val_acc: 0.0000e+00\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8534 - acc: 0.0000e+00 - val_loss: 1.9860 - val_acc: 0.0000e+00\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8519 - acc: 0.0000e+00 - val_loss: 1.9852 - val_acc: 0.0000e+00\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - ETA: 0s - loss: 3.5346 - acc: 0.0000e+0 - 0s 1ms/step - loss: 2.8506 - acc: 0.0000e+00 - val_loss: 1.9844 - val_acc: 0.0000e+00\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8491 - acc: 0.0000e+00 - val_loss: 1.9836 - val_acc: 0.0000e+00\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8476 - acc: 0.0000e+00 - val_loss: 1.9828 - val_acc: 0.0000e+00\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8462 - acc: 0.0000e+00 - val_loss: 1.9819 - val_acc: 0.0000e+00\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8447 - acc: 0.0000e+00 - val_loss: 1.9811 - val_acc: 0.0000e+00\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8433 - acc: 0.0000e+00 - val_loss: 1.9803 - val_acc: 0.0000e+00\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8418 - acc: 0.0000e+00 - val_loss: 1.9795 - val_acc: 0.0000e+00\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8404 - acc: 0.0000e+00 - val_loss: 1.9786 - val_acc: 0.0000e+00\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8388 - acc: 0.0000e+00 - val_loss: 1.9778 - val_acc: 0.0000e+00\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8374 - acc: 0.0000e+00 - val_loss: 1.9771 - val_acc: 0.0000e+00\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8360 - acc: 0.0000e+00 - val_loss: 1.9764 - val_acc: 0.0000e+00\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8345 - acc: 0.0000e+00 - val_loss: 1.9757 - val_acc: 0.0000e+00\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 975us/step - loss: 2.8329 - acc: 0.0000e+00 - val_loss: 1.9749 - val_acc: 0.0000e+00\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8315 - acc: 0.0000e+00 - val_loss: 1.9742 - val_acc: 0.0000e+00\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8300 - acc: 0.0000e+00 - val_loss: 1.9735 - val_acc: 0.0000e+00\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8285 - acc: 0.0000e+00 - val_loss: 1.9728 - val_acc: 0.0000e+00\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8270 - acc: 0.0000e+00 - val_loss: 1.9720 - val_acc: 0.0000e+00\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8255 - acc: 0.0000e+00 - val_loss: 1.9713 - val_acc: 0.0000e+00\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8240 - acc: 0.0000e+00 - val_loss: 1.9705 - val_acc: 0.0000e+00\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8224 - acc: 0.0000e+00 - val_loss: 1.9698 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8210 - acc: 0.0000e+00 - val_loss: 1.9691 - val_acc: 0.0000e+00\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8194 - acc: 0.0000e+00 - val_loss: 1.9683 - val_acc: 0.0000e+00\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8179 - acc: 0.0000e+00 - val_loss: 1.9676 - val_acc: 0.0000e+00\n",
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8163 - acc: 0.0000e+00 - val_loss: 1.9668 - val_acc: 0.0000e+00\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8148 - acc: 0.0000e+00 - val_loss: 1.9660 - val_acc: 0.0000e+00\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8132 - acc: 0.0000e+00 - val_loss: 1.9652 - val_acc: 0.0000e+00\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8117 - acc: 0.0000e+00 - val_loss: 1.9644 - val_acc: 0.0000e+00\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8102 - acc: 0.0000e+00 - val_loss: 1.9636 - val_acc: 0.0000e+00\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8087 - acc: 0.0000e+00 - val_loss: 1.9628 - val_acc: 0.0000e+00\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8071 - acc: 0.0000e+00 - val_loss: 1.9620 - val_acc: 0.0000e+00\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8056 - acc: 0.0000e+00 - val_loss: 1.9612 - val_acc: 0.0000e+00\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8040 - acc: 0.0000e+00 - val_loss: 1.9603 - val_acc: 0.0000e+00\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8024 - acc: 0.0000e+00 - val_loss: 1.9595 - val_acc: 0.0000e+00\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.8010 - acc: 0.0000e+00 - val_loss: 1.9586 - val_acc: 0.0000e+00\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7994 - acc: 0.0000e+00 - val_loss: 1.9577 - val_acc: 0.0000e+00\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7980 - acc: 0.0000e+00 - val_loss: 1.9568 - val_acc: 0.0000e+00\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7963 - acc: 0.0000e+00 - val_loss: 1.9559 - val_acc: 0.0000e+00\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 975us/step - loss: 2.7948 - acc: 0.0000e+00 - val_loss: 1.9549 - val_acc: 0.0000e+00\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7933 - acc: 0.0000e+00 - val_loss: 1.9539 - val_acc: 0.0000e+00\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7917 - acc: 0.0000e+00 - val_loss: 1.9530 - val_acc: 0.0000e+00\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7901 - acc: 0.0000e+00 - val_loss: 1.9520 - val_acc: 0.0000e+00\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7885 - acc: 0.0000e+00 - val_loss: 1.9510 - val_acc: 0.0000e+00\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7870 - acc: 0.0000e+00 - val_loss: 1.9500 - val_acc: 0.0000e+00\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7854 - acc: 0.0000e+00 - val_loss: 1.9490 - val_acc: 0.0000e+00\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7838 - acc: 0.0000e+00 - val_loss: 1.9479 - val_acc: 0.0000e+00\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7822 - acc: 0.0000e+00 - val_loss: 1.9469 - val_acc: 0.0000e+00\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7806 - acc: 0.0000e+00 - val_loss: 1.9459 - val_acc: 0.0000e+00\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7790 - acc: 0.0000e+00 - val_loss: 1.9448 - val_acc: 0.0000e+00\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7774 - acc: 0.0000e+00 - val_loss: 1.9438 - val_acc: 0.0000e+00\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7757 - acc: 0.0000e+00 - val_loss: 1.9427 - val_acc: 0.0000e+00\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7742 - acc: 0.0000e+00 - val_loss: 1.9416 - val_acc: 0.0000e+00\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7725 - acc: 0.0000e+00 - val_loss: 1.9406 - val_acc: 0.0000e+00\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7708 - acc: 0.0000e+00 - val_loss: 1.9395 - val_acc: 0.0000e+00\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7692 - acc: 0.0000e+00 - val_loss: 1.9384 - val_acc: 0.0000e+00\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7675 - acc: 0.0000e+00 - val_loss: 1.9372 - val_acc: 0.0000e+00\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7658 - acc: 0.0000e+00 - val_loss: 1.9360 - val_acc: 0.0000e+00\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7641 - acc: 0.0000e+00 - val_loss: 1.9348 - val_acc: 0.0000e+00\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7624 - acc: 0.0000e+00 - val_loss: 1.9337 - val_acc: 0.0000e+00\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7607 - acc: 0.0000e+00 - val_loss: 1.9325 - val_acc: 0.0000e+00\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7590 - acc: 0.0000e+00 - val_loss: 1.9313 - val_acc: 0.0000e+00\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7573 - acc: 0.0000e+00 - val_loss: 1.9301 - val_acc: 0.0000e+00\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7557 - acc: 0.0000e+00 - val_loss: 1.9289 - val_acc: 0.0000e+00\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7538 - acc: 0.0000e+00 - val_loss: 1.9277 - val_acc: 0.0000e+00\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7521 - acc: 0.0000e+00 - val_loss: 1.9264 - val_acc: 0.0000e+00\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7504 - acc: 0.0000e+00 - val_loss: 1.9250 - val_acc: 0.0000e+00\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7486 - acc: 0.0000e+00 - val_loss: 1.9236 - val_acc: 0.0000e+00\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7468 - acc: 0.0000e+00 - val_loss: 1.9222 - val_acc: 0.0000e+00\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7450 - acc: 0.0000e+00 - val_loss: 1.9208 - val_acc: 0.0000e+00\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7432 - acc: 0.0000e+00 - val_loss: 1.9194 - val_acc: 0.0000e+00\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7415 - acc: 0.0000e+00 - val_loss: 1.9180 - val_acc: 0.0000e+00\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7396 - acc: 0.0000e+00 - val_loss: 1.9166 - val_acc: 0.0000e+00\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 0s 1000us/step - loss: 2.7377 - acc: 0.0000e+00 - val_loss: 1.9152 - val_acc: 0.0000e+00\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 0s 987us/step - loss: 2.7359 - acc: 0.0000e+00 - val_loss: 1.9138 - val_acc: 0.0000e+00\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 0s 987us/step - loss: 2.7340 - acc: 0.0000e+00 - val_loss: 1.9124 - val_acc: 0.0000e+00\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 0s 1000us/step - loss: 2.7321 - acc: 0.0000e+00 - val_loss: 1.9110 - val_acc: 0.0000e+00\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7302 - acc: 0.0000e+00 - val_loss: 1.9095 - val_acc: 0.0000e+00\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7283 - acc: 0.0000e+00 - val_loss: 1.9081 - val_acc: 0.0000e+00\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7264 - acc: 0.0000e+00 - val_loss: 1.9066 - val_acc: 0.0000e+00\n",
      "Epoch 289/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7245 - acc: 0.0000e+00 - val_loss: 1.9051 - val_acc: 0.0000e+00\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7225 - acc: 0.0000e+00 - val_loss: 1.9035 - val_acc: 0.0000e+00\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7206 - acc: 0.0000e+00 - val_loss: 1.9019 - val_acc: 0.0000e+00\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7186 - acc: 0.0000e+00 - val_loss: 1.9004 - val_acc: 0.0000e+00\n",
      "Epoch 293/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7167 - acc: 0.0000e+00 - val_loss: 1.8989 - val_acc: 0.0000e+00\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7147 - acc: 0.0000e+00 - val_loss: 1.8973 - val_acc: 0.0000e+00\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7126 - acc: 0.0000e+00 - val_loss: 1.8957 - val_acc: 0.0000e+00\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7107 - acc: 0.0000e+00 - val_loss: 1.8939 - val_acc: 0.0000e+00\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7086 - acc: 0.0000e+00 - val_loss: 1.8923 - val_acc: 0.0000e+00\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7066 - acc: 0.0000e+00 - val_loss: 1.8907 - val_acc: 0.0000e+00\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7045 - acc: 0.0000e+00 - val_loss: 1.8891 - val_acc: 0.0000e+00\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7024 - acc: 0.0000e+00 - val_loss: 1.8874 - val_acc: 0.0000e+00\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.7004 - acc: 0.0000e+00 - val_loss: 1.8858 - val_acc: 0.0000e+00\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6983 - acc: 0.0000e+00 - val_loss: 1.8841 - val_acc: 0.0000e+00\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6961 - acc: 0.0000e+00 - val_loss: 1.8823 - val_acc: 0.0000e+00\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6940 - acc: 0.0000e+00 - val_loss: 1.8805 - val_acc: 0.0000e+00\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6919 - acc: 0.0000e+00 - val_loss: 1.8786 - val_acc: 0.0000e+00\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6897 - acc: 0.0000e+00 - val_loss: 1.8768 - val_acc: 0.0000e+00\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6876 - acc: 0.0000e+00 - val_loss: 1.8748 - val_acc: 0.0000e+00\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6855 - acc: 0.0000e+00 - val_loss: 1.8729 - val_acc: 0.0000e+00\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6833 - acc: 0.0000e+00 - val_loss: 1.8712 - val_acc: 0.0000e+00\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6811 - acc: 0.0000e+00 - val_loss: 1.8694 - val_acc: 0.0000e+00\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6789 - acc: 0.0000e+00 - val_loss: 1.8676 - val_acc: 0.0000e+00\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6767 - acc: 0.0000e+00 - val_loss: 1.8658 - val_acc: 0.0000e+00\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6745 - acc: 0.0000e+00 - val_loss: 1.8639 - val_acc: 0.0000e+00\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6723 - acc: 0.0000e+00 - val_loss: 1.8620 - val_acc: 0.0000e+00\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6701 - acc: 0.0000e+00 - val_loss: 1.8602 - val_acc: 0.0000e+00\n",
      "Epoch 316/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6678 - acc: 0.0000e+00 - val_loss: 1.8583 - val_acc: 0.0000e+00\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6656 - acc: 0.0000e+00 - val_loss: 1.8564 - val_acc: 0.0000e+00\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6633 - acc: 0.0000e+00 - val_loss: 1.8543 - val_acc: 0.0000e+00\n",
      "Epoch 319/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6610 - acc: 0.0000e+00 - val_loss: 1.8524 - val_acc: 0.0000e+00\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6586 - acc: 0.0000e+00 - val_loss: 1.8504 - val_acc: 0.0000e+00\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6564 - acc: 0.0000e+00 - val_loss: 1.8485 - val_acc: 0.0000e+00\n",
      "Epoch 322/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6540 - acc: 0.0000e+00 - val_loss: 1.8465 - val_acc: 0.0000e+00\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6517 - acc: 0.0000e+00 - val_loss: 1.8443 - val_acc: 0.0000e+00\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6493 - acc: 0.0000e+00 - val_loss: 1.8422 - val_acc: 0.0000e+00\n",
      "Epoch 325/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6469 - acc: 0.0000e+00 - val_loss: 1.8401 - val_acc: 0.0000e+00\n",
      "Epoch 326/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6445 - acc: 0.0000e+00 - val_loss: 1.8379 - val_acc: 0.0000e+00\n",
      "Epoch 327/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6421 - acc: 0.0000e+00 - val_loss: 1.8357 - val_acc: 0.0000e+00\n",
      "Epoch 328/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6396 - acc: 0.0000e+00 - val_loss: 1.8337 - val_acc: 0.0000e+00\n",
      "Epoch 329/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6372 - acc: 0.0000e+00 - val_loss: 1.8316 - val_acc: 0.0000e+00\n",
      "Epoch 330/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6348 - acc: 0.0000e+00 - val_loss: 1.8295 - val_acc: 0.0000e+00\n",
      "Epoch 331/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6323 - acc: 0.0000e+00 - val_loss: 1.8273 - val_acc: 0.0000e+00\n",
      "Epoch 332/500\n",
      "80/80 [==============================] - 0s 987us/step - loss: 2.6298 - acc: 0.0000e+00 - val_loss: 1.8250 - val_acc: 0.0000e+00\n",
      "Epoch 333/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6273 - acc: 0.0000e+00 - val_loss: 1.8228 - val_acc: 0.0000e+00\n",
      "Epoch 334/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6248 - acc: 0.0000e+00 - val_loss: 1.8207 - val_acc: 0.0000e+00\n",
      "Epoch 335/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6223 - acc: 0.0000e+00 - val_loss: 1.8185 - val_acc: 0.0000e+00\n",
      "Epoch 336/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6197 - acc: 0.0000e+00 - val_loss: 1.8162 - val_acc: 0.0000e+00\n",
      "Epoch 337/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6171 - acc: 0.0000e+00 - val_loss: 1.8139 - val_acc: 0.0000e+00\n",
      "Epoch 338/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6146 - acc: 0.0000e+00 - val_loss: 1.8114 - val_acc: 0.0000e+00\n",
      "Epoch 339/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6120 - acc: 0.0000e+00 - val_loss: 1.8090 - val_acc: 0.0000e+00\n",
      "Epoch 340/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6093 - acc: 0.0000e+00 - val_loss: 1.8068 - val_acc: 0.0000e+00\n",
      "Epoch 341/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6067 - acc: 0.0000e+00 - val_loss: 1.8043 - val_acc: 0.0000e+00\n",
      "Epoch 342/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6041 - acc: 0.0000e+00 - val_loss: 1.8020 - val_acc: 0.0000e+00\n",
      "Epoch 343/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.6014 - acc: 0.0000e+00 - val_loss: 1.7996 - val_acc: 0.0000e+00\n",
      "Epoch 344/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5987 - acc: 0.0000e+00 - val_loss: 1.7973 - val_acc: 0.0000e+00\n",
      "Epoch 345/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5961 - acc: 0.0000e+00 - val_loss: 1.7948 - val_acc: 0.0000e+00\n",
      "Epoch 346/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5933 - acc: 0.0000e+00 - val_loss: 1.7924 - val_acc: 0.0000e+00\n",
      "Epoch 347/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5906 - acc: 0.0000e+00 - val_loss: 1.7899 - val_acc: 0.0000e+00\n",
      "Epoch 348/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5878 - acc: 0.0000e+00 - val_loss: 1.7875 - val_acc: 0.0000e+00\n",
      "Epoch 349/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5850 - acc: 0.0000e+00 - val_loss: 1.7850 - val_acc: 0.0000e+00\n",
      "Epoch 350/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5823 - acc: 0.0000e+00 - val_loss: 1.7825 - val_acc: 0.0000e+00\n",
      "Epoch 351/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5795 - acc: 0.0000e+00 - val_loss: 1.7799 - val_acc: 0.0000e+00\n",
      "Epoch 352/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5766 - acc: 0.0000e+00 - val_loss: 1.7772 - val_acc: 0.0000e+00\n",
      "Epoch 353/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5738 - acc: 0.0000e+00 - val_loss: 1.7746 - val_acc: 0.0000e+00\n",
      "Epoch 354/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5710 - acc: 0.0000e+00 - val_loss: 1.7720 - val_acc: 0.0000e+00\n",
      "Epoch 355/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5682 - acc: 0.0000e+00 - val_loss: 1.7693 - val_acc: 0.0000e+00\n",
      "Epoch 356/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5653 - acc: 0.0000e+00 - val_loss: 1.7667 - val_acc: 0.0000e+00\n",
      "Epoch 357/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5625 - acc: 0.0000e+00 - val_loss: 1.7641 - val_acc: 0.0000e+00\n",
      "Epoch 358/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5596 - acc: 0.0000e+00 - val_loss: 1.7615 - val_acc: 0.0000e+00\n",
      "Epoch 359/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5567 - acc: 0.0000e+00 - val_loss: 1.7589 - val_acc: 0.0000e+00\n",
      "Epoch 360/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5539 - acc: 0.0000e+00 - val_loss: 1.7562 - val_acc: 0.0000e+00\n",
      "Epoch 361/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5510 - acc: 0.0000e+00 - val_loss: 1.7536 - val_acc: 0.0000e+00\n",
      "Epoch 362/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5481 - acc: 0.0000e+00 - val_loss: 1.7509 - val_acc: 0.0000e+00\n",
      "Epoch 363/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5451 - acc: 0.0000e+00 - val_loss: 1.7481 - val_acc: 0.0000e+00\n",
      "Epoch 364/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5422 - acc: 0.0000e+00 - val_loss: 1.7453 - val_acc: 0.0000e+00\n",
      "Epoch 365/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5392 - acc: 0.0000e+00 - val_loss: 1.7425 - val_acc: 0.0000e+00\n",
      "Epoch 366/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5363 - acc: 0.0000e+00 - val_loss: 1.7396 - val_acc: 0.0000e+00\n",
      "Epoch 367/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5333 - acc: 0.0000e+00 - val_loss: 1.7369 - val_acc: 0.0000e+00\n",
      "Epoch 368/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5303 - acc: 0.0000e+00 - val_loss: 1.7341 - val_acc: 0.0000e+00\n",
      "Epoch 369/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5273 - acc: 0.0000e+00 - val_loss: 1.7313 - val_acc: 0.0000e+00\n",
      "Epoch 370/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5243 - acc: 0.0000e+00 - val_loss: 1.7285 - val_acc: 0.0000e+00\n",
      "Epoch 371/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5212 - acc: 0.0000e+00 - val_loss: 1.7258 - val_acc: 0.0000e+00\n",
      "Epoch 372/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5181 - acc: 0.0000e+00 - val_loss: 1.7231 - val_acc: 0.0000e+00\n",
      "Epoch 373/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5151 - acc: 0.0000e+00 - val_loss: 1.7203 - val_acc: 0.0000e+00\n",
      "Epoch 374/500\n",
      "80/80 [==============================] - 0s 1000us/step - loss: 2.5121 - acc: 0.0000e+00 - val_loss: 1.7175 - val_acc: 0.0000e+00\n",
      "Epoch 375/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5090 - acc: 0.0000e+00 - val_loss: 1.7146 - val_acc: 0.0000e+00\n",
      "Epoch 376/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5063 - acc: 0.0000e+00 - val_loss: 1.7123 - val_acc: 0.0000e+00\n",
      "Epoch 377/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5045 - acc: 0.0000e+00 - val_loss: 1.7102 - val_acc: 0.0000e+00\n",
      "Epoch 378/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5030 - acc: 0.0000e+00 - val_loss: 1.7081 - val_acc: 0.0000e+00\n",
      "Epoch 379/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5016 - acc: 0.0000e+00 - val_loss: 1.7060 - val_acc: 0.0000e+00\n",
      "Epoch 380/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.5004 - acc: 0.0000e+00 - val_loss: 1.7040 - val_acc: 0.0000e+00\n",
      "Epoch 381/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4992 - acc: 0.0000e+00 - val_loss: 1.7019 - val_acc: 0.0000e+00\n",
      "Epoch 382/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4981 - acc: 0.0000e+00 - val_loss: 1.7001 - val_acc: 0.0000e+00\n",
      "Epoch 383/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4969 - acc: 0.0000e+00 - val_loss: 1.6984 - val_acc: 0.0000e+00\n",
      "Epoch 384/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4958 - acc: 0.0000e+00 - val_loss: 1.6968 - val_acc: 0.0000e+00\n",
      "Epoch 385/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4947 - acc: 0.0000e+00 - val_loss: 1.6952 - val_acc: 0.0000e+00\n",
      "Epoch 386/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4935 - acc: 0.0000e+00 - val_loss: 1.6936 - val_acc: 0.0000e+00\n",
      "Epoch 387/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4924 - acc: 0.0000e+00 - val_loss: 1.6921 - val_acc: 0.0000e+00\n",
      "Epoch 388/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4913 - acc: 0.0000e+00 - val_loss: 1.6906 - val_acc: 0.0000e+00\n",
      "Epoch 389/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4902 - acc: 0.0000e+00 - val_loss: 1.6891 - val_acc: 0.0000e+00\n",
      "Epoch 390/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4893 - acc: 0.0000e+00 - val_loss: 1.6875 - val_acc: 0.0000e+00\n",
      "Epoch 391/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4882 - acc: 0.0000e+00 - val_loss: 1.6859 - val_acc: 0.0000e+00\n",
      "Epoch 392/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4871 - acc: 0.0000e+00 - val_loss: 1.6844 - val_acc: 0.0000e+00\n",
      "Epoch 393/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4861 - acc: 0.0000e+00 - val_loss: 1.6828 - val_acc: 0.0000e+00\n",
      "Epoch 394/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4851 - acc: 0.0000e+00 - val_loss: 1.6812 - val_acc: 0.0000e+00\n",
      "Epoch 395/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4840 - acc: 0.0000e+00 - val_loss: 1.6797 - val_acc: 0.0000e+00\n",
      "Epoch 396/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4831 - acc: 0.0000e+00 - val_loss: 1.6781 - val_acc: 0.0000e+00\n",
      "Epoch 397/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4820 - acc: 0.0000e+00 - val_loss: 1.6766 - val_acc: 0.0000e+00\n",
      "Epoch 398/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4811 - acc: 0.0000e+00 - val_loss: 1.6751 - val_acc: 0.0000e+00\n",
      "Epoch 399/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4801 - acc: 0.0000e+00 - val_loss: 1.6737 - val_acc: 0.0000e+00\n",
      "Epoch 400/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4792 - acc: 0.0000e+00 - val_loss: 1.6724 - val_acc: 0.0000e+00\n",
      "Epoch 401/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4781 - acc: 0.0000e+00 - val_loss: 1.6710 - val_acc: 0.0000e+00\n",
      "Epoch 402/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4772 - acc: 0.0000e+00 - val_loss: 1.6696 - val_acc: 0.0000e+00\n",
      "Epoch 403/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4764 - acc: 0.0000e+00 - val_loss: 1.6680 - val_acc: 0.0000e+00\n",
      "Epoch 404/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4754 - acc: 0.0000e+00 - val_loss: 1.6667 - val_acc: 0.0000e+00\n",
      "Epoch 405/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4744 - acc: 0.0000e+00 - val_loss: 1.6653 - val_acc: 0.0000e+00\n",
      "Epoch 406/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4734 - acc: 0.0000e+00 - val_loss: 1.6639 - val_acc: 0.0000e+00\n",
      "Epoch 407/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4725 - acc: 0.0000e+00 - val_loss: 1.6625 - val_acc: 0.0000e+00\n",
      "Epoch 408/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4716 - acc: 0.0000e+00 - val_loss: 1.6611 - val_acc: 0.0000e+00\n",
      "Epoch 409/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4706 - acc: 0.0000e+00 - val_loss: 1.6597 - val_acc: 0.0000e+00\n",
      "Epoch 410/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4697 - acc: 0.0000e+00 - val_loss: 1.6583 - val_acc: 0.0000e+00\n",
      "Epoch 411/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4688 - acc: 0.0000e+00 - val_loss: 1.6568 - val_acc: 0.0000e+00\n",
      "Epoch 412/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4678 - acc: 0.0000e+00 - val_loss: 1.6554 - val_acc: 0.0000e+00\n",
      "Epoch 413/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4669 - acc: 0.0000e+00 - val_loss: 1.6546 - val_acc: 0.0000e+00\n",
      "Epoch 414/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4663 - acc: 0.0000e+00 - val_loss: 1.6543 - val_acc: 0.0000e+00\n",
      "Epoch 415/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4657 - acc: 0.0000e+00 - val_loss: 1.6535 - val_acc: 0.0000e+00\n",
      "Epoch 416/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4649 - acc: 0.0000e+00 - val_loss: 1.6525 - val_acc: 0.0000e+00\n",
      "Epoch 417/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4644 - acc: 0.0000e+00 - val_loss: 1.6515 - val_acc: 0.0000e+00\n",
      "Epoch 418/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4637 - acc: 0.0000e+00 - val_loss: 1.6509 - val_acc: 0.0000e+00\n",
      "Epoch 419/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4632 - acc: 0.0000e+00 - val_loss: 1.6505 - val_acc: 0.0000e+00\n",
      "Epoch 420/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4627 - acc: 0.0000e+00 - val_loss: 1.6501 - val_acc: 0.0000e+00\n",
      "Epoch 421/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4623 - acc: 0.0000e+00 - val_loss: 1.6498 - val_acc: 0.0000e+00\n",
      "Epoch 422/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4620 - acc: 0.0000e+00 - val_loss: 1.6496 - val_acc: 0.0000e+00\n",
      "Epoch 423/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4618 - acc: 0.0000e+00 - val_loss: 1.6493 - val_acc: 0.0000e+00\n",
      "Epoch 424/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4614 - acc: 0.0000e+00 - val_loss: 1.6490 - val_acc: 0.0000e+00\n",
      "Epoch 425/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4612 - acc: 0.0000e+00 - val_loss: 1.6488 - val_acc: 0.0000e+00\n",
      "Epoch 426/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4610 - acc: 0.0000e+00 - val_loss: 1.6485 - val_acc: 0.0000e+00\n",
      "Epoch 427/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4609 - acc: 0.0000e+00 - val_loss: 1.6484 - val_acc: 0.0000e+00\n",
      "Epoch 428/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4607 - acc: 0.0000e+00 - val_loss: 1.6482 - val_acc: 0.0000e+00\n",
      "Epoch 429/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4607 - acc: 0.0000e+00 - val_loss: 1.6480 - val_acc: 0.0000e+00\n",
      "Epoch 430/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4605 - acc: 0.0000e+00 - val_loss: 1.6479 - val_acc: 0.0000e+00\n",
      "Epoch 431/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4605 - acc: 0.0000e+00 - val_loss: 1.6480 - val_acc: 0.0000e+00\n",
      "Epoch 432/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4604 - acc: 0.0000e+00 - val_loss: 1.6480 - val_acc: 0.0000e+00\n",
      "Epoch 433/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4604 - acc: 0.0000e+00 - val_loss: 1.6480 - val_acc: 0.0000e+00\n",
      "Epoch 434/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4603 - acc: 0.0000e+00 - val_loss: 1.6479 - val_acc: 0.0000e+00\n",
      "Epoch 435/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4603 - acc: 0.0000e+00 - val_loss: 1.6478 - val_acc: 0.0000e+00\n",
      "Epoch 436/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4603 - acc: 0.0000e+00 - val_loss: 1.6475 - val_acc: 0.0000e+00\n",
      "Epoch 437/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4602 - acc: 0.0000e+00 - val_loss: 1.6475 - val_acc: 0.0000e+00\n",
      "Epoch 438/500\n",
      "80/80 [==============================] - 0s 1000us/step - loss: 2.4601 - acc: 0.0000e+00 - val_loss: 1.6475 - val_acc: 0.0000e+00\n",
      "Epoch 439/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4601 - acc: 0.0000e+00 - val_loss: 1.6474 - val_acc: 0.0000e+00\n",
      "Epoch 440/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4601 - acc: 0.0000e+00 - val_loss: 1.6473 - val_acc: 0.0000e+00\n",
      "Epoch 441/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4602 - acc: 0.0000e+00 - val_loss: 1.6474 - val_acc: 0.0000e+00\n",
      "Epoch 442/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4600 - acc: 0.0000e+00 - val_loss: 1.6473 - val_acc: 0.0000e+00\n",
      "Epoch 443/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4600 - acc: 0.0000e+00 - val_loss: 1.6471 - val_acc: 0.0000e+00\n",
      "Epoch 444/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4600 - acc: 0.0000e+00 - val_loss: 1.6471 - val_acc: 0.0000e+00\n",
      "Epoch 445/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4599 - acc: 0.0000e+00 - val_loss: 1.6472 - val_acc: 0.0000e+00\n",
      "Epoch 446/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4599 - acc: 0.0000e+00 - val_loss: 1.6474 - val_acc: 0.0000e+00\n",
      "Epoch 447/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4598 - acc: 0.0000e+00 - val_loss: 1.6475 - val_acc: 0.0000e+00\n",
      "Epoch 448/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4598 - acc: 0.0000e+00 - val_loss: 1.6476 - val_acc: 0.0000e+00\n",
      "Epoch 449/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4598 - acc: 0.0000e+00 - val_loss: 1.6477 - val_acc: 0.0000e+00\n",
      "Epoch 450/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4597 - acc: 0.0000e+00 - val_loss: 1.6482 - val_acc: 0.0000e+00\n",
      "Epoch 451/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4597 - acc: 0.0000e+00 - val_loss: 1.6485 - val_acc: 0.0000e+00\n",
      "Epoch 452/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4597 - acc: 0.0000e+00 - val_loss: 1.6485 - val_acc: 0.0000e+00\n",
      "Epoch 453/500\n",
      "80/80 [==============================] - ETA: 0s - loss: 2.3861 - acc: 0.0000e+0 - 0s 1ms/step - loss: 2.4597 - acc: 0.0000e+00 - val_loss: 1.6485 - val_acc: 0.0000e+00\n",
      "Epoch 454/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4596 - acc: 0.0000e+00 - val_loss: 1.6489 - val_acc: 0.0000e+00\n",
      "Epoch 455/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4597 - acc: 0.0000e+00 - val_loss: 1.6488 - val_acc: 0.0000e+00\n",
      "Epoch 456/500\n",
      "80/80 [==============================] - ETA: 0s - loss: 3.2215 - acc: 0.0000e+0 - 0s 1ms/step - loss: 2.4597 - acc: 0.0000e+00 - val_loss: 1.6488 - val_acc: 0.0000e+00\n",
      "Epoch 457/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4596 - acc: 0.0000e+00 - val_loss: 1.6483 - val_acc: 0.0000e+00\n",
      "Epoch 458/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4595 - acc: 0.0000e+00 - val_loss: 1.6481 - val_acc: 0.0000e+00\n",
      "Epoch 459/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4596 - acc: 0.0000e+00 - val_loss: 1.6481 - val_acc: 0.0000e+00\n",
      "Epoch 460/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4595 - acc: 0.0000e+00 - val_loss: 1.6485 - val_acc: 0.0000e+00\n",
      "Epoch 461/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4595 - acc: 0.0000e+00 - val_loss: 1.6486 - val_acc: 0.0000e+00\n",
      "Epoch 462/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4595 - acc: 0.0000e+00 - val_loss: 1.6488 - val_acc: 0.0000e+00\n",
      "Epoch 463/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4595 - acc: 0.0000e+00 - val_loss: 1.6490 - val_acc: 0.0000e+00\n",
      "Epoch 464/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4594 - acc: 0.0000e+00 - val_loss: 1.6486 - val_acc: 0.0000e+00\n",
      "Epoch 465/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4595 - acc: 0.0000e+00 - val_loss: 1.6479 - val_acc: 0.0000e+00\n",
      "Epoch 466/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4594 - acc: 0.0000e+00 - val_loss: 1.6474 - val_acc: 0.0000e+00\n",
      "Epoch 467/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4594 - acc: 0.0000e+00 - val_loss: 1.6478 - val_acc: 0.0000e+00\n",
      "Epoch 468/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4593 - acc: 0.0000e+00 - val_loss: 1.6480 - val_acc: 0.0000e+00\n",
      "Epoch 469/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4593 - acc: 0.0000e+00 - val_loss: 1.6481 - val_acc: 0.0000e+00\n",
      "Epoch 470/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4593 - acc: 0.0000e+00 - val_loss: 1.6480 - val_acc: 0.0000e+00\n",
      "Epoch 471/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4593 - acc: 0.0000e+00 - val_loss: 1.6476 - val_acc: 0.0000e+00\n",
      "Epoch 472/500\n",
      "80/80 [==============================] - 0s 1000us/step - loss: 2.4593 - acc: 0.0000e+00 - val_loss: 1.6476 - val_acc: 0.0000e+00\n",
      "Epoch 473/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4593 - acc: 0.0000e+00 - val_loss: 1.6480 - val_acc: 0.0000e+00\n",
      "Epoch 474/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4593 - acc: 0.0000e+00 - val_loss: 1.6480 - val_acc: 0.0000e+00\n",
      "Epoch 475/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4593 - acc: 0.0000e+00 - val_loss: 1.6482 - val_acc: 0.0000e+00\n",
      "Epoch 476/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4593 - acc: 0.0000e+00 - val_loss: 1.6481 - val_acc: 0.0000e+00\n",
      "Epoch 477/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4592 - acc: 0.0000e+00 - val_loss: 1.6475 - val_acc: 0.0000e+00\n",
      "Epoch 478/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4594 - acc: 0.0000e+00 - val_loss: 1.6469 - val_acc: 0.0000e+00\n",
      "Epoch 479/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4594 - acc: 0.0000e+00 - val_loss: 1.6471 - val_acc: 0.0000e+00\n",
      "Epoch 480/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4593 - acc: 0.0000e+00 - val_loss: 1.6473 - val_acc: 0.0000e+00\n",
      "Epoch 481/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4593 - acc: 0.0000e+00 - val_loss: 1.6480 - val_acc: 0.0000e+00\n",
      "Epoch 482/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4593 - acc: 0.0000e+00 - val_loss: 1.6487 - val_acc: 0.0000e+00\n",
      "Epoch 483/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4593 - acc: 0.0000e+00 - val_loss: 1.6488 - val_acc: 0.0000e+00\n",
      "Epoch 484/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4592 - acc: 0.0000e+00 - val_loss: 1.6484 - val_acc: 0.0000e+00\n",
      "Epoch 485/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4591 - acc: 0.0000e+00 - val_loss: 1.6477 - val_acc: 0.0000e+00\n",
      "Epoch 486/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4591 - acc: 0.0000e+00 - val_loss: 1.6468 - val_acc: 0.0000e+00\n",
      "Epoch 487/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4593 - acc: 0.0000e+00 - val_loss: 1.6462 - val_acc: 0.0000e+00\n",
      "Epoch 488/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4594 - acc: 0.0000e+00 - val_loss: 1.6462 - val_acc: 0.0000e+00\n",
      "Epoch 489/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4594 - acc: 0.0000e+00 - val_loss: 1.6466 - val_acc: 0.0000e+00\n",
      "Epoch 490/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4592 - acc: 0.0000e+00 - val_loss: 1.6472 - val_acc: 0.0000e+00\n",
      "Epoch 491/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4591 - acc: 0.0000e+00 - val_loss: 1.6481 - val_acc: 0.0000e+00\n",
      "Epoch 492/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4591 - acc: 0.0000e+00 - val_loss: 1.6491 - val_acc: 0.0000e+00\n",
      "Epoch 493/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4592 - acc: 0.0000e+00 - val_loss: 1.6498 - val_acc: 0.0000e+00\n",
      "Epoch 494/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4593 - acc: 0.0000e+00 - val_loss: 1.6499 - val_acc: 0.0000e+00\n",
      "Epoch 495/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4593 - acc: 0.0000e+00 - val_loss: 1.6498 - val_acc: 0.0000e+00\n",
      "Epoch 496/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4592 - acc: 0.0000e+00 - val_loss: 1.6494 - val_acc: 0.0000e+00\n",
      "Epoch 497/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4592 - acc: 0.0000e+00 - val_loss: 1.6487 - val_acc: 0.0000e+00\n",
      "Epoch 498/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4591 - acc: 0.0000e+00 - val_loss: 1.6481 - val_acc: 0.0000e+00\n",
      "Epoch 499/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4590 - acc: 0.0000e+00 - val_loss: 1.6479 - val_acc: 0.0000e+00\n",
      "Epoch 500/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4590 - acc: 0.0000e+00 - val_loss: 1.6479 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(20),results,c='r')\n",
    "plt.scatter(range(20),y_test,c='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
