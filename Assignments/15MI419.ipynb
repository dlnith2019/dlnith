{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15MI419.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDGlJKpGk9-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,LSTM\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDQdO--QlF8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1=[]\n",
        "for num in range (1,101):\n",
        "  X1.append((((num*2)*5)-1)/100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC198GPSlZPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a6cwSjxld_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X2=X1[::-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ0FSzVmllbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Liq40h1zlvlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.column_stack((X1, X2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VkKg8BUlm6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD3IJNUVl_hE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = [(x1*x2)/5 for x1,x2 in zip(X1,X2)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtTNy95kmRO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlb9AiixmX8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.array(data,dtype=float)\n",
        "target = np.array(target,dtype=float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMBwDIaTmeQR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05f6c929-326d-4fe7-d5ea-39d8e30fa7ee"
      },
      "source": [
        "data = np.array(data).reshape(100, 2,1)\n",
        "data.shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 2, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMKGA0KtmrXc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f2103a1-9f0e-4417-c897-650bd1906cfa"
      },
      "source": [
        "target.shape"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jormCXfmvC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(data,target,test_size=0.2,random_state=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_lEh2d5mxm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(2,1)))\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(25, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_tiD6X0m1KN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7bf359c-bc61-4a44-c438-b6c52099a602"
      },
      "source": [
        "history = model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/500\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 13.8277 - val_loss: 13.7880\n",
            "Epoch 2/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 13.6998 - val_loss: 13.6597\n",
            "Epoch 3/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 13.5614 - val_loss: 13.5141\n",
            "Epoch 4/500\n",
            "80/80 [==============================] - 0s 964us/step - loss: 13.4003 - val_loss: 13.3422\n",
            "Epoch 5/500\n",
            "80/80 [==============================] - 0s 976us/step - loss: 13.2029 - val_loss: 13.1248\n",
            "Epoch 6/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 12.9376 - val_loss: 12.8291\n",
            "Epoch 7/500\n",
            "80/80 [==============================] - 0s 989us/step - loss: 12.5516 - val_loss: 12.3863\n",
            "Epoch 8/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 11.9182 - val_loss: 11.6531\n",
            "Epoch 9/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 10.6502 - val_loss: 10.5051\n",
            "Epoch 10/500\n",
            "80/80 [==============================] - 0s 990us/step - loss: 8.5557 - val_loss: 12.4352\n",
            "Epoch 11/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.0707 - val_loss: 10.3618\n",
            "Epoch 12/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.0599 - val_loss: 9.2738\n",
            "Epoch 13/500\n",
            "80/80 [==============================] - 0s 956us/step - loss: 6.6230 - val_loss: 8.5233\n",
            "Epoch 14/500\n",
            "80/80 [==============================] - 0s 959us/step - loss: 6.1281 - val_loss: 7.8165\n",
            "Epoch 15/500\n",
            "80/80 [==============================] - 0s 997us/step - loss: 5.2434 - val_loss: 6.9771\n",
            "Epoch 16/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.5186 - val_loss: 5.8965\n",
            "Epoch 17/500\n",
            "80/80 [==============================] - 0s 999us/step - loss: 3.6823 - val_loss: 4.4830\n",
            "Epoch 18/500\n",
            "80/80 [==============================] - 0s 952us/step - loss: 2.8446 - val_loss: 3.2342\n",
            "Epoch 19/500\n",
            "80/80 [==============================] - 0s 989us/step - loss: 1.9825 - val_loss: 1.9476\n",
            "Epoch 20/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1790 - val_loss: 1.1811\n",
            "Epoch 21/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.7635 - val_loss: 0.8213\n",
            "Epoch 22/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.6519 - val_loss: 0.6711\n",
            "Epoch 23/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.5996 - val_loss: 0.5367\n",
            "Epoch 24/500\n",
            "80/80 [==============================] - 0s 984us/step - loss: 0.5341 - val_loss: 0.5090\n",
            "Epoch 25/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4854 - val_loss: 0.4181\n",
            "Epoch 26/500\n",
            "80/80 [==============================] - 0s 988us/step - loss: 0.4239 - val_loss: 0.3534\n",
            "Epoch 27/500\n",
            "80/80 [==============================] - 0s 934us/step - loss: 0.3848 - val_loss: 0.3404\n",
            "Epoch 28/500\n",
            "80/80 [==============================] - 0s 952us/step - loss: 0.3596 - val_loss: 0.3146\n",
            "Epoch 29/500\n",
            "80/80 [==============================] - 0s 947us/step - loss: 0.3281 - val_loss: 0.2873\n",
            "Epoch 30/500\n",
            "80/80 [==============================] - 0s 983us/step - loss: 0.3024 - val_loss: 0.2392\n",
            "Epoch 31/500\n",
            "80/80 [==============================] - 0s 955us/step - loss: 0.2690 - val_loss: 0.2122\n",
            "Epoch 32/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.2613 - val_loss: 0.2333\n",
            "Epoch 33/500\n",
            "80/80 [==============================] - 0s 964us/step - loss: 0.2732 - val_loss: 0.1959\n",
            "Epoch 34/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.2341 - val_loss: 0.1921\n",
            "Epoch 35/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.2245 - val_loss: 0.1716\n",
            "Epoch 36/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1991 - val_loss: 0.1560\n",
            "Epoch 37/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1837 - val_loss: 0.1450\n",
            "Epoch 38/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1738 - val_loss: 0.1458\n",
            "Epoch 39/500\n",
            "80/80 [==============================] - 0s 971us/step - loss: 0.1604 - val_loss: 0.1509\n",
            "Epoch 40/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1563 - val_loss: 0.1285\n",
            "Epoch 41/500\n",
            "80/80 [==============================] - 0s 959us/step - loss: 0.1480 - val_loss: 0.1223\n",
            "Epoch 42/500\n",
            "80/80 [==============================] - 0s 952us/step - loss: 0.1393 - val_loss: 0.1064\n",
            "Epoch 43/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1313 - val_loss: 0.1052\n",
            "Epoch 44/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 0.1231 - val_loss: 0.1034\n",
            "Epoch 45/500\n",
            "80/80 [==============================] - 0s 983us/step - loss: 0.1157 - val_loss: 0.0928\n",
            "Epoch 46/500\n",
            "80/80 [==============================] - 0s 972us/step - loss: 0.1068 - val_loss: 0.0837\n",
            "Epoch 47/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1022 - val_loss: 0.0819\n",
            "Epoch 48/500\n",
            "80/80 [==============================] - 0s 975us/step - loss: 0.0937 - val_loss: 0.0785\n",
            "Epoch 49/500\n",
            "80/80 [==============================] - 0s 966us/step - loss: 0.0899 - val_loss: 0.0775\n",
            "Epoch 50/500\n",
            "80/80 [==============================] - 0s 978us/step - loss: 0.0834 - val_loss: 0.0655\n",
            "Epoch 51/500\n",
            "80/80 [==============================] - 0s 942us/step - loss: 0.0788 - val_loss: 0.0608\n",
            "Epoch 52/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.0621\n",
            "Epoch 53/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0576\n",
            "Epoch 54/500\n",
            "80/80 [==============================] - 0s 934us/step - loss: 0.0671 - val_loss: 0.0570\n",
            "Epoch 55/500\n",
            "80/80 [==============================] - 0s 960us/step - loss: 0.0628 - val_loss: 0.0504\n",
            "Epoch 56/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0519\n",
            "Epoch 57/500\n",
            "80/80 [==============================] - 0s 920us/step - loss: 0.0545 - val_loss: 0.0429\n",
            "Epoch 58/500\n",
            "80/80 [==============================] - 0s 970us/step - loss: 0.0516 - val_loss: 0.0469\n",
            "Epoch 59/500\n",
            "80/80 [==============================] - 0s 973us/step - loss: 0.0509 - val_loss: 0.0391\n",
            "Epoch 60/500\n",
            "80/80 [==============================] - 0s 978us/step - loss: 0.0438 - val_loss: 0.0386\n",
            "Epoch 61/500\n",
            "80/80 [==============================] - 0s 937us/step - loss: 0.0415 - val_loss: 0.0387\n",
            "Epoch 62/500\n",
            "80/80 [==============================] - 0s 957us/step - loss: 0.0403 - val_loss: 0.0403\n",
            "Epoch 63/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0392 - val_loss: 0.0340\n",
            "Epoch 64/500\n",
            "80/80 [==============================] - 0s 975us/step - loss: 0.0361 - val_loss: 0.0368\n",
            "Epoch 65/500\n",
            "80/80 [==============================] - 0s 958us/step - loss: 0.0421 - val_loss: 0.0278\n",
            "Epoch 66/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0388 - val_loss: 0.0538\n",
            "Epoch 67/500\n",
            "80/80 [==============================] - 0s 972us/step - loss: 0.0663 - val_loss: 0.0836\n",
            "Epoch 68/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0348\n",
            "Epoch 69/500\n",
            "80/80 [==============================] - 0s 996us/step - loss: 0.0370 - val_loss: 0.0420\n",
            "Epoch 70/500\n",
            "80/80 [==============================] - 0s 940us/step - loss: 0.0429 - val_loss: 0.0297\n",
            "Epoch 71/500\n",
            "80/80 [==============================] - 0s 974us/step - loss: 0.0306 - val_loss: 0.0265\n",
            "Epoch 72/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0267 - val_loss: 0.0271\n",
            "Epoch 73/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.0252\n",
            "Epoch 74/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0232 - val_loss: 0.0174\n",
            "Epoch 75/500\n",
            "80/80 [==============================] - 0s 979us/step - loss: 0.0201 - val_loss: 0.0161\n",
            "Epoch 76/500\n",
            "80/80 [==============================] - 0s 940us/step - loss: 0.0184 - val_loss: 0.0154\n",
            "Epoch 77/500\n",
            "80/80 [==============================] - 0s 960us/step - loss: 0.0169 - val_loss: 0.0150\n",
            "Epoch 78/500\n",
            "80/80 [==============================] - 0s 939us/step - loss: 0.0155 - val_loss: 0.0140\n",
            "Epoch 79/500\n",
            "80/80 [==============================] - 0s 933us/step - loss: 0.0149 - val_loss: 0.0123\n",
            "Epoch 80/500\n",
            "80/80 [==============================] - 0s 959us/step - loss: 0.0138 - val_loss: 0.0116\n",
            "Epoch 81/500\n",
            "80/80 [==============================] - 0s 936us/step - loss: 0.0138 - val_loss: 0.0126\n",
            "Epoch 82/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0099\n",
            "Epoch 83/500\n",
            "80/80 [==============================] - 0s 957us/step - loss: 0.0123 - val_loss: 0.0119\n",
            "Epoch 84/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0077\n",
            "Epoch 85/500\n",
            "80/80 [==============================] - 0s 992us/step - loss: 0.0107 - val_loss: 0.0068\n",
            "Epoch 86/500\n",
            "80/80 [==============================] - 0s 969us/step - loss: 0.0101 - val_loss: 0.0075\n",
            "Epoch 87/500\n",
            "80/80 [==============================] - 0s 980us/step - loss: 0.0088 - val_loss: 0.0059\n",
            "Epoch 88/500\n",
            "80/80 [==============================] - 0s 951us/step - loss: 0.0089 - val_loss: 0.0059\n",
            "Epoch 89/500\n",
            "80/80 [==============================] - 0s 971us/step - loss: 0.0082 - val_loss: 0.0047\n",
            "Epoch 90/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0045\n",
            "Epoch 91/500\n",
            "80/80 [==============================] - 0s 985us/step - loss: 0.0074 - val_loss: 0.0069\n",
            "Epoch 92/500\n",
            "80/80 [==============================] - 0s 963us/step - loss: 0.0073 - val_loss: 0.0038\n",
            "Epoch 93/500\n",
            "80/80 [==============================] - 0s 980us/step - loss: 0.0060 - val_loss: 0.0031\n",
            "Epoch 94/500\n",
            "80/80 [==============================] - 0s 961us/step - loss: 0.0056 - val_loss: 0.0034\n",
            "Epoch 95/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 0.0052 - val_loss: 0.0032\n",
            "Epoch 96/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0044\n",
            "Epoch 97/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 0.0051 - val_loss: 0.0020\n",
            "Epoch 98/500\n",
            "80/80 [==============================] - 0s 931us/step - loss: 0.0059 - val_loss: 0.0019\n",
            "Epoch 99/500\n",
            "80/80 [==============================] - 0s 947us/step - loss: 0.0054 - val_loss: 0.0068\n",
            "Epoch 100/500\n",
            "80/80 [==============================] - 0s 948us/step - loss: 0.0053 - val_loss: 0.0016\n",
            "Epoch 101/500\n",
            "80/80 [==============================] - 0s 995us/step - loss: 0.0039 - val_loss: 0.0023\n",
            "Epoch 102/500\n",
            "80/80 [==============================] - 0s 990us/step - loss: 0.0032 - val_loss: 0.0023\n",
            "Epoch 103/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0025\n",
            "Epoch 104/500\n",
            "80/80 [==============================] - 0s 977us/step - loss: 0.0028 - val_loss: 0.0014\n",
            "Epoch 105/500\n",
            "80/80 [==============================] - 0s 943us/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 106/500\n",
            "80/80 [==============================] - 0s 918us/step - loss: 0.0024 - val_loss: 7.0667e-04\n",
            "Epoch 107/500\n",
            "80/80 [==============================] - 0s 938us/step - loss: 0.0025 - val_loss: 0.0016\n",
            "Epoch 108/500\n",
            "80/80 [==============================] - 0s 988us/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 109/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0010\n",
            "Epoch 110/500\n",
            "80/80 [==============================] - 0s 964us/step - loss: 0.0021 - val_loss: 9.6959e-04\n",
            "Epoch 111/500\n",
            "80/80 [==============================] - 0s 977us/step - loss: 0.0030 - val_loss: 0.0049\n",
            "Epoch 112/500\n",
            "80/80 [==============================] - 0s 944us/step - loss: 0.0024 - val_loss: 0.0011\n",
            "Epoch 113/500\n",
            "80/80 [==============================] - 0s 970us/step - loss: 0.0015 - val_loss: 0.0012\n",
            "Epoch 114/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0016\n",
            "Epoch 115/500\n",
            "80/80 [==============================] - 0s 998us/step - loss: 0.0013 - val_loss: 0.0010\n",
            "Epoch 116/500\n",
            "80/80 [==============================] - 0s 958us/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 117/500\n",
            "80/80 [==============================] - 0s 980us/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 118/500\n",
            "80/80 [==============================] - 0s 953us/step - loss: 0.0010 - val_loss: 7.6152e-04\n",
            "Epoch 119/500\n",
            "80/80 [==============================] - 0s 950us/step - loss: 9.8036e-04 - val_loss: 0.0013\n",
            "Epoch 120/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.7120e-04 - val_loss: 0.0026\n",
            "Epoch 121/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 2.1837e-04\n",
            "Epoch 122/500\n",
            "80/80 [==============================] - 0s 978us/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 123/500\n",
            "80/80 [==============================] - 0s 957us/step - loss: 0.0013 - val_loss: 0.0041\n",
            "Epoch 124/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 125/500\n",
            "80/80 [==============================] - 0s 976us/step - loss: 0.0015 - val_loss: 3.9198e-04\n",
            "Epoch 126/500\n",
            "80/80 [==============================] - 0s 978us/step - loss: 0.0017 - val_loss: 9.8419e-04\n",
            "Epoch 127/500\n",
            "80/80 [==============================] - 0s 981us/step - loss: 0.0018 - val_loss: 0.0085\n",
            "Epoch 128/500\n",
            "80/80 [==============================] - 0s 957us/step - loss: 0.0046 - val_loss: 6.5197e-04\n",
            "Epoch 129/500\n",
            "80/80 [==============================] - 0s 978us/step - loss: 0.0040 - val_loss: 8.1494e-04\n",
            "Epoch 130/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0098\n",
            "Epoch 131/500\n",
            "80/80 [==============================] - 0s 962us/step - loss: 0.0073 - val_loss: 0.0020\n",
            "Epoch 132/500\n",
            "80/80 [==============================] - 0s 946us/step - loss: 0.0034 - val_loss: 0.0027\n",
            "Epoch 133/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0063\n",
            "Epoch 134/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0015\n",
            "Epoch 135/500\n",
            "80/80 [==============================] - 0s 954us/step - loss: 0.0033 - val_loss: 0.0096\n",
            "Epoch 136/500\n",
            "80/80 [==============================] - 0s 994us/step - loss: 0.0108 - val_loss: 0.0241\n",
            "Epoch 137/500\n",
            "80/80 [==============================] - 0s 977us/step - loss: 0.0165 - val_loss: 0.0120\n",
            "Epoch 138/500\n",
            "80/80 [==============================] - 0s 966us/step - loss: 0.0188 - val_loss: 0.0315\n",
            "Epoch 139/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0224 - val_loss: 0.0203\n",
            "Epoch 140/500\n",
            "80/80 [==============================] - 0s 952us/step - loss: 0.0202 - val_loss: 0.0030\n",
            "Epoch 141/500\n",
            "80/80 [==============================] - 0s 985us/step - loss: 0.0133 - val_loss: 0.0112\n",
            "Epoch 142/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0080\n",
            "Epoch 143/500\n",
            "80/80 [==============================] - 0s 983us/step - loss: 0.0064 - val_loss: 0.0030\n",
            "Epoch 144/500\n",
            "80/80 [==============================] - 0s 948us/step - loss: 0.0064 - val_loss: 0.0019\n",
            "Epoch 145/500\n",
            "80/80 [==============================] - 0s 973us/step - loss: 0.0032 - val_loss: 0.0031\n",
            "Epoch 146/500\n",
            "80/80 [==============================] - 0s 972us/step - loss: 0.0028 - val_loss: 0.0035\n",
            "Epoch 147/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 8.3349e-04\n",
            "Epoch 148/500\n",
            "80/80 [==============================] - 0s 938us/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 149/500\n",
            "80/80 [==============================] - 0s 930us/step - loss: 0.0022 - val_loss: 0.0015\n",
            "Epoch 150/500\n",
            "80/80 [==============================] - 0s 943us/step - loss: 0.0016 - val_loss: 0.0020\n",
            "Epoch 151/500\n",
            "80/80 [==============================] - 0s 950us/step - loss: 0.0033 - val_loss: 0.0159\n",
            "Epoch 152/500\n",
            "80/80 [==============================] - 0s 954us/step - loss: 0.0112 - val_loss: 0.0055\n",
            "Epoch 153/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0017\n",
            "Epoch 154/500\n",
            "80/80 [==============================] - 0s 949us/step - loss: 0.0077 - val_loss: 0.0110\n",
            "Epoch 155/500\n",
            "80/80 [==============================] - 0s 980us/step - loss: 0.0107 - val_loss: 0.0062\n",
            "Epoch 156/500\n",
            "80/80 [==============================] - 0s 985us/step - loss: 0.0071 - val_loss: 0.0090\n",
            "Epoch 157/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0055\n",
            "Epoch 158/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0036\n",
            "Epoch 159/500\n",
            "80/80 [==============================] - 0s 977us/step - loss: 0.0051 - val_loss: 0.0032\n",
            "Epoch 160/500\n",
            "80/80 [==============================] - 0s 975us/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 161/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 6.8565e-04\n",
            "Epoch 162/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0036\n",
            "Epoch 163/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.0325e-04 - val_loss: 5.8450e-04\n",
            "Epoch 164/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 2.4238e-04\n",
            "Epoch 165/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0042\n",
            "Epoch 166/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 5.4455e-04\n",
            "Epoch 167/500\n",
            "80/80 [==============================] - 0s 953us/step - loss: 0.0014 - val_loss: 2.7233e-04\n",
            "Epoch 168/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0134\n",
            "Epoch 169/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 6.0648e-04\n",
            "Epoch 170/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0019\n",
            "Epoch 171/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0052\n",
            "Epoch 172/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 4.4581e-04\n",
            "Epoch 173/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 174/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0118\n",
            "Epoch 175/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0035\n",
            "Epoch 176/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 1.7512e-04\n",
            "Epoch 177/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0143\n",
            "Epoch 178/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0018\n",
            "Epoch 179/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0013\n",
            "Epoch 180/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 9.8409e-04\n",
            "Epoch 181/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 6.0138e-04\n",
            "Epoch 182/500\n",
            "80/80 [==============================] - 0s 931us/step - loss: 9.4513e-04 - val_loss: 0.0022\n",
            "Epoch 183/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.5281e-04 - val_loss: 5.7435e-04\n",
            "Epoch 184/500\n",
            "80/80 [==============================] - 0s 961us/step - loss: 5.6397e-04 - val_loss: 2.4813e-04\n",
            "Epoch 185/500\n",
            "80/80 [==============================] - 0s 977us/step - loss: 6.4975e-04 - val_loss: 0.0012\n",
            "Epoch 186/500\n",
            "80/80 [==============================] - 0s 936us/step - loss: 5.2928e-04 - val_loss: 0.0021\n",
            "Epoch 187/500\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 6.3406e-04 - val_loss: 2.0380e-04\n",
            "Epoch 188/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.1038e-04 - val_loss: 8.3727e-04\n",
            "Epoch 189/500\n",
            "80/80 [==============================] - 0s 978us/step - loss: 5.1471e-04 - val_loss: 0.0025\n",
            "Epoch 190/500\n",
            "80/80 [==============================] - 0s 962us/step - loss: 0.0010 - val_loss: 2.3971e-04\n",
            "Epoch 191/500\n",
            "80/80 [==============================] - 0s 976us/step - loss: 4.8594e-04 - val_loss: 1.3757e-04\n",
            "Epoch 192/500\n",
            "80/80 [==============================] - 0s 970us/step - loss: 5.1918e-04 - val_loss: 0.0025\n",
            "Epoch 193/500\n",
            "80/80 [==============================] - 0s 953us/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 194/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 195/500\n",
            "80/80 [==============================] - 0s 925us/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 196/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.7854e-04 - val_loss: 0.0017\n",
            "Epoch 197/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.4108e-04 - val_loss: 1.8402e-04\n",
            "Epoch 198/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.1651e-04 - val_loss: 0.0027\n",
            "Epoch 199/500\n",
            "80/80 [==============================] - 0s 968us/step - loss: 0.0012 - val_loss: 0.0022\n",
            "Epoch 200/500\n",
            "80/80 [==============================] - 0s 958us/step - loss: 0.0012 - val_loss: 2.7623e-04\n",
            "Epoch 201/500\n",
            "80/80 [==============================] - 0s 962us/step - loss: 6.6074e-04 - val_loss: 5.4520e-04\n",
            "Epoch 202/500\n",
            "80/80 [==============================] - 0s 962us/step - loss: 7.3873e-04 - val_loss: 0.0021\n",
            "Epoch 203/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 2.0847e-04\n",
            "Epoch 204/500\n",
            "80/80 [==============================] - 0s 954us/step - loss: 6.2004e-04 - val_loss: 2.5639e-04\n",
            "Epoch 205/500\n",
            "80/80 [==============================] - 0s 959us/step - loss: 2.4576e-04 - val_loss: 0.0012\n",
            "Epoch 206/500\n",
            "80/80 [==============================] - 0s 975us/step - loss: 2.2957e-04 - val_loss: 4.6835e-04\n",
            "Epoch 207/500\n",
            "80/80 [==============================] - 0s 952us/step - loss: 2.4690e-04 - val_loss: 1.6212e-04\n",
            "Epoch 208/500\n",
            "80/80 [==============================] - 0s 928us/step - loss: 4.1524e-04 - val_loss: 0.0012\n",
            "Epoch 209/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.2666e-04 - val_loss: 0.0013\n",
            "Epoch 210/500\n",
            "80/80 [==============================] - 0s 912us/step - loss: 4.0837e-04 - val_loss: 2.1796e-04\n",
            "Epoch 211/500\n",
            "80/80 [==============================] - 0s 930us/step - loss: 2.0690e-04 - val_loss: 8.5151e-04\n",
            "Epoch 212/500\n",
            "80/80 [==============================] - 0s 978us/step - loss: 2.5582e-04 - val_loss: 9.8498e-04\n",
            "Epoch 213/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.4664e-04 - val_loss: 2.2744e-04\n",
            "Epoch 214/500\n",
            "80/80 [==============================] - 0s 992us/step - loss: 4.0092e-04 - val_loss: 9.1224e-04\n",
            "Epoch 215/500\n",
            "80/80 [==============================] - 0s 986us/step - loss: 4.7136e-04 - val_loss: 0.0026\n",
            "Epoch 216/500\n",
            "80/80 [==============================] - 0s 979us/step - loss: 6.5656e-04 - val_loss: 6.2942e-04\n",
            "Epoch 217/500\n",
            "80/80 [==============================] - 0s 956us/step - loss: 0.0017 - val_loss: 2.9991e-04\n",
            "Epoch 218/500\n",
            "80/80 [==============================] - 0s 958us/step - loss: 0.0012 - val_loss: 0.0064\n",
            "Epoch 219/500\n",
            "80/80 [==============================] - 0s 974us/step - loss: 0.0017 - val_loss: 9.9585e-04\n",
            "Epoch 220/500\n",
            "80/80 [==============================] - 0s 950us/step - loss: 9.6527e-04 - val_loss: 0.0026\n",
            "Epoch 221/500\n",
            "80/80 [==============================] - 0s 990us/step - loss: 0.0029 - val_loss: 0.0034\n",
            "Epoch 222/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0027\n",
            "Epoch 223/500\n",
            "80/80 [==============================] - 0s 995us/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 224/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 4.9452e-04\n",
            "Epoch 225/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0042\n",
            "Epoch 226/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0011\n",
            "Epoch 227/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 9.7035e-04\n",
            "Epoch 228/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0048\n",
            "Epoch 229/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 7.4288e-04\n",
            "Epoch 230/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 231/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0072\n",
            "Epoch 232/500\n",
            "80/80 [==============================] - 0s 956us/step - loss: 0.0031 - val_loss: 0.0015\n",
            "Epoch 233/500\n",
            "80/80 [==============================] - 0s 930us/step - loss: 0.0031 - val_loss: 2.6211e-04\n",
            "Epoch 234/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0079\n",
            "Epoch 235/500\n",
            "80/80 [==============================] - 0s 994us/step - loss: 0.0039 - val_loss: 0.0069\n",
            "Epoch 236/500\n",
            "80/80 [==============================] - 0s 969us/step - loss: 0.0066 - val_loss: 0.0035\n",
            "Epoch 237/500\n",
            "80/80 [==============================] - 0s 999us/step - loss: 0.0044 - val_loss: 0.0054\n",
            "Epoch 238/500\n",
            "80/80 [==============================] - 0s 952us/step - loss: 0.0033 - val_loss: 0.0025\n",
            "Epoch 239/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 3.0265e-04\n",
            "Epoch 240/500\n",
            "80/80 [==============================] - 0s 968us/step - loss: 0.0015 - val_loss: 0.0029\n",
            "Epoch 241/500\n",
            "80/80 [==============================] - 0s 988us/step - loss: 0.0022 - val_loss: 0.0012\n",
            "Epoch 242/500\n",
            "80/80 [==============================] - 0s 960us/step - loss: 0.0022 - val_loss: 9.1448e-04\n",
            "Epoch 243/500\n",
            "80/80 [==============================] - 0s 973us/step - loss: 0.0025 - val_loss: 0.0045\n",
            "Epoch 244/500\n",
            "80/80 [==============================] - 0s 988us/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 245/500\n",
            "80/80 [==============================] - 0s 959us/step - loss: 0.0016 - val_loss: 6.6082e-04\n",
            "Epoch 246/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 0.0014 - val_loss: 5.3395e-04\n",
            "Epoch 247/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.6665e-04 - val_loss: 0.0021\n",
            "Epoch 248/500\n",
            "80/80 [==============================] - 0s 976us/step - loss: 4.4765e-04 - val_loss: 0.0011\n",
            "Epoch 249/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.6964e-04 - val_loss: 4.4893e-04\n",
            "Epoch 250/500\n",
            "80/80 [==============================] - 0s 968us/step - loss: 1.7662e-04 - val_loss: 6.5677e-04\n",
            "Epoch 251/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.1907e-04 - val_loss: 0.0011\n",
            "Epoch 252/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.9516e-04 - val_loss: 6.8346e-04\n",
            "Epoch 253/500\n",
            "80/80 [==============================] - 0s 918us/step - loss: 2.1210e-04 - val_loss: 2.4190e-04\n",
            "Epoch 254/500\n",
            "80/80 [==============================] - 0s 988us/step - loss: 5.3012e-04 - val_loss: 5.8612e-04\n",
            "Epoch 255/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.4921e-04 - val_loss: 0.0013\n",
            "Epoch 256/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.4204e-04 - val_loss: 8.0302e-04\n",
            "Epoch 257/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.7184e-04 - val_loss: 2.3474e-04\n",
            "Epoch 258/500\n",
            "80/80 [==============================] - 0s 996us/step - loss: 5.9691e-04 - val_loss: 0.0024\n",
            "Epoch 259/500\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 9.9886e-04 - val_loss: 0.0019\n",
            "Epoch 260/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.5272e-04 - val_loss: 1.2253e-04\n",
            "Epoch 261/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.4477e-04 - val_loss: 9.9534e-04\n",
            "Epoch 262/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7875e-04 - val_loss: 5.8671e-04\n",
            "Epoch 263/500\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 1.6720e-04 - val_loss: 8.2707e-04\n",
            "Epoch 264/500\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 1.7207e-04 - val_loss: 0.0011\n",
            "Epoch 265/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 1.7536e-04 - val_loss: 2.5042e-04\n",
            "Epoch 266/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 2.7981e-04 - val_loss: 0.0012\n",
            "Epoch 267/500\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 5.2102e-04 - val_loss: 0.0029\n",
            "Epoch 268/500\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 8.2022e-04 - val_loss: 2.6858e-04\n",
            "Epoch 269/500\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 4.5407e-04 - val_loss: 1.7651e-04\n",
            "Epoch 270/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.0811e-04 - val_loss: 0.0052\n",
            "Epoch 271/500\n",
            "80/80 [==============================] - 0s 937us/step - loss: 0.0015 - val_loss: 8.4660e-04\n",
            "Epoch 272/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.7949e-04 - val_loss: 2.9336e-04\n",
            "Epoch 273/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.8867e-04 - val_loss: 0.0064\n",
            "Epoch 274/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0011\n",
            "Epoch 275/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 9.2364e-04\n",
            "Epoch 276/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "Epoch 277/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.8522e-04 - val_loss: 7.5961e-04\n",
            "Epoch 278/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.5840e-04 - val_loss: 3.8721e-04\n",
            "Epoch 279/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.0096e-04 - val_loss: 6.7541e-04\n",
            "Epoch 280/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.4800e-04 - val_loss: 0.0015\n",
            "Epoch 281/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.8579e-04 - val_loss: 9.1360e-04\n",
            "Epoch 282/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.2087e-04 - val_loss: 3.1991e-04\n",
            "Epoch 283/500\n",
            "80/80 [==============================] - 0s 965us/step - loss: 4.6709e-04 - val_loss: 1.1597e-04\n",
            "Epoch 284/500\n",
            "80/80 [==============================] - 0s 988us/step - loss: 5.3580e-04 - val_loss: 9.1159e-04\n",
            "Epoch 285/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.9036e-04 - val_loss: 0.0018\n",
            "Epoch 286/500\n",
            "80/80 [==============================] - 0s 981us/step - loss: 5.5015e-04 - val_loss: 3.3150e-04\n",
            "Epoch 287/500\n",
            "80/80 [==============================] - 0s 987us/step - loss: 7.0461e-04 - val_loss: 1.8427e-04\n",
            "Epoch 288/500\n",
            "80/80 [==============================] - 0s 965us/step - loss: 8.5185e-04 - val_loss: 0.0052\n",
            "Epoch 289/500\n",
            "80/80 [==============================] - 0s 957us/step - loss: 0.0023 - val_loss: 0.0030\n",
            "Epoch 290/500\n",
            "80/80 [==============================] - 0s 959us/step - loss: 0.0025 - val_loss: 0.0042\n",
            "Epoch 291/500\n",
            "80/80 [==============================] - 0s 981us/step - loss: 0.0070 - val_loss: 0.0055\n",
            "Epoch 292/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0057\n",
            "Epoch 293/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0035\n",
            "Epoch 294/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0056\n",
            "Epoch 295/500\n",
            "80/80 [==============================] - 0s 954us/step - loss: 0.0064 - val_loss: 0.0064\n",
            "Epoch 296/500\n",
            "80/80 [==============================] - 0s 998us/step - loss: 0.0052 - val_loss: 0.0095\n",
            "Epoch 297/500\n",
            "80/80 [==============================] - 0s 969us/step - loss: 0.0031 - val_loss: 0.0013\n",
            "Epoch 298/500\n",
            "80/80 [==============================] - 0s 991us/step - loss: 0.0018 - val_loss: 0.0025\n",
            "Epoch 299/500\n",
            "80/80 [==============================] - 0s 964us/step - loss: 0.0081 - val_loss: 0.0186\n",
            "Epoch 300/500\n",
            "80/80 [==============================] - 0s 976us/step - loss: 0.0242 - val_loss: 0.0022\n",
            "Epoch 301/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.0131\n",
            "Epoch 302/500\n",
            "80/80 [==============================] - 0s 984us/step - loss: 0.0195 - val_loss: 0.0537\n",
            "Epoch 303/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0829 - val_loss: 0.0212\n",
            "Epoch 304/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0671 - val_loss: 0.1136\n",
            "Epoch 305/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0916 - val_loss: 0.0342\n",
            "Epoch 306/500\n",
            "80/80 [==============================] - 0s 991us/step - loss: 0.1098 - val_loss: 0.0525\n",
            "Epoch 307/500\n",
            "80/80 [==============================] - 0s 976us/step - loss: 0.0312 - val_loss: 0.0130\n",
            "Epoch 308/500\n",
            "80/80 [==============================] - 0s 981us/step - loss: 0.0258 - val_loss: 0.0091\n",
            "Epoch 309/500\n",
            "80/80 [==============================] - 0s 985us/step - loss: 0.0188 - val_loss: 0.0031\n",
            "Epoch 310/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0057\n",
            "Epoch 311/500\n",
            "80/80 [==============================] - 0s 965us/step - loss: 0.0060 - val_loss: 0.0138\n",
            "Epoch 312/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0019\n",
            "Epoch 313/500\n",
            "80/80 [==============================] - 0s 963us/step - loss: 0.0029 - val_loss: 0.0025\n",
            "Epoch 314/500\n",
            "80/80 [==============================] - 0s 958us/step - loss: 0.0020 - val_loss: 0.0013\n",
            "Epoch 315/500\n",
            "80/80 [==============================] - 0s 974us/step - loss: 0.0012 - val_loss: 8.2353e-04\n",
            "Epoch 316/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.0516e-04 - val_loss: 8.4361e-04\n",
            "Epoch 317/500\n",
            "80/80 [==============================] - 0s 928us/step - loss: 9.2019e-04 - val_loss: 5.2915e-04\n",
            "Epoch 318/500\n",
            "80/80 [==============================] - 0s 975us/step - loss: 0.0020 - val_loss: 0.0041\n",
            "Epoch 319/500\n",
            "80/80 [==============================] - 0s 905us/step - loss: 0.0040 - val_loss: 3.2222e-04\n",
            "Epoch 320/500\n",
            "80/80 [==============================] - 0s 975us/step - loss: 0.0027 - val_loss: 0.0014\n",
            "Epoch 321/500\n",
            "80/80 [==============================] - 0s 986us/step - loss: 0.0011 - val_loss: 0.0014\n",
            "Epoch 322/500\n",
            "80/80 [==============================] - 0s 990us/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 323/500\n",
            "80/80 [==============================] - 0s 933us/step - loss: 0.0013 - val_loss: 0.0022\n",
            "Epoch 324/500\n",
            "80/80 [==============================] - 0s 948us/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 325/500\n",
            "80/80 [==============================] - 0s 958us/step - loss: 9.7712e-04 - val_loss: 4.9176e-04\n",
            "Epoch 326/500\n",
            "80/80 [==============================] - 0s 947us/step - loss: 0.0015 - val_loss: 0.0021\n",
            "Epoch 327/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0018\n",
            "Epoch 328/500\n",
            "80/80 [==============================] - 0s 984us/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 329/500\n",
            "80/80 [==============================] - 0s 976us/step - loss: 0.0015 - val_loss: 1.7296e-04\n",
            "Epoch 330/500\n",
            "80/80 [==============================] - 0s 954us/step - loss: 6.1905e-04 - val_loss: 8.0887e-04\n",
            "Epoch 331/500\n",
            "80/80 [==============================] - 0s 951us/step - loss: 6.3518e-04 - val_loss: 0.0011\n",
            "Epoch 332/500\n",
            "80/80 [==============================] - 0s 940us/step - loss: 5.7771e-04 - val_loss: 1.9983e-04\n",
            "Epoch 333/500\n",
            "80/80 [==============================] - 0s 972us/step - loss: 2.8663e-04 - val_loss: 1.5721e-04\n",
            "Epoch 334/500\n",
            "80/80 [==============================] - 0s 964us/step - loss: 3.9002e-04 - val_loss: 2.4285e-04\n",
            "Epoch 335/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.2106e-04 - val_loss: 1.6812e-04\n",
            "Epoch 336/500\n",
            "80/80 [==============================] - 0s 976us/step - loss: 2.2747e-04 - val_loss: 1.2977e-04\n",
            "Epoch 337/500\n",
            "80/80 [==============================] - 0s 958us/step - loss: 2.1988e-04 - val_loss: 1.0128e-04\n",
            "Epoch 338/500\n",
            "80/80 [==============================] - 0s 988us/step - loss: 2.0450e-04 - val_loss: 6.2028e-04\n",
            "Epoch 339/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.2814e-04 - val_loss: 1.8887e-04\n",
            "Epoch 340/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.1447e-04 - val_loss: 4.4477e-04\n",
            "Epoch 341/500\n",
            "80/80 [==============================] - 0s 994us/step - loss: 1.8313e-04 - val_loss: 9.7001e-05\n",
            "Epoch 342/500\n",
            "80/80 [==============================] - 0s 994us/step - loss: 1.2737e-04 - val_loss: 4.8328e-04\n",
            "Epoch 343/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 2.7040e-04 - val_loss: 4.7559e-04\n",
            "Epoch 344/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3770e-04 - val_loss: 1.4257e-04\n",
            "Epoch 345/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.1874e-04 - val_loss: 7.3057e-04\n",
            "Epoch 346/500\n",
            "80/80 [==============================] - 0s 966us/step - loss: 4.8733e-04 - val_loss: 1.2006e-04\n",
            "Epoch 347/500\n",
            "80/80 [==============================] - 0s 912us/step - loss: 1.7213e-04 - val_loss: 2.4116e-04\n",
            "Epoch 348/500\n",
            "80/80 [==============================] - 0s 948us/step - loss: 1.7366e-04 - val_loss: 1.4360e-04\n",
            "Epoch 349/500\n",
            "80/80 [==============================] - 0s 949us/step - loss: 1.7159e-04 - val_loss: 1.1931e-04\n",
            "Epoch 350/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7352e-04 - val_loss: 2.3583e-04\n",
            "Epoch 351/500\n",
            "80/80 [==============================] - 0s 993us/step - loss: 1.6227e-04 - val_loss: 2.6981e-04\n",
            "Epoch 352/500\n",
            "80/80 [==============================] - 0s 956us/step - loss: 1.4742e-04 - val_loss: 9.0954e-05\n",
            "Epoch 353/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7526e-04 - val_loss: 3.8651e-04\n",
            "Epoch 354/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.5129e-04 - val_loss: 1.1415e-04\n",
            "Epoch 355/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.8568e-04 - val_loss: 1.6396e-04\n",
            "Epoch 356/500\n",
            "80/80 [==============================] - 0s 958us/step - loss: 2.3729e-04 - val_loss: 5.2386e-04\n",
            "Epoch 357/500\n",
            "80/80 [==============================] - 0s 949us/step - loss: 4.5651e-04 - val_loss: 3.6432e-04\n",
            "Epoch 358/500\n",
            "80/80 [==============================] - 0s 948us/step - loss: 7.6262e-04 - val_loss: 4.9716e-04\n",
            "Epoch 359/500\n",
            "80/80 [==============================] - 0s 968us/step - loss: 6.8634e-04 - val_loss: 0.0010\n",
            "Epoch 360/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.5384e-04 - val_loss: 1.7868e-04\n",
            "Epoch 361/500\n",
            "80/80 [==============================] - 0s 986us/step - loss: 3.5793e-04 - val_loss: 1.8796e-04\n",
            "Epoch 362/500\n",
            "80/80 [==============================] - 0s 964us/step - loss: 2.5262e-04 - val_loss: 1.3998e-04\n",
            "Epoch 363/500\n",
            "80/80 [==============================] - 0s 981us/step - loss: 1.4119e-04 - val_loss: 1.3393e-04\n",
            "Epoch 364/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4477e-04 - val_loss: 1.3823e-04\n",
            "Epoch 365/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.2928e-04 - val_loss: 1.2601e-04\n",
            "Epoch 366/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4400e-04 - val_loss: 9.8602e-05\n",
            "Epoch 367/500\n",
            "80/80 [==============================] - 0s 970us/step - loss: 1.0977e-04 - val_loss: 4.0037e-04\n",
            "Epoch 368/500\n",
            "80/80 [==============================] - 0s 986us/step - loss: 1.5522e-04 - val_loss: 1.6428e-04\n",
            "Epoch 369/500\n",
            "80/80 [==============================] - 0s 998us/step - loss: 2.3914e-04 - val_loss: 4.1062e-04\n",
            "Epoch 370/500\n",
            "80/80 [==============================] - 0s 953us/step - loss: 3.9606e-04 - val_loss: 0.0011\n",
            "Epoch 371/500\n",
            "80/80 [==============================] - 0s 946us/step - loss: 9.0696e-04 - val_loss: 5.0932e-04\n",
            "Epoch 372/500\n",
            "80/80 [==============================] - 0s 933us/step - loss: 0.0013 - val_loss: 1.4598e-04\n",
            "Epoch 373/500\n",
            "80/80 [==============================] - 0s 987us/step - loss: 7.0906e-04 - val_loss: 2.8536e-04\n",
            "Epoch 374/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 7.8960e-04 - val_loss: 0.0015\n",
            "Epoch 375/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 6.4612e-04\n",
            "Epoch 376/500\n",
            "80/80 [==============================] - 0s 984us/step - loss: 4.0710e-04 - val_loss: 4.0904e-04\n",
            "Epoch 377/500\n",
            "80/80 [==============================] - 0s 966us/step - loss: 3.7592e-04 - val_loss: 2.1535e-04\n",
            "Epoch 378/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.8179e-04 - val_loss: 8.1032e-04\n",
            "Epoch 379/500\n",
            "80/80 [==============================] - 0s 994us/step - loss: 4.5494e-04 - val_loss: 3.4965e-04\n",
            "Epoch 380/500\n",
            "80/80 [==============================] - 0s 958us/step - loss: 3.3708e-04 - val_loss: 8.7023e-05\n",
            "Epoch 381/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.7968e-04 - val_loss: 2.5072e-04\n",
            "Epoch 382/500\n",
            "80/80 [==============================] - 0s 958us/step - loss: 1.6290e-04 - val_loss: 4.6165e-04\n",
            "Epoch 383/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.6111e-04 - val_loss: 1.0640e-04\n",
            "Epoch 384/500\n",
            "80/80 [==============================] - 0s 951us/step - loss: 1.1880e-04 - val_loss: 2.9185e-04\n",
            "Epoch 385/500\n",
            "80/80 [==============================] - 0s 957us/step - loss: 1.6747e-04 - val_loss: 8.5506e-05\n",
            "Epoch 386/500\n",
            "80/80 [==============================] - 0s 988us/step - loss: 1.6195e-04 - val_loss: 1.2148e-04\n",
            "Epoch 387/500\n",
            "80/80 [==============================] - 0s 995us/step - loss: 1.2423e-04 - val_loss: 9.0563e-05\n",
            "Epoch 388/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.5458e-05 - val_loss: 2.2776e-04\n",
            "Epoch 389/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1321e-04 - val_loss: 2.0484e-04\n",
            "Epoch 390/500\n",
            "80/80 [==============================] - 0s 935us/step - loss: 8.8827e-05 - val_loss: 1.1474e-04\n",
            "Epoch 391/500\n",
            "80/80 [==============================] - 0s 998us/step - loss: 1.3552e-04 - val_loss: 1.2429e-04\n",
            "Epoch 392/500\n",
            "80/80 [==============================] - 0s 957us/step - loss: 8.1570e-05 - val_loss: 1.6090e-04\n",
            "Epoch 393/500\n",
            "80/80 [==============================] - 0s 920us/step - loss: 8.6340e-05 - val_loss: 7.7591e-05\n",
            "Epoch 394/500\n",
            "80/80 [==============================] - 0s 980us/step - loss: 6.3890e-05 - val_loss: 5.1943e-04\n",
            "Epoch 395/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.5863e-04 - val_loss: 1.2765e-04\n",
            "Epoch 396/500\n",
            "80/80 [==============================] - 0s 970us/step - loss: 3.1549e-04 - val_loss: 1.3107e-04\n",
            "Epoch 397/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.9411e-04 - val_loss: 7.2839e-04\n",
            "Epoch 398/500\n",
            "80/80 [==============================] - 0s 962us/step - loss: 4.2066e-04 - val_loss: 2.2679e-04\n",
            "Epoch 399/500\n",
            "80/80 [==============================] - 0s 993us/step - loss: 6.6085e-04 - val_loss: 7.9827e-05\n",
            "Epoch 400/500\n",
            "80/80 [==============================] - 0s 966us/step - loss: 4.5347e-04 - val_loss: 4.0640e-04\n",
            "Epoch 401/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 4.8141e-04 - val_loss: 1.3727e-04\n",
            "Epoch 402/500\n",
            "80/80 [==============================] - 0s 945us/step - loss: 9.9010e-05 - val_loss: 1.8366e-04\n",
            "Epoch 403/500\n",
            "80/80 [==============================] - 0s 960us/step - loss: 1.1665e-04 - val_loss: 1.0897e-04\n",
            "Epoch 404/500\n",
            "80/80 [==============================] - 0s 980us/step - loss: 1.0001e-04 - val_loss: 1.2813e-04\n",
            "Epoch 405/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.8139e-05 - val_loss: 9.5017e-05\n",
            "Epoch 406/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4899e-04 - val_loss: 1.6402e-04\n",
            "Epoch 407/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.9254e-04 - val_loss: 4.0543e-04\n",
            "Epoch 408/500\n",
            "80/80 [==============================] - 0s 998us/step - loss: 1.4708e-04 - val_loss: 1.0666e-04\n",
            "Epoch 409/500\n",
            "80/80 [==============================] - 0s 968us/step - loss: 1.1801e-04 - val_loss: 1.7666e-04\n",
            "Epoch 410/500\n",
            "80/80 [==============================] - 0s 923us/step - loss: 1.1576e-04 - val_loss: 3.1688e-04\n",
            "Epoch 411/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.6093e-05 - val_loss: 1.0277e-04\n",
            "Epoch 412/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.8321e-05 - val_loss: 3.1330e-04\n",
            "Epoch 413/500\n",
            "80/80 [==============================] - 0s 969us/step - loss: 1.0505e-04 - val_loss: 9.2265e-05\n",
            "Epoch 414/500\n",
            "80/80 [==============================] - 0s 970us/step - loss: 7.9438e-05 - val_loss: 7.8338e-05\n",
            "Epoch 415/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1812e-04 - val_loss: 1.2794e-04\n",
            "Epoch 416/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 1.0136e-04 - val_loss: 3.5167e-04\n",
            "Epoch 417/500\n",
            "80/80 [==============================] - 0s 960us/step - loss: 1.2533e-04 - val_loss: 7.5545e-05\n",
            "Epoch 418/500\n",
            "80/80 [==============================] - 0s 941us/step - loss: 1.1670e-04 - val_loss: 8.8258e-05\n",
            "Epoch 419/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7055e-04 - val_loss: 4.8713e-04\n",
            "Epoch 420/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.3156e-04 - val_loss: 5.0331e-04\n",
            "Epoch 421/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7305e-04 - val_loss: 2.8309e-04\n",
            "Epoch 422/500\n",
            "80/80 [==============================] - 0s 968us/step - loss: 4.4000e-04 - val_loss: 1.7670e-04\n",
            "Epoch 423/500\n",
            "80/80 [==============================] - 0s 941us/step - loss: 2.8306e-04 - val_loss: 8.5960e-04\n",
            "Epoch 424/500\n",
            "80/80 [==============================] - 0s 927us/step - loss: 2.8123e-04 - val_loss: 9.6310e-05\n",
            "Epoch 425/500\n",
            "80/80 [==============================] - 0s 934us/step - loss: 3.1172e-04 - val_loss: 9.5370e-05\n",
            "Epoch 426/500\n",
            "80/80 [==============================] - 0s 986us/step - loss: 1.5596e-04 - val_loss: 1.5459e-04\n",
            "Epoch 427/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.5623e-04 - val_loss: 1.4034e-04\n",
            "Epoch 428/500\n",
            "80/80 [==============================] - 0s 998us/step - loss: 8.9068e-05 - val_loss: 2.0655e-04\n",
            "Epoch 429/500\n",
            "80/80 [==============================] - 0s 997us/step - loss: 7.1986e-05 - val_loss: 2.8944e-04\n",
            "Epoch 430/500\n",
            "80/80 [==============================] - 0s 965us/step - loss: 1.0492e-04 - val_loss: 1.0234e-04\n",
            "Epoch 431/500\n",
            "80/80 [==============================] - 0s 990us/step - loss: 8.5636e-05 - val_loss: 1.0080e-04\n",
            "Epoch 432/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.6483e-04 - val_loss: 3.9318e-04\n",
            "Epoch 433/500\n",
            "80/80 [==============================] - 0s 963us/step - loss: 1.9959e-04 - val_loss: 5.1368e-04\n",
            "Epoch 434/500\n",
            "80/80 [==============================] - 0s 972us/step - loss: 2.3712e-04 - val_loss: 2.2878e-04\n",
            "Epoch 435/500\n",
            "80/80 [==============================] - 0s 987us/step - loss: 2.1332e-04 - val_loss: 3.4116e-04\n",
            "Epoch 436/500\n",
            "80/80 [==============================] - 0s 953us/step - loss: 1.1465e-04 - val_loss: 1.7951e-04\n",
            "Epoch 437/500\n",
            "80/80 [==============================] - 0s 995us/step - loss: 6.8451e-05 - val_loss: 1.7142e-04\n",
            "Epoch 438/500\n",
            "80/80 [==============================] - 0s 986us/step - loss: 6.5299e-05 - val_loss: 1.7779e-04\n",
            "Epoch 439/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.9594e-05 - val_loss: 1.2949e-04\n",
            "Epoch 440/500\n",
            "80/80 [==============================] - 0s 965us/step - loss: 5.7110e-05 - val_loss: 2.0568e-04\n",
            "Epoch 441/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 7.1281e-05 - val_loss: 1.8222e-04\n",
            "Epoch 442/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.8046e-05 - val_loss: 8.0107e-05\n",
            "Epoch 443/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.9397e-05 - val_loss: 1.3271e-04\n",
            "Epoch 444/500\n",
            "80/80 [==============================] - 0s 971us/step - loss: 6.5965e-05 - val_loss: 2.4668e-04\n",
            "Epoch 445/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.0096e-05 - val_loss: 7.0766e-05\n",
            "Epoch 446/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.1682e-04 - val_loss: 7.1198e-05\n",
            "Epoch 447/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.4529e-04 - val_loss: 3.6099e-04\n",
            "Epoch 448/500\n",
            "80/80 [==============================] - 0s 964us/step - loss: 1.2408e-04 - val_loss: 1.3274e-04\n",
            "Epoch 449/500\n",
            "80/80 [==============================] - 0s 973us/step - loss: 5.6616e-05 - val_loss: 1.1865e-04\n",
            "Epoch 450/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.2579e-05 - val_loss: 1.6068e-04\n",
            "Epoch 451/500\n",
            "80/80 [==============================] - 0s 974us/step - loss: 6.1162e-05 - val_loss: 1.7085e-04\n",
            "Epoch 452/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.5608e-05 - val_loss: 1.5180e-04\n",
            "Epoch 453/500\n",
            "80/80 [==============================] - 0s 992us/step - loss: 5.5474e-05 - val_loss: 9.5899e-05\n",
            "Epoch 454/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.7741e-05 - val_loss: 1.9701e-04\n",
            "Epoch 455/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.5620e-05 - val_loss: 1.9315e-04\n",
            "Epoch 456/500\n",
            "80/80 [==============================] - 0s 975us/step - loss: 7.0047e-05 - val_loss: 8.3058e-05\n",
            "Epoch 457/500\n",
            "80/80 [==============================] - 0s 976us/step - loss: 5.7064e-05 - val_loss: 1.0272e-04\n",
            "Epoch 458/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.7515e-05 - val_loss: 2.9144e-04\n",
            "Epoch 459/500\n",
            "80/80 [==============================] - 0s 971us/step - loss: 1.1755e-04 - val_loss: 2.5793e-04\n",
            "Epoch 460/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.0737e-04 - val_loss: 8.0410e-05\n",
            "Epoch 461/500\n",
            "80/80 [==============================] - 0s 950us/step - loss: 1.5818e-04 - val_loss: 8.0911e-05\n",
            "Epoch 462/500\n",
            "80/80 [==============================] - 0s 935us/step - loss: 1.3372e-04 - val_loss: 0.0011\n",
            "Epoch 463/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 5.8889e-04 - val_loss: 6.8978e-04\n",
            "Epoch 464/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.9384e-04 - val_loss: 2.4030e-04\n",
            "Epoch 465/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 3.6433e-04 - val_loss: 1.2437e-04\n",
            "Epoch 466/500\n",
            "80/80 [==============================] - 0s 969us/step - loss: 1.4890e-04 - val_loss: 3.0622e-04\n",
            "Epoch 467/500\n",
            "80/80 [==============================] - 0s 944us/step - loss: 1.2821e-04 - val_loss: 1.6035e-04\n",
            "Epoch 468/500\n",
            "80/80 [==============================] - 0s 984us/step - loss: 1.2078e-04 - val_loss: 8.4196e-05\n",
            "Epoch 469/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.0432e-04 - val_loss: 8.4061e-05\n",
            "Epoch 470/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 1.7656e-04 - val_loss: 1.4028e-04\n",
            "Epoch 471/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 6.0295e-05 - val_loss: 2.5071e-04\n",
            "Epoch 472/500\n",
            "80/80 [==============================] - 0s 938us/step - loss: 7.2277e-05 - val_loss: 1.0135e-04\n",
            "Epoch 473/500\n",
            "80/80 [==============================] - 0s 992us/step - loss: 2.6415e-04 - val_loss: 4.3431e-04\n",
            "Epoch 474/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4072e-04 - val_loss: 4.8794e-04\n",
            "Epoch 475/500\n",
            "80/80 [==============================] - 0s 985us/step - loss: 1.4645e-04 - val_loss: 1.0198e-04\n",
            "Epoch 476/500\n",
            "80/80 [==============================] - 0s 988us/step - loss: 5.9932e-05 - val_loss: 3.0120e-04\n",
            "Epoch 477/500\n",
            "80/80 [==============================] - 0s 927us/step - loss: 9.7601e-05 - val_loss: 1.0631e-04\n",
            "Epoch 478/500\n",
            "80/80 [==============================] - 0s 959us/step - loss: 7.2636e-05 - val_loss: 1.7839e-04\n",
            "Epoch 479/500\n",
            "80/80 [==============================] - 0s 989us/step - loss: 7.0054e-05 - val_loss: 1.2773e-04\n",
            "Epoch 480/500\n",
            "80/80 [==============================] - 0s 968us/step - loss: 5.8696e-05 - val_loss: 1.0536e-04\n",
            "Epoch 481/500\n",
            "80/80 [==============================] - 0s 992us/step - loss: 7.0582e-05 - val_loss: 1.2770e-04\n",
            "Epoch 482/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 9.7941e-05 - val_loss: 2.4239e-04\n",
            "Epoch 483/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 7.5754e-05 - val_loss: 1.5336e-04\n",
            "Epoch 484/500\n",
            "80/80 [==============================] - 0s 977us/step - loss: 7.7302e-05 - val_loss: 1.1274e-04\n",
            "Epoch 485/500\n",
            "80/80 [==============================] - 0s 998us/step - loss: 9.1201e-05 - val_loss: 7.9236e-05\n",
            "Epoch 486/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 1.2421e-04 - val_loss: 1.1379e-04\n",
            "Epoch 487/500\n",
            "80/80 [==============================] - 0s 979us/step - loss: 7.5792e-05 - val_loss: 3.2034e-04\n",
            "Epoch 488/500\n",
            "80/80 [==============================] - 0s 994us/step - loss: 1.6278e-04 - val_loss: 2.1345e-04\n",
            "Epoch 489/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 8.4040e-05 - val_loss: 1.1624e-04\n",
            "Epoch 490/500\n",
            "80/80 [==============================] - 0s 972us/step - loss: 9.0130e-05 - val_loss: 8.3658e-05\n",
            "Epoch 491/500\n",
            "80/80 [==============================] - 0s 979us/step - loss: 7.9024e-05 - val_loss: 2.7923e-04\n",
            "Epoch 492/500\n",
            "80/80 [==============================] - 0s 946us/step - loss: 1.8134e-04 - val_loss: 1.5746e-04\n",
            "Epoch 493/500\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 2.4312e-04 - val_loss: 6.9320e-04\n",
            "Epoch 494/500\n",
            "80/80 [==============================] - 0s 965us/step - loss: 5.8880e-04 - val_loss: 9.7539e-05\n",
            "Epoch 495/500\n",
            "80/80 [==============================] - 0s 947us/step - loss: 2.4029e-04 - val_loss: 0.0011\n",
            "Epoch 496/500\n",
            "80/80 [==============================] - 0s 928us/step - loss: 8.4938e-04 - val_loss: 2.4365e-04\n",
            "Epoch 497/500\n",
            "80/80 [==============================] - 0s 996us/step - loss: 7.8330e-04 - val_loss: 0.0011\n",
            "Epoch 498/500\n",
            "80/80 [==============================] - 0s 967us/step - loss: 0.0015 - val_loss: 0.0011\n",
            "Epoch 499/500\n",
            "80/80 [==============================] - 0s 974us/step - loss: 0.0029 - val_loss: 3.2810e-04\n",
            "Epoch 500/500\n",
            "80/80 [==============================] - 0s 924us/step - loss: 0.0014 - val_loss: 0.0013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YjqyGphnkkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkg6MIzynlMV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8bc1a711-43a4-4373-9f96-d6189315c3e6"
      },
      "source": [
        "results.shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSwwt6LhnlWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b60e781-3585-4593-ad3b-85ea1be521db"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4KirRxDnoj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "0c0117ff-fb7a-45d0-d66c-8ad4a607c8f7"
      },
      "source": [
        "plt.scatter(range(20),results,c='r')\n",
        "plt.scatter(range(20),y_test,c='g')\n",
        "plt.show()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAD8CAYAAACFK0QrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAE1BJREFUeJzt3X9sJGd9x/HP1z5fqXPITu4sml7w\nblNVSG2vHJGFKL/Ej5ZLUnTUVVUFbVt6Aa3wgXRBbRCVpShB8h+Ulrtr1XO1PY4f7RSiFq5NEBQC\nRKWoTcCXXuKE0CZEXpdTSExoLlws9ZzLt3/MmK59u/auPT92n32/JGvXz87ufjWe/Xj2meeZMXcX\nAKC3DRRdAABg+whzAAgAYQ4AASDMASAAhDkABIAwB4AAEOYAEADCHAACQJgDQAB2ZPGie/bs8XK5\nnMVLA0CQzpw580N3H9vq8zMJ83K5rLm5uSxeGgCCZGb17TyfbhYACABhDgABIMwBIACEOQAEgDAH\ngAAQ5gAQAMIcAAJAmANAAAhzBCGaPazyrTs0cLupfOsORbOHiy4JyBVhjp/o1UCMZg+rem5W9V2X\n5CbVd11S9dxsz9SP3hTNRyofK2vgjgGVj5UVzUeF1tNWmJvZgpnNm9lZM2OefoB6ORCnn6hpeWht\n2/JQ3A5kIZqPVD19s+rn63K56ufrqp6+udBA72TP/M3uvt/dJzKrBoXp5UBcvOJSR+3N9Oq3EhRj\n+q4jWvaLa9qW/aKm7zpSUEV0syCRRiAWZfz5wY7a1+vlbyUoxuLKMx2156HdMHdJXzGzM2ZWzbIg\nFGO7gVikmWurGl5Z2za8Ere3o5e/laAY4+c7a89Du2H+ene/TtINkt5nZm9cv4CZVc1szszmlpaW\nUi0S2dtuIG7Xdro5KlMnVNs7pdKFQZlLpQuDqu2dUmXqRFvP7+VvJSjGzNndGl7by6Lhi3F7Uczd\nO3uC2e2SLrj7n7ZaZmJiwjmfee+JZg9r+omaFq+4pPHnBzVzbbXtQNzu+1bPza7ZOx5eUUeBvB3l\nW3eovuvy4C5dGNTCR1/I/P3Rg6JI0dFDmn7DihZH4j3ymX8dUuUDn5AqlS29pJmd2c4xyU3D3Myu\nkDTg7j9O7t8j6cPu/s+tnkOYoxNFh2nR/0zQo6JImp6WFhel8XFpZmbLQS5tP8zbudLQyySdNrPV\n5f9uoyAHOlV0N0dl6oQ0q0K+laCHVSrbCu+0bRrm7v6EpFfmUAv61Pjzg033zPM8+FqZOqGKCG/0\nLoYmonBFH3wFQkCYo3DbHY2CAkWRVC5LAwPxbVTslPZ+1vFolnZwABToAxmM6Ohn2z0Ayp45gC2J\nTh5R9cCK6qOKZ86OStUDK4pOFjelvZ8R5l2m287EBrQyvf8ZLe9c27a8M25H/toZmoicrJ6JbfUE\nPqtnYpOkyj6+tqK7LI501o5ssWfeRbrxTGxAK+NDzaeut2rvRiGdLZMw7yLdeCY2oJWZg8c1bGv7\nWYZtp2YOHi+oos6EdrZMwryLdOOZ2IBWKvsqqk2eUmmkJJOpNFJSbfJUz3QJhna2TPrMu8jM2d2q\nvnbtQaWiz8QGbKSyr9Iz4b1e0aeRSBt75l2k8p7jqn15SKVnFU+eeVaqfXlIlff0xtdWoJf08jn8\nmyHMu0mlosoHPqGF0yW9+GHTwukSEzCAjIR2GglmgALoW0Wdw7+ZzM9nvhWEOQB0hun8AADCHABC\nQJgDQAAIcwAIAGEOAAEgzAEgAIQ5AASAMAeAABDmABAAwhwAAkCYA+hZIV0paLsIcwA9KbQrBW0X\nYQ6gJ4V2paDtIswB9KTQrhS0XYQ5gJ4U2pWCtoswB9CTQrtS0HYR5gB6UmXqhGp7p1S6MBhfM/fC\noGp7pwq7UlDRuNIQAHQBrjQEACDMASAEbYe5mQ2a2X+Y2ReyLAgA0LlO9syPSHo0q0IAbA1T2iG1\nGeZmdo2k35B0MttyAHSCKe1Y1e6e+TFJH5T0YqsFzKxqZnNmNre0tJRKcQA2xpR2rNo0zM3s7ZKe\ndvczGy3n7jV3n3D3ibGxsdQKBNAaU9qxqp0989dJOmhmC5I+K+ktZva3mVYFoC1MaceqTcPc3f/Y\n3a9x97KkmyR93d1/N/PKAGyKKe1YxThzoIcxpR2rmM4PAF2A6fz4f1EklcvSwEB8G0VFVwQgJ4R5\nKKJI0dFDKk/WNXCbqzxZV3T0EIEO9AnCPBDRySOqHlhRfVTx5JFRqXpgRdHJI0WXBiAHhHkgpvc/\no+Wda9uWd8btAMJHmAdicaSzdgBhIcwDMT60u6N2AGEhzAMxc/C4hm1tP8uw7dTMweMFVQQgT4R5\nICr7KqpNnlJppCSTqTRSUm3ylCr7KkWXBiAHTBoCgC7ApCEAAGEOACEgzAEgAIQ5AASAMAeAABDm\nABAAwhwAAkCYA0AACHMACABhDgAB6Mowj2YPq3zrDg3cbirfukPR7OGiSwKArtZ1YR7NHlb13Kzq\nuy7FV8zZdUnVc7MEOgBsoOvCfPqJmpaH1rYtD8XtAIDmui7MF6+41FE7AKALw3z8+cGO2gEAXRjm\nM9dWNbyytm14JW4HADTXdWFemTqh2t4plS4MylwqXRhUbe+UKlMnii4NALoWVxoCgC7AlYYAAIQ5\nAISAMAeAABDmABAAwhwAAkCYA0AANg1zM3uJmX3LzB40s0fM7I48CgMAtG9HG8v8r6S3uPsFMxuS\n9E0z+5K735dxbQCANm0a5h7PKrqQ/DqU/KQ/0wgAsGVt9Zmb2aCZnZX0tKR73P3+bMsCAHSirTB3\n90vuvl/SNZJebWa/vH4ZM6ua2ZyZzS0tLaVdJwBgAx2NZnH3ZyXdK+n6Jo/V3H3C3SfGxsbSqg8A\n0IZ2RrOMmdlocv+nJf26pO9mXRgAoH3t7JlfLeleM3tI0rcV95l/IduyelgUSeWyNDAQ30ZR0RUB\n6APtjGZ5SNKrcqil90WRoqOHND25osURafx8XTNHD6kiSZVK0dUBCBgzQFMUnTyi6oEV1UclN6k+\nKlUPrCg6eaTo0gAEjjBP0fT+Z7S8c23b8s64HQCyRJinaHGks3YASAthnqLxod0dtQNAWgjzFM0c\nPK5hW9vPMmw7NXPweEEVAegXhHmKKvsqqk2eUmmkJJOpNFJSbfKUKvsYyQIgWxafRytdExMTPjc3\nl/rrAkCozOyMu09s9fnsmQNAAAhzAAgAYQ6gOJz+IjWEOYBiJKe/KE/WNXCbqzxZV3T0EIG+RYQ5\ngEJw+ot0EeYACsHpL9JFmAMoBKe/SBdhDqAQnP4iXYQ50O8KGlHC6S/SRZgD/azAESWc/iJdTOcH\n+lj05j2qvnbtgcjhi1Lt33arcu8PiyusDzGdH8CWMaIkHIQ50McYURIOwhzoY4woCQdhDvQxRpSE\ngzAH+hgjSsLBaBYA6AKMZgEAEOYAEALCHAACQJgDQAAIcwAIAGEOAAEgzAEgAIQ5AASAMAeAAGwa\n5mb2cjO718y+Y2aPmBmXzgaALrOjjWVekPSH7v6Amb1U0hkzu8fdv5NxbQCANm26Z+7uT7r7A8n9\nH0t6VNLerAvbsoKuZwgAReqoz9zMypJeJen+LIrZtgKvZwgARWo7zM1sl6TPSbrF3Z9r8njVzObM\nbG5paSnNGtsWnTyi6oEV1UclN6k+KlUPrCg6STc/gLC1FeZmNqQ4yCN3/3yzZdy95u4T7j4xNjaW\nZo1t43qGAPpVO6NZTNLHJT3q7h/LvqSt43qGAPpVO3vmr5P0e5LeYmZnk58bM65rS7ieIYB+1c5o\nlm+6u7n7r7j7/uTni3kU1ymuZwigXwU1A5TrGQLoV1wDFAC6ANcABQAQ5gAQAsIcAAJAmANAAAhz\nAAgAYQ4AASDMASAAhDkABIAwB4AAEOYAEADCHAACQJgDQAAIcwAIAGEOAAEgzAEgAIQ5AASAMAeA\nABDmABAAwhwAAkCYA0AACHMACABhDgABIMwBIACEOQAEgDAHgAAQ5gAQAMIcAAJAmANAAAhzAAgA\nYQ4AASDMASAAhDkABGDTMDezU2b2tJk9nEdBAIDOtbNn/klJ12dcBwBgGzYNc3f/hqQf5VALAGCL\nUuszN7Oqmc2Z2dzS0lJaLwsEL5qPVD5W1sAdAyofKyuaj4ouCT0otTB395q7T7j7xNjYWFovCwQt\nmo9Uvbuq+vm6XK76+bqqd1cJdHSM0SxAgaa/Nq3lleU1bcsry5r+2nRBFaFXEeZAgRbPL3bUDrTS\nztDEz0j6d0mvMLPvm9m7sy8L6A/jO67qqB1opZ3RLO9096vdfcjdr3H3j+dRGNAPZr4qDV9c2zZ8\nMW4HOkE3C1Cgyr/8SLW7pdKzknl8W7s7bgc6saPoAoC+Nj6uynxdlfl17aXxQspB72LPfB3G/CJX\nMzPS8PDatuHhuB3oAGHegDG/yF2lItVqUqkkmcW3tVrcDnTA3D31F52YmPC5ubnUXzdr5WNl1c/X\nL2svjZS0cMtC/gUB6BtmdsbdJ7b6fPbMGzDmF0CvIswbMOYXQK8izBsw5hdAryLMGzDmF0CvIswb\njY+rMi8tHJNevCO+rczH7cCGokgql6WBgfg2YgQU8kWYN2LM77b07Rj9KFJ09JDKk3UN3OYqT9YV\nHT1EoCNXhHkjxvxuWT+P0Y9OHlH1wIrqo5KbVB+VqgdWFJ08UnRp6COMM0cq+nmMfvkDpvro5e2l\nZ6WFo+l/vhAmxpmjK/TzGP3Fkc7agSwQ5khFP4/RHx/a3VE7kAXCHKno5zH6MwePa9h2rmkbtp2a\nOXi8oIrQjwhzpKKfx+hX9lVUmzyl0khJJlNppKTa5ClV9nHgHPnhACjSUS5L9csPgKpUkhYW8q4G\n6DkcAEV3YIw+UCjCHOlgjD5QKC4bh/RUKoQ3UBD2zAEgAIQ5AASAMAeAABDmABAAwhwAAkCYA0AA\nMpkBamZLkppMB+zYHkk/TOF1skBtW9fN9VHb1nRzbVJ317daW8ndx7b6IpmEeVrMbG4701uzRG1b\n1831UdvWdHNtUnfXl1ZtdLMAQAAIcwAIQLeHea3oAjZAbVvXzfVR29Z0c21Sd9eXSm1d3WcOAGhP\nt++ZAwDaUHiYm9n1ZvafZva4mX2oyeM/ZWZ3Jo/fb2blHGt7uZnda2bfMbNHzOxIk2XeZGbnzexs\n8nNbjvUtmNl88r6XXQ3EYn+erLuHzOy6nOp6RcP6OGtmz5nZLeuWyXW9mdkpM3vazB5uaLvKzO4x\ns8eS2ytbPPddyTKPmdm7cqrto2b23eTvdtrMRls8d8NtIKPabjezcw1/uxtbPHfDz3aG9d3ZUNuC\nmZ1t8dys113T/Mhsu3P3wn4kDUr6nqRrJe2U9KCkX1y3zGFJf5Xcv0nSnTnWd7Wk65L7L5X0X03q\ne5OkLxS0/hYk7dng8RslfUmSSXqNpPsL+hv/QPEY2sLWm6Q3SrpO0sMNbX8i6UPJ/Q9J+kiT510l\n6Ynk9srk/pU51PY2STuS+x9pVls720BGtd0u6Y/a+Ltv+NnOqr51j/+ZpNsKWndN8yOr7a7oPfNX\nS3rc3Z9w94uSPivpHeuWeYekTyX3/0HSW83M8ijO3Z909weS+z+W9KikvXm8d0reIenTHrtP0qiZ\nXZ1zDW+V9D13T2MS2Za5+zckrb8gaeO29SlJv9nkqQck3ePuP3L3/5F0j6Trs67N3b/i7i8kv94n\n6Zo037NdLdZbO9r5bG/bRvUlOfE7kj6T9vu2Y4P8yGS7KzrM90r674bfv6/Lw/InyyQb93lJu3Op\nrkHSvfMqSfc3efhXzexBM/uSmf1SjmW5pK+Y2RkzqzZ5vJ31m7Wb1PrDVNR6W/Uyd38yuf8DSS9r\nskw3rMObFX/DamazbSAr70+6gE616CbohvX2BklPuftjLR7Pbd2ty49Mtruiw7wnmNkuSZ+TdIu7\nP7fu4QcUdyG8UtJfSPrHHEt7vbtfJ+kGSe8zszfm+N6bMrOdkg5K+vsmDxe53i7j8XfbrhvaZWbT\nkl6QFLVYpIhtYFbSz0vaL+lJxV0Z3eid2nivPJd1t1F+pLndFR3m5yS9vOH3a5K2psuY2Q5JI5Ke\nyaW6+D2HFP8hInf//PrH3f05d7+Q3P+ipCEz25NHbe5+Lrl9WtJpxV9tG7WzfrN0g6QH3P2p9Q8U\nud4aPLXa7ZTcPt1kmcLWoZn9gaS3S6okH/rLtLENpM7dn3L3S+7+oqS/bvGehW57SVb8lqQ7Wy2T\nx7prkR+ZbHdFh/m3Jf2Cmf1cshd3k6S71i1zl6TVI7m/LenrrTbstCV9bh+X9Ki7f6zFMj+z2odv\nZq9WvE4z/2djZleY2UtX7ys+YPbwusXukvT7FnuNpPMNX+/y0HLPqKj1tk7jtvUuSf/UZJkvS3qb\nmV2ZdCe8LWnLlJldL+mDkg66+3KLZdrZBrKorfG4y2SL92zns52lX5P0XXf/frMH81h3G+RHNttd\nVkdyOzjie6Pio7zfkzSdtH1Y8UYsSS9R/DX9cUnfknRtjrW9XvFXoIcknU1+bpT0XknvTZZ5v6RH\nFB+tv0/Sa3Oq7drkPR9M3n913TXWZpL+Mlm385Imclx3VygO55GGtsLWm+J/Kk9KWlHc//huxcde\nvibpMUlflXRVsuyEpJMNz7052f4el3Qop9oeV9xnurrdrY7o+llJX9xoG8ihtr9JtqeHFAfT1etr\nS36/7LOdR31J+ydXt7WGZfNed63yI5PtjhmgABCAortZAAApIMwBIACEOQAEgDAHgAAQ5gAQAMIc\nAAJAmANAAAhzAAjA/wFapvZFEf8lpwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7C0xIDjnlec",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "e54446fd-9a83-40e2-b19d-87b191776d87"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQoEuIpIQ/w/BrK2kOYNfTAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}