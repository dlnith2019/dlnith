{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1:_sequence_generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9bARyBTiKuy",
        "colab_type": "text"
      },
      "source": [
        "Submitted By: Somya Saraswat(15MI409)\n",
        "**Assignment 1: To Generate a sequence and to predict the next value of the sequence.** \n",
        "---\n",
        "In this code I generated a series: **5,9,17,29,45,...** and trained the model to predict the next value of the series. Explaination of the series is as follows, The series is generated in a pattern that is sum of previous number and a multiple of 4. For example, X[0]=5, X[1]=5+4=9, X[3]=9+4*2=17 and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-rEF-P8O1wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpZv2iNuO5av",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egLYVTzcO653",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTuBfrobO-1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import SimpleRNN, LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxsRbgfkPIOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b1HBPjEPRC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cScLW_f5PZUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X= [[[(i*j+j)/500] for i in range(5)]for j in range (100)]\n",
        "X= [[[(5+2*(i+j)*(i+j+1))] for i in range(5)]for j in range (100)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOfwmY6XPreM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y= [(5+2*(i+5)*(i+6))for i in range (100)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMPsYEnVPzR1",
        "colab_type": "code",
        "outputId": "3e8d4965-94e2-4904-df69-c8c074937536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " for i in range(100):\n",
        "    print(X[i],Y[i])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5], [9], [17], [29], [45]] 65\n",
            "[[9], [17], [29], [45], [65]] 89\n",
            "[[17], [29], [45], [65], [89]] 117\n",
            "[[29], [45], [65], [89], [117]] 149\n",
            "[[45], [65], [89], [117], [149]] 185\n",
            "[[65], [89], [117], [149], [185]] 225\n",
            "[[89], [117], [149], [185], [225]] 269\n",
            "[[117], [149], [185], [225], [269]] 317\n",
            "[[149], [185], [225], [269], [317]] 369\n",
            "[[185], [225], [269], [317], [369]] 425\n",
            "[[225], [269], [317], [369], [425]] 485\n",
            "[[269], [317], [369], [425], [485]] 549\n",
            "[[317], [369], [425], [485], [549]] 617\n",
            "[[369], [425], [485], [549], [617]] 689\n",
            "[[425], [485], [549], [617], [689]] 765\n",
            "[[485], [549], [617], [689], [765]] 845\n",
            "[[549], [617], [689], [765], [845]] 929\n",
            "[[617], [689], [765], [845], [929]] 1017\n",
            "[[689], [765], [845], [929], [1017]] 1109\n",
            "[[765], [845], [929], [1017], [1109]] 1205\n",
            "[[845], [929], [1017], [1109], [1205]] 1305\n",
            "[[929], [1017], [1109], [1205], [1305]] 1409\n",
            "[[1017], [1109], [1205], [1305], [1409]] 1517\n",
            "[[1109], [1205], [1305], [1409], [1517]] 1629\n",
            "[[1205], [1305], [1409], [1517], [1629]] 1745\n",
            "[[1305], [1409], [1517], [1629], [1745]] 1865\n",
            "[[1409], [1517], [1629], [1745], [1865]] 1989\n",
            "[[1517], [1629], [1745], [1865], [1989]] 2117\n",
            "[[1629], [1745], [1865], [1989], [2117]] 2249\n",
            "[[1745], [1865], [1989], [2117], [2249]] 2385\n",
            "[[1865], [1989], [2117], [2249], [2385]] 2525\n",
            "[[1989], [2117], [2249], [2385], [2525]] 2669\n",
            "[[2117], [2249], [2385], [2525], [2669]] 2817\n",
            "[[2249], [2385], [2525], [2669], [2817]] 2969\n",
            "[[2385], [2525], [2669], [2817], [2969]] 3125\n",
            "[[2525], [2669], [2817], [2969], [3125]] 3285\n",
            "[[2669], [2817], [2969], [3125], [3285]] 3449\n",
            "[[2817], [2969], [3125], [3285], [3449]] 3617\n",
            "[[2969], [3125], [3285], [3449], [3617]] 3789\n",
            "[[3125], [3285], [3449], [3617], [3789]] 3965\n",
            "[[3285], [3449], [3617], [3789], [3965]] 4145\n",
            "[[3449], [3617], [3789], [3965], [4145]] 4329\n",
            "[[3617], [3789], [3965], [4145], [4329]] 4517\n",
            "[[3789], [3965], [4145], [4329], [4517]] 4709\n",
            "[[3965], [4145], [4329], [4517], [4709]] 4905\n",
            "[[4145], [4329], [4517], [4709], [4905]] 5105\n",
            "[[4329], [4517], [4709], [4905], [5105]] 5309\n",
            "[[4517], [4709], [4905], [5105], [5309]] 5517\n",
            "[[4709], [4905], [5105], [5309], [5517]] 5729\n",
            "[[4905], [5105], [5309], [5517], [5729]] 5945\n",
            "[[5105], [5309], [5517], [5729], [5945]] 6165\n",
            "[[5309], [5517], [5729], [5945], [6165]] 6389\n",
            "[[5517], [5729], [5945], [6165], [6389]] 6617\n",
            "[[5729], [5945], [6165], [6389], [6617]] 6849\n",
            "[[5945], [6165], [6389], [6617], [6849]] 7085\n",
            "[[6165], [6389], [6617], [6849], [7085]] 7325\n",
            "[[6389], [6617], [6849], [7085], [7325]] 7569\n",
            "[[6617], [6849], [7085], [7325], [7569]] 7817\n",
            "[[6849], [7085], [7325], [7569], [7817]] 8069\n",
            "[[7085], [7325], [7569], [7817], [8069]] 8325\n",
            "[[7325], [7569], [7817], [8069], [8325]] 8585\n",
            "[[7569], [7817], [8069], [8325], [8585]] 8849\n",
            "[[7817], [8069], [8325], [8585], [8849]] 9117\n",
            "[[8069], [8325], [8585], [8849], [9117]] 9389\n",
            "[[8325], [8585], [8849], [9117], [9389]] 9665\n",
            "[[8585], [8849], [9117], [9389], [9665]] 9945\n",
            "[[8849], [9117], [9389], [9665], [9945]] 10229\n",
            "[[9117], [9389], [9665], [9945], [10229]] 10517\n",
            "[[9389], [9665], [9945], [10229], [10517]] 10809\n",
            "[[9665], [9945], [10229], [10517], [10809]] 11105\n",
            "[[9945], [10229], [10517], [10809], [11105]] 11405\n",
            "[[10229], [10517], [10809], [11105], [11405]] 11709\n",
            "[[10517], [10809], [11105], [11405], [11709]] 12017\n",
            "[[10809], [11105], [11405], [11709], [12017]] 12329\n",
            "[[11105], [11405], [11709], [12017], [12329]] 12645\n",
            "[[11405], [11709], [12017], [12329], [12645]] 12965\n",
            "[[11709], [12017], [12329], [12645], [12965]] 13289\n",
            "[[12017], [12329], [12645], [12965], [13289]] 13617\n",
            "[[12329], [12645], [12965], [13289], [13617]] 13949\n",
            "[[12645], [12965], [13289], [13617], [13949]] 14285\n",
            "[[12965], [13289], [13617], [13949], [14285]] 14625\n",
            "[[13289], [13617], [13949], [14285], [14625]] 14969\n",
            "[[13617], [13949], [14285], [14625], [14969]] 15317\n",
            "[[13949], [14285], [14625], [14969], [15317]] 15669\n",
            "[[14285], [14625], [14969], [15317], [15669]] 16025\n",
            "[[14625], [14969], [15317], [15669], [16025]] 16385\n",
            "[[14969], [15317], [15669], [16025], [16385]] 16749\n",
            "[[15317], [15669], [16025], [16385], [16749]] 17117\n",
            "[[15669], [16025], [16385], [16749], [17117]] 17489\n",
            "[[16025], [16385], [16749], [17117], [17489]] 17865\n",
            "[[16385], [16749], [17117], [17489], [17865]] 18245\n",
            "[[16749], [17117], [17489], [17865], [18245]] 18629\n",
            "[[17117], [17489], [17865], [18245], [18629]] 19017\n",
            "[[17489], [17865], [18245], [18629], [19017]] 19409\n",
            "[[17865], [18245], [18629], [19017], [19409]] 19805\n",
            "[[18245], [18629], [19017], [19409], [19805]] 20205\n",
            "[[18629], [19017], [19409], [19805], [20205]] 20609\n",
            "[[19017], [19409], [19805], [20205], [20609]] 21017\n",
            "[[19409], [19805], [20205], [20609], [21017]] 21429\n",
            "[[19805], [20205], [20609], [21017], [21429]] 21845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m65vJTSjQZt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=np.array(X, dtype='float32')\n",
        "Y=np.array(Y,dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtrihDNZREfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X/=500\n",
        "Y/=500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma916GSqRI_r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29241f2c-8433-4127-9b1b-9244ceb0b71e"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlXkKiNkRfMC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b188e84-6df5-4f72-ced4-7c25310f4d72"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfMYqzDPRhJO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94a68161-98d1-4a66-daac-5e9e8b69b8b5"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test= train_test_split(X,Y,test_size=0.2,random_state=5)\n",
        "X_train.shape"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_eA2iVxSG_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elkKKkjnWrQr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0165b45f-1c3e-445f-b43c-1da1792a92e5"
      },
      "source": [
        "Y_test.shape"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnTCWLdSSfgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import SimpleRNN, LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM((2),input_shape=(5,1), return_sequences=True))\n",
        "model.add(LSTM((3),input_shape=(5,1), return_sequences=True))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1,activation='relu'))\n",
        "model.compile(optimizer='adam',loss='mae', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1Ijq5YuTBL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "07072d54-975b-49d7-edbc-c79b6abd1569"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_17 (LSTM)               (None, 5, 2)              32        \n",
            "_________________________________________________________________\n",
            "lstm_18 (LSTM)               (None, 5, 3)              72        \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 16        \n",
            "=================================================================\n",
            "Total params: 120\n",
            "Trainable params: 120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZB1FhVFTYx5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "638cd706-9033-4f79-d391-c0e1b095e494"
      },
      "source": [
        "hist= model.fit(X_train, Y_train, epochs=2000, batch_size=100, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/2000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 16.3763 - acc: 0.0000e+00 - val_loss: 11.6855 - val_acc: 0.0000e+00\n",
            "Epoch 2/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 16.3746 - acc: 0.0000e+00 - val_loss: 11.6838 - val_acc: 0.0000e+00\n",
            "Epoch 3/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 16.3731 - acc: 0.0000e+00 - val_loss: 11.6818 - val_acc: 0.0000e+00\n",
            "Epoch 4/2000\n",
            "80/80 [==============================] - 0s 128us/step - loss: 16.3713 - acc: 0.0000e+00 - val_loss: 11.6797 - val_acc: 0.0000e+00\n",
            "Epoch 5/2000\n",
            "80/80 [==============================] - 0s 136us/step - loss: 16.3694 - acc: 0.0000e+00 - val_loss: 11.6775 - val_acc: 0.0000e+00\n",
            "Epoch 6/2000\n",
            "80/80 [==============================] - 0s 142us/step - loss: 16.3673 - acc: 0.0000e+00 - val_loss: 11.6753 - val_acc: 0.0000e+00\n",
            "Epoch 7/2000\n",
            "80/80 [==============================] - 0s 145us/step - loss: 16.3652 - acc: 0.0000e+00 - val_loss: 11.6731 - val_acc: 0.0000e+00\n",
            "Epoch 8/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 16.3630 - acc: 0.0000e+00 - val_loss: 11.6708 - val_acc: 0.0000e+00\n",
            "Epoch 9/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 16.3608 - acc: 0.0000e+00 - val_loss: 11.6685 - val_acc: 0.0000e+00\n",
            "Epoch 10/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 16.3586 - acc: 0.0000e+00 - val_loss: 11.6661 - val_acc: 0.0000e+00\n",
            "Epoch 11/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 16.3563 - acc: 0.0000e+00 - val_loss: 11.6637 - val_acc: 0.0000e+00\n",
            "Epoch 12/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 16.3540 - acc: 0.0000e+00 - val_loss: 11.6612 - val_acc: 0.0000e+00\n",
            "Epoch 13/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 16.3516 - acc: 0.0000e+00 - val_loss: 11.6588 - val_acc: 0.0000e+00\n",
            "Epoch 14/2000\n",
            "80/80 [==============================] - 0s 141us/step - loss: 16.3493 - acc: 0.0000e+00 - val_loss: 11.6563 - val_acc: 0.0000e+00\n",
            "Epoch 15/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 16.3469 - acc: 0.0000e+00 - val_loss: 11.6537 - val_acc: 0.0000e+00\n",
            "Epoch 16/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 16.3444 - acc: 0.0000e+00 - val_loss: 11.6512 - val_acc: 0.0000e+00\n",
            "Epoch 17/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 16.3419 - acc: 0.0000e+00 - val_loss: 11.6486 - val_acc: 0.0000e+00\n",
            "Epoch 18/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 16.3394 - acc: 0.0000e+00 - val_loss: 11.6459 - val_acc: 0.0000e+00\n",
            "Epoch 19/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 16.3369 - acc: 0.0000e+00 - val_loss: 11.6432 - val_acc: 0.0000e+00\n",
            "Epoch 20/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 16.3343 - acc: 0.0000e+00 - val_loss: 11.6405 - val_acc: 0.0000e+00\n",
            "Epoch 21/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 16.3317 - acc: 0.0000e+00 - val_loss: 11.6377 - val_acc: 0.0000e+00\n",
            "Epoch 22/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 16.3290 - acc: 0.0000e+00 - val_loss: 11.6349 - val_acc: 0.0000e+00\n",
            "Epoch 23/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 16.3263 - acc: 0.0000e+00 - val_loss: 11.6321 - val_acc: 0.0000e+00\n",
            "Epoch 24/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 16.3236 - acc: 0.0000e+00 - val_loss: 11.6292 - val_acc: 0.0000e+00\n",
            "Epoch 25/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 16.3208 - acc: 0.0000e+00 - val_loss: 11.6263 - val_acc: 0.0000e+00\n",
            "Epoch 26/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 16.3180 - acc: 0.0000e+00 - val_loss: 11.6233 - val_acc: 0.0000e+00\n",
            "Epoch 27/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 16.3152 - acc: 0.0000e+00 - val_loss: 11.6203 - val_acc: 0.0000e+00\n",
            "Epoch 28/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 16.3123 - acc: 0.0000e+00 - val_loss: 11.6173 - val_acc: 0.0000e+00\n",
            "Epoch 29/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 16.3093 - acc: 0.0000e+00 - val_loss: 11.6142 - val_acc: 0.0000e+00\n",
            "Epoch 30/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 16.3064 - acc: 0.0000e+00 - val_loss: 11.6111 - val_acc: 0.0000e+00\n",
            "Epoch 31/2000\n",
            "80/80 [==============================] - 0s 139us/step - loss: 16.3033 - acc: 0.0000e+00 - val_loss: 11.6078 - val_acc: 0.0000e+00\n",
            "Epoch 32/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 16.3003 - acc: 0.0000e+00 - val_loss: 11.6046 - val_acc: 0.0000e+00\n",
            "Epoch 33/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 16.2971 - acc: 0.0000e+00 - val_loss: 11.6013 - val_acc: 0.0000e+00\n",
            "Epoch 34/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 16.2940 - acc: 0.0000e+00 - val_loss: 11.5979 - val_acc: 0.0000e+00\n",
            "Epoch 35/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 16.2908 - acc: 0.0000e+00 - val_loss: 11.5945 - val_acc: 0.0000e+00\n",
            "Epoch 36/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 16.2875 - acc: 0.0000e+00 - val_loss: 11.5911 - val_acc: 0.0000e+00\n",
            "Epoch 37/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 16.2842 - acc: 0.0000e+00 - val_loss: 11.5876 - val_acc: 0.0000e+00\n",
            "Epoch 38/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 16.2808 - acc: 0.0000e+00 - val_loss: 11.5840 - val_acc: 0.0000e+00\n",
            "Epoch 39/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 16.2774 - acc: 0.0000e+00 - val_loss: 11.5804 - val_acc: 0.0000e+00\n",
            "Epoch 40/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 16.2739 - acc: 0.0000e+00 - val_loss: 11.5767 - val_acc: 0.0000e+00\n",
            "Epoch 41/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 16.2704 - acc: 0.0000e+00 - val_loss: 11.5730 - val_acc: 0.0000e+00\n",
            "Epoch 42/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 16.2668 - acc: 0.0000e+00 - val_loss: 11.5692 - val_acc: 0.0000e+00\n",
            "Epoch 43/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 16.2632 - acc: 0.0000e+00 - val_loss: 11.5653 - val_acc: 0.0000e+00\n",
            "Epoch 44/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 16.2595 - acc: 0.0000e+00 - val_loss: 11.5614 - val_acc: 0.0000e+00\n",
            "Epoch 45/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 16.2557 - acc: 0.0000e+00 - val_loss: 11.5574 - val_acc: 0.0000e+00\n",
            "Epoch 46/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 16.2519 - acc: 0.0000e+00 - val_loss: 11.5534 - val_acc: 0.0000e+00\n",
            "Epoch 47/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 16.2481 - acc: 0.0000e+00 - val_loss: 11.5493 - val_acc: 0.0000e+00\n",
            "Epoch 48/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 16.2441 - acc: 0.0000e+00 - val_loss: 11.5451 - val_acc: 0.0000e+00\n",
            "Epoch 49/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 16.2401 - acc: 0.0000e+00 - val_loss: 11.5409 - val_acc: 0.0000e+00\n",
            "Epoch 50/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 16.2362 - acc: 0.0000e+00 - val_loss: 11.5366 - val_acc: 0.0000e+00\n",
            "Epoch 51/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 16.2322 - acc: 0.0000e+00 - val_loss: 11.5323 - val_acc: 0.0000e+00\n",
            "Epoch 52/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 16.2281 - acc: 0.0000e+00 - val_loss: 11.5279 - val_acc: 0.0000e+00\n",
            "Epoch 53/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 16.2240 - acc: 0.0000e+00 - val_loss: 11.5234 - val_acc: 0.0000e+00\n",
            "Epoch 54/2000\n",
            "80/80 [==============================] - 0s 137us/step - loss: 16.2198 - acc: 0.0000e+00 - val_loss: 11.5189 - val_acc: 0.0000e+00\n",
            "Epoch 55/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 16.2156 - acc: 0.0000e+00 - val_loss: 11.5143 - val_acc: 0.0000e+00\n",
            "Epoch 56/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 16.2113 - acc: 0.0000e+00 - val_loss: 11.5096 - val_acc: 0.0000e+00\n",
            "Epoch 57/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 16.2069 - acc: 0.0000e+00 - val_loss: 11.5048 - val_acc: 0.0000e+00\n",
            "Epoch 58/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 16.2025 - acc: 0.0000e+00 - val_loss: 11.5000 - val_acc: 0.0000e+00\n",
            "Epoch 59/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 16.1980 - acc: 0.0000e+00 - val_loss: 11.4951 - val_acc: 0.0000e+00\n",
            "Epoch 60/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 16.1934 - acc: 0.0000e+00 - val_loss: 11.4901 - val_acc: 0.0000e+00\n",
            "Epoch 61/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 16.1889 - acc: 0.0000e+00 - val_loss: 11.4851 - val_acc: 0.0000e+00\n",
            "Epoch 62/2000\n",
            "80/80 [==============================] - 0s 125us/step - loss: 16.1843 - acc: 0.0000e+00 - val_loss: 11.4799 - val_acc: 0.0000e+00\n",
            "Epoch 63/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 16.1796 - acc: 0.0000e+00 - val_loss: 11.4748 - val_acc: 0.0000e+00\n",
            "Epoch 64/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 16.1749 - acc: 0.0000e+00 - val_loss: 11.4695 - val_acc: 0.0000e+00\n",
            "Epoch 65/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 16.1702 - acc: 0.0000e+00 - val_loss: 11.4642 - val_acc: 0.0000e+00\n",
            "Epoch 66/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 16.1653 - acc: 0.0000e+00 - val_loss: 11.4588 - val_acc: 0.0000e+00\n",
            "Epoch 67/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 16.1604 - acc: 0.0000e+00 - val_loss: 11.4533 - val_acc: 0.0000e+00\n",
            "Epoch 68/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 16.1554 - acc: 0.0000e+00 - val_loss: 11.4477 - val_acc: 0.0000e+00\n",
            "Epoch 69/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 16.1504 - acc: 0.0000e+00 - val_loss: 11.4421 - val_acc: 0.0000e+00\n",
            "Epoch 70/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 16.1452 - acc: 0.0000e+00 - val_loss: 11.4363 - val_acc: 0.0000e+00\n",
            "Epoch 71/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 16.1401 - acc: 0.0000e+00 - val_loss: 11.4305 - val_acc: 0.0000e+00\n",
            "Epoch 72/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 16.1350 - acc: 0.0000e+00 - val_loss: 11.4246 - val_acc: 0.0000e+00\n",
            "Epoch 73/2000\n",
            "80/80 [==============================] - 0s 134us/step - loss: 16.1298 - acc: 0.0000e+00 - val_loss: 11.4186 - val_acc: 0.0000e+00\n",
            "Epoch 74/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 16.1246 - acc: 0.0000e+00 - val_loss: 11.4125 - val_acc: 0.0000e+00\n",
            "Epoch 75/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 16.1192 - acc: 0.0000e+00 - val_loss: 11.4063 - val_acc: 0.0000e+00\n",
            "Epoch 76/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 16.1138 - acc: 0.0000e+00 - val_loss: 11.4000 - val_acc: 0.0000e+00\n",
            "Epoch 77/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 16.1083 - acc: 0.0000e+00 - val_loss: 11.3937 - val_acc: 0.0000e+00\n",
            "Epoch 78/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 16.1028 - acc: 0.0000e+00 - val_loss: 11.3872 - val_acc: 0.0000e+00\n",
            "Epoch 79/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 16.0971 - acc: 0.0000e+00 - val_loss: 11.3807 - val_acc: 0.0000e+00\n",
            "Epoch 80/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 16.0914 - acc: 0.0000e+00 - val_loss: 11.3740 - val_acc: 0.0000e+00\n",
            "Epoch 81/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 16.0857 - acc: 0.0000e+00 - val_loss: 11.3673 - val_acc: 0.0000e+00\n",
            "Epoch 82/2000\n",
            "80/80 [==============================] - 0s 141us/step - loss: 16.0800 - acc: 0.0000e+00 - val_loss: 11.3605 - val_acc: 0.0000e+00\n",
            "Epoch 83/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 16.0742 - acc: 0.0000e+00 - val_loss: 11.3536 - val_acc: 0.0000e+00\n",
            "Epoch 84/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 16.0684 - acc: 0.0000e+00 - val_loss: 11.3466 - val_acc: 0.0000e+00\n",
            "Epoch 85/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 16.0625 - acc: 0.0000e+00 - val_loss: 11.3395 - val_acc: 0.0000e+00\n",
            "Epoch 86/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 16.0565 - acc: 0.0000e+00 - val_loss: 11.3324 - val_acc: 0.0000e+00\n",
            "Epoch 87/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 16.0504 - acc: 0.0000e+00 - val_loss: 11.3251 - val_acc: 0.0000e+00\n",
            "Epoch 88/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 16.0442 - acc: 0.0000e+00 - val_loss: 11.3177 - val_acc: 0.0000e+00\n",
            "Epoch 89/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 16.0380 - acc: 0.0000e+00 - val_loss: 11.3102 - val_acc: 0.0000e+00\n",
            "Epoch 90/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 16.0318 - acc: 0.0000e+00 - val_loss: 11.3025 - val_acc: 0.0000e+00\n",
            "Epoch 91/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 16.0255 - acc: 0.0000e+00 - val_loss: 11.2947 - val_acc: 0.0000e+00\n",
            "Epoch 92/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 16.0193 - acc: 0.0000e+00 - val_loss: 11.2868 - val_acc: 0.0000e+00\n",
            "Epoch 93/2000\n",
            "80/80 [==============================] - 0s 130us/step - loss: 16.0129 - acc: 0.0000e+00 - val_loss: 11.2789 - val_acc: 0.0000e+00\n",
            "Epoch 94/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 16.0064 - acc: 0.0000e+00 - val_loss: 11.2708 - val_acc: 0.0000e+00\n",
            "Epoch 95/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 15.9999 - acc: 0.0000e+00 - val_loss: 11.2626 - val_acc: 0.0000e+00\n",
            "Epoch 96/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 15.9933 - acc: 0.0000e+00 - val_loss: 11.2543 - val_acc: 0.0000e+00\n",
            "Epoch 97/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 15.9866 - acc: 0.0000e+00 - val_loss: 11.2459 - val_acc: 0.0000e+00\n",
            "Epoch 98/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 15.9798 - acc: 0.0000e+00 - val_loss: 11.2374 - val_acc: 0.0000e+00\n",
            "Epoch 99/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 15.9732 - acc: 0.0000e+00 - val_loss: 11.2288 - val_acc: 0.0000e+00\n",
            "Epoch 100/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 15.9664 - acc: 0.0000e+00 - val_loss: 11.2201 - val_acc: 0.0000e+00\n",
            "Epoch 101/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 15.9596 - acc: 0.0000e+00 - val_loss: 11.2113 - val_acc: 0.0000e+00\n",
            "Epoch 102/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 15.9527 - acc: 0.0000e+00 - val_loss: 11.2024 - val_acc: 0.0000e+00\n",
            "Epoch 103/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 15.9458 - acc: 0.0000e+00 - val_loss: 11.1933 - val_acc: 0.0000e+00\n",
            "Epoch 104/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 15.9387 - acc: 0.0000e+00 - val_loss: 11.1842 - val_acc: 0.0000e+00\n",
            "Epoch 105/2000\n",
            "80/80 [==============================] - 0s 268us/step - loss: 15.9316 - acc: 0.0000e+00 - val_loss: 11.1749 - val_acc: 0.0000e+00\n",
            "Epoch 106/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 15.9243 - acc: 0.0000e+00 - val_loss: 11.1654 - val_acc: 0.0000e+00\n",
            "Epoch 107/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 15.9172 - acc: 0.0000e+00 - val_loss: 11.1558 - val_acc: 0.0000e+00\n",
            "Epoch 108/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 15.9101 - acc: 0.0000e+00 - val_loss: 11.1461 - val_acc: 0.0000e+00\n",
            "Epoch 109/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 15.9028 - acc: 0.0000e+00 - val_loss: 11.1364 - val_acc: 0.0000e+00\n",
            "Epoch 110/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 15.8955 - acc: 0.0000e+00 - val_loss: 11.1265 - val_acc: 0.0000e+00\n",
            "Epoch 111/2000\n",
            "80/80 [==============================] - 0s 133us/step - loss: 15.8881 - acc: 0.0000e+00 - val_loss: 11.1165 - val_acc: 0.0000e+00\n",
            "Epoch 112/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 15.8806 - acc: 0.0000e+00 - val_loss: 11.1064 - val_acc: 0.0000e+00\n",
            "Epoch 113/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 15.8730 - acc: 0.0000e+00 - val_loss: 11.0961 - val_acc: 0.0000e+00\n",
            "Epoch 114/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 15.8655 - acc: 0.0000e+00 - val_loss: 11.0858 - val_acc: 0.0000e+00\n",
            "Epoch 115/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 15.8581 - acc: 0.0000e+00 - val_loss: 11.0754 - val_acc: 0.0000e+00\n",
            "Epoch 116/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 15.8505 - acc: 0.0000e+00 - val_loss: 11.0648 - val_acc: 0.0000e+00\n",
            "Epoch 117/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 15.8428 - acc: 0.0000e+00 - val_loss: 11.0542 - val_acc: 0.0000e+00\n",
            "Epoch 118/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 15.8351 - acc: 0.0000e+00 - val_loss: 11.0433 - val_acc: 0.0000e+00\n",
            "Epoch 119/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 15.8273 - acc: 0.0000e+00 - val_loss: 11.0322 - val_acc: 0.0000e+00\n",
            "Epoch 120/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 15.8194 - acc: 0.0000e+00 - val_loss: 11.0210 - val_acc: 0.0000e+00\n",
            "Epoch 121/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 15.8115 - acc: 0.0000e+00 - val_loss: 11.0098 - val_acc: 0.0000e+00\n",
            "Epoch 122/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 15.8038 - acc: 0.0000e+00 - val_loss: 10.9984 - val_acc: 0.0000e+00\n",
            "Epoch 123/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 15.7959 - acc: 0.0000e+00 - val_loss: 10.9869 - val_acc: 0.0000e+00\n",
            "Epoch 124/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 15.7880 - acc: 0.0000e+00 - val_loss: 10.9753 - val_acc: 0.0000e+00\n",
            "Epoch 125/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 15.7800 - acc: 0.0000e+00 - val_loss: 10.9637 - val_acc: 0.0000e+00\n",
            "Epoch 126/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 15.7719 - acc: 0.0000e+00 - val_loss: 10.9519 - val_acc: 0.0000e+00\n",
            "Epoch 127/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 15.7637 - acc: 0.0000e+00 - val_loss: 10.9399 - val_acc: 0.0000e+00\n",
            "Epoch 128/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 15.7556 - acc: 0.0000e+00 - val_loss: 10.9278 - val_acc: 0.0000e+00\n",
            "Epoch 129/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 15.7475 - acc: 0.0000e+00 - val_loss: 10.9157 - val_acc: 0.0000e+00\n",
            "Epoch 130/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 15.7394 - acc: 0.0000e+00 - val_loss: 10.9035 - val_acc: 0.0000e+00\n",
            "Epoch 131/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 15.7312 - acc: 0.0000e+00 - val_loss: 10.8911 - val_acc: 0.0000e+00\n",
            "Epoch 132/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 15.7229 - acc: 0.0000e+00 - val_loss: 10.8785 - val_acc: 0.0000e+00\n",
            "Epoch 133/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 15.7144 - acc: 0.0000e+00 - val_loss: 10.8659 - val_acc: 0.0000e+00\n",
            "Epoch 134/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 15.7059 - acc: 0.0000e+00 - val_loss: 10.8541 - val_acc: 0.0000e+00\n",
            "Epoch 135/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 15.6974 - acc: 0.0000e+00 - val_loss: 10.8425 - val_acc: 0.0000e+00\n",
            "Epoch 136/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 15.6887 - acc: 0.0000e+00 - val_loss: 10.8307 - val_acc: 0.0000e+00\n",
            "Epoch 137/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 15.6799 - acc: 0.0000e+00 - val_loss: 10.8188 - val_acc: 0.0000e+00\n",
            "Epoch 138/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 15.6710 - acc: 0.0000e+00 - val_loss: 10.8068 - val_acc: 0.0000e+00\n",
            "Epoch 139/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 15.6619 - acc: 0.0000e+00 - val_loss: 10.7946 - val_acc: 0.0000e+00\n",
            "Epoch 140/2000\n",
            "80/80 [==============================] - 0s 139us/step - loss: 15.6528 - acc: 0.0000e+00 - val_loss: 10.7823 - val_acc: 0.0000e+00\n",
            "Epoch 141/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 15.6436 - acc: 0.0000e+00 - val_loss: 10.7699 - val_acc: 0.0000e+00\n",
            "Epoch 142/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 15.6347 - acc: 0.0000e+00 - val_loss: 10.7574 - val_acc: 0.0000e+00\n",
            "Epoch 143/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 15.6256 - acc: 0.0000e+00 - val_loss: 10.7448 - val_acc: 0.0000e+00\n",
            "Epoch 144/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 15.6164 - acc: 0.0000e+00 - val_loss: 10.7320 - val_acc: 0.0000e+00\n",
            "Epoch 145/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 15.6071 - acc: 0.0000e+00 - val_loss: 10.7191 - val_acc: 0.0000e+00\n",
            "Epoch 146/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 15.5977 - acc: 0.0000e+00 - val_loss: 10.7060 - val_acc: 0.0000e+00\n",
            "Epoch 147/2000\n",
            "80/80 [==============================] - 0s 136us/step - loss: 15.5882 - acc: 0.0000e+00 - val_loss: 10.6938 - val_acc: 0.0000e+00\n",
            "Epoch 148/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 15.5786 - acc: 0.0000e+00 - val_loss: 10.6821 - val_acc: 0.0000e+00\n",
            "Epoch 149/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 15.5689 - acc: 0.0000e+00 - val_loss: 10.6702 - val_acc: 0.0000e+00\n",
            "Epoch 150/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 15.5591 - acc: 0.0000e+00 - val_loss: 10.6582 - val_acc: 0.0000e+00\n",
            "Epoch 151/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 15.5492 - acc: 0.0000e+00 - val_loss: 10.6460 - val_acc: 0.0000e+00\n",
            "Epoch 152/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 15.5391 - acc: 0.0000e+00 - val_loss: 10.6335 - val_acc: 0.0000e+00\n",
            "Epoch 153/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 15.5290 - acc: 0.0000e+00 - val_loss: 10.6209 - val_acc: 0.0000e+00\n",
            "Epoch 154/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 15.5187 - acc: 0.0000e+00 - val_loss: 10.6081 - val_acc: 0.0000e+00\n",
            "Epoch 155/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 15.5087 - acc: 0.0000e+00 - val_loss: 10.5953 - val_acc: 0.0000e+00\n",
            "Epoch 156/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 15.4987 - acc: 0.0000e+00 - val_loss: 10.5824 - val_acc: 0.0000e+00\n",
            "Epoch 157/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 15.4885 - acc: 0.0000e+00 - val_loss: 10.5693 - val_acc: 0.0000e+00\n",
            "Epoch 158/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 15.4783 - acc: 0.0000e+00 - val_loss: 10.5562 - val_acc: 0.0000e+00\n",
            "Epoch 159/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 15.4679 - acc: 0.0000e+00 - val_loss: 10.5429 - val_acc: 0.0000e+00\n",
            "Epoch 160/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 15.4575 - acc: 0.0000e+00 - val_loss: 10.5295 - val_acc: 0.0000e+00\n",
            "Epoch 161/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 15.4472 - acc: 0.0000e+00 - val_loss: 10.5160 - val_acc: 0.0000e+00\n",
            "Epoch 162/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 15.4370 - acc: 0.0000e+00 - val_loss: 10.5023 - val_acc: 0.0000e+00\n",
            "Epoch 163/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 15.4266 - acc: 0.0000e+00 - val_loss: 10.4885 - val_acc: 0.0000e+00\n",
            "Epoch 164/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 15.4162 - acc: 0.0000e+00 - val_loss: 10.4745 - val_acc: 0.0000e+00\n",
            "Epoch 165/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 15.4056 - acc: 0.0000e+00 - val_loss: 10.4605 - val_acc: 0.0000e+00\n",
            "Epoch 166/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 15.3950 - acc: 0.0000e+00 - val_loss: 10.4464 - val_acc: 0.0000e+00\n",
            "Epoch 167/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 15.3843 - acc: 0.0000e+00 - val_loss: 10.4322 - val_acc: 0.0000e+00\n",
            "Epoch 168/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 15.3739 - acc: 0.0000e+00 - val_loss: 10.4179 - val_acc: 0.0000e+00\n",
            "Epoch 169/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 15.3634 - acc: 0.0000e+00 - val_loss: 10.4036 - val_acc: 0.0000e+00\n",
            "Epoch 170/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 15.3529 - acc: 0.0000e+00 - val_loss: 10.3888 - val_acc: 0.0000e+00\n",
            "Epoch 171/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 15.3423 - acc: 0.0000e+00 - val_loss: 10.3739 - val_acc: 0.0000e+00\n",
            "Epoch 172/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 15.3316 - acc: 0.0000e+00 - val_loss: 10.3589 - val_acc: 0.0000e+00\n",
            "Epoch 173/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 15.3208 - acc: 0.0000e+00 - val_loss: 10.3438 - val_acc: 0.0000e+00\n",
            "Epoch 174/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 15.3099 - acc: 0.0000e+00 - val_loss: 10.3286 - val_acc: 0.0000e+00\n",
            "Epoch 175/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 15.2993 - acc: 0.0000e+00 - val_loss: 10.3134 - val_acc: 0.0000e+00\n",
            "Epoch 176/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 15.2887 - acc: 0.0000e+00 - val_loss: 10.2982 - val_acc: 0.0000e+00\n",
            "Epoch 177/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 15.2781 - acc: 0.0000e+00 - val_loss: 10.2828 - val_acc: 0.0000e+00\n",
            "Epoch 178/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 15.2673 - acc: 0.0000e+00 - val_loss: 10.2673 - val_acc: 0.0000e+00\n",
            "Epoch 179/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 15.2565 - acc: 0.0000e+00 - val_loss: 10.2515 - val_acc: 0.0000e+00\n",
            "Epoch 180/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 15.2455 - acc: 0.0000e+00 - val_loss: 10.2357 - val_acc: 0.0000e+00\n",
            "Epoch 181/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 15.2344 - acc: 0.0000e+00 - val_loss: 10.2201 - val_acc: 0.0000e+00\n",
            "Epoch 182/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 15.2233 - acc: 0.0000e+00 - val_loss: 10.2059 - val_acc: 0.0000e+00\n",
            "Epoch 183/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 15.2120 - acc: 0.0000e+00 - val_loss: 10.1916 - val_acc: 0.0000e+00\n",
            "Epoch 184/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 15.2007 - acc: 0.0000e+00 - val_loss: 10.1772 - val_acc: 0.0000e+00\n",
            "Epoch 185/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 15.1893 - acc: 0.0000e+00 - val_loss: 10.1627 - val_acc: 0.0000e+00\n",
            "Epoch 186/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 15.1777 - acc: 0.0000e+00 - val_loss: 10.1479 - val_acc: 0.0000e+00\n",
            "Epoch 187/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 15.1659 - acc: 0.0000e+00 - val_loss: 10.1330 - val_acc: 0.0000e+00\n",
            "Epoch 188/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 15.1539 - acc: 0.0000e+00 - val_loss: 10.1180 - val_acc: 0.0000e+00\n",
            "Epoch 189/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 15.1419 - acc: 0.0000e+00 - val_loss: 10.1029 - val_acc: 0.0000e+00\n",
            "Epoch 190/2000\n",
            "80/80 [==============================] - 0s 145us/step - loss: 15.1300 - acc: 0.0000e+00 - val_loss: 10.0877 - val_acc: 0.0000e+00\n",
            "Epoch 191/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 15.1182 - acc: 0.0000e+00 - val_loss: 10.0724 - val_acc: 0.0000e+00\n",
            "Epoch 192/2000\n",
            "80/80 [==============================] - 0s 134us/step - loss: 15.1064 - acc: 0.0000e+00 - val_loss: 10.0571 - val_acc: 0.0000e+00\n",
            "Epoch 193/2000\n",
            "80/80 [==============================] - 0s 119us/step - loss: 15.0944 - acc: 0.0000e+00 - val_loss: 10.0416 - val_acc: 0.0000e+00\n",
            "Epoch 194/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 15.0822 - acc: 0.0000e+00 - val_loss: 10.0260 - val_acc: 0.0000e+00\n",
            "Epoch 195/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 15.0699 - acc: 0.0000e+00 - val_loss: 10.0103 - val_acc: 0.0000e+00\n",
            "Epoch 196/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 15.0576 - acc: 0.0000e+00 - val_loss: 9.9945 - val_acc: 0.0000e+00\n",
            "Epoch 197/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 15.0451 - acc: 0.0000e+00 - val_loss: 9.9786 - val_acc: 0.0000e+00\n",
            "Epoch 198/2000\n",
            "80/80 [==============================] - 0s 145us/step - loss: 15.0327 - acc: 0.0000e+00 - val_loss: 9.9625 - val_acc: 0.0000e+00\n",
            "Epoch 199/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 15.0206 - acc: 0.0000e+00 - val_loss: 9.9460 - val_acc: 0.0000e+00\n",
            "Epoch 200/2000\n",
            "80/80 [==============================] - 0s 129us/step - loss: 15.0082 - acc: 0.0000e+00 - val_loss: 9.9295 - val_acc: 0.0000e+00\n",
            "Epoch 201/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 14.9958 - acc: 0.0000e+00 - val_loss: 9.9129 - val_acc: 0.0000e+00\n",
            "Epoch 202/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 14.9833 - acc: 0.0000e+00 - val_loss: 9.8962 - val_acc: 0.0000e+00\n",
            "Epoch 203/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 14.9708 - acc: 0.0000e+00 - val_loss: 9.8794 - val_acc: 0.0000e+00\n",
            "Epoch 204/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 14.9581 - acc: 0.0000e+00 - val_loss: 9.8624 - val_acc: 0.0000e+00\n",
            "Epoch 205/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 14.9453 - acc: 0.0000e+00 - val_loss: 9.8459 - val_acc: 0.0000e+00\n",
            "Epoch 206/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 14.9323 - acc: 0.0000e+00 - val_loss: 9.8305 - val_acc: 0.0000e+00\n",
            "Epoch 207/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 14.9192 - acc: 0.0000e+00 - val_loss: 9.8151 - val_acc: 0.0000e+00\n",
            "Epoch 208/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 14.9061 - acc: 0.0000e+00 - val_loss: 9.7996 - val_acc: 0.0000e+00\n",
            "Epoch 209/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 14.8928 - acc: 0.0000e+00 - val_loss: 9.7840 - val_acc: 0.0000e+00\n",
            "Epoch 210/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 14.8794 - acc: 0.0000e+00 - val_loss: 9.7681 - val_acc: 0.0000e+00\n",
            "Epoch 211/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 14.8656 - acc: 0.0000e+00 - val_loss: 9.7521 - val_acc: 0.0000e+00\n",
            "Epoch 212/2000\n",
            "80/80 [==============================] - 0s 230us/step - loss: 14.8518 - acc: 0.0000e+00 - val_loss: 9.7360 - val_acc: 0.0000e+00\n",
            "Epoch 213/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 14.8378 - acc: 0.0000e+00 - val_loss: 9.7198 - val_acc: 0.0000e+00\n",
            "Epoch 214/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 14.8238 - acc: 0.0000e+00 - val_loss: 9.7035 - val_acc: 0.0000e+00\n",
            "Epoch 215/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 14.8102 - acc: 0.0000e+00 - val_loss: 9.6871 - val_acc: 0.0000e+00\n",
            "Epoch 216/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 14.7962 - acc: 0.0000e+00 - val_loss: 9.6706 - val_acc: 0.0000e+00\n",
            "Epoch 217/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 14.7822 - acc: 0.0000e+00 - val_loss: 9.6540 - val_acc: 0.0000e+00\n",
            "Epoch 218/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 14.7681 - acc: 0.0000e+00 - val_loss: 9.6374 - val_acc: 0.0000e+00\n",
            "Epoch 219/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 14.7538 - acc: 0.0000e+00 - val_loss: 9.6207 - val_acc: 0.0000e+00\n",
            "Epoch 220/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 14.7394 - acc: 0.0000e+00 - val_loss: 9.6039 - val_acc: 0.0000e+00\n",
            "Epoch 221/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 14.7246 - acc: 0.0000e+00 - val_loss: 9.5870 - val_acc: 0.0000e+00\n",
            "Epoch 222/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 14.7098 - acc: 0.0000e+00 - val_loss: 9.5699 - val_acc: 0.0000e+00\n",
            "Epoch 223/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 14.6952 - acc: 0.0000e+00 - val_loss: 9.5529 - val_acc: 0.0000e+00\n",
            "Epoch 224/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 14.6807 - acc: 0.0000e+00 - val_loss: 9.5358 - val_acc: 0.0000e+00\n",
            "Epoch 225/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 14.6658 - acc: 0.0000e+00 - val_loss: 9.5186 - val_acc: 0.0000e+00\n",
            "Epoch 226/2000\n",
            "80/80 [==============================] - 0s 289us/step - loss: 14.6509 - acc: 0.0000e+00 - val_loss: 9.5014 - val_acc: 0.0000e+00\n",
            "Epoch 227/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 14.6359 - acc: 0.0000e+00 - val_loss: 9.4841 - val_acc: 0.0000e+00\n",
            "Epoch 228/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 14.6206 - acc: 0.0000e+00 - val_loss: 9.4667 - val_acc: 0.0000e+00\n",
            "Epoch 229/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 14.6050 - acc: 0.0000e+00 - val_loss: 9.4493 - val_acc: 0.0000e+00\n",
            "Epoch 230/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 14.5894 - acc: 0.0000e+00 - val_loss: 9.4321 - val_acc: 0.0000e+00\n",
            "Epoch 231/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 14.5736 - acc: 0.0000e+00 - val_loss: 9.4168 - val_acc: 0.0000e+00\n",
            "Epoch 232/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 14.5574 - acc: 0.0000e+00 - val_loss: 9.4014 - val_acc: 0.0000e+00\n",
            "Epoch 233/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 14.5411 - acc: 0.0000e+00 - val_loss: 9.3859 - val_acc: 0.0000e+00\n",
            "Epoch 234/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 14.5246 - acc: 0.0000e+00 - val_loss: 9.3703 - val_acc: 0.0000e+00\n",
            "Epoch 235/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 14.5079 - acc: 0.0000e+00 - val_loss: 9.3546 - val_acc: 0.0000e+00\n",
            "Epoch 236/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 14.4907 - acc: 0.0000e+00 - val_loss: 9.3388 - val_acc: 0.0000e+00\n",
            "Epoch 237/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 14.4735 - acc: 0.0000e+00 - val_loss: 9.3229 - val_acc: 0.0000e+00\n",
            "Epoch 238/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 14.4560 - acc: 0.0000e+00 - val_loss: 9.3068 - val_acc: 0.0000e+00\n",
            "Epoch 239/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 14.4380 - acc: 0.0000e+00 - val_loss: 9.2906 - val_acc: 0.0000e+00\n",
            "Epoch 240/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 14.4204 - acc: 0.0000e+00 - val_loss: 9.2744 - val_acc: 0.0000e+00\n",
            "Epoch 241/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 14.4027 - acc: 0.0000e+00 - val_loss: 9.2580 - val_acc: 0.0000e+00\n",
            "Epoch 242/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 14.3846 - acc: 0.0000e+00 - val_loss: 9.2416 - val_acc: 0.0000e+00\n",
            "Epoch 243/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 14.3665 - acc: 0.0000e+00 - val_loss: 9.2243 - val_acc: 0.0000e+00\n",
            "Epoch 244/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 14.3481 - acc: 0.0000e+00 - val_loss: 9.2066 - val_acc: 0.0000e+00\n",
            "Epoch 245/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 14.3296 - acc: 0.0000e+00 - val_loss: 9.1887 - val_acc: 0.0000e+00\n",
            "Epoch 246/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 14.3110 - acc: 0.0000e+00 - val_loss: 9.1700 - val_acc: 0.0000e+00\n",
            "Epoch 247/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 14.2919 - acc: 0.0000e+00 - val_loss: 9.1512 - val_acc: 0.0000e+00\n",
            "Epoch 248/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 14.2730 - acc: 0.0000e+00 - val_loss: 9.1322 - val_acc: 0.0000e+00\n",
            "Epoch 249/2000\n",
            "80/80 [==============================] - 0s 239us/step - loss: 14.2542 - acc: 0.0000e+00 - val_loss: 9.1130 - val_acc: 0.0000e+00\n",
            "Epoch 250/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 14.2352 - acc: 0.0000e+00 - val_loss: 9.0934 - val_acc: 0.0000e+00\n",
            "Epoch 251/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 14.2161 - acc: 0.0000e+00 - val_loss: 9.0726 - val_acc: 0.0000e+00\n",
            "Epoch 252/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 14.1968 - acc: 0.0000e+00 - val_loss: 9.0518 - val_acc: 0.0000e+00\n",
            "Epoch 253/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 14.1774 - acc: 0.0000e+00 - val_loss: 9.0301 - val_acc: 0.0000e+00\n",
            "Epoch 254/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 14.1576 - acc: 0.0000e+00 - val_loss: 9.0084 - val_acc: 0.0000e+00\n",
            "Epoch 255/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 14.1377 - acc: 0.0000e+00 - val_loss: 8.9862 - val_acc: 0.0000e+00\n",
            "Epoch 256/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 14.1173 - acc: 0.0000e+00 - val_loss: 8.9639 - val_acc: 0.0000e+00\n",
            "Epoch 257/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 14.0972 - acc: 0.0000e+00 - val_loss: 8.9416 - val_acc: 0.0000e+00\n",
            "Epoch 258/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 14.0767 - acc: 0.0000e+00 - val_loss: 8.9192 - val_acc: 0.0000e+00\n",
            "Epoch 259/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 14.0561 - acc: 0.0000e+00 - val_loss: 8.8967 - val_acc: 0.0000e+00\n",
            "Epoch 260/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 14.0348 - acc: 0.0000e+00 - val_loss: 8.8742 - val_acc: 0.0000e+00\n",
            "Epoch 261/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 14.0133 - acc: 0.0000e+00 - val_loss: 8.8516 - val_acc: 0.0000e+00\n",
            "Epoch 262/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 13.9910 - acc: 0.0000e+00 - val_loss: 8.8288 - val_acc: 0.0000e+00\n",
            "Epoch 263/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 13.9685 - acc: 0.0000e+00 - val_loss: 8.8042 - val_acc: 0.0000e+00\n",
            "Epoch 264/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 13.9456 - acc: 0.0000e+00 - val_loss: 8.7792 - val_acc: 0.0000e+00\n",
            "Epoch 265/2000\n",
            "80/80 [==============================] - 0s 132us/step - loss: 13.9224 - acc: 0.0000e+00 - val_loss: 8.7535 - val_acc: 0.0000e+00\n",
            "Epoch 266/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 13.8995 - acc: 0.0000e+00 - val_loss: 8.7274 - val_acc: 0.0000e+00\n",
            "Epoch 267/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 13.8760 - acc: 0.0000e+00 - val_loss: 8.7005 - val_acc: 0.0000e+00\n",
            "Epoch 268/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 13.8522 - acc: 0.0000e+00 - val_loss: 8.6721 - val_acc: 0.0000e+00\n",
            "Epoch 269/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 13.8281 - acc: 0.0000e+00 - val_loss: 8.6409 - val_acc: 0.0000e+00\n",
            "Epoch 270/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 13.8038 - acc: 0.0000e+00 - val_loss: 8.6084 - val_acc: 0.0000e+00\n",
            "Epoch 271/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 13.7793 - acc: 0.0000e+00 - val_loss: 8.5749 - val_acc: 0.0000e+00\n",
            "Epoch 272/2000\n",
            "80/80 [==============================] - 0s 124us/step - loss: 13.7544 - acc: 0.0000e+00 - val_loss: 8.5407 - val_acc: 0.0000e+00\n",
            "Epoch 273/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 13.7287 - acc: 0.0000e+00 - val_loss: 8.5078 - val_acc: 0.0000e+00\n",
            "Epoch 274/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 13.7021 - acc: 0.0000e+00 - val_loss: 8.4751 - val_acc: 0.0000e+00\n",
            "Epoch 275/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 13.6750 - acc: 0.0000e+00 - val_loss: 8.4409 - val_acc: 0.0000e+00\n",
            "Epoch 276/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 13.6473 - acc: 0.0000e+00 - val_loss: 8.4057 - val_acc: 0.0000e+00\n",
            "Epoch 277/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 13.6187 - acc: 0.0000e+00 - val_loss: 8.3701 - val_acc: 0.0000e+00\n",
            "Epoch 278/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 13.5891 - acc: 0.0000e+00 - val_loss: 8.3342 - val_acc: 0.0000e+00\n",
            "Epoch 279/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 13.5581 - acc: 0.0000e+00 - val_loss: 8.2984 - val_acc: 0.0000e+00\n",
            "Epoch 280/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 13.5257 - acc: 0.0000e+00 - val_loss: 8.2627 - val_acc: 0.0000e+00\n",
            "Epoch 281/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 13.4916 - acc: 0.0000e+00 - val_loss: 8.2271 - val_acc: 0.0000e+00\n",
            "Epoch 282/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 13.4559 - acc: 0.0000e+00 - val_loss: 8.1916 - val_acc: 0.0000e+00\n",
            "Epoch 283/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 13.4191 - acc: 0.0000e+00 - val_loss: 8.1562 - val_acc: 0.0000e+00\n",
            "Epoch 284/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 13.3805 - acc: 0.0000e+00 - val_loss: 8.1209 - val_acc: 0.0000e+00\n",
            "Epoch 285/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 13.3397 - acc: 0.0000e+00 - val_loss: 8.0856 - val_acc: 0.0000e+00\n",
            "Epoch 286/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 13.2965 - acc: 0.0000e+00 - val_loss: 8.0504 - val_acc: 0.0000e+00\n",
            "Epoch 287/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 13.2510 - acc: 0.0000e+00 - val_loss: 8.0152 - val_acc: 0.0000e+00\n",
            "Epoch 288/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 13.2024 - acc: 0.0000e+00 - val_loss: 7.9800 - val_acc: 0.0000e+00\n",
            "Epoch 289/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 13.1509 - acc: 0.0000e+00 - val_loss: 7.9448 - val_acc: 0.0000e+00\n",
            "Epoch 290/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 13.0960 - acc: 0.0000e+00 - val_loss: 7.9098 - val_acc: 0.0000e+00\n",
            "Epoch 291/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 13.0381 - acc: 0.0000e+00 - val_loss: 7.8742 - val_acc: 0.0000e+00\n",
            "Epoch 292/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 12.9765 - acc: 0.0000e+00 - val_loss: 7.8310 - val_acc: 0.0000e+00\n",
            "Epoch 293/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 12.9123 - acc: 0.0000e+00 - val_loss: 7.7855 - val_acc: 0.0000e+00\n",
            "Epoch 294/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 12.8462 - acc: 0.0000e+00 - val_loss: 7.7407 - val_acc: 0.0000e+00\n",
            "Epoch 295/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 12.7816 - acc: 0.0000e+00 - val_loss: 7.6968 - val_acc: 0.0000e+00\n",
            "Epoch 296/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 12.7195 - acc: 0.0000e+00 - val_loss: 7.6540 - val_acc: 0.0000e+00\n",
            "Epoch 297/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 12.6598 - acc: 0.0000e+00 - val_loss: 7.6121 - val_acc: 0.0000e+00\n",
            "Epoch 298/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 12.6024 - acc: 0.0000e+00 - val_loss: 7.5709 - val_acc: 0.0000e+00\n",
            "Epoch 299/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 12.5478 - acc: 0.0000e+00 - val_loss: 7.5303 - val_acc: 0.0000e+00\n",
            "Epoch 300/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 12.4954 - acc: 0.0000e+00 - val_loss: 7.4904 - val_acc: 0.0000e+00\n",
            "Epoch 301/2000\n",
            "80/80 [==============================] - 0s 255us/step - loss: 12.4448 - acc: 0.0000e+00 - val_loss: 7.4510 - val_acc: 0.0000e+00\n",
            "Epoch 302/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 12.3959 - acc: 0.0000e+00 - val_loss: 7.4128 - val_acc: 0.0000e+00\n",
            "Epoch 303/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 12.3489 - acc: 0.0000e+00 - val_loss: 7.3755 - val_acc: 0.0000e+00\n",
            "Epoch 304/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 12.3036 - acc: 0.0000e+00 - val_loss: 7.3391 - val_acc: 0.0000e+00\n",
            "Epoch 305/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 12.2596 - acc: 0.0000e+00 - val_loss: 7.3035 - val_acc: 0.0000e+00\n",
            "Epoch 306/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 12.2166 - acc: 0.0000e+00 - val_loss: 7.2694 - val_acc: 0.0000e+00\n",
            "Epoch 307/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 12.1749 - acc: 0.0000e+00 - val_loss: 7.2369 - val_acc: 0.0000e+00\n",
            "Epoch 308/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 12.1343 - acc: 0.0000e+00 - val_loss: 7.2047 - val_acc: 0.0000e+00\n",
            "Epoch 309/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 12.0946 - acc: 0.0000e+00 - val_loss: 7.1727 - val_acc: 0.0000e+00\n",
            "Epoch 310/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 12.0555 - acc: 0.0000e+00 - val_loss: 7.1406 - val_acc: 0.0000e+00\n",
            "Epoch 311/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 12.0166 - acc: 0.0000e+00 - val_loss: 7.1083 - val_acc: 0.0000e+00\n",
            "Epoch 312/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 11.9778 - acc: 0.0000e+00 - val_loss: 7.0757 - val_acc: 0.0000e+00\n",
            "Epoch 313/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 11.9391 - acc: 0.0000e+00 - val_loss: 7.0430 - val_acc: 0.0000e+00\n",
            "Epoch 314/2000\n",
            "80/80 [==============================] - 0s 128us/step - loss: 11.9003 - acc: 0.0000e+00 - val_loss: 7.0099 - val_acc: 0.0000e+00\n",
            "Epoch 315/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 11.8615 - acc: 0.0000e+00 - val_loss: 6.9765 - val_acc: 0.0000e+00\n",
            "Epoch 316/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 11.8225 - acc: 0.0000e+00 - val_loss: 6.9428 - val_acc: 0.0000e+00\n",
            "Epoch 317/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 11.7838 - acc: 0.0000e+00 - val_loss: 6.9088 - val_acc: 0.0000e+00\n",
            "Epoch 318/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 11.7452 - acc: 0.0000e+00 - val_loss: 6.8745 - val_acc: 0.0000e+00\n",
            "Epoch 319/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 11.7065 - acc: 0.0000e+00 - val_loss: 6.8399 - val_acc: 0.0000e+00\n",
            "Epoch 320/2000\n",
            "80/80 [==============================] - 0s 134us/step - loss: 11.6676 - acc: 0.0000e+00 - val_loss: 6.8049 - val_acc: 0.0000e+00\n",
            "Epoch 321/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 11.6285 - acc: 0.0000e+00 - val_loss: 6.7695 - val_acc: 0.0000e+00\n",
            "Epoch 322/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 11.5891 - acc: 0.0000e+00 - val_loss: 6.7337 - val_acc: 0.0000e+00\n",
            "Epoch 323/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 11.5495 - acc: 0.0000e+00 - val_loss: 6.6974 - val_acc: 0.0000e+00\n",
            "Epoch 324/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 11.5097 - acc: 0.0000e+00 - val_loss: 6.6608 - val_acc: 0.0000e+00\n",
            "Epoch 325/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 11.4697 - acc: 0.0000e+00 - val_loss: 6.6286 - val_acc: 0.0000e+00\n",
            "Epoch 326/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 11.4314 - acc: 0.0000e+00 - val_loss: 6.6019 - val_acc: 0.0000e+00\n",
            "Epoch 327/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 11.3964 - acc: 0.0000e+00 - val_loss: 6.5753 - val_acc: 0.0000e+00\n",
            "Epoch 328/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 11.3640 - acc: 0.0000e+00 - val_loss: 6.5483 - val_acc: 0.0000e+00\n",
            "Epoch 329/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 11.3339 - acc: 0.0000e+00 - val_loss: 6.5235 - val_acc: 0.0000e+00\n",
            "Epoch 330/2000\n",
            "80/80 [==============================] - 0s 131us/step - loss: 11.3045 - acc: 0.0000e+00 - val_loss: 6.5054 - val_acc: 0.0000e+00\n",
            "Epoch 331/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 11.2754 - acc: 0.0000e+00 - val_loss: 6.4870 - val_acc: 0.0000e+00\n",
            "Epoch 332/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 11.2472 - acc: 0.0000e+00 - val_loss: 6.4685 - val_acc: 0.0000e+00\n",
            "Epoch 333/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 11.2209 - acc: 0.0000e+00 - val_loss: 6.4496 - val_acc: 0.0000e+00\n",
            "Epoch 334/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 11.1954 - acc: 0.0000e+00 - val_loss: 6.4304 - val_acc: 0.0000e+00\n",
            "Epoch 335/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 11.1698 - acc: 0.0000e+00 - val_loss: 6.4108 - val_acc: 0.0000e+00\n",
            "Epoch 336/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 11.1456 - acc: 0.0000e+00 - val_loss: 6.3910 - val_acc: 0.0000e+00\n",
            "Epoch 337/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 11.1215 - acc: 0.0000e+00 - val_loss: 6.3710 - val_acc: 0.0000e+00\n",
            "Epoch 338/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 11.0976 - acc: 0.0000e+00 - val_loss: 6.3511 - val_acc: 0.0000e+00\n",
            "Epoch 339/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 11.0737 - acc: 0.0000e+00 - val_loss: 6.3342 - val_acc: 0.0000e+00\n",
            "Epoch 340/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 11.0497 - acc: 0.0000e+00 - val_loss: 6.3183 - val_acc: 0.0000e+00\n",
            "Epoch 341/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 11.0256 - acc: 0.0000e+00 - val_loss: 6.3041 - val_acc: 0.0000e+00\n",
            "Epoch 342/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 11.0014 - acc: 0.0000e+00 - val_loss: 6.2899 - val_acc: 0.0000e+00\n",
            "Epoch 343/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 10.9772 - acc: 0.0000e+00 - val_loss: 6.2753 - val_acc: 0.0000e+00\n",
            "Epoch 344/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 10.9529 - acc: 0.0000e+00 - val_loss: 6.2604 - val_acc: 0.0000e+00\n",
            "Epoch 345/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 10.9284 - acc: 0.0000e+00 - val_loss: 6.2452 - val_acc: 0.0000e+00\n",
            "Epoch 346/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 10.9039 - acc: 0.0000e+00 - val_loss: 6.2297 - val_acc: 0.0000e+00\n",
            "Epoch 347/2000\n",
            "80/80 [==============================] - 0s 127us/step - loss: 10.8798 - acc: 0.0000e+00 - val_loss: 6.2140 - val_acc: 0.0000e+00\n",
            "Epoch 348/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 10.8558 - acc: 0.0000e+00 - val_loss: 6.1979 - val_acc: 0.0000e+00\n",
            "Epoch 349/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 10.8317 - acc: 0.0000e+00 - val_loss: 6.1817 - val_acc: 0.0000e+00\n",
            "Epoch 350/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 10.8075 - acc: 0.0000e+00 - val_loss: 6.1652 - val_acc: 0.0000e+00\n",
            "Epoch 351/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 10.7835 - acc: 0.0000e+00 - val_loss: 6.1487 - val_acc: 0.0000e+00\n",
            "Epoch 352/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 10.7601 - acc: 0.0000e+00 - val_loss: 6.1323 - val_acc: 0.0000e+00\n",
            "Epoch 353/2000\n",
            "80/80 [==============================] - 0s 139us/step - loss: 10.7371 - acc: 0.0000e+00 - val_loss: 6.1164 - val_acc: 0.0000e+00\n",
            "Epoch 354/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 10.7150 - acc: 0.0000e+00 - val_loss: 6.1006 - val_acc: 0.0000e+00\n",
            "Epoch 355/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 10.6931 - acc: 0.0000e+00 - val_loss: 6.0848 - val_acc: 0.0000e+00\n",
            "Epoch 356/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 10.6713 - acc: 0.0000e+00 - val_loss: 6.0690 - val_acc: 0.0000e+00\n",
            "Epoch 357/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 10.6496 - acc: 0.0000e+00 - val_loss: 6.0533 - val_acc: 0.0000e+00\n",
            "Epoch 358/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 10.6280 - acc: 0.0000e+00 - val_loss: 6.0376 - val_acc: 0.0000e+00\n",
            "Epoch 359/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 10.6065 - acc: 0.0000e+00 - val_loss: 6.0226 - val_acc: 0.0000e+00\n",
            "Epoch 360/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 10.5851 - acc: 0.0000e+00 - val_loss: 6.0093 - val_acc: 0.0000e+00\n",
            "Epoch 361/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 10.5640 - acc: 0.0000e+00 - val_loss: 5.9961 - val_acc: 0.0000e+00\n",
            "Epoch 362/2000\n",
            "80/80 [==============================] - 0s 132us/step - loss: 10.5433 - acc: 0.0000e+00 - val_loss: 5.9834 - val_acc: 0.0000e+00\n",
            "Epoch 363/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 10.5231 - acc: 0.0000e+00 - val_loss: 5.9707 - val_acc: 0.0000e+00\n",
            "Epoch 364/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 10.5032 - acc: 0.0000e+00 - val_loss: 5.9578 - val_acc: 0.0000e+00\n",
            "Epoch 365/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 10.4836 - acc: 0.0000e+00 - val_loss: 5.9451 - val_acc: 0.0000e+00\n",
            "Epoch 366/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 10.4644 - acc: 0.0000e+00 - val_loss: 5.9325 - val_acc: 0.0000e+00\n",
            "Epoch 367/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 10.4451 - acc: 0.0000e+00 - val_loss: 5.9200 - val_acc: 0.0000e+00\n",
            "Epoch 368/2000\n",
            "80/80 [==============================] - 0s 128us/step - loss: 10.4259 - acc: 0.0000e+00 - val_loss: 5.9075 - val_acc: 0.0000e+00\n",
            "Epoch 369/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 10.4070 - acc: 0.0000e+00 - val_loss: 5.8953 - val_acc: 0.0000e+00\n",
            "Epoch 370/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 10.3882 - acc: 0.0000e+00 - val_loss: 5.8831 - val_acc: 0.0000e+00\n",
            "Epoch 371/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 10.3696 - acc: 0.0000e+00 - val_loss: 5.8710 - val_acc: 0.0000e+00\n",
            "Epoch 372/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 10.3515 - acc: 0.0000e+00 - val_loss: 5.8589 - val_acc: 0.0000e+00\n",
            "Epoch 373/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 10.3335 - acc: 0.0000e+00 - val_loss: 5.8467 - val_acc: 0.0000e+00\n",
            "Epoch 374/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 10.3157 - acc: 0.0000e+00 - val_loss: 5.8345 - val_acc: 0.0000e+00\n",
            "Epoch 375/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 10.2978 - acc: 0.0000e+00 - val_loss: 5.8224 - val_acc: 0.0000e+00\n",
            "Epoch 376/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 10.2801 - acc: 0.0000e+00 - val_loss: 5.8101 - val_acc: 0.0000e+00\n",
            "Epoch 377/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 10.2624 - acc: 0.0000e+00 - val_loss: 5.7979 - val_acc: 0.0000e+00\n",
            "Epoch 378/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 10.2448 - acc: 0.0000e+00 - val_loss: 5.7856 - val_acc: 0.0000e+00\n",
            "Epoch 379/2000\n",
            "80/80 [==============================] - 0s 224us/step - loss: 10.2274 - acc: 0.0000e+00 - val_loss: 5.7734 - val_acc: 0.0000e+00\n",
            "Epoch 380/2000\n",
            "80/80 [==============================] - 0s 228us/step - loss: 10.2099 - acc: 0.0000e+00 - val_loss: 5.7610 - val_acc: 0.0000e+00\n",
            "Epoch 381/2000\n",
            "80/80 [==============================] - 0s 131us/step - loss: 10.1925 - acc: 0.0000e+00 - val_loss: 5.7485 - val_acc: 0.0000e+00\n",
            "Epoch 382/2000\n",
            "80/80 [==============================] - 0s 242us/step - loss: 10.1750 - acc: 0.0000e+00 - val_loss: 5.7360 - val_acc: 0.0000e+00\n",
            "Epoch 383/2000\n",
            "80/80 [==============================] - 0s 214us/step - loss: 10.1577 - acc: 0.0000e+00 - val_loss: 5.7232 - val_acc: 0.0000e+00\n",
            "Epoch 384/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 10.1406 - acc: 0.0000e+00 - val_loss: 5.7102 - val_acc: 0.0000e+00\n",
            "Epoch 385/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 10.1235 - acc: 0.0000e+00 - val_loss: 5.7000 - val_acc: 0.0000e+00\n",
            "Epoch 386/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 10.1063 - acc: 0.0000e+00 - val_loss: 5.6905 - val_acc: 0.0000e+00\n",
            "Epoch 387/2000\n",
            "80/80 [==============================] - 0s 194us/step - loss: 10.0890 - acc: 0.0000e+00 - val_loss: 5.6810 - val_acc: 0.0000e+00\n",
            "Epoch 388/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 10.0715 - acc: 0.0000e+00 - val_loss: 5.6715 - val_acc: 0.0000e+00\n",
            "Epoch 389/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 10.0539 - acc: 0.0000e+00 - val_loss: 5.6620 - val_acc: 0.0000e+00\n",
            "Epoch 390/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 10.0361 - acc: 0.0000e+00 - val_loss: 5.6525 - val_acc: 0.0000e+00\n",
            "Epoch 391/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 10.0195 - acc: 0.0000e+00 - val_loss: 5.6427 - val_acc: 0.0000e+00\n",
            "Epoch 392/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 10.0031 - acc: 0.0000e+00 - val_loss: 5.6325 - val_acc: 0.0000e+00\n",
            "Epoch 393/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 9.9866 - acc: 0.0000e+00 - val_loss: 5.6221 - val_acc: 0.0000e+00\n",
            "Epoch 394/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 9.9701 - acc: 0.0000e+00 - val_loss: 5.6114 - val_acc: 0.0000e+00\n",
            "Epoch 395/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 9.9547 - acc: 0.0000e+00 - val_loss: 5.6004 - val_acc: 0.0000e+00\n",
            "Epoch 396/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 9.9394 - acc: 0.0000e+00 - val_loss: 5.5892 - val_acc: 0.0000e+00\n",
            "Epoch 397/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 9.9239 - acc: 0.0000e+00 - val_loss: 5.5779 - val_acc: 0.0000e+00\n",
            "Epoch 398/2000\n",
            "80/80 [==============================] - 0s 125us/step - loss: 9.9084 - acc: 0.0000e+00 - val_loss: 5.5664 - val_acc: 0.0000e+00\n",
            "Epoch 399/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 9.8927 - acc: 0.0000e+00 - val_loss: 5.5549 - val_acc: 0.0000e+00\n",
            "Epoch 400/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 9.8770 - acc: 0.0000e+00 - val_loss: 5.5434 - val_acc: 0.0000e+00\n",
            "Epoch 401/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 9.8612 - acc: 0.0000e+00 - val_loss: 5.5317 - val_acc: 0.0000e+00\n",
            "Epoch 402/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 9.8454 - acc: 0.0000e+00 - val_loss: 5.5201 - val_acc: 0.0000e+00\n",
            "Epoch 403/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 9.8296 - acc: 0.0000e+00 - val_loss: 5.5095 - val_acc: 0.0000e+00\n",
            "Epoch 404/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 9.8138 - acc: 0.0000e+00 - val_loss: 5.5002 - val_acc: 0.0000e+00\n",
            "Epoch 405/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 9.7980 - acc: 0.0000e+00 - val_loss: 5.4910 - val_acc: 0.0000e+00\n",
            "Epoch 406/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 9.7822 - acc: 0.0000e+00 - val_loss: 5.4818 - val_acc: 0.0000e+00\n",
            "Epoch 407/2000\n",
            "80/80 [==============================] - 0s 119us/step - loss: 9.7663 - acc: 0.0000e+00 - val_loss: 5.4727 - val_acc: 0.0000e+00\n",
            "Epoch 408/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 9.7505 - acc: 0.0000e+00 - val_loss: 5.4637 - val_acc: 0.0000e+00\n",
            "Epoch 409/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 9.7346 - acc: 0.0000e+00 - val_loss: 5.4546 - val_acc: 0.0000e+00\n",
            "Epoch 410/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 9.7190 - acc: 0.0000e+00 - val_loss: 5.4458 - val_acc: 0.0000e+00\n",
            "Epoch 411/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 9.7034 - acc: 0.0000e+00 - val_loss: 5.4371 - val_acc: 0.0000e+00\n",
            "Epoch 412/2000\n",
            "80/80 [==============================] - 0s 120us/step - loss: 9.6878 - acc: 0.0000e+00 - val_loss: 5.4285 - val_acc: 0.0000e+00\n",
            "Epoch 413/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 9.6722 - acc: 0.0000e+00 - val_loss: 5.4201 - val_acc: 0.0000e+00\n",
            "Epoch 414/2000\n",
            "80/80 [==============================] - 0s 125us/step - loss: 9.6574 - acc: 0.0000e+00 - val_loss: 5.4113 - val_acc: 0.0000e+00\n",
            "Epoch 415/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 9.6429 - acc: 0.0000e+00 - val_loss: 5.4022 - val_acc: 0.0000e+00\n",
            "Epoch 416/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 9.6281 - acc: 0.0000e+00 - val_loss: 5.3928 - val_acc: 0.0000e+00\n",
            "Epoch 417/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 9.6131 - acc: 0.0000e+00 - val_loss: 5.3830 - val_acc: 0.0000e+00\n",
            "Epoch 418/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 9.5982 - acc: 0.0000e+00 - val_loss: 5.3732 - val_acc: 0.0000e+00\n",
            "Epoch 419/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 9.5836 - acc: 0.0000e+00 - val_loss: 5.3633 - val_acc: 0.0000e+00\n",
            "Epoch 420/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 9.5690 - acc: 0.0000e+00 - val_loss: 5.3534 - val_acc: 0.0000e+00\n",
            "Epoch 421/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 9.5544 - acc: 0.0000e+00 - val_loss: 5.3435 - val_acc: 0.0000e+00\n",
            "Epoch 422/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 9.5399 - acc: 0.0000e+00 - val_loss: 5.3335 - val_acc: 0.0000e+00\n",
            "Epoch 423/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 9.5253 - acc: 0.0000e+00 - val_loss: 5.3234 - val_acc: 0.0000e+00\n",
            "Epoch 424/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 9.5108 - acc: 0.0000e+00 - val_loss: 5.3133 - val_acc: 0.0000e+00\n",
            "Epoch 425/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 9.4962 - acc: 0.0000e+00 - val_loss: 5.3032 - val_acc: 0.0000e+00\n",
            "Epoch 426/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 9.4817 - acc: 0.0000e+00 - val_loss: 5.2928 - val_acc: 0.0000e+00\n",
            "Epoch 427/2000\n",
            "80/80 [==============================] - 0s 139us/step - loss: 9.4673 - acc: 0.0000e+00 - val_loss: 5.2823 - val_acc: 0.0000e+00\n",
            "Epoch 428/2000\n",
            "80/80 [==============================] - 0s 119us/step - loss: 9.4532 - acc: 0.0000e+00 - val_loss: 5.2725 - val_acc: 0.0000e+00\n",
            "Epoch 429/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 9.4391 - acc: 0.0000e+00 - val_loss: 5.2633 - val_acc: 0.0000e+00\n",
            "Epoch 430/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 9.4248 - acc: 0.0000e+00 - val_loss: 5.2562 - val_acc: 0.0000e+00\n",
            "Epoch 431/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 9.4103 - acc: 0.0000e+00 - val_loss: 5.2508 - val_acc: 0.0000e+00\n",
            "Epoch 432/2000\n",
            "80/80 [==============================] - 0s 125us/step - loss: 9.3957 - acc: 0.0000e+00 - val_loss: 5.2447 - val_acc: 0.0000e+00\n",
            "Epoch 433/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 9.3815 - acc: 0.0000e+00 - val_loss: 5.2382 - val_acc: 0.0000e+00\n",
            "Epoch 434/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 9.3673 - acc: 0.0000e+00 - val_loss: 5.2313 - val_acc: 0.0000e+00\n",
            "Epoch 435/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 9.3531 - acc: 0.0000e+00 - val_loss: 5.2240 - val_acc: 0.0000e+00\n",
            "Epoch 436/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 9.3389 - acc: 0.0000e+00 - val_loss: 5.2163 - val_acc: 0.0000e+00\n",
            "Epoch 437/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 9.3246 - acc: 0.0000e+00 - val_loss: 5.2082 - val_acc: 0.0000e+00\n",
            "Epoch 438/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 9.3103 - acc: 0.0000e+00 - val_loss: 5.1998 - val_acc: 0.0000e+00\n",
            "Epoch 439/2000\n",
            "80/80 [==============================] - 0s 285us/step - loss: 9.2960 - acc: 0.0000e+00 - val_loss: 5.1911 - val_acc: 0.0000e+00\n",
            "Epoch 440/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 9.2817 - acc: 0.0000e+00 - val_loss: 5.1820 - val_acc: 0.0000e+00\n",
            "Epoch 441/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 9.2677 - acc: 0.0000e+00 - val_loss: 5.1740 - val_acc: 0.0000e+00\n",
            "Epoch 442/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 9.2535 - acc: 0.0000e+00 - val_loss: 5.1669 - val_acc: 0.0000e+00\n",
            "Epoch 443/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 9.2391 - acc: 0.0000e+00 - val_loss: 5.1608 - val_acc: 0.0000e+00\n",
            "Epoch 444/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 9.2247 - acc: 0.0000e+00 - val_loss: 5.1540 - val_acc: 0.0000e+00\n",
            "Epoch 445/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 9.2106 - acc: 0.0000e+00 - val_loss: 5.1461 - val_acc: 0.0000e+00\n",
            "Epoch 446/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 9.1969 - acc: 0.0000e+00 - val_loss: 5.1372 - val_acc: 0.0000e+00\n",
            "Epoch 447/2000\n",
            "80/80 [==============================] - 0s 128us/step - loss: 9.1830 - acc: 0.0000e+00 - val_loss: 5.1274 - val_acc: 0.0000e+00\n",
            "Epoch 448/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 9.1693 - acc: 0.0000e+00 - val_loss: 5.1182 - val_acc: 0.0000e+00\n",
            "Epoch 449/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 9.1557 - acc: 0.0000e+00 - val_loss: 5.1096 - val_acc: 0.0000e+00\n",
            "Epoch 450/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 9.1420 - acc: 0.0000e+00 - val_loss: 5.1015 - val_acc: 0.0000e+00\n",
            "Epoch 451/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 9.1283 - acc: 0.0000e+00 - val_loss: 5.0942 - val_acc: 0.0000e+00\n",
            "Epoch 452/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 9.1145 - acc: 0.0000e+00 - val_loss: 5.0877 - val_acc: 0.0000e+00\n",
            "Epoch 453/2000\n",
            "80/80 [==============================] - 0s 128us/step - loss: 9.1010 - acc: 0.0000e+00 - val_loss: 5.0797 - val_acc: 0.0000e+00\n",
            "Epoch 454/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 9.0875 - acc: 0.0000e+00 - val_loss: 5.0703 - val_acc: 0.0000e+00\n",
            "Epoch 455/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 9.0738 - acc: 0.0000e+00 - val_loss: 5.0598 - val_acc: 0.0000e+00\n",
            "Epoch 456/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 9.0600 - acc: 0.0000e+00 - val_loss: 5.0500 - val_acc: 0.0000e+00\n",
            "Epoch 457/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 9.0465 - acc: 0.0000e+00 - val_loss: 5.0409 - val_acc: 0.0000e+00\n",
            "Epoch 458/2000\n",
            "80/80 [==============================] - 0s 139us/step - loss: 9.0329 - acc: 0.0000e+00 - val_loss: 5.0323 - val_acc: 0.0000e+00\n",
            "Epoch 459/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 9.0192 - acc: 0.0000e+00 - val_loss: 5.0244 - val_acc: 0.0000e+00\n",
            "Epoch 460/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 9.0057 - acc: 0.0000e+00 - val_loss: 5.0150 - val_acc: 0.0000e+00\n",
            "Epoch 461/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 8.9922 - acc: 0.0000e+00 - val_loss: 5.0043 - val_acc: 0.0000e+00\n",
            "Epoch 462/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 8.9787 - acc: 0.0000e+00 - val_loss: 4.9942 - val_acc: 0.0000e+00\n",
            "Epoch 463/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 8.9655 - acc: 0.0000e+00 - val_loss: 4.9841 - val_acc: 0.0000e+00\n",
            "Epoch 464/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 8.9526 - acc: 0.0000e+00 - val_loss: 4.9740 - val_acc: 0.0000e+00\n",
            "Epoch 465/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 8.9397 - acc: 0.0000e+00 - val_loss: 4.9638 - val_acc: 0.0000e+00\n",
            "Epoch 466/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 8.9268 - acc: 0.0000e+00 - val_loss: 4.9536 - val_acc: 0.0000e+00\n",
            "Epoch 467/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 8.9140 - acc: 0.0000e+00 - val_loss: 4.9434 - val_acc: 0.0000e+00\n",
            "Epoch 468/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 8.9012 - acc: 0.0000e+00 - val_loss: 4.9331 - val_acc: 0.0000e+00\n",
            "Epoch 469/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 8.8884 - acc: 0.0000e+00 - val_loss: 4.9227 - val_acc: 0.0000e+00\n",
            "Epoch 470/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 8.8757 - acc: 0.0000e+00 - val_loss: 4.9123 - val_acc: 0.0000e+00\n",
            "Epoch 471/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 8.8630 - acc: 0.0000e+00 - val_loss: 4.9017 - val_acc: 0.0000e+00\n",
            "Epoch 472/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 8.8505 - acc: 0.0000e+00 - val_loss: 4.8886 - val_acc: 0.0000e+00\n",
            "Epoch 473/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 8.8378 - acc: 0.0000e+00 - val_loss: 4.8755 - val_acc: 0.0000e+00\n",
            "Epoch 474/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 8.8251 - acc: 0.0000e+00 - val_loss: 4.8625 - val_acc: 0.0000e+00\n",
            "Epoch 475/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 8.8125 - acc: 0.0000e+00 - val_loss: 4.8493 - val_acc: 0.0000e+00\n",
            "Epoch 476/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 8.7998 - acc: 0.0000e+00 - val_loss: 4.8360 - val_acc: 0.0000e+00\n",
            "Epoch 477/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 8.7871 - acc: 0.0000e+00 - val_loss: 4.8224 - val_acc: 0.0000e+00\n",
            "Epoch 478/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 8.7742 - acc: 0.0000e+00 - val_loss: 4.8087 - val_acc: 0.0000e+00\n",
            "Epoch 479/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 8.7615 - acc: 0.0000e+00 - val_loss: 4.7948 - val_acc: 0.0000e+00\n",
            "Epoch 480/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 8.7489 - acc: 0.0000e+00 - val_loss: 4.7837 - val_acc: 0.0000e+00\n",
            "Epoch 481/2000\n",
            "80/80 [==============================] - 0s 142us/step - loss: 8.7363 - acc: 0.0000e+00 - val_loss: 4.7752 - val_acc: 0.0000e+00\n",
            "Epoch 482/2000\n",
            "80/80 [==============================] - 0s 141us/step - loss: 8.7233 - acc: 0.0000e+00 - val_loss: 4.7690 - val_acc: 0.0000e+00\n",
            "Epoch 483/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 8.7108 - acc: 0.0000e+00 - val_loss: 4.7616 - val_acc: 0.0000e+00\n",
            "Epoch 484/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 8.6982 - acc: 0.0000e+00 - val_loss: 4.7533 - val_acc: 0.0000e+00\n",
            "Epoch 485/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 8.6857 - acc: 0.0000e+00 - val_loss: 4.7442 - val_acc: 0.0000e+00\n",
            "Epoch 486/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 8.6731 - acc: 0.0000e+00 - val_loss: 4.7345 - val_acc: 0.0000e+00\n",
            "Epoch 487/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 8.6605 - acc: 0.0000e+00 - val_loss: 4.7243 - val_acc: 0.0000e+00\n",
            "Epoch 488/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 8.6479 - acc: 0.0000e+00 - val_loss: 4.7134 - val_acc: 0.0000e+00\n",
            "Epoch 489/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 8.6352 - acc: 0.0000e+00 - val_loss: 4.7008 - val_acc: 0.0000e+00\n",
            "Epoch 490/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 8.6225 - acc: 0.0000e+00 - val_loss: 4.6863 - val_acc: 0.0000e+00\n",
            "Epoch 491/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 8.6097 - acc: 0.0000e+00 - val_loss: 4.6745 - val_acc: 0.0000e+00\n",
            "Epoch 492/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 8.5974 - acc: 0.0000e+00 - val_loss: 4.6641 - val_acc: 0.0000e+00\n",
            "Epoch 493/2000\n",
            "80/80 [==============================] - 0s 130us/step - loss: 8.5851 - acc: 0.0000e+00 - val_loss: 4.6552 - val_acc: 0.0000e+00\n",
            "Epoch 494/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 8.5727 - acc: 0.0000e+00 - val_loss: 4.6475 - val_acc: 0.0000e+00\n",
            "Epoch 495/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 8.5603 - acc: 0.0000e+00 - val_loss: 4.6409 - val_acc: 0.0000e+00\n",
            "Epoch 496/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 8.5481 - acc: 0.0000e+00 - val_loss: 4.6318 - val_acc: 0.0000e+00\n",
            "Epoch 497/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 8.5360 - acc: 0.0000e+00 - val_loss: 4.6202 - val_acc: 0.0000e+00\n",
            "Epoch 498/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 8.5238 - acc: 0.0000e+00 - val_loss: 4.6066 - val_acc: 0.0000e+00\n",
            "Epoch 499/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 8.5117 - acc: 0.0000e+00 - val_loss: 4.5944 - val_acc: 0.0000e+00\n",
            "Epoch 500/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 8.4997 - acc: 0.0000e+00 - val_loss: 4.5833 - val_acc: 0.0000e+00\n",
            "Epoch 501/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 8.4878 - acc: 0.0000e+00 - val_loss: 4.5734 - val_acc: 0.0000e+00\n",
            "Epoch 502/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 8.4759 - acc: 0.0000e+00 - val_loss: 4.5647 - val_acc: 0.0000e+00\n",
            "Epoch 503/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 8.4641 - acc: 0.0000e+00 - val_loss: 4.5572 - val_acc: 0.0000e+00\n",
            "Epoch 504/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 8.4523 - acc: 0.0000e+00 - val_loss: 4.5506 - val_acc: 0.0000e+00\n",
            "Epoch 505/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 8.4405 - acc: 0.0000e+00 - val_loss: 4.5449 - val_acc: 0.0000e+00\n",
            "Epoch 506/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 8.4290 - acc: 0.0000e+00 - val_loss: 4.5363 - val_acc: 0.0000e+00\n",
            "Epoch 507/2000\n",
            "80/80 [==============================] - 0s 236us/step - loss: 8.4174 - acc: 0.0000e+00 - val_loss: 4.5251 - val_acc: 0.0000e+00\n",
            "Epoch 508/2000\n",
            "80/80 [==============================] - 0s 138us/step - loss: 8.4056 - acc: 0.0000e+00 - val_loss: 4.5115 - val_acc: 0.0000e+00\n",
            "Epoch 509/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 8.3943 - acc: 0.0000e+00 - val_loss: 4.4997 - val_acc: 0.0000e+00\n",
            "Epoch 510/2000\n",
            "80/80 [==============================] - 0s 266us/step - loss: 8.3830 - acc: 0.0000e+00 - val_loss: 4.4898 - val_acc: 0.0000e+00\n",
            "Epoch 511/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 8.3717 - acc: 0.0000e+00 - val_loss: 4.4814 - val_acc: 0.0000e+00\n",
            "Epoch 512/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 8.3603 - acc: 0.0000e+00 - val_loss: 4.4747 - val_acc: 0.0000e+00\n",
            "Epoch 513/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 8.3489 - acc: 0.0000e+00 - val_loss: 4.4689 - val_acc: 0.0000e+00\n",
            "Epoch 514/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 8.3376 - acc: 0.0000e+00 - val_loss: 4.4643 - val_acc: 0.0000e+00\n",
            "Epoch 515/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 8.3268 - acc: 0.0000e+00 - val_loss: 4.4567 - val_acc: 0.0000e+00\n",
            "Epoch 516/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 8.3158 - acc: 0.0000e+00 - val_loss: 4.4465 - val_acc: 0.0000e+00\n",
            "Epoch 517/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 8.3045 - acc: 0.0000e+00 - val_loss: 4.4338 - val_acc: 0.0000e+00\n",
            "Epoch 518/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 8.2931 - acc: 0.0000e+00 - val_loss: 4.4225 - val_acc: 0.0000e+00\n",
            "Epoch 519/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 8.2822 - acc: 0.0000e+00 - val_loss: 4.4126 - val_acc: 0.0000e+00\n",
            "Epoch 520/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 8.2714 - acc: 0.0000e+00 - val_loss: 4.4044 - val_acc: 0.0000e+00\n",
            "Epoch 521/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 8.2605 - acc: 0.0000e+00 - val_loss: 4.3978 - val_acc: 0.0000e+00\n",
            "Epoch 522/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 8.2495 - acc: 0.0000e+00 - val_loss: 4.3926 - val_acc: 0.0000e+00\n",
            "Epoch 523/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 8.2385 - acc: 0.0000e+00 - val_loss: 4.3883 - val_acc: 0.0000e+00\n",
            "Epoch 524/2000\n",
            "80/80 [==============================] - 0s 138us/step - loss: 8.2278 - acc: 0.0000e+00 - val_loss: 4.3811 - val_acc: 0.0000e+00\n",
            "Epoch 525/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 8.2171 - acc: 0.0000e+00 - val_loss: 4.3711 - val_acc: 0.0000e+00\n",
            "Epoch 526/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 8.2061 - acc: 0.0000e+00 - val_loss: 4.3626 - val_acc: 0.0000e+00\n",
            "Epoch 527/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 8.1954 - acc: 0.0000e+00 - val_loss: 4.3553 - val_acc: 0.0000e+00\n",
            "Epoch 528/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 8.1847 - acc: 0.0000e+00 - val_loss: 4.3496 - val_acc: 0.0000e+00\n",
            "Epoch 529/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 8.1739 - acc: 0.0000e+00 - val_loss: 4.3453 - val_acc: 0.0000e+00\n",
            "Epoch 530/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 8.1633 - acc: 0.0000e+00 - val_loss: 4.3382 - val_acc: 0.0000e+00\n",
            "Epoch 531/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 8.1526 - acc: 0.0000e+00 - val_loss: 4.3283 - val_acc: 0.0000e+00\n",
            "Epoch 532/2000\n",
            "80/80 [==============================] - 0s 232us/step - loss: 8.1421 - acc: 0.0000e+00 - val_loss: 4.3203 - val_acc: 0.0000e+00\n",
            "Epoch 533/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 8.1316 - acc: 0.0000e+00 - val_loss: 4.3143 - val_acc: 0.0000e+00\n",
            "Epoch 534/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 8.1210 - acc: 0.0000e+00 - val_loss: 4.3101 - val_acc: 0.0000e+00\n",
            "Epoch 535/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 8.1102 - acc: 0.0000e+00 - val_loss: 4.3034 - val_acc: 0.0000e+00\n",
            "Epoch 536/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 8.0997 - acc: 0.0000e+00 - val_loss: 4.2945 - val_acc: 0.0000e+00\n",
            "Epoch 537/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 8.0892 - acc: 0.0000e+00 - val_loss: 4.2876 - val_acc: 0.0000e+00\n",
            "Epoch 538/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 8.0787 - acc: 0.0000e+00 - val_loss: 4.2825 - val_acc: 0.0000e+00\n",
            "Epoch 539/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 8.0682 - acc: 0.0000e+00 - val_loss: 4.2745 - val_acc: 0.0000e+00\n",
            "Epoch 540/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 8.0577 - acc: 0.0000e+00 - val_loss: 4.2685 - val_acc: 0.0000e+00\n",
            "Epoch 541/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 4.2648 - val_acc: 0.0000e+00\n",
            "Epoch 542/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 8.0367 - acc: 0.0000e+00 - val_loss: 4.2573 - val_acc: 0.0000e+00\n",
            "Epoch 543/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 8.0262 - acc: 0.0000e+00 - val_loss: 4.2523 - val_acc: 0.0000e+00\n",
            "Epoch 544/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 8.0158 - acc: 0.0000e+00 - val_loss: 4.2495 - val_acc: 0.0000e+00\n",
            "Epoch 545/2000\n",
            "80/80 [==============================] - 0s 133us/step - loss: 8.0052 - acc: 0.0000e+00 - val_loss: 4.2487 - val_acc: 0.0000e+00\n",
            "Epoch 546/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 7.9950 - acc: 0.0000e+00 - val_loss: 4.2439 - val_acc: 0.0000e+00\n",
            "Epoch 547/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 7.9845 - acc: 0.0000e+00 - val_loss: 4.2355 - val_acc: 0.0000e+00\n",
            "Epoch 548/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 7.9740 - acc: 0.0000e+00 - val_loss: 4.2297 - val_acc: 0.0000e+00\n",
            "Epoch 549/2000\n",
            "80/80 [==============================] - 0s 127us/step - loss: 7.9636 - acc: 0.0000e+00 - val_loss: 4.2261 - val_acc: 0.0000e+00\n",
            "Epoch 550/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 7.9531 - acc: 0.0000e+00 - val_loss: 4.2245 - val_acc: 0.0000e+00\n",
            "Epoch 551/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 7.9427 - acc: 0.0000e+00 - val_loss: 4.2194 - val_acc: 0.0000e+00\n",
            "Epoch 552/2000\n",
            "80/80 [==============================] - 0s 131us/step - loss: 7.9322 - acc: 0.0000e+00 - val_loss: 4.2109 - val_acc: 0.0000e+00\n",
            "Epoch 553/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 7.9219 - acc: 0.0000e+00 - val_loss: 4.2049 - val_acc: 0.0000e+00\n",
            "Epoch 554/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 7.9115 - acc: 0.0000e+00 - val_loss: 4.2010 - val_acc: 0.0000e+00\n",
            "Epoch 555/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 7.9010 - acc: 0.0000e+00 - val_loss: 4.1990 - val_acc: 0.0000e+00\n",
            "Epoch 556/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 7.8904 - acc: 0.0000e+00 - val_loss: 4.1988 - val_acc: 0.0000e+00\n",
            "Epoch 557/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 7.8806 - acc: 0.0000e+00 - val_loss: 4.1911 - val_acc: 0.0000e+00\n",
            "Epoch 558/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 7.8703 - acc: 0.0000e+00 - val_loss: 4.1769 - val_acc: 0.0000e+00\n",
            "Epoch 559/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 7.8598 - acc: 0.0000e+00 - val_loss: 4.1627 - val_acc: 0.0000e+00\n",
            "Epoch 560/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 7.8497 - acc: 0.0000e+00 - val_loss: 4.1484 - val_acc: 0.0000e+00\n",
            "Epoch 561/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 7.8397 - acc: 0.0000e+00 - val_loss: 4.1372 - val_acc: 0.0000e+00\n",
            "Epoch 562/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 7.8296 - acc: 0.0000e+00 - val_loss: 4.1295 - val_acc: 0.0000e+00\n",
            "Epoch 563/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 7.8195 - acc: 0.0000e+00 - val_loss: 4.1215 - val_acc: 0.0000e+00\n",
            "Epoch 564/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 7.8094 - acc: 0.0000e+00 - val_loss: 4.1129 - val_acc: 0.0000e+00\n",
            "Epoch 565/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 7.7994 - acc: 0.0000e+00 - val_loss: 4.1037 - val_acc: 0.0000e+00\n",
            "Epoch 566/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 7.7893 - acc: 0.0000e+00 - val_loss: 4.0937 - val_acc: 0.0000e+00\n",
            "Epoch 567/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 7.7793 - acc: 0.0000e+00 - val_loss: 4.0828 - val_acc: 0.0000e+00\n",
            "Epoch 568/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 7.7692 - acc: 0.0000e+00 - val_loss: 4.0712 - val_acc: 0.0000e+00\n",
            "Epoch 569/2000\n",
            "80/80 [==============================] - 0s 135us/step - loss: 7.7593 - acc: 0.0000e+00 - val_loss: 4.0661 - val_acc: 0.0000e+00\n",
            "Epoch 570/2000\n",
            "80/80 [==============================] - 0s 135us/step - loss: 7.7493 - acc: 0.0000e+00 - val_loss: 4.0643 - val_acc: 0.0000e+00\n",
            "Epoch 571/2000\n",
            "80/80 [==============================] - 0s 128us/step - loss: 7.7396 - acc: 0.0000e+00 - val_loss: 4.0613 - val_acc: 0.0000e+00\n",
            "Epoch 572/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 7.7299 - acc: 0.0000e+00 - val_loss: 4.0571 - val_acc: 0.0000e+00\n",
            "Epoch 573/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 7.7201 - acc: 0.0000e+00 - val_loss: 4.0520 - val_acc: 0.0000e+00\n",
            "Epoch 574/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 7.7103 - acc: 0.0000e+00 - val_loss: 4.0460 - val_acc: 0.0000e+00\n",
            "Epoch 575/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 7.7004 - acc: 0.0000e+00 - val_loss: 4.0392 - val_acc: 0.0000e+00\n",
            "Epoch 576/2000\n",
            "80/80 [==============================] - 0s 279us/step - loss: 7.6905 - acc: 0.0000e+00 - val_loss: 4.0315 - val_acc: 0.0000e+00\n",
            "Epoch 577/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 7.6805 - acc: 0.0000e+00 - val_loss: 4.0231 - val_acc: 0.0000e+00\n",
            "Epoch 578/2000\n",
            "80/80 [==============================] - 0s 275us/step - loss: 7.6714 - acc: 0.0000e+00 - val_loss: 4.0185 - val_acc: 0.0000e+00\n",
            "Epoch 579/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 7.6616 - acc: 0.0000e+00 - val_loss: 4.0175 - val_acc: 0.0000e+00\n",
            "Epoch 580/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 7.6513 - acc: 0.0000e+00 - val_loss: 4.0196 - val_acc: 0.0000e+00\n",
            "Epoch 581/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 7.6418 - acc: 0.0000e+00 - val_loss: 4.0199 - val_acc: 0.0000e+00\n",
            "Epoch 582/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 7.6323 - acc: 0.0000e+00 - val_loss: 4.0188 - val_acc: 0.0000e+00\n",
            "Epoch 583/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 7.6228 - acc: 0.0000e+00 - val_loss: 4.0164 - val_acc: 0.0000e+00\n",
            "Epoch 584/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 7.6136 - acc: 0.0000e+00 - val_loss: 4.0105 - val_acc: 0.0000e+00\n",
            "Epoch 585/2000\n",
            "80/80 [==============================] - 0s 124us/step - loss: 7.6041 - acc: 0.0000e+00 - val_loss: 4.0014 - val_acc: 0.0000e+00\n",
            "Epoch 586/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 7.5942 - acc: 0.0000e+00 - val_loss: 3.9892 - val_acc: 0.0000e+00\n",
            "Epoch 587/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 7.5840 - acc: 0.0000e+00 - val_loss: 3.9739 - val_acc: 0.0000e+00\n",
            "Epoch 588/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 7.5746 - acc: 0.0000e+00 - val_loss: 3.9629 - val_acc: 0.0000e+00\n",
            "Epoch 589/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 7.5657 - acc: 0.0000e+00 - val_loss: 3.9560 - val_acc: 0.0000e+00\n",
            "Epoch 590/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 7.5562 - acc: 0.0000e+00 - val_loss: 3.9529 - val_acc: 0.0000e+00\n",
            "Epoch 591/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 7.5462 - acc: 0.0000e+00 - val_loss: 3.9507 - val_acc: 0.0000e+00\n",
            "Epoch 592/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 7.5365 - acc: 0.0000e+00 - val_loss: 3.9490 - val_acc: 0.0000e+00\n",
            "Epoch 593/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 7.5277 - acc: 0.0000e+00 - val_loss: 3.9432 - val_acc: 0.0000e+00\n",
            "Epoch 594/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 7.5186 - acc: 0.0000e+00 - val_loss: 3.9340 - val_acc: 0.0000e+00\n",
            "Epoch 595/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 7.5091 - acc: 0.0000e+00 - val_loss: 3.9218 - val_acc: 0.0000e+00\n",
            "Epoch 596/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 7.4995 - acc: 0.0000e+00 - val_loss: 3.9112 - val_acc: 0.0000e+00\n",
            "Epoch 597/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 7.4904 - acc: 0.0000e+00 - val_loss: 3.9023 - val_acc: 0.0000e+00\n",
            "Epoch 598/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 7.4814 - acc: 0.0000e+00 - val_loss: 3.8947 - val_acc: 0.0000e+00\n",
            "Epoch 599/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 7.4723 - acc: 0.0000e+00 - val_loss: 3.8885 - val_acc: 0.0000e+00\n",
            "Epoch 600/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 7.4631 - acc: 0.0000e+00 - val_loss: 3.8835 - val_acc: 0.0000e+00\n",
            "Epoch 601/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 7.4539 - acc: 0.0000e+00 - val_loss: 3.8796 - val_acc: 0.0000e+00\n",
            "Epoch 602/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 7.4447 - acc: 0.0000e+00 - val_loss: 3.8767 - val_acc: 0.0000e+00\n",
            "Epoch 603/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 7.4356 - acc: 0.0000e+00 - val_loss: 3.8700 - val_acc: 0.0000e+00\n",
            "Epoch 604/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 7.4265 - acc: 0.0000e+00 - val_loss: 3.8597 - val_acc: 0.0000e+00\n",
            "Epoch 605/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 7.4176 - acc: 0.0000e+00 - val_loss: 3.8511 - val_acc: 0.0000e+00\n",
            "Epoch 606/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 7.4086 - acc: 0.0000e+00 - val_loss: 3.8441 - val_acc: 0.0000e+00\n",
            "Epoch 607/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 7.3997 - acc: 0.0000e+00 - val_loss: 3.8388 - val_acc: 0.0000e+00\n",
            "Epoch 608/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 7.3907 - acc: 0.0000e+00 - val_loss: 3.8350 - val_acc: 0.0000e+00\n",
            "Epoch 609/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 7.3816 - acc: 0.0000e+00 - val_loss: 3.8328 - val_acc: 0.0000e+00\n",
            "Epoch 610/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 7.3725 - acc: 0.0000e+00 - val_loss: 3.8319 - val_acc: 0.0000e+00\n",
            "Epoch 611/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 7.3635 - acc: 0.0000e+00 - val_loss: 3.8272 - val_acc: 0.0000e+00\n",
            "Epoch 612/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 7.3545 - acc: 0.0000e+00 - val_loss: 3.8191 - val_acc: 0.0000e+00\n",
            "Epoch 613/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 7.3455 - acc: 0.0000e+00 - val_loss: 3.8131 - val_acc: 0.0000e+00\n",
            "Epoch 614/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 7.3366 - acc: 0.0000e+00 - val_loss: 3.8091 - val_acc: 0.0000e+00\n",
            "Epoch 615/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 7.3277 - acc: 0.0000e+00 - val_loss: 3.8069 - val_acc: 0.0000e+00\n",
            "Epoch 616/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 7.3186 - acc: 0.0000e+00 - val_loss: 3.8064 - val_acc: 0.0000e+00\n",
            "Epoch 617/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 7.3098 - acc: 0.0000e+00 - val_loss: 3.8022 - val_acc: 0.0000e+00\n",
            "Epoch 618/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 7.3008 - acc: 0.0000e+00 - val_loss: 3.7947 - val_acc: 0.0000e+00\n",
            "Epoch 619/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 7.2918 - acc: 0.0000e+00 - val_loss: 3.7860 - val_acc: 0.0000e+00\n",
            "Epoch 620/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 7.2832 - acc: 0.0000e+00 - val_loss: 3.7797 - val_acc: 0.0000e+00\n",
            "Epoch 621/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 7.2745 - acc: 0.0000e+00 - val_loss: 3.7722 - val_acc: 0.0000e+00\n",
            "Epoch 622/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 7.2657 - acc: 0.0000e+00 - val_loss: 3.7636 - val_acc: 0.0000e+00\n",
            "Epoch 623/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 7.2568 - acc: 0.0000e+00 - val_loss: 3.7540 - val_acc: 0.0000e+00\n",
            "Epoch 624/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 7.2480 - acc: 0.0000e+00 - val_loss: 3.7467 - val_acc: 0.0000e+00\n",
            "Epoch 625/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 7.2392 - acc: 0.0000e+00 - val_loss: 3.7381 - val_acc: 0.0000e+00\n",
            "Epoch 626/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 7.2305 - acc: 0.0000e+00 - val_loss: 3.7320 - val_acc: 0.0000e+00\n",
            "Epoch 627/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 7.2219 - acc: 0.0000e+00 - val_loss: 3.7246 - val_acc: 0.0000e+00\n",
            "Epoch 628/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 7.2132 - acc: 0.0000e+00 - val_loss: 3.7162 - val_acc: 0.0000e+00\n",
            "Epoch 629/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 7.2046 - acc: 0.0000e+00 - val_loss: 3.7071 - val_acc: 0.0000e+00\n",
            "Epoch 630/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 7.1960 - acc: 0.0000e+00 - val_loss: 3.6973 - val_acc: 0.0000e+00\n",
            "Epoch 631/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 7.1875 - acc: 0.0000e+00 - val_loss: 3.6965 - val_acc: 0.0000e+00\n",
            "Epoch 632/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 7.1789 - acc: 0.0000e+00 - val_loss: 3.6942 - val_acc: 0.0000e+00\n",
            "Epoch 633/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 7.1705 - acc: 0.0000e+00 - val_loss: 3.6905 - val_acc: 0.0000e+00\n",
            "Epoch 634/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 7.1620 - acc: 0.0000e+00 - val_loss: 3.6857 - val_acc: 0.0000e+00\n",
            "Epoch 635/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 7.1535 - acc: 0.0000e+00 - val_loss: 3.6798 - val_acc: 0.0000e+00\n",
            "Epoch 636/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 7.1450 - acc: 0.0000e+00 - val_loss: 3.6731 - val_acc: 0.0000e+00\n",
            "Epoch 637/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 7.1365 - acc: 0.0000e+00 - val_loss: 3.6655 - val_acc: 0.0000e+00\n",
            "Epoch 638/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 7.1279 - acc: 0.0000e+00 - val_loss: 3.6572 - val_acc: 0.0000e+00\n",
            "Epoch 639/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 7.1194 - acc: 0.0000e+00 - val_loss: 3.6485 - val_acc: 0.0000e+00\n",
            "Epoch 640/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 7.1110 - acc: 0.0000e+00 - val_loss: 3.6393 - val_acc: 0.0000e+00\n",
            "Epoch 641/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 7.1025 - acc: 0.0000e+00 - val_loss: 3.6299 - val_acc: 0.0000e+00\n",
            "Epoch 642/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 7.0940 - acc: 0.0000e+00 - val_loss: 3.6203 - val_acc: 0.0000e+00\n",
            "Epoch 643/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 7.0860 - acc: 0.0000e+00 - val_loss: 3.6171 - val_acc: 0.0000e+00\n",
            "Epoch 644/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 7.0773 - acc: 0.0000e+00 - val_loss: 3.6201 - val_acc: 0.0000e+00\n",
            "Epoch 645/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 7.0690 - acc: 0.0000e+00 - val_loss: 3.6221 - val_acc: 0.0000e+00\n",
            "Epoch 646/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 7.0607 - acc: 0.0000e+00 - val_loss: 3.6230 - val_acc: 0.0000e+00\n",
            "Epoch 647/2000\n",
            "80/80 [==============================] - 0s 223us/step - loss: 7.0525 - acc: 0.0000e+00 - val_loss: 3.6165 - val_acc: 0.0000e+00\n",
            "Epoch 648/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 7.0440 - acc: 0.0000e+00 - val_loss: 3.6097 - val_acc: 0.0000e+00\n",
            "Epoch 649/2000\n",
            "80/80 [==============================] - 0s 227us/step - loss: 7.0357 - acc: 0.0000e+00 - val_loss: 3.6028 - val_acc: 0.0000e+00\n",
            "Epoch 650/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 7.0273 - acc: 0.0000e+00 - val_loss: 3.5957 - val_acc: 0.0000e+00\n",
            "Epoch 651/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 7.0189 - acc: 0.0000e+00 - val_loss: 3.5883 - val_acc: 0.0000e+00\n",
            "Epoch 652/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 7.0105 - acc: 0.0000e+00 - val_loss: 3.5808 - val_acc: 0.0000e+00\n",
            "Epoch 653/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 7.0021 - acc: 0.0000e+00 - val_loss: 3.5733 - val_acc: 0.0000e+00\n",
            "Epoch 654/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 6.9937 - acc: 0.0000e+00 - val_loss: 3.5655 - val_acc: 0.0000e+00\n",
            "Epoch 655/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 6.9856 - acc: 0.0000e+00 - val_loss: 3.5641 - val_acc: 0.0000e+00\n",
            "Epoch 656/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 6.9771 - acc: 0.0000e+00 - val_loss: 3.5619 - val_acc: 0.0000e+00\n",
            "Epoch 657/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 6.9689 - acc: 0.0000e+00 - val_loss: 3.5588 - val_acc: 0.0000e+00\n",
            "Epoch 658/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 6.9610 - acc: 0.0000e+00 - val_loss: 3.5509 - val_acc: 0.0000e+00\n",
            "Epoch 659/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 6.9529 - acc: 0.0000e+00 - val_loss: 3.5454 - val_acc: 0.0000e+00\n",
            "Epoch 660/2000\n",
            "80/80 [==============================] - 0s 141us/step - loss: 6.9450 - acc: 0.0000e+00 - val_loss: 3.5419 - val_acc: 0.0000e+00\n",
            "Epoch 661/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 6.9372 - acc: 0.0000e+00 - val_loss: 3.5337 - val_acc: 0.0000e+00\n",
            "Epoch 662/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 6.9292 - acc: 0.0000e+00 - val_loss: 3.5279 - val_acc: 0.0000e+00\n",
            "Epoch 663/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 6.9212 - acc: 0.0000e+00 - val_loss: 3.5176 - val_acc: 0.0000e+00\n",
            "Epoch 664/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 6.9134 - acc: 0.0000e+00 - val_loss: 3.5100 - val_acc: 0.0000e+00\n",
            "Epoch 665/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 6.9055 - acc: 0.0000e+00 - val_loss: 3.5056 - val_acc: 0.0000e+00\n",
            "Epoch 666/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 6.8975 - acc: 0.0000e+00 - val_loss: 3.4966 - val_acc: 0.0000e+00\n",
            "Epoch 667/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 6.8897 - acc: 0.0000e+00 - val_loss: 3.4909 - val_acc: 0.0000e+00\n",
            "Epoch 668/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 6.8818 - acc: 0.0000e+00 - val_loss: 3.4807 - val_acc: 0.0000e+00\n",
            "Epoch 669/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 6.8741 - acc: 0.0000e+00 - val_loss: 3.4793 - val_acc: 0.0000e+00\n",
            "Epoch 670/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 6.8664 - acc: 0.0000e+00 - val_loss: 3.4734 - val_acc: 0.0000e+00\n",
            "Epoch 671/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 6.8588 - acc: 0.0000e+00 - val_loss: 3.4637 - val_acc: 0.0000e+00\n",
            "Epoch 672/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 6.8510 - acc: 0.0000e+00 - val_loss: 3.4556 - val_acc: 0.0000e+00\n",
            "Epoch 673/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 6.8435 - acc: 0.0000e+00 - val_loss: 3.4567 - val_acc: 0.0000e+00\n",
            "Epoch 674/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 6.8360 - acc: 0.0000e+00 - val_loss: 3.4534 - val_acc: 0.0000e+00\n",
            "Epoch 675/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 6.8285 - acc: 0.0000e+00 - val_loss: 3.4463 - val_acc: 0.0000e+00\n",
            "Epoch 676/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 6.8208 - acc: 0.0000e+00 - val_loss: 3.4356 - val_acc: 0.0000e+00\n",
            "Epoch 677/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 6.8129 - acc: 0.0000e+00 - val_loss: 3.4293 - val_acc: 0.0000e+00\n",
            "Epoch 678/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 6.8055 - acc: 0.0000e+00 - val_loss: 3.4268 - val_acc: 0.0000e+00\n",
            "Epoch 679/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 6.7978 - acc: 0.0000e+00 - val_loss: 3.4203 - val_acc: 0.0000e+00\n",
            "Epoch 680/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 6.7902 - acc: 0.0000e+00 - val_loss: 3.4178 - val_acc: 0.0000e+00\n",
            "Epoch 681/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 6.7828 - acc: 0.0000e+00 - val_loss: 3.4112 - val_acc: 0.0000e+00\n",
            "Epoch 682/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 6.7752 - acc: 0.0000e+00 - val_loss: 3.4013 - val_acc: 0.0000e+00\n",
            "Epoch 683/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 6.7679 - acc: 0.0000e+00 - val_loss: 3.3961 - val_acc: 0.0000e+00\n",
            "Epoch 684/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 6.7605 - acc: 0.0000e+00 - val_loss: 3.3951 - val_acc: 0.0000e+00\n",
            "Epoch 685/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 6.7527 - acc: 0.0000e+00 - val_loss: 3.3905 - val_acc: 0.0000e+00\n",
            "Epoch 686/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 6.7453 - acc: 0.0000e+00 - val_loss: 3.3824 - val_acc: 0.0000e+00\n",
            "Epoch 687/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 6.7380 - acc: 0.0000e+00 - val_loss: 3.3792 - val_acc: 0.0000e+00\n",
            "Epoch 688/2000\n",
            "80/80 [==============================] - 0s 131us/step - loss: 6.7304 - acc: 0.0000e+00 - val_loss: 3.3801 - val_acc: 0.0000e+00\n",
            "Epoch 689/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 6.7233 - acc: 0.0000e+00 - val_loss: 3.3761 - val_acc: 0.0000e+00\n",
            "Epoch 690/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 6.7158 - acc: 0.0000e+00 - val_loss: 3.3674 - val_acc: 0.0000e+00\n",
            "Epoch 691/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 6.7081 - acc: 0.0000e+00 - val_loss: 3.3634 - val_acc: 0.0000e+00\n",
            "Epoch 692/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 6.7006 - acc: 0.0000e+00 - val_loss: 3.3637 - val_acc: 0.0000e+00\n",
            "Epoch 693/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 6.6933 - acc: 0.0000e+00 - val_loss: 3.3600 - val_acc: 0.0000e+00\n",
            "Epoch 694/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 6.6859 - acc: 0.0000e+00 - val_loss: 3.3528 - val_acc: 0.0000e+00\n",
            "Epoch 695/2000\n",
            "80/80 [==============================] - 0s 127us/step - loss: 6.6784 - acc: 0.0000e+00 - val_loss: 3.3450 - val_acc: 0.0000e+00\n",
            "Epoch 696/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 6.6712 - acc: 0.0000e+00 - val_loss: 3.3415 - val_acc: 0.0000e+00\n",
            "Epoch 697/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 6.6640 - acc: 0.0000e+00 - val_loss: 3.3371 - val_acc: 0.0000e+00\n",
            "Epoch 698/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 6.6567 - acc: 0.0000e+00 - val_loss: 3.3317 - val_acc: 0.0000e+00\n",
            "Epoch 699/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 6.6493 - acc: 0.0000e+00 - val_loss: 3.3254 - val_acc: 0.0000e+00\n",
            "Epoch 700/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 6.6419 - acc: 0.0000e+00 - val_loss: 3.3185 - val_acc: 0.0000e+00\n",
            "Epoch 701/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 6.6344 - acc: 0.0000e+00 - val_loss: 3.3113 - val_acc: 0.0000e+00\n",
            "Epoch 702/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 6.6271 - acc: 0.0000e+00 - val_loss: 3.3091 - val_acc: 0.0000e+00\n",
            "Epoch 703/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 6.6205 - acc: 0.0000e+00 - val_loss: 3.2975 - val_acc: 0.0000e+00\n",
            "Epoch 704/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 6.6130 - acc: 0.0000e+00 - val_loss: 3.2900 - val_acc: 0.0000e+00\n",
            "Epoch 705/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 6.6060 - acc: 0.0000e+00 - val_loss: 3.2865 - val_acc: 0.0000e+00\n",
            "Epoch 706/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 6.5986 - acc: 0.0000e+00 - val_loss: 3.2867 - val_acc: 0.0000e+00\n",
            "Epoch 707/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 6.5912 - acc: 0.0000e+00 - val_loss: 3.2774 - val_acc: 0.0000e+00\n",
            "Epoch 708/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 6.5840 - acc: 0.0000e+00 - val_loss: 3.2737 - val_acc: 0.0000e+00\n",
            "Epoch 709/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 6.5768 - acc: 0.0000e+00 - val_loss: 3.2698 - val_acc: 0.0000e+00\n",
            "Epoch 710/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 6.5697 - acc: 0.0000e+00 - val_loss: 3.2659 - val_acc: 0.0000e+00\n",
            "Epoch 711/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 6.5626 - acc: 0.0000e+00 - val_loss: 3.2619 - val_acc: 0.0000e+00\n",
            "Epoch 712/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 6.5555 - acc: 0.0000e+00 - val_loss: 3.2581 - val_acc: 0.0000e+00\n",
            "Epoch 713/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 6.5484 - acc: 0.0000e+00 - val_loss: 3.2544 - val_acc: 0.0000e+00\n",
            "Epoch 714/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 6.5413 - acc: 0.0000e+00 - val_loss: 3.2434 - val_acc: 0.0000e+00\n",
            "Epoch 715/2000\n",
            "80/80 [==============================] - 0s 132us/step - loss: 6.5342 - acc: 0.0000e+00 - val_loss: 3.2333 - val_acc: 0.0000e+00\n",
            "Epoch 716/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 6.5272 - acc: 0.0000e+00 - val_loss: 3.2294 - val_acc: 0.0000e+00\n",
            "Epoch 717/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 6.5201 - acc: 0.0000e+00 - val_loss: 3.2258 - val_acc: 0.0000e+00\n",
            "Epoch 718/2000\n",
            "80/80 [==============================] - 0s 133us/step - loss: 6.5129 - acc: 0.0000e+00 - val_loss: 3.2223 - val_acc: 0.0000e+00\n",
            "Epoch 719/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 6.5058 - acc: 0.0000e+00 - val_loss: 3.2188 - val_acc: 0.0000e+00\n",
            "Epoch 720/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 6.4987 - acc: 0.0000e+00 - val_loss: 3.2143 - val_acc: 0.0000e+00\n",
            "Epoch 721/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 6.4918 - acc: 0.0000e+00 - val_loss: 3.2088 - val_acc: 0.0000e+00\n",
            "Epoch 722/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 6.4848 - acc: 0.0000e+00 - val_loss: 3.2028 - val_acc: 0.0000e+00\n",
            "Epoch 723/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 6.4777 - acc: 0.0000e+00 - val_loss: 3.1962 - val_acc: 0.0000e+00\n",
            "Epoch 724/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 6.4708 - acc: 0.0000e+00 - val_loss: 3.1904 - val_acc: 0.0000e+00\n",
            "Epoch 725/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 6.4638 - acc: 0.0000e+00 - val_loss: 3.1855 - val_acc: 0.0000e+00\n",
            "Epoch 726/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 6.4569 - acc: 0.0000e+00 - val_loss: 3.1812 - val_acc: 0.0000e+00\n",
            "Epoch 727/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 6.4499 - acc: 0.0000e+00 - val_loss: 3.1779 - val_acc: 0.0000e+00\n",
            "Epoch 728/2000\n",
            "80/80 [==============================] - 0s 250us/step - loss: 6.4429 - acc: 0.0000e+00 - val_loss: 3.1754 - val_acc: 0.0000e+00\n",
            "Epoch 729/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 6.4359 - acc: 0.0000e+00 - val_loss: 3.1738 - val_acc: 0.0000e+00\n",
            "Epoch 730/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 6.4289 - acc: 0.0000e+00 - val_loss: 3.1715 - val_acc: 0.0000e+00\n",
            "Epoch 731/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 6.4223 - acc: 0.0000e+00 - val_loss: 3.1608 - val_acc: 0.0000e+00\n",
            "Epoch 732/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 6.4151 - acc: 0.0000e+00 - val_loss: 3.1519 - val_acc: 0.0000e+00\n",
            "Epoch 733/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 6.4083 - acc: 0.0000e+00 - val_loss: 3.1445 - val_acc: 0.0000e+00\n",
            "Epoch 734/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 6.4015 - acc: 0.0000e+00 - val_loss: 3.1384 - val_acc: 0.0000e+00\n",
            "Epoch 735/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 6.3946 - acc: 0.0000e+00 - val_loss: 3.1334 - val_acc: 0.0000e+00\n",
            "Epoch 736/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 6.3876 - acc: 0.0000e+00 - val_loss: 3.1296 - val_acc: 0.0000e+00\n",
            "Epoch 737/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 6.3807 - acc: 0.0000e+00 - val_loss: 3.1266 - val_acc: 0.0000e+00\n",
            "Epoch 738/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 6.3737 - acc: 0.0000e+00 - val_loss: 3.1246 - val_acc: 0.0000e+00\n",
            "Epoch 739/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 6.3667 - acc: 0.0000e+00 - val_loss: 3.1234 - val_acc: 0.0000e+00\n",
            "Epoch 740/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 6.3597 - acc: 0.0000e+00 - val_loss: 3.1229 - val_acc: 0.0000e+00\n",
            "Epoch 741/2000\n",
            "80/80 [==============================] - 0s 194us/step - loss: 6.3528 - acc: 0.0000e+00 - val_loss: 3.1177 - val_acc: 0.0000e+00\n",
            "Epoch 742/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 6.3460 - acc: 0.0000e+00 - val_loss: 3.1083 - val_acc: 0.0000e+00\n",
            "Epoch 743/2000\n",
            "80/80 [==============================] - 0s 134us/step - loss: 6.3389 - acc: 0.0000e+00 - val_loss: 3.0991 - val_acc: 0.0000e+00\n",
            "Epoch 744/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 6.3321 - acc: 0.0000e+00 - val_loss: 3.0900 - val_acc: 0.0000e+00\n",
            "Epoch 745/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 6.3252 - acc: 0.0000e+00 - val_loss: 3.0829 - val_acc: 0.0000e+00\n",
            "Epoch 746/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 6.3184 - acc: 0.0000e+00 - val_loss: 3.0774 - val_acc: 0.0000e+00\n",
            "Epoch 747/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 6.3115 - acc: 0.0000e+00 - val_loss: 3.0733 - val_acc: 0.0000e+00\n",
            "Epoch 748/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 6.3046 - acc: 0.0000e+00 - val_loss: 3.0706 - val_acc: 0.0000e+00\n",
            "Epoch 749/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 6.2978 - acc: 0.0000e+00 - val_loss: 3.0618 - val_acc: 0.0000e+00\n",
            "Epoch 750/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 6.2909 - acc: 0.0000e+00 - val_loss: 3.0547 - val_acc: 0.0000e+00\n",
            "Epoch 751/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 6.2844 - acc: 0.0000e+00 - val_loss: 3.0580 - val_acc: 0.0000e+00\n",
            "Epoch 752/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 6.2779 - acc: 0.0000e+00 - val_loss: 3.0545 - val_acc: 0.0000e+00\n",
            "Epoch 753/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 6.2713 - acc: 0.0000e+00 - val_loss: 3.0451 - val_acc: 0.0000e+00\n",
            "Epoch 754/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 6.2640 - acc: 0.0000e+00 - val_loss: 3.0304 - val_acc: 0.0000e+00\n",
            "Epoch 755/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 6.2579 - acc: 0.0000e+00 - val_loss: 3.0267 - val_acc: 0.0000e+00\n",
            "Epoch 756/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 6.2510 - acc: 0.0000e+00 - val_loss: 3.0327 - val_acc: 0.0000e+00\n",
            "Epoch 757/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 6.2439 - acc: 0.0000e+00 - val_loss: 3.0319 - val_acc: 0.0000e+00\n",
            "Epoch 758/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 6.2375 - acc: 0.0000e+00 - val_loss: 3.0254 - val_acc: 0.0000e+00\n",
            "Epoch 759/2000\n",
            "80/80 [==============================] - 0s 210us/step - loss: 6.2306 - acc: 0.0000e+00 - val_loss: 3.0152 - val_acc: 0.0000e+00\n",
            "Epoch 760/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 6.2235 - acc: 0.0000e+00 - val_loss: 3.0100 - val_acc: 0.0000e+00\n",
            "Epoch 761/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 6.2167 - acc: 0.0000e+00 - val_loss: 3.0095 - val_acc: 0.0000e+00\n",
            "Epoch 762/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 6.2104 - acc: 0.0000e+00 - val_loss: 3.0036 - val_acc: 0.0000e+00\n",
            "Epoch 763/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 6.2037 - acc: 0.0000e+00 - val_loss: 2.9931 - val_acc: 0.0000e+00\n",
            "Epoch 764/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 6.1968 - acc: 0.0000e+00 - val_loss: 2.9923 - val_acc: 0.0000e+00\n",
            "Epoch 765/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 6.1902 - acc: 0.0000e+00 - val_loss: 2.9864 - val_acc: 0.0000e+00\n",
            "Epoch 766/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 6.1834 - acc: 0.0000e+00 - val_loss: 2.9761 - val_acc: 0.0000e+00\n",
            "Epoch 767/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 6.1775 - acc: 0.0000e+00 - val_loss: 2.9771 - val_acc: 0.0000e+00\n",
            "Epoch 768/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 6.1703 - acc: 0.0000e+00 - val_loss: 2.9827 - val_acc: 0.0000e+00\n",
            "Epoch 769/2000\n",
            "80/80 [==============================] - 0s 142us/step - loss: 6.1641 - acc: 0.0000e+00 - val_loss: 2.9830 - val_acc: 0.0000e+00\n",
            "Epoch 770/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 6.1578 - acc: 0.0000e+00 - val_loss: 2.9786 - val_acc: 0.0000e+00\n",
            "Epoch 771/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 6.1512 - acc: 0.0000e+00 - val_loss: 2.9715 - val_acc: 0.0000e+00\n",
            "Epoch 772/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 6.1446 - acc: 0.0000e+00 - val_loss: 2.9620 - val_acc: 0.0000e+00\n",
            "Epoch 773/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 6.1378 - acc: 0.0000e+00 - val_loss: 2.9501 - val_acc: 0.0000e+00\n",
            "Epoch 774/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 6.1313 - acc: 0.0000e+00 - val_loss: 2.9441 - val_acc: 0.0000e+00\n",
            "Epoch 775/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 6.1248 - acc: 0.0000e+00 - val_loss: 2.9435 - val_acc: 0.0000e+00\n",
            "Epoch 776/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 6.1178 - acc: 0.0000e+00 - val_loss: 2.9397 - val_acc: 0.0000e+00\n",
            "Epoch 777/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 6.1112 - acc: 0.0000e+00 - val_loss: 2.9332 - val_acc: 0.0000e+00\n",
            "Epoch 778/2000\n",
            "80/80 [==============================] - 0s 122us/step - loss: 6.1045 - acc: 0.0000e+00 - val_loss: 2.9225 - val_acc: 0.0000e+00\n",
            "Epoch 779/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 6.0983 - acc: 0.0000e+00 - val_loss: 2.9180 - val_acc: 0.0000e+00\n",
            "Epoch 780/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 6.0917 - acc: 0.0000e+00 - val_loss: 2.9174 - val_acc: 0.0000e+00\n",
            "Epoch 781/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 6.0850 - acc: 0.0000e+00 - val_loss: 2.9122 - val_acc: 0.0000e+00\n",
            "Epoch 782/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 6.0785 - acc: 0.0000e+00 - val_loss: 2.9110 - val_acc: 0.0000e+00\n",
            "Epoch 783/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 6.0721 - acc: 0.0000e+00 - val_loss: 2.9052 - val_acc: 0.0000e+00\n",
            "Epoch 784/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 6.0653 - acc: 0.0000e+00 - val_loss: 2.8953 - val_acc: 0.0000e+00\n",
            "Epoch 785/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 6.0591 - acc: 0.0000e+00 - val_loss: 2.8914 - val_acc: 0.0000e+00\n",
            "Epoch 786/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 6.0526 - acc: 0.0000e+00 - val_loss: 2.8928 - val_acc: 0.0000e+00\n",
            "Epoch 787/2000\n",
            "80/80 [==============================] - 0s 137us/step - loss: 6.0455 - acc: 0.0000e+00 - val_loss: 2.8909 - val_acc: 0.0000e+00\n",
            "Epoch 788/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 6.0391 - acc: 0.0000e+00 - val_loss: 2.8844 - val_acc: 0.0000e+00\n",
            "Epoch 789/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 6.0324 - acc: 0.0000e+00 - val_loss: 2.8752 - val_acc: 0.0000e+00\n",
            "Epoch 790/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 6.0263 - acc: 0.0000e+00 - val_loss: 2.8719 - val_acc: 0.0000e+00\n",
            "Epoch 791/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 6.0196 - acc: 0.0000e+00 - val_loss: 2.8739 - val_acc: 0.0000e+00\n",
            "Epoch 792/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 6.0136 - acc: 0.0000e+00 - val_loss: 2.8656 - val_acc: 0.0000e+00\n",
            "Epoch 793/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 6.0065 - acc: 0.0000e+00 - val_loss: 2.8482 - val_acc: 0.0000e+00\n",
            "Epoch 794/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 6.0008 - acc: 0.0000e+00 - val_loss: 2.8379 - val_acc: 0.0000e+00\n",
            "Epoch 795/2000\n",
            "80/80 [==============================] - 0s 133us/step - loss: 5.9949 - acc: 0.0000e+00 - val_loss: 2.8336 - val_acc: 0.0000e+00\n",
            "Epoch 796/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 5.9882 - acc: 0.0000e+00 - val_loss: 2.8349 - val_acc: 0.0000e+00\n",
            "Epoch 797/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 5.9813 - acc: 0.0000e+00 - val_loss: 2.8396 - val_acc: 0.0000e+00\n",
            "Epoch 798/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 5.9742 - acc: 0.0000e+00 - val_loss: 2.8396 - val_acc: 0.0000e+00\n",
            "Epoch 799/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 5.9685 - acc: 0.0000e+00 - val_loss: 2.8304 - val_acc: 0.0000e+00\n",
            "Epoch 800/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 5.9614 - acc: 0.0000e+00 - val_loss: 2.8206 - val_acc: 0.0000e+00\n",
            "Epoch 801/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 5.9551 - acc: 0.0000e+00 - val_loss: 2.8153 - val_acc: 0.0000e+00\n",
            "Epoch 802/2000\n",
            "80/80 [==============================] - 0s 130us/step - loss: 5.9487 - acc: 0.0000e+00 - val_loss: 2.8143 - val_acc: 0.0000e+00\n",
            "Epoch 803/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 5.9421 - acc: 0.0000e+00 - val_loss: 2.8118 - val_acc: 0.0000e+00\n",
            "Epoch 804/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 5.9357 - acc: 0.0000e+00 - val_loss: 2.8081 - val_acc: 0.0000e+00\n",
            "Epoch 805/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 5.9292 - acc: 0.0000e+00 - val_loss: 2.8036 - val_acc: 0.0000e+00\n",
            "Epoch 806/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 5.9228 - acc: 0.0000e+00 - val_loss: 2.7983 - val_acc: 0.0000e+00\n",
            "Epoch 807/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 5.9164 - acc: 0.0000e+00 - val_loss: 2.7926 - val_acc: 0.0000e+00\n",
            "Epoch 808/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 5.9100 - acc: 0.0000e+00 - val_loss: 2.7881 - val_acc: 0.0000e+00\n",
            "Epoch 809/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 5.9038 - acc: 0.0000e+00 - val_loss: 2.7899 - val_acc: 0.0000e+00\n",
            "Epoch 810/2000\n",
            "80/80 [==============================] - 0s 125us/step - loss: 5.8973 - acc: 0.0000e+00 - val_loss: 2.7827 - val_acc: 0.0000e+00\n",
            "Epoch 811/2000\n",
            "80/80 [==============================] - 0s 126us/step - loss: 5.8909 - acc: 0.0000e+00 - val_loss: 2.7805 - val_acc: 0.0000e+00\n",
            "Epoch 812/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 5.8845 - acc: 0.0000e+00 - val_loss: 2.7776 - val_acc: 0.0000e+00\n",
            "Epoch 813/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 5.8783 - acc: 0.0000e+00 - val_loss: 2.7664 - val_acc: 0.0000e+00\n",
            "Epoch 814/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 5.8722 - acc: 0.0000e+00 - val_loss: 2.7621 - val_acc: 0.0000e+00\n",
            "Epoch 815/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 5.8658 - acc: 0.0000e+00 - val_loss: 2.7591 - val_acc: 0.0000e+00\n",
            "Epoch 816/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 5.8594 - acc: 0.0000e+00 - val_loss: 2.7574 - val_acc: 0.0000e+00\n",
            "Epoch 817/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 5.8530 - acc: 0.0000e+00 - val_loss: 2.7553 - val_acc: 0.0000e+00\n",
            "Epoch 818/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 5.8468 - acc: 0.0000e+00 - val_loss: 2.7451 - val_acc: 0.0000e+00\n",
            "Epoch 819/2000\n",
            "80/80 [==============================] - 0s 137us/step - loss: 5.8404 - acc: 0.0000e+00 - val_loss: 2.7353 - val_acc: 0.0000e+00\n",
            "Epoch 820/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 5.8344 - acc: 0.0000e+00 - val_loss: 2.7327 - val_acc: 0.0000e+00\n",
            "Epoch 821/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 5.8279 - acc: 0.0000e+00 - val_loss: 2.7316 - val_acc: 0.0000e+00\n",
            "Epoch 822/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 5.8216 - acc: 0.0000e+00 - val_loss: 2.7300 - val_acc: 0.0000e+00\n",
            "Epoch 823/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 5.8153 - acc: 0.0000e+00 - val_loss: 2.7281 - val_acc: 0.0000e+00\n",
            "Epoch 824/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 5.8092 - acc: 0.0000e+00 - val_loss: 2.7182 - val_acc: 0.0000e+00\n",
            "Epoch 825/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 5.8028 - acc: 0.0000e+00 - val_loss: 2.7087 - val_acc: 0.0000e+00\n",
            "Epoch 826/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 5.7965 - acc: 0.0000e+00 - val_loss: 2.6996 - val_acc: 0.0000e+00\n",
            "Epoch 827/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 5.7903 - acc: 0.0000e+00 - val_loss: 2.6939 - val_acc: 0.0000e+00\n",
            "Epoch 828/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 5.7841 - acc: 0.0000e+00 - val_loss: 2.6890 - val_acc: 0.0000e+00\n",
            "Epoch 829/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 5.7778 - acc: 0.0000e+00 - val_loss: 2.6846 - val_acc: 0.0000e+00\n",
            "Epoch 830/2000\n",
            "80/80 [==============================] - 0s 194us/step - loss: 5.7714 - acc: 0.0000e+00 - val_loss: 2.6808 - val_acc: 0.0000e+00\n",
            "Epoch 831/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 5.7652 - acc: 0.0000e+00 - val_loss: 2.6773 - val_acc: 0.0000e+00\n",
            "Epoch 832/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 5.7590 - acc: 0.0000e+00 - val_loss: 2.6738 - val_acc: 0.0000e+00\n",
            "Epoch 833/2000\n",
            "80/80 [==============================] - 0s 138us/step - loss: 5.7527 - acc: 0.0000e+00 - val_loss: 2.6702 - val_acc: 0.0000e+00\n",
            "Epoch 834/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 5.7464 - acc: 0.0000e+00 - val_loss: 2.6667 - val_acc: 0.0000e+00\n",
            "Epoch 835/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 5.7401 - acc: 0.0000e+00 - val_loss: 2.6631 - val_acc: 0.0000e+00\n",
            "Epoch 836/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 5.7338 - acc: 0.0000e+00 - val_loss: 2.6595 - val_acc: 0.0000e+00\n",
            "Epoch 837/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 5.7275 - acc: 0.0000e+00 - val_loss: 2.6558 - val_acc: 0.0000e+00\n",
            "Epoch 838/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 5.7211 - acc: 0.0000e+00 - val_loss: 2.6522 - val_acc: 0.0000e+00\n",
            "Epoch 839/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 5.7149 - acc: 0.0000e+00 - val_loss: 2.6501 - val_acc: 0.0000e+00\n",
            "Epoch 840/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 5.7090 - acc: 0.0000e+00 - val_loss: 2.6443 - val_acc: 0.0000e+00\n",
            "Epoch 841/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 5.7025 - acc: 0.0000e+00 - val_loss: 2.6355 - val_acc: 0.0000e+00\n",
            "Epoch 842/2000\n",
            "80/80 [==============================] - 0s 138us/step - loss: 5.6961 - acc: 0.0000e+00 - val_loss: 2.6276 - val_acc: 0.0000e+00\n",
            "Epoch 843/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 5.6899 - acc: 0.0000e+00 - val_loss: 2.6218 - val_acc: 0.0000e+00\n",
            "Epoch 844/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 5.6837 - acc: 0.0000e+00 - val_loss: 2.6161 - val_acc: 0.0000e+00\n",
            "Epoch 845/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 5.6774 - acc: 0.0000e+00 - val_loss: 2.6106 - val_acc: 0.0000e+00\n",
            "Epoch 846/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 5.6712 - acc: 0.0000e+00 - val_loss: 2.6051 - val_acc: 0.0000e+00\n",
            "Epoch 847/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 5.6650 - acc: 0.0000e+00 - val_loss: 2.6001 - val_acc: 0.0000e+00\n",
            "Epoch 848/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 5.6588 - acc: 0.0000e+00 - val_loss: 2.5988 - val_acc: 0.0000e+00\n",
            "Epoch 849/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 5.6523 - acc: 0.0000e+00 - val_loss: 2.5983 - val_acc: 0.0000e+00\n",
            "Epoch 850/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 5.6461 - acc: 0.0000e+00 - val_loss: 2.6008 - val_acc: 0.0000e+00\n",
            "Epoch 851/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 5.6402 - acc: 0.0000e+00 - val_loss: 2.5975 - val_acc: 0.0000e+00\n",
            "Epoch 852/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 5.6341 - acc: 0.0000e+00 - val_loss: 2.5891 - val_acc: 0.0000e+00\n",
            "Epoch 853/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 5.6273 - acc: 0.0000e+00 - val_loss: 2.5783 - val_acc: 0.0000e+00\n",
            "Epoch 854/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 5.6211 - acc: 0.0000e+00 - val_loss: 2.5715 - val_acc: 0.0000e+00\n",
            "Epoch 855/2000\n",
            "80/80 [==============================] - 0s 135us/step - loss: 5.6150 - acc: 0.0000e+00 - val_loss: 2.5651 - val_acc: 0.0000e+00\n",
            "Epoch 856/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 5.6094 - acc: 0.0000e+00 - val_loss: 2.5625 - val_acc: 0.0000e+00\n",
            "Epoch 857/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 5.6024 - acc: 0.0000e+00 - val_loss: 2.5600 - val_acc: 0.0000e+00\n",
            "Epoch 858/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 5.5960 - acc: 0.0000e+00 - val_loss: 2.5573 - val_acc: 0.0000e+00\n",
            "Epoch 859/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 5.5895 - acc: 0.0000e+00 - val_loss: 2.5546 - val_acc: 0.0000e+00\n",
            "Epoch 860/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 5.5838 - acc: 0.0000e+00 - val_loss: 2.5502 - val_acc: 0.0000e+00\n",
            "Epoch 861/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 5.5776 - acc: 0.0000e+00 - val_loss: 2.5440 - val_acc: 0.0000e+00\n",
            "Epoch 862/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 5.5712 - acc: 0.0000e+00 - val_loss: 2.5367 - val_acc: 0.0000e+00\n",
            "Epoch 863/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 5.5649 - acc: 0.0000e+00 - val_loss: 2.5333 - val_acc: 0.0000e+00\n",
            "Epoch 864/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 5.5583 - acc: 0.0000e+00 - val_loss: 2.5303 - val_acc: 0.0000e+00\n",
            "Epoch 865/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 5.5522 - acc: 0.0000e+00 - val_loss: 2.5254 - val_acc: 0.0000e+00\n",
            "Epoch 866/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 5.5459 - acc: 0.0000e+00 - val_loss: 2.5188 - val_acc: 0.0000e+00\n",
            "Epoch 867/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 5.5396 - acc: 0.0000e+00 - val_loss: 2.5126 - val_acc: 0.0000e+00\n",
            "Epoch 868/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 5.5341 - acc: 0.0000e+00 - val_loss: 2.5098 - val_acc: 0.0000e+00\n",
            "Epoch 869/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 5.5270 - acc: 0.0000e+00 - val_loss: 2.5070 - val_acc: 0.0000e+00\n",
            "Epoch 870/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 5.5211 - acc: 0.0000e+00 - val_loss: 2.5023 - val_acc: 0.0000e+00\n",
            "Epoch 871/2000\n",
            "80/80 [==============================] - 0s 127us/step - loss: 5.5149 - acc: 0.0000e+00 - val_loss: 2.4959 - val_acc: 0.0000e+00\n",
            "Epoch 872/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 5.5086 - acc: 0.0000e+00 - val_loss: 2.4914 - val_acc: 0.0000e+00\n",
            "Epoch 873/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 5.5023 - acc: 0.0000e+00 - val_loss: 2.4887 - val_acc: 0.0000e+00\n",
            "Epoch 874/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 5.4961 - acc: 0.0000e+00 - val_loss: 2.4842 - val_acc: 0.0000e+00\n",
            "Epoch 875/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 5.4898 - acc: 0.0000e+00 - val_loss: 2.4799 - val_acc: 0.0000e+00\n",
            "Epoch 876/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 5.4837 - acc: 0.0000e+00 - val_loss: 2.4756 - val_acc: 0.0000e+00\n",
            "Epoch 877/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 5.4775 - acc: 0.0000e+00 - val_loss: 2.4696 - val_acc: 0.0000e+00\n",
            "Epoch 878/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 5.4715 - acc: 0.0000e+00 - val_loss: 2.4669 - val_acc: 0.0000e+00\n",
            "Epoch 879/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 5.4652 - acc: 0.0000e+00 - val_loss: 2.4623 - val_acc: 0.0000e+00\n",
            "Epoch 880/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 5.4590 - acc: 0.0000e+00 - val_loss: 2.4560 - val_acc: 0.0000e+00\n",
            "Epoch 881/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 5.4530 - acc: 0.0000e+00 - val_loss: 2.4513 - val_acc: 0.0000e+00\n",
            "Epoch 882/2000\n",
            "80/80 [==============================] - 0s 123us/step - loss: 5.4469 - acc: 0.0000e+00 - val_loss: 2.4479 - val_acc: 0.0000e+00\n",
            "Epoch 883/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 5.4407 - acc: 0.0000e+00 - val_loss: 2.4458 - val_acc: 0.0000e+00\n",
            "Epoch 884/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 5.4343 - acc: 0.0000e+00 - val_loss: 2.4418 - val_acc: 0.0000e+00\n",
            "Epoch 885/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 5.4281 - acc: 0.0000e+00 - val_loss: 2.4362 - val_acc: 0.0000e+00\n",
            "Epoch 886/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 5.4223 - acc: 0.0000e+00 - val_loss: 2.4325 - val_acc: 0.0000e+00\n",
            "Epoch 887/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 5.4161 - acc: 0.0000e+00 - val_loss: 2.4302 - val_acc: 0.0000e+00\n",
            "Epoch 888/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 5.4099 - acc: 0.0000e+00 - val_loss: 2.4260 - val_acc: 0.0000e+00\n",
            "Epoch 889/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 5.4037 - acc: 0.0000e+00 - val_loss: 2.4205 - val_acc: 0.0000e+00\n",
            "Epoch 890/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 5.3977 - acc: 0.0000e+00 - val_loss: 2.4163 - val_acc: 0.0000e+00\n",
            "Epoch 891/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 5.3916 - acc: 0.0000e+00 - val_loss: 2.4136 - val_acc: 0.0000e+00\n",
            "Epoch 892/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 5.3853 - acc: 0.0000e+00 - val_loss: 2.4091 - val_acc: 0.0000e+00\n",
            "Epoch 893/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 5.3791 - acc: 0.0000e+00 - val_loss: 2.4060 - val_acc: 0.0000e+00\n",
            "Epoch 894/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 5.3732 - acc: 0.0000e+00 - val_loss: 2.4013 - val_acc: 0.0000e+00\n",
            "Epoch 895/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 5.3670 - acc: 0.0000e+00 - val_loss: 2.3952 - val_acc: 0.0000e+00\n",
            "Epoch 896/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 5.3611 - acc: 0.0000e+00 - val_loss: 2.3906 - val_acc: 0.0000e+00\n",
            "Epoch 897/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 5.3551 - acc: 0.0000e+00 - val_loss: 2.3879 - val_acc: 0.0000e+00\n",
            "Epoch 898/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 5.3485 - acc: 0.0000e+00 - val_loss: 2.3834 - val_acc: 0.0000e+00\n",
            "Epoch 899/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 5.3424 - acc: 0.0000e+00 - val_loss: 2.3775 - val_acc: 0.0000e+00\n",
            "Epoch 900/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 5.3365 - acc: 0.0000e+00 - val_loss: 2.3735 - val_acc: 0.0000e+00\n",
            "Epoch 901/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 5.3301 - acc: 0.0000e+00 - val_loss: 2.3708 - val_acc: 0.0000e+00\n",
            "Epoch 902/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 5.3244 - acc: 0.0000e+00 - val_loss: 2.3665 - val_acc: 0.0000e+00\n",
            "Epoch 903/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 5.3186 - acc: 0.0000e+00 - val_loss: 2.3594 - val_acc: 0.0000e+00\n",
            "Epoch 904/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 5.3119 - acc: 0.0000e+00 - val_loss: 2.3538 - val_acc: 0.0000e+00\n",
            "Epoch 905/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 5.3061 - acc: 0.0000e+00 - val_loss: 2.3498 - val_acc: 0.0000e+00\n",
            "Epoch 906/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 5.3000 - acc: 0.0000e+00 - val_loss: 2.3470 - val_acc: 0.0000e+00\n",
            "Epoch 907/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 5.2935 - acc: 0.0000e+00 - val_loss: 2.3454 - val_acc: 0.0000e+00\n",
            "Epoch 908/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 5.2886 - acc: 0.0000e+00 - val_loss: 2.3408 - val_acc: 0.0000e+00\n",
            "Epoch 909/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 5.2820 - acc: 0.0000e+00 - val_loss: 2.3334 - val_acc: 0.0000e+00\n",
            "Epoch 910/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 5.2757 - acc: 0.0000e+00 - val_loss: 2.3275 - val_acc: 0.0000e+00\n",
            "Epoch 911/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 5.2702 - acc: 0.0000e+00 - val_loss: 2.3234 - val_acc: 0.0000e+00\n",
            "Epoch 912/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 5.2642 - acc: 0.0000e+00 - val_loss: 2.3199 - val_acc: 0.0000e+00\n",
            "Epoch 913/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 5.2578 - acc: 0.0000e+00 - val_loss: 2.3177 - val_acc: 0.0000e+00\n",
            "Epoch 914/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 5.2510 - acc: 0.0000e+00 - val_loss: 2.3166 - val_acc: 0.0000e+00\n",
            "Epoch 915/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 5.2460 - acc: 0.0000e+00 - val_loss: 2.3124 - val_acc: 0.0000e+00\n",
            "Epoch 916/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 5.2401 - acc: 0.0000e+00 - val_loss: 2.3055 - val_acc: 0.0000e+00\n",
            "Epoch 917/2000\n",
            "80/80 [==============================] - 0s 145us/step - loss: 5.2325 - acc: 0.0000e+00 - val_loss: 2.3001 - val_acc: 0.0000e+00\n",
            "Epoch 918/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 5.2267 - acc: 0.0000e+00 - val_loss: 2.2961 - val_acc: 0.0000e+00\n",
            "Epoch 919/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 5.2205 - acc: 0.0000e+00 - val_loss: 2.2933 - val_acc: 0.0000e+00\n",
            "Epoch 920/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 5.2146 - acc: 0.0000e+00 - val_loss: 2.2903 - val_acc: 0.0000e+00\n",
            "Epoch 921/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 5.2091 - acc: 0.0000e+00 - val_loss: 2.2846 - val_acc: 0.0000e+00\n",
            "Epoch 922/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 5.2023 - acc: 0.0000e+00 - val_loss: 2.2791 - val_acc: 0.0000e+00\n",
            "Epoch 923/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 5.1968 - acc: 0.0000e+00 - val_loss: 2.2753 - val_acc: 0.0000e+00\n",
            "Epoch 924/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 5.1908 - acc: 0.0000e+00 - val_loss: 2.2725 - val_acc: 0.0000e+00\n",
            "Epoch 925/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 5.1842 - acc: 0.0000e+00 - val_loss: 2.2706 - val_acc: 0.0000e+00\n",
            "Epoch 926/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 5.1789 - acc: 0.0000e+00 - val_loss: 2.2659 - val_acc: 0.0000e+00\n",
            "Epoch 927/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 5.1728 - acc: 0.0000e+00 - val_loss: 2.2587 - val_acc: 0.0000e+00\n",
            "Epoch 928/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 5.1659 - acc: 0.0000e+00 - val_loss: 2.2529 - val_acc: 0.0000e+00\n",
            "Epoch 929/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 5.1601 - acc: 0.0000e+00 - val_loss: 2.2483 - val_acc: 0.0000e+00\n",
            "Epoch 930/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 5.1537 - acc: 0.0000e+00 - val_loss: 2.2448 - val_acc: 0.0000e+00\n",
            "Epoch 931/2000\n",
            "80/80 [==============================] - 0s 136us/step - loss: 5.1480 - acc: 0.0000e+00 - val_loss: 2.2413 - val_acc: 0.0000e+00\n",
            "Epoch 932/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 5.1424 - acc: 0.0000e+00 - val_loss: 2.2352 - val_acc: 0.0000e+00\n",
            "Epoch 933/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 5.1360 - acc: 0.0000e+00 - val_loss: 2.2292 - val_acc: 0.0000e+00\n",
            "Epoch 934/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 5.1297 - acc: 0.0000e+00 - val_loss: 2.2267 - val_acc: 0.0000e+00\n",
            "Epoch 935/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 5.1239 - acc: 0.0000e+00 - val_loss: 2.2221 - val_acc: 0.0000e+00\n",
            "Epoch 936/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 5.1177 - acc: 0.0000e+00 - val_loss: 2.2160 - val_acc: 0.0000e+00\n",
            "Epoch 937/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 5.1113 - acc: 0.0000e+00 - val_loss: 2.2126 - val_acc: 0.0000e+00\n",
            "Epoch 938/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 5.1053 - acc: 0.0000e+00 - val_loss: 2.2090 - val_acc: 0.0000e+00\n",
            "Epoch 939/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 5.0992 - acc: 0.0000e+00 - val_loss: 2.2052 - val_acc: 0.0000e+00\n",
            "Epoch 940/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 5.0930 - acc: 0.0000e+00 - val_loss: 2.2013 - val_acc: 0.0000e+00\n",
            "Epoch 941/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 5.0869 - acc: 0.0000e+00 - val_loss: 2.1975 - val_acc: 0.0000e+00\n",
            "Epoch 942/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 5.0811 - acc: 0.0000e+00 - val_loss: 2.1944 - val_acc: 0.0000e+00\n",
            "Epoch 943/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 5.0751 - acc: 0.0000e+00 - val_loss: 2.1905 - val_acc: 0.0000e+00\n",
            "Epoch 944/2000\n",
            "80/80 [==============================] - 0s 129us/step - loss: 5.0691 - acc: 0.0000e+00 - val_loss: 2.1838 - val_acc: 0.0000e+00\n",
            "Epoch 945/2000\n",
            "80/80 [==============================] - 0s 135us/step - loss: 5.0631 - acc: 0.0000e+00 - val_loss: 2.1794 - val_acc: 0.0000e+00\n",
            "Epoch 946/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 5.0568 - acc: 0.0000e+00 - val_loss: 2.1733 - val_acc: 0.0000e+00\n",
            "Epoch 947/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 5.0508 - acc: 0.0000e+00 - val_loss: 2.1684 - val_acc: 0.0000e+00\n",
            "Epoch 948/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 5.0451 - acc: 0.0000e+00 - val_loss: 2.1641 - val_acc: 0.0000e+00\n",
            "Epoch 949/2000\n",
            "80/80 [==============================] - 0s 137us/step - loss: 5.0396 - acc: 0.0000e+00 - val_loss: 2.1593 - val_acc: 0.0000e+00\n",
            "Epoch 950/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 5.0329 - acc: 0.0000e+00 - val_loss: 2.1555 - val_acc: 0.0000e+00\n",
            "Epoch 951/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 5.0267 - acc: 0.0000e+00 - val_loss: 2.1529 - val_acc: 0.0000e+00\n",
            "Epoch 952/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 5.0205 - acc: 0.0000e+00 - val_loss: 2.1504 - val_acc: 0.0000e+00\n",
            "Epoch 953/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 5.0145 - acc: 0.0000e+00 - val_loss: 2.1451 - val_acc: 0.0000e+00\n",
            "Epoch 954/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 5.0083 - acc: 0.0000e+00 - val_loss: 2.1400 - val_acc: 0.0000e+00\n",
            "Epoch 955/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 5.0022 - acc: 0.0000e+00 - val_loss: 2.1353 - val_acc: 0.0000e+00\n",
            "Epoch 956/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 4.9962 - acc: 0.0000e+00 - val_loss: 2.1309 - val_acc: 0.0000e+00\n",
            "Epoch 957/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 4.9901 - acc: 0.0000e+00 - val_loss: 2.1267 - val_acc: 0.0000e+00\n",
            "Epoch 958/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 4.9840 - acc: 0.0000e+00 - val_loss: 2.1227 - val_acc: 0.0000e+00\n",
            "Epoch 959/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 4.9779 - acc: 0.0000e+00 - val_loss: 2.1187 - val_acc: 0.0000e+00\n",
            "Epoch 960/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 4.9718 - acc: 0.0000e+00 - val_loss: 2.1116 - val_acc: 0.0000e+00\n",
            "Epoch 961/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 4.9657 - acc: 0.0000e+00 - val_loss: 2.1051 - val_acc: 0.0000e+00\n",
            "Epoch 962/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 4.9597 - acc: 0.0000e+00 - val_loss: 2.0993 - val_acc: 0.0000e+00\n",
            "Epoch 963/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 4.9539 - acc: 0.0000e+00 - val_loss: 2.0972 - val_acc: 0.0000e+00\n",
            "Epoch 964/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 4.9474 - acc: 0.0000e+00 - val_loss: 2.0962 - val_acc: 0.0000e+00\n",
            "Epoch 965/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 4.9412 - acc: 0.0000e+00 - val_loss: 2.0980 - val_acc: 0.0000e+00\n",
            "Epoch 966/2000\n",
            "80/80 [==============================] - 0s 135us/step - loss: 4.9351 - acc: 0.0000e+00 - val_loss: 2.0924 - val_acc: 0.0000e+00\n",
            "Epoch 967/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 4.9289 - acc: 0.0000e+00 - val_loss: 2.0875 - val_acc: 0.0000e+00\n",
            "Epoch 968/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 4.9227 - acc: 0.0000e+00 - val_loss: 2.0835 - val_acc: 0.0000e+00\n",
            "Epoch 969/2000\n",
            "80/80 [==============================] - 0s 194us/step - loss: 4.9165 - acc: 0.0000e+00 - val_loss: 2.0805 - val_acc: 0.0000e+00\n",
            "Epoch 970/2000\n",
            "80/80 [==============================] - 0s 132us/step - loss: 4.9104 - acc: 0.0000e+00 - val_loss: 2.0699 - val_acc: 0.0000e+00\n",
            "Epoch 971/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 4.9047 - acc: 0.0000e+00 - val_loss: 2.0684 - val_acc: 0.0000e+00\n",
            "Epoch 972/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 4.8981 - acc: 0.0000e+00 - val_loss: 2.0678 - val_acc: 0.0000e+00\n",
            "Epoch 973/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 4.8920 - acc: 0.0000e+00 - val_loss: 2.0591 - val_acc: 0.0000e+00\n",
            "Epoch 974/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 4.8858 - acc: 0.0000e+00 - val_loss: 2.0518 - val_acc: 0.0000e+00\n",
            "Epoch 975/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 4.8800 - acc: 0.0000e+00 - val_loss: 2.0531 - val_acc: 0.0000e+00\n",
            "Epoch 976/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 4.8735 - acc: 0.0000e+00 - val_loss: 2.0546 - val_acc: 0.0000e+00\n",
            "Epoch 977/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 4.8679 - acc: 0.0000e+00 - val_loss: 2.0471 - val_acc: 0.0000e+00\n",
            "Epoch 978/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 4.8613 - acc: 0.0000e+00 - val_loss: 2.0399 - val_acc: 0.0000e+00\n",
            "Epoch 979/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 4.8551 - acc: 0.0000e+00 - val_loss: 2.0334 - val_acc: 0.0000e+00\n",
            "Epoch 980/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 4.8489 - acc: 0.0000e+00 - val_loss: 2.0275 - val_acc: 0.0000e+00\n",
            "Epoch 981/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 4.8427 - acc: 0.0000e+00 - val_loss: 2.0223 - val_acc: 0.0000e+00\n",
            "Epoch 982/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 4.8367 - acc: 0.0000e+00 - val_loss: 2.0252 - val_acc: 0.0000e+00\n",
            "Epoch 983/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 4.8304 - acc: 0.0000e+00 - val_loss: 2.0191 - val_acc: 0.0000e+00\n",
            "Epoch 984/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 4.8240 - acc: 0.0000e+00 - val_loss: 2.0050 - val_acc: 0.0000e+00\n",
            "Epoch 985/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 4.8189 - acc: 0.0000e+00 - val_loss: 2.0000 - val_acc: 0.0000e+00\n",
            "Epoch 986/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 4.8128 - acc: 0.0000e+00 - val_loss: 2.0030 - val_acc: 0.0000e+00\n",
            "Epoch 987/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 4.8056 - acc: 0.0000e+00 - val_loss: 2.0053 - val_acc: 0.0000e+00\n",
            "Epoch 988/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 4.7999 - acc: 0.0000e+00 - val_loss: 1.9983 - val_acc: 0.0000e+00\n",
            "Epoch 989/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 4.7933 - acc: 0.0000e+00 - val_loss: 1.9830 - val_acc: 0.0000e+00\n",
            "Epoch 990/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 4.7879 - acc: 0.0000e+00 - val_loss: 1.9795 - val_acc: 0.0000e+00\n",
            "Epoch 991/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 4.7817 - acc: 0.0000e+00 - val_loss: 1.9834 - val_acc: 0.0000e+00\n",
            "Epoch 992/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 4.7746 - acc: 0.0000e+00 - val_loss: 1.9865 - val_acc: 0.0000e+00\n",
            "Epoch 993/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 4.7692 - acc: 0.0000e+00 - val_loss: 1.9803 - val_acc: 0.0000e+00\n",
            "Epoch 994/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 4.7627 - acc: 0.0000e+00 - val_loss: 1.9658 - val_acc: 0.0000e+00\n",
            "Epoch 995/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 4.7568 - acc: 0.0000e+00 - val_loss: 1.9605 - val_acc: 0.0000e+00\n",
            "Epoch 996/2000\n",
            "80/80 [==============================] - 0s 231us/step - loss: 4.7509 - acc: 0.0000e+00 - val_loss: 1.9625 - val_acc: 0.0000e+00\n",
            "Epoch 997/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 4.7440 - acc: 0.0000e+00 - val_loss: 1.9635 - val_acc: 0.0000e+00\n",
            "Epoch 998/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 4.7377 - acc: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00\n",
            "Epoch 999/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 4.7322 - acc: 0.0000e+00 - val_loss: 1.9539 - val_acc: 0.0000e+00\n",
            "Epoch 1000/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 4.7253 - acc: 0.0000e+00 - val_loss: 1.9366 - val_acc: 0.0000e+00\n",
            "Epoch 1001/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 4.7199 - acc: 0.0000e+00 - val_loss: 1.9315 - val_acc: 0.0000e+00\n",
            "Epoch 1002/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 4.7145 - acc: 0.0000e+00 - val_loss: 1.9302 - val_acc: 0.0000e+00\n",
            "Epoch 1003/2000\n",
            "80/80 [==============================] - 0s 133us/step - loss: 4.7071 - acc: 0.0000e+00 - val_loss: 1.9396 - val_acc: 0.0000e+00\n",
            "Epoch 1004/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 4.7007 - acc: 0.0000e+00 - val_loss: 1.9388 - val_acc: 0.0000e+00\n",
            "Epoch 1005/2000\n",
            "80/80 [==============================] - 0s 142us/step - loss: 4.6949 - acc: 0.0000e+00 - val_loss: 1.9287 - val_acc: 0.0000e+00\n",
            "Epoch 1006/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 4.6877 - acc: 0.0000e+00 - val_loss: 1.9126 - val_acc: 0.0000e+00\n",
            "Epoch 1007/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 4.6826 - acc: 0.0000e+00 - val_loss: 1.9089 - val_acc: 0.0000e+00\n",
            "Epoch 1008/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 4.6769 - acc: 0.0000e+00 - val_loss: 1.9051 - val_acc: 0.0000e+00\n",
            "Epoch 1009/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 4.6702 - acc: 0.0000e+00 - val_loss: 1.9070 - val_acc: 0.0000e+00\n",
            "Epoch 1010/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 4.6628 - acc: 0.0000e+00 - val_loss: 1.9136 - val_acc: 0.0000e+00\n",
            "Epoch 1011/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 4.6566 - acc: 0.0000e+00 - val_loss: 1.9209 - val_acc: 0.0000e+00\n",
            "Epoch 1012/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 4.6517 - acc: 0.0000e+00 - val_loss: 1.8997 - val_acc: 0.0000e+00\n",
            "Epoch 1013/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 4.6439 - acc: 0.0000e+00 - val_loss: 1.8854 - val_acc: 0.0000e+00\n",
            "Epoch 1014/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 4.6377 - acc: 0.0000e+00 - val_loss: 1.8795 - val_acc: 0.0000e+00\n",
            "Epoch 1015/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 4.6316 - acc: 0.0000e+00 - val_loss: 1.8831 - val_acc: 0.0000e+00\n",
            "Epoch 1016/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 4.6247 - acc: 0.0000e+00 - val_loss: 1.8870 - val_acc: 0.0000e+00\n",
            "Epoch 1017/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 4.6189 - acc: 0.0000e+00 - val_loss: 1.8789 - val_acc: 0.0000e+00\n",
            "Epoch 1018/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 4.6121 - acc: 0.0000e+00 - val_loss: 1.8714 - val_acc: 0.0000e+00\n",
            "Epoch 1019/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 4.6057 - acc: 0.0000e+00 - val_loss: 1.8634 - val_acc: 0.0000e+00\n",
            "Epoch 1020/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 4.5993 - acc: 0.0000e+00 - val_loss: 1.8551 - val_acc: 0.0000e+00\n",
            "Epoch 1021/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 4.5934 - acc: 0.0000e+00 - val_loss: 1.8544 - val_acc: 0.0000e+00\n",
            "Epoch 1022/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 4.5865 - acc: 0.0000e+00 - val_loss: 1.8620 - val_acc: 0.0000e+00\n",
            "Epoch 1023/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 4.5810 - acc: 0.0000e+00 - val_loss: 1.8582 - val_acc: 0.0000e+00\n",
            "Epoch 1024/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 4.5745 - acc: 0.0000e+00 - val_loss: 1.8420 - val_acc: 0.0000e+00\n",
            "Epoch 1025/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 4.5674 - acc: 0.0000e+00 - val_loss: 1.8334 - val_acc: 0.0000e+00\n",
            "Epoch 1026/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 4.5620 - acc: 0.0000e+00 - val_loss: 1.8346 - val_acc: 0.0000e+00\n",
            "Epoch 1027/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 4.5548 - acc: 0.0000e+00 - val_loss: 1.8387 - val_acc: 0.0000e+00\n",
            "Epoch 1028/2000\n",
            "80/80 [==============================] - 0s 207us/step - loss: 4.5485 - acc: 0.0000e+00 - val_loss: 1.8434 - val_acc: 0.0000e+00\n",
            "Epoch 1029/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 4.5426 - acc: 0.0000e+00 - val_loss: 1.8314 - val_acc: 0.0000e+00\n",
            "Epoch 1030/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 4.5357 - acc: 0.0000e+00 - val_loss: 1.8192 - val_acc: 0.0000e+00\n",
            "Epoch 1031/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 4.5291 - acc: 0.0000e+00 - val_loss: 1.8113 - val_acc: 0.0000e+00\n",
            "Epoch 1032/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 4.5225 - acc: 0.0000e+00 - val_loss: 1.8075 - val_acc: 0.0000e+00\n",
            "Epoch 1033/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 4.5161 - acc: 0.0000e+00 - val_loss: 1.8028 - val_acc: 0.0000e+00\n",
            "Epoch 1034/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 4.5096 - acc: 0.0000e+00 - val_loss: 1.7974 - val_acc: 0.0000e+00\n",
            "Epoch 1035/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 4.5032 - acc: 0.0000e+00 - val_loss: 1.7957 - val_acc: 0.0000e+00\n",
            "Epoch 1036/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 4.4967 - acc: 0.0000e+00 - val_loss: 1.7938 - val_acc: 0.0000e+00\n",
            "Epoch 1037/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 4.4903 - acc: 0.0000e+00 - val_loss: 1.7920 - val_acc: 0.0000e+00\n",
            "Epoch 1038/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 4.4839 - acc: 0.0000e+00 - val_loss: 1.7872 - val_acc: 0.0000e+00\n",
            "Epoch 1039/2000\n",
            "80/80 [==============================] - 0s 187us/step - loss: 4.4774 - acc: 0.0000e+00 - val_loss: 1.7810 - val_acc: 0.0000e+00\n",
            "Epoch 1040/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 4.4708 - acc: 0.0000e+00 - val_loss: 1.7737 - val_acc: 0.0000e+00\n",
            "Epoch 1041/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 4.4642 - acc: 0.0000e+00 - val_loss: 1.7672 - val_acc: 0.0000e+00\n",
            "Epoch 1042/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 4.4581 - acc: 0.0000e+00 - val_loss: 1.7674 - val_acc: 0.0000e+00\n",
            "Epoch 1043/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 4.4512 - acc: 0.0000e+00 - val_loss: 1.7673 - val_acc: 0.0000e+00\n",
            "Epoch 1044/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 4.4447 - acc: 0.0000e+00 - val_loss: 1.7562 - val_acc: 0.0000e+00\n",
            "Epoch 1045/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 4.4381 - acc: 0.0000e+00 - val_loss: 1.7515 - val_acc: 0.0000e+00\n",
            "Epoch 1046/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 4.4315 - acc: 0.0000e+00 - val_loss: 1.7461 - val_acc: 0.0000e+00\n",
            "Epoch 1047/2000\n",
            "80/80 [==============================] - 0s 261us/step - loss: 4.4249 - acc: 0.0000e+00 - val_loss: 1.7401 - val_acc: 0.0000e+00\n",
            "Epoch 1048/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 4.4186 - acc: 0.0000e+00 - val_loss: 1.7413 - val_acc: 0.0000e+00\n",
            "Epoch 1049/2000\n",
            "80/80 [==============================] - 0s 145us/step - loss: 4.4119 - acc: 0.0000e+00 - val_loss: 1.7442 - val_acc: 0.0000e+00\n",
            "Epoch 1050/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 4.4055 - acc: 0.0000e+00 - val_loss: 1.7347 - val_acc: 0.0000e+00\n",
            "Epoch 1051/2000\n",
            "80/80 [==============================] - 0s 206us/step - loss: 4.3986 - acc: 0.0000e+00 - val_loss: 1.7319 - val_acc: 0.0000e+00\n",
            "Epoch 1052/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 4.3919 - acc: 0.0000e+00 - val_loss: 1.7276 - val_acc: 0.0000e+00\n",
            "Epoch 1053/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 4.3853 - acc: 0.0000e+00 - val_loss: 1.7250 - val_acc: 0.0000e+00\n",
            "Epoch 1054/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 4.3787 - acc: 0.0000e+00 - val_loss: 1.7218 - val_acc: 0.0000e+00\n",
            "Epoch 1055/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 4.3723 - acc: 0.0000e+00 - val_loss: 1.7073 - val_acc: 0.0000e+00\n",
            "Epoch 1056/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 4.3653 - acc: 0.0000e+00 - val_loss: 1.7005 - val_acc: 0.0000e+00\n",
            "Epoch 1057/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 4.3591 - acc: 0.0000e+00 - val_loss: 1.7122 - val_acc: 0.0000e+00\n",
            "Epoch 1058/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 4.3534 - acc: 0.0000e+00 - val_loss: 1.6994 - val_acc: 0.0000e+00\n",
            "Epoch 1059/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 4.3455 - acc: 0.0000e+00 - val_loss: 1.6898 - val_acc: 0.0000e+00\n",
            "Epoch 1060/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 4.3386 - acc: 0.0000e+00 - val_loss: 1.6856 - val_acc: 0.0000e+00\n",
            "Epoch 1061/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 4.3321 - acc: 0.0000e+00 - val_loss: 1.6854 - val_acc: 0.0000e+00\n",
            "Epoch 1062/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 4.3249 - acc: 0.0000e+00 - val_loss: 1.6849 - val_acc: 0.0000e+00\n",
            "Epoch 1063/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 4.3185 - acc: 0.0000e+00 - val_loss: 1.6738 - val_acc: 0.0000e+00\n",
            "Epoch 1064/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 4.3119 - acc: 0.0000e+00 - val_loss: 1.6757 - val_acc: 0.0000e+00\n",
            "Epoch 1065/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 4.3050 - acc: 0.0000e+00 - val_loss: 1.6667 - val_acc: 0.0000e+00\n",
            "Epoch 1066/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 4.2978 - acc: 0.0000e+00 - val_loss: 1.6579 - val_acc: 0.0000e+00\n",
            "Epoch 1067/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 4.2914 - acc: 0.0000e+00 - val_loss: 1.6534 - val_acc: 0.0000e+00\n",
            "Epoch 1068/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 4.2845 - acc: 0.0000e+00 - val_loss: 1.6543 - val_acc: 0.0000e+00\n",
            "Epoch 1069/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 4.2776 - acc: 0.0000e+00 - val_loss: 1.6452 - val_acc: 0.0000e+00\n",
            "Epoch 1070/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 4.2704 - acc: 0.0000e+00 - val_loss: 1.6422 - val_acc: 0.0000e+00\n",
            "Epoch 1071/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 4.2637 - acc: 0.0000e+00 - val_loss: 1.6377 - val_acc: 0.0000e+00\n",
            "Epoch 1072/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 4.2566 - acc: 0.0000e+00 - val_loss: 1.6269 - val_acc: 0.0000e+00\n",
            "Epoch 1073/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 4.2517 - acc: 0.0000e+00 - val_loss: 1.6353 - val_acc: 0.0000e+00\n",
            "Epoch 1074/2000\n",
            "80/80 [==============================] - 0s 244us/step - loss: 4.2438 - acc: 0.0000e+00 - val_loss: 1.6272 - val_acc: 0.0000e+00\n",
            "Epoch 1075/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 4.2360 - acc: 0.0000e+00 - val_loss: 1.6171 - val_acc: 0.0000e+00\n",
            "Epoch 1076/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 4.2300 - acc: 0.0000e+00 - val_loss: 1.6188 - val_acc: 0.0000e+00\n",
            "Epoch 1077/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 4.2221 - acc: 0.0000e+00 - val_loss: 1.6042 - val_acc: 0.0000e+00\n",
            "Epoch 1078/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 4.2168 - acc: 0.0000e+00 - val_loss: 1.6010 - val_acc: 0.0000e+00\n",
            "Epoch 1079/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 4.2084 - acc: 0.0000e+00 - val_loss: 1.6022 - val_acc: 0.0000e+00\n",
            "Epoch 1080/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 4.2021 - acc: 0.0000e+00 - val_loss: 1.5902 - val_acc: 0.0000e+00\n",
            "Epoch 1081/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 4.1939 - acc: 0.0000e+00 - val_loss: 1.5854 - val_acc: 0.0000e+00\n",
            "Epoch 1082/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 4.1889 - acc: 0.0000e+00 - val_loss: 1.5890 - val_acc: 0.0000e+00\n",
            "Epoch 1083/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 4.1802 - acc: 0.0000e+00 - val_loss: 1.6058 - val_acc: 0.0000e+00\n",
            "Epoch 1084/2000\n",
            "80/80 [==============================] - 0s 136us/step - loss: 4.1795 - acc: 0.0000e+00 - val_loss: 1.6172 - val_acc: 0.0000e+00\n",
            "Epoch 1085/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 4.1995 - acc: 0.0000e+00 - val_loss: 1.6065 - val_acc: 0.0000e+00\n",
            "Epoch 1086/2000\n",
            "80/80 [==============================] - 0s 137us/step - loss: 4.1856 - acc: 0.0000e+00 - val_loss: 1.5883 - val_acc: 0.0000e+00\n",
            "Epoch 1087/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 4.1556 - acc: 0.0000e+00 - val_loss: 1.6589 - val_acc: 0.0000e+00\n",
            "Epoch 1088/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 4.1925 - acc: 0.0000e+00 - val_loss: 1.5769 - val_acc: 0.0000e+00\n",
            "Epoch 1089/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 4.1487 - acc: 0.0000e+00 - val_loss: 1.6063 - val_acc: 0.0000e+00\n",
            "Epoch 1090/2000\n",
            "80/80 [==============================] - 0s 136us/step - loss: 4.1635 - acc: 0.0000e+00 - val_loss: 1.5953 - val_acc: 0.0000e+00\n",
            "Epoch 1091/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 4.1496 - acc: 0.0000e+00 - val_loss: 1.5625 - val_acc: 0.0000e+00\n",
            "Epoch 1092/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 4.1247 - acc: 0.0000e+00 - val_loss: 1.6251 - val_acc: 0.0000e+00\n",
            "Epoch 1093/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 4.1529 - acc: 0.0000e+00 - val_loss: 1.5532 - val_acc: 0.0000e+00\n",
            "Epoch 1094/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 4.1114 - acc: 0.0000e+00 - val_loss: 1.5722 - val_acc: 0.0000e+00\n",
            "Epoch 1095/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 4.1187 - acc: 0.0000e+00 - val_loss: 1.5761 - val_acc: 0.0000e+00\n",
            "Epoch 1096/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 4.1172 - acc: 0.0000e+00 - val_loss: 1.5408 - val_acc: 0.0000e+00\n",
            "Epoch 1097/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 4.0938 - acc: 0.0000e+00 - val_loss: 1.5662 - val_acc: 0.0000e+00\n",
            "Epoch 1098/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 4.0971 - acc: 0.0000e+00 - val_loss: 1.5278 - val_acc: 0.0000e+00\n",
            "Epoch 1099/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 4.0789 - acc: 0.0000e+00 - val_loss: 1.5316 - val_acc: 0.0000e+00\n",
            "Epoch 1100/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 4.0796 - acc: 0.0000e+00 - val_loss: 1.5235 - val_acc: 0.0000e+00\n",
            "Epoch 1101/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 4.0720 - acc: 0.0000e+00 - val_loss: 1.5018 - val_acc: 0.0000e+00\n",
            "Epoch 1102/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 4.0559 - acc: 0.0000e+00 - val_loss: 1.5397 - val_acc: 0.0000e+00\n",
            "Epoch 1103/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 4.0735 - acc: 0.0000e+00 - val_loss: 1.4950 - val_acc: 0.0000e+00\n",
            "Epoch 1104/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 4.0450 - acc: 0.0000e+00 - val_loss: 1.5023 - val_acc: 0.0000e+00\n",
            "Epoch 1105/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 4.0468 - acc: 0.0000e+00 - val_loss: 1.4829 - val_acc: 0.0000e+00\n",
            "Epoch 1106/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 4.0302 - acc: 0.0000e+00 - val_loss: 1.5231 - val_acc: 0.0000e+00\n",
            "Epoch 1107/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 4.0451 - acc: 0.0000e+00 - val_loss: 1.4801 - val_acc: 0.0000e+00\n",
            "Epoch 1108/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 4.0205 - acc: 0.0000e+00 - val_loss: 1.4885 - val_acc: 0.0000e+00\n",
            "Epoch 1109/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 4.0218 - acc: 0.0000e+00 - val_loss: 1.4787 - val_acc: 0.0000e+00\n",
            "Epoch 1110/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 4.0107 - acc: 0.0000e+00 - val_loss: 1.4745 - val_acc: 0.0000e+00\n",
            "Epoch 1111/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 4.0015 - acc: 0.0000e+00 - val_loss: 1.4614 - val_acc: 0.0000e+00\n",
            "Epoch 1112/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 3.9917 - acc: 0.0000e+00 - val_loss: 1.4674 - val_acc: 0.0000e+00\n",
            "Epoch 1113/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 3.9906 - acc: 0.0000e+00 - val_loss: 1.4624 - val_acc: 0.0000e+00\n",
            "Epoch 1114/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 3.9831 - acc: 0.0000e+00 - val_loss: 1.4608 - val_acc: 0.0000e+00\n",
            "Epoch 1115/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 3.9777 - acc: 0.0000e+00 - val_loss: 1.4544 - val_acc: 0.0000e+00\n",
            "Epoch 1116/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 3.9684 - acc: 0.0000e+00 - val_loss: 1.4781 - val_acc: 0.0000e+00\n",
            "Epoch 1117/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 3.9725 - acc: 0.0000e+00 - val_loss: 1.4541 - val_acc: 0.0000e+00\n",
            "Epoch 1118/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 3.9593 - acc: 0.0000e+00 - val_loss: 1.4518 - val_acc: 0.0000e+00\n",
            "Epoch 1119/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 3.9544 - acc: 0.0000e+00 - val_loss: 1.4405 - val_acc: 0.0000e+00\n",
            "Epoch 1120/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 3.9440 - acc: 0.0000e+00 - val_loss: 1.4335 - val_acc: 0.0000e+00\n",
            "Epoch 1121/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 3.9390 - acc: 0.0000e+00 - val_loss: 1.4343 - val_acc: 0.0000e+00\n",
            "Epoch 1122/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 3.9342 - acc: 0.0000e+00 - val_loss: 1.4289 - val_acc: 0.0000e+00\n",
            "Epoch 1123/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 3.9286 - acc: 0.0000e+00 - val_loss: 1.4245 - val_acc: 0.0000e+00\n",
            "Epoch 1124/2000\n",
            "80/80 [==============================] - 0s 135us/step - loss: 3.9213 - acc: 0.0000e+00 - val_loss: 1.4225 - val_acc: 0.0000e+00\n",
            "Epoch 1125/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 3.9148 - acc: 0.0000e+00 - val_loss: 1.4231 - val_acc: 0.0000e+00\n",
            "Epoch 1126/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 3.9097 - acc: 0.0000e+00 - val_loss: 1.4220 - val_acc: 0.0000e+00\n",
            "Epoch 1127/2000\n",
            "80/80 [==============================] - 0s 116us/step - loss: 3.9044 - acc: 0.0000e+00 - val_loss: 1.4197 - val_acc: 0.0000e+00\n",
            "Epoch 1128/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 3.8985 - acc: 0.0000e+00 - val_loss: 1.4159 - val_acc: 0.0000e+00\n",
            "Epoch 1129/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 3.8919 - acc: 0.0000e+00 - val_loss: 1.4121 - val_acc: 0.0000e+00\n",
            "Epoch 1130/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 3.8861 - acc: 0.0000e+00 - val_loss: 1.4109 - val_acc: 0.0000e+00\n",
            "Epoch 1131/2000\n",
            "80/80 [==============================] - 0s 299us/step - loss: 3.8808 - acc: 0.0000e+00 - val_loss: 1.4074 - val_acc: 0.0000e+00\n",
            "Epoch 1132/2000\n",
            "80/80 [==============================] - 0s 138us/step - loss: 3.8753 - acc: 0.0000e+00 - val_loss: 1.4080 - val_acc: 0.0000e+00\n",
            "Epoch 1133/2000\n",
            "80/80 [==============================] - 0s 226us/step - loss: 3.8699 - acc: 0.0000e+00 - val_loss: 1.4041 - val_acc: 0.0000e+00\n",
            "Epoch 1134/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 3.8643 - acc: 0.0000e+00 - val_loss: 1.4042 - val_acc: 0.0000e+00\n",
            "Epoch 1135/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 3.8584 - acc: 0.0000e+00 - val_loss: 1.4032 - val_acc: 0.0000e+00\n",
            "Epoch 1136/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 3.8534 - acc: 0.0000e+00 - val_loss: 1.4013 - val_acc: 0.0000e+00\n",
            "Epoch 1137/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 3.8476 - acc: 0.0000e+00 - val_loss: 1.4001 - val_acc: 0.0000e+00\n",
            "Epoch 1138/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 3.8427 - acc: 0.0000e+00 - val_loss: 1.3947 - val_acc: 0.0000e+00\n",
            "Epoch 1139/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 3.8367 - acc: 0.0000e+00 - val_loss: 1.3922 - val_acc: 0.0000e+00\n",
            "Epoch 1140/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 3.8315 - acc: 0.0000e+00 - val_loss: 1.3864 - val_acc: 0.0000e+00\n",
            "Epoch 1141/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 3.8265 - acc: 0.0000e+00 - val_loss: 1.3846 - val_acc: 0.0000e+00\n",
            "Epoch 1142/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 3.8208 - acc: 0.0000e+00 - val_loss: 1.3851 - val_acc: 0.0000e+00\n",
            "Epoch 1143/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 3.8156 - acc: 0.0000e+00 - val_loss: 1.3813 - val_acc: 0.0000e+00\n",
            "Epoch 1144/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 3.8100 - acc: 0.0000e+00 - val_loss: 1.3817 - val_acc: 0.0000e+00\n",
            "Epoch 1145/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 3.8047 - acc: 0.0000e+00 - val_loss: 1.3806 - val_acc: 0.0000e+00\n",
            "Epoch 1146/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 3.7999 - acc: 0.0000e+00 - val_loss: 1.3759 - val_acc: 0.0000e+00\n",
            "Epoch 1147/2000\n",
            "80/80 [==============================] - 0s 137us/step - loss: 3.7940 - acc: 0.0000e+00 - val_loss: 1.3705 - val_acc: 0.0000e+00\n",
            "Epoch 1148/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 3.7887 - acc: 0.0000e+00 - val_loss: 1.3666 - val_acc: 0.0000e+00\n",
            "Epoch 1149/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 3.7835 - acc: 0.0000e+00 - val_loss: 1.3636 - val_acc: 0.0000e+00\n",
            "Epoch 1150/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 3.7790 - acc: 0.0000e+00 - val_loss: 1.3578 - val_acc: 0.0000e+00\n",
            "Epoch 1151/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 3.7738 - acc: 0.0000e+00 - val_loss: 1.3577 - val_acc: 0.0000e+00\n",
            "Epoch 1152/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 3.7674 - acc: 0.0000e+00 - val_loss: 1.3584 - val_acc: 0.0000e+00\n",
            "Epoch 1153/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 3.7624 - acc: 0.0000e+00 - val_loss: 1.3568 - val_acc: 0.0000e+00\n",
            "Epoch 1154/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 3.7574 - acc: 0.0000e+00 - val_loss: 1.3531 - val_acc: 0.0000e+00\n",
            "Epoch 1155/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 3.7521 - acc: 0.0000e+00 - val_loss: 1.3502 - val_acc: 0.0000e+00\n",
            "Epoch 1156/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 3.7463 - acc: 0.0000e+00 - val_loss: 1.3479 - val_acc: 0.0000e+00\n",
            "Epoch 1157/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 3.7413 - acc: 0.0000e+00 - val_loss: 1.3448 - val_acc: 0.0000e+00\n",
            "Epoch 1158/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 3.7360 - acc: 0.0000e+00 - val_loss: 1.3423 - val_acc: 0.0000e+00\n",
            "Epoch 1159/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 3.7311 - acc: 0.0000e+00 - val_loss: 1.3400 - val_acc: 0.0000e+00\n",
            "Epoch 1160/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 3.7258 - acc: 0.0000e+00 - val_loss: 1.3389 - val_acc: 0.0000e+00\n",
            "Epoch 1161/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 3.7204 - acc: 0.0000e+00 - val_loss: 1.3360 - val_acc: 0.0000e+00\n",
            "Epoch 1162/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 3.7153 - acc: 0.0000e+00 - val_loss: 1.3326 - val_acc: 0.0000e+00\n",
            "Epoch 1163/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 3.7100 - acc: 0.0000e+00 - val_loss: 1.3294 - val_acc: 0.0000e+00\n",
            "Epoch 1164/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 3.7051 - acc: 0.0000e+00 - val_loss: 1.3267 - val_acc: 0.0000e+00\n",
            "Epoch 1165/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 3.7000 - acc: 0.0000e+00 - val_loss: 1.3240 - val_acc: 0.0000e+00\n",
            "Epoch 1166/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 3.6952 - acc: 0.0000e+00 - val_loss: 1.3214 - val_acc: 0.0000e+00\n",
            "Epoch 1167/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 3.6900 - acc: 0.0000e+00 - val_loss: 1.3197 - val_acc: 0.0000e+00\n",
            "Epoch 1168/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 3.6848 - acc: 0.0000e+00 - val_loss: 1.3185 - val_acc: 0.0000e+00\n",
            "Epoch 1169/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 3.6798 - acc: 0.0000e+00 - val_loss: 1.3163 - val_acc: 0.0000e+00\n",
            "Epoch 1170/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 3.6747 - acc: 0.0000e+00 - val_loss: 1.3129 - val_acc: 0.0000e+00\n",
            "Epoch 1171/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 3.6696 - acc: 0.0000e+00 - val_loss: 1.3104 - val_acc: 0.0000e+00\n",
            "Epoch 1172/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 3.6644 - acc: 0.0000e+00 - val_loss: 1.3090 - val_acc: 0.0000e+00\n",
            "Epoch 1173/2000\n",
            "80/80 [==============================] - 0s 139us/step - loss: 3.6595 - acc: 0.0000e+00 - val_loss: 1.3060 - val_acc: 0.0000e+00\n",
            "Epoch 1174/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 3.6541 - acc: 0.0000e+00 - val_loss: 1.3037 - val_acc: 0.0000e+00\n",
            "Epoch 1175/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 3.6492 - acc: 0.0000e+00 - val_loss: 1.3019 - val_acc: 0.0000e+00\n",
            "Epoch 1176/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 3.6438 - acc: 0.0000e+00 - val_loss: 1.3004 - val_acc: 0.0000e+00\n",
            "Epoch 1177/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 3.6392 - acc: 0.0000e+00 - val_loss: 1.2978 - val_acc: 0.0000e+00\n",
            "Epoch 1178/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 3.6338 - acc: 0.0000e+00 - val_loss: 1.2952 - val_acc: 0.0000e+00\n",
            "Epoch 1179/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 3.6291 - acc: 0.0000e+00 - val_loss: 1.2912 - val_acc: 0.0000e+00\n",
            "Epoch 1180/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 3.6236 - acc: 0.0000e+00 - val_loss: 1.2876 - val_acc: 0.0000e+00\n",
            "Epoch 1181/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 3.6185 - acc: 0.0000e+00 - val_loss: 1.2847 - val_acc: 0.0000e+00\n",
            "Epoch 1182/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 3.6136 - acc: 0.0000e+00 - val_loss: 1.2820 - val_acc: 0.0000e+00\n",
            "Epoch 1183/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 3.6085 - acc: 0.0000e+00 - val_loss: 1.2800 - val_acc: 0.0000e+00\n",
            "Epoch 1184/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 3.6035 - acc: 0.0000e+00 - val_loss: 1.2782 - val_acc: 0.0000e+00\n",
            "Epoch 1185/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 3.5986 - acc: 0.0000e+00 - val_loss: 1.2766 - val_acc: 0.0000e+00\n",
            "Epoch 1186/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 3.5933 - acc: 0.0000e+00 - val_loss: 1.2752 - val_acc: 0.0000e+00\n",
            "Epoch 1187/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 3.5883 - acc: 0.0000e+00 - val_loss: 1.2736 - val_acc: 0.0000e+00\n",
            "Epoch 1188/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 3.5834 - acc: 0.0000e+00 - val_loss: 1.2702 - val_acc: 0.0000e+00\n",
            "Epoch 1189/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 3.5785 - acc: 0.0000e+00 - val_loss: 1.2674 - val_acc: 0.0000e+00\n",
            "Epoch 1190/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 3.5733 - acc: 0.0000e+00 - val_loss: 1.2654 - val_acc: 0.0000e+00\n",
            "Epoch 1191/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 3.5685 - acc: 0.0000e+00 - val_loss: 1.2632 - val_acc: 0.0000e+00\n",
            "Epoch 1192/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 3.5635 - acc: 0.0000e+00 - val_loss: 1.2615 - val_acc: 0.0000e+00\n",
            "Epoch 1193/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 3.5584 - acc: 0.0000e+00 - val_loss: 1.2603 - val_acc: 0.0000e+00\n",
            "Epoch 1194/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 3.5538 - acc: 0.0000e+00 - val_loss: 1.2573 - val_acc: 0.0000e+00\n",
            "Epoch 1195/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 3.5483 - acc: 0.0000e+00 - val_loss: 1.2543 - val_acc: 0.0000e+00\n",
            "Epoch 1196/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 3.5436 - acc: 0.0000e+00 - val_loss: 1.2519 - val_acc: 0.0000e+00\n",
            "Epoch 1197/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 3.5385 - acc: 0.0000e+00 - val_loss: 1.2503 - val_acc: 0.0000e+00\n",
            "Epoch 1198/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 3.5334 - acc: 0.0000e+00 - val_loss: 1.2491 - val_acc: 0.0000e+00\n",
            "Epoch 1199/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 3.5284 - acc: 0.0000e+00 - val_loss: 1.2485 - val_acc: 0.0000e+00\n",
            "Epoch 1200/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 3.5239 - acc: 0.0000e+00 - val_loss: 1.2459 - val_acc: 0.0000e+00\n",
            "Epoch 1201/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 3.5188 - acc: 0.0000e+00 - val_loss: 1.2423 - val_acc: 0.0000e+00\n",
            "Epoch 1202/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 3.5138 - acc: 0.0000e+00 - val_loss: 1.2394 - val_acc: 0.0000e+00\n",
            "Epoch 1203/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 3.5085 - acc: 0.0000e+00 - val_loss: 1.2374 - val_acc: 0.0000e+00\n",
            "Epoch 1204/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 3.5037 - acc: 0.0000e+00 - val_loss: 1.2335 - val_acc: 0.0000e+00\n",
            "Epoch 1205/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 3.4990 - acc: 0.0000e+00 - val_loss: 1.2304 - val_acc: 0.0000e+00\n",
            "Epoch 1206/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 3.4941 - acc: 0.0000e+00 - val_loss: 1.2290 - val_acc: 0.0000e+00\n",
            "Epoch 1207/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 3.4894 - acc: 0.0000e+00 - val_loss: 1.2284 - val_acc: 0.0000e+00\n",
            "Epoch 1208/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 3.4847 - acc: 0.0000e+00 - val_loss: 1.2259 - val_acc: 0.0000e+00\n",
            "Epoch 1209/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 3.4793 - acc: 0.0000e+00 - val_loss: 1.2245 - val_acc: 0.0000e+00\n",
            "Epoch 1210/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 3.4745 - acc: 0.0000e+00 - val_loss: 1.2239 - val_acc: 0.0000e+00\n",
            "Epoch 1211/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 3.4692 - acc: 0.0000e+00 - val_loss: 1.2223 - val_acc: 0.0000e+00\n",
            "Epoch 1212/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 3.4651 - acc: 0.0000e+00 - val_loss: 1.2210 - val_acc: 0.0000e+00\n",
            "Epoch 1213/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 3.4594 - acc: 0.0000e+00 - val_loss: 1.2217 - val_acc: 0.0000e+00\n",
            "Epoch 1214/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 3.4551 - acc: 0.0000e+00 - val_loss: 1.2187 - val_acc: 0.0000e+00\n",
            "Epoch 1215/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 3.4497 - acc: 0.0000e+00 - val_loss: 1.2161 - val_acc: 0.0000e+00\n",
            "Epoch 1216/2000\n",
            "80/80 [==============================] - 0s 131us/step - loss: 3.4457 - acc: 0.0000e+00 - val_loss: 1.2110 - val_acc: 0.0000e+00\n",
            "Epoch 1217/2000\n",
            "80/80 [==============================] - 0s 125us/step - loss: 3.4401 - acc: 0.0000e+00 - val_loss: 1.2083 - val_acc: 0.0000e+00\n",
            "Epoch 1218/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 3.4354 - acc: 0.0000e+00 - val_loss: 1.2065 - val_acc: 0.0000e+00\n",
            "Epoch 1219/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 3.4298 - acc: 0.0000e+00 - val_loss: 1.2041 - val_acc: 0.0000e+00\n",
            "Epoch 1220/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 3.4257 - acc: 0.0000e+00 - val_loss: 1.2000 - val_acc: 0.0000e+00\n",
            "Epoch 1221/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 3.4205 - acc: 0.0000e+00 - val_loss: 1.1947 - val_acc: 0.0000e+00\n",
            "Epoch 1222/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 3.4159 - acc: 0.0000e+00 - val_loss: 1.1922 - val_acc: 0.0000e+00\n",
            "Epoch 1223/2000\n",
            "80/80 [==============================] - 0s 124us/step - loss: 3.4113 - acc: 0.0000e+00 - val_loss: 1.1935 - val_acc: 0.0000e+00\n",
            "Epoch 1224/2000\n",
            "80/80 [==============================] - 0s 128us/step - loss: 3.4068 - acc: 0.0000e+00 - val_loss: 1.1949 - val_acc: 0.0000e+00\n",
            "Epoch 1225/2000\n",
            "80/80 [==============================] - 0s 145us/step - loss: 3.4021 - acc: 0.0000e+00 - val_loss: 1.1928 - val_acc: 0.0000e+00\n",
            "Epoch 1226/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 3.3966 - acc: 0.0000e+00 - val_loss: 1.1915 - val_acc: 0.0000e+00\n",
            "Epoch 1227/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 3.3924 - acc: 0.0000e+00 - val_loss: 1.1883 - val_acc: 0.0000e+00\n",
            "Epoch 1228/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 3.3862 - acc: 0.0000e+00 - val_loss: 1.1878 - val_acc: 0.0000e+00\n",
            "Epoch 1229/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 3.3834 - acc: 0.0000e+00 - val_loss: 1.1829 - val_acc: 0.0000e+00\n",
            "Epoch 1230/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 3.3772 - acc: 0.0000e+00 - val_loss: 1.1807 - val_acc: 0.0000e+00\n",
            "Epoch 1231/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 3.3730 - acc: 0.0000e+00 - val_loss: 1.1802 - val_acc: 0.0000e+00\n",
            "Epoch 1232/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 3.3670 - acc: 0.0000e+00 - val_loss: 1.1821 - val_acc: 0.0000e+00\n",
            "Epoch 1233/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 3.3643 - acc: 0.0000e+00 - val_loss: 1.1795 - val_acc: 0.0000e+00\n",
            "Epoch 1234/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 3.3587 - acc: 0.0000e+00 - val_loss: 1.1761 - val_acc: 0.0000e+00\n",
            "Epoch 1235/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 3.3540 - acc: 0.0000e+00 - val_loss: 1.1739 - val_acc: 0.0000e+00\n",
            "Epoch 1236/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 3.3488 - acc: 0.0000e+00 - val_loss: 1.1714 - val_acc: 0.0000e+00\n",
            "Epoch 1237/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 3.3431 - acc: 0.0000e+00 - val_loss: 1.1685 - val_acc: 0.0000e+00\n",
            "Epoch 1238/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 3.3397 - acc: 0.0000e+00 - val_loss: 1.1657 - val_acc: 0.0000e+00\n",
            "Epoch 1239/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 3.3340 - acc: 0.0000e+00 - val_loss: 1.1652 - val_acc: 0.0000e+00\n",
            "Epoch 1240/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 3.3302 - acc: 0.0000e+00 - val_loss: 1.1650 - val_acc: 0.0000e+00\n",
            "Epoch 1241/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 3.3250 - acc: 0.0000e+00 - val_loss: 1.1647 - val_acc: 0.0000e+00\n",
            "Epoch 1242/2000\n",
            "80/80 [==============================] - 0s 235us/step - loss: 3.3206 - acc: 0.0000e+00 - val_loss: 1.1609 - val_acc: 0.0000e+00\n",
            "Epoch 1243/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 3.3153 - acc: 0.0000e+00 - val_loss: 1.1554 - val_acc: 0.0000e+00\n",
            "Epoch 1244/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 3.3105 - acc: 0.0000e+00 - val_loss: 1.1524 - val_acc: 0.0000e+00\n",
            "Epoch 1245/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 3.3062 - acc: 0.0000e+00 - val_loss: 1.1526 - val_acc: 0.0000e+00\n",
            "Epoch 1246/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 3.3006 - acc: 0.0000e+00 - val_loss: 1.1527 - val_acc: 0.0000e+00\n",
            "Epoch 1247/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 3.2959 - acc: 0.0000e+00 - val_loss: 1.1518 - val_acc: 0.0000e+00\n",
            "Epoch 1248/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 3.2918 - acc: 0.0000e+00 - val_loss: 1.1510 - val_acc: 0.0000e+00\n",
            "Epoch 1249/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 3.2871 - acc: 0.0000e+00 - val_loss: 1.1467 - val_acc: 0.0000e+00\n",
            "Epoch 1250/2000\n",
            "80/80 [==============================] - 0s 142us/step - loss: 3.2816 - acc: 0.0000e+00 - val_loss: 1.1419 - val_acc: 0.0000e+00\n",
            "Epoch 1251/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 3.2780 - acc: 0.0000e+00 - val_loss: 1.1385 - val_acc: 0.0000e+00\n",
            "Epoch 1252/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 3.2739 - acc: 0.0000e+00 - val_loss: 1.1392 - val_acc: 0.0000e+00\n",
            "Epoch 1253/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 3.2675 - acc: 0.0000e+00 - val_loss: 1.1405 - val_acc: 0.0000e+00\n",
            "Epoch 1254/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 3.2640 - acc: 0.0000e+00 - val_loss: 1.1380 - val_acc: 0.0000e+00\n",
            "Epoch 1255/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 3.2596 - acc: 0.0000e+00 - val_loss: 1.1335 - val_acc: 0.0000e+00\n",
            "Epoch 1256/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 3.2543 - acc: 0.0000e+00 - val_loss: 1.1288 - val_acc: 0.0000e+00\n",
            "Epoch 1257/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 3.2496 - acc: 0.0000e+00 - val_loss: 1.1268 - val_acc: 0.0000e+00\n",
            "Epoch 1258/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 3.2476 - acc: 0.0000e+00 - val_loss: 1.1260 - val_acc: 0.0000e+00\n",
            "Epoch 1259/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 3.2401 - acc: 0.0000e+00 - val_loss: 1.1271 - val_acc: 0.0000e+00\n",
            "Epoch 1260/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 3.2355 - acc: 0.0000e+00 - val_loss: 1.1278 - val_acc: 0.0000e+00\n",
            "Epoch 1261/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 3.2317 - acc: 0.0000e+00 - val_loss: 1.1257 - val_acc: 0.0000e+00\n",
            "Epoch 1262/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 3.2262 - acc: 0.0000e+00 - val_loss: 1.1204 - val_acc: 0.0000e+00\n",
            "Epoch 1263/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 3.2215 - acc: 0.0000e+00 - val_loss: 1.1168 - val_acc: 0.0000e+00\n",
            "Epoch 1264/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 3.2173 - acc: 0.0000e+00 - val_loss: 1.1153 - val_acc: 0.0000e+00\n",
            "Epoch 1265/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 3.2130 - acc: 0.0000e+00 - val_loss: 1.1144 - val_acc: 0.0000e+00\n",
            "Epoch 1266/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 3.2072 - acc: 0.0000e+00 - val_loss: 1.1142 - val_acc: 0.0000e+00\n",
            "Epoch 1267/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 3.2027 - acc: 0.0000e+00 - val_loss: 1.1139 - val_acc: 0.0000e+00\n",
            "Epoch 1268/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 3.1982 - acc: 0.0000e+00 - val_loss: 1.1099 - val_acc: 0.0000e+00\n",
            "Epoch 1269/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 3.1933 - acc: 0.0000e+00 - val_loss: 1.1053 - val_acc: 0.0000e+00\n",
            "Epoch 1270/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 3.1886 - acc: 0.0000e+00 - val_loss: 1.1017 - val_acc: 0.0000e+00\n",
            "Epoch 1271/2000\n",
            "80/80 [==============================] - 0s 131us/step - loss: 3.1843 - acc: 0.0000e+00 - val_loss: 1.1000 - val_acc: 0.0000e+00\n",
            "Epoch 1272/2000\n",
            "80/80 [==============================] - 0s 135us/step - loss: 3.1794 - acc: 0.0000e+00 - val_loss: 1.0989 - val_acc: 0.0000e+00\n",
            "Epoch 1273/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 3.1749 - acc: 0.0000e+00 - val_loss: 1.0977 - val_acc: 0.0000e+00\n",
            "Epoch 1274/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 3.1703 - acc: 0.0000e+00 - val_loss: 1.0964 - val_acc: 0.0000e+00\n",
            "Epoch 1275/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 3.1654 - acc: 0.0000e+00 - val_loss: 1.0952 - val_acc: 0.0000e+00\n",
            "Epoch 1276/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 3.1611 - acc: 0.0000e+00 - val_loss: 1.0956 - val_acc: 0.0000e+00\n",
            "Epoch 1277/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 3.1563 - acc: 0.0000e+00 - val_loss: 1.0963 - val_acc: 0.0000e+00\n",
            "Epoch 1278/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 3.1518 - acc: 0.0000e+00 - val_loss: 1.0956 - val_acc: 0.0000e+00\n",
            "Epoch 1279/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 3.1472 - acc: 0.0000e+00 - val_loss: 1.0950 - val_acc: 0.0000e+00\n",
            "Epoch 1280/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 3.1427 - acc: 0.0000e+00 - val_loss: 1.0930 - val_acc: 0.0000e+00\n",
            "Epoch 1281/2000\n",
            "80/80 [==============================] - 0s 122us/step - loss: 3.1379 - acc: 0.0000e+00 - val_loss: 1.0906 - val_acc: 0.0000e+00\n",
            "Epoch 1282/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 3.1333 - acc: 0.0000e+00 - val_loss: 1.0881 - val_acc: 0.0000e+00\n",
            "Epoch 1283/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 3.1286 - acc: 0.0000e+00 - val_loss: 1.0839 - val_acc: 0.0000e+00\n",
            "Epoch 1284/2000\n",
            "80/80 [==============================] - 0s 241us/step - loss: 3.1238 - acc: 0.0000e+00 - val_loss: 1.0797 - val_acc: 0.0000e+00\n",
            "Epoch 1285/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 3.1194 - acc: 0.0000e+00 - val_loss: 1.0767 - val_acc: 0.0000e+00\n",
            "Epoch 1286/2000\n",
            "80/80 [==============================] - 0s 257us/step - loss: 3.1151 - acc: 0.0000e+00 - val_loss: 1.0722 - val_acc: 0.0000e+00\n",
            "Epoch 1287/2000\n",
            "80/80 [==============================] - 0s 263us/step - loss: 3.1103 - acc: 0.0000e+00 - val_loss: 1.0708 - val_acc: 0.0000e+00\n",
            "Epoch 1288/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 3.1056 - acc: 0.0000e+00 - val_loss: 1.0713 - val_acc: 0.0000e+00\n",
            "Epoch 1289/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 3.1014 - acc: 0.0000e+00 - val_loss: 1.0707 - val_acc: 0.0000e+00\n",
            "Epoch 1290/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 3.0964 - acc: 0.0000e+00 - val_loss: 1.0700 - val_acc: 0.0000e+00\n",
            "Epoch 1291/2000\n",
            "80/80 [==============================] - 0s 123us/step - loss: 3.0918 - acc: 0.0000e+00 - val_loss: 1.0698 - val_acc: 0.0000e+00\n",
            "Epoch 1292/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 3.0873 - acc: 0.0000e+00 - val_loss: 1.0709 - val_acc: 0.0000e+00\n",
            "Epoch 1293/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 3.0829 - acc: 0.0000e+00 - val_loss: 1.0700 - val_acc: 0.0000e+00\n",
            "Epoch 1294/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 3.0783 - acc: 0.0000e+00 - val_loss: 1.0680 - val_acc: 0.0000e+00\n",
            "Epoch 1295/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 3.0741 - acc: 0.0000e+00 - val_loss: 1.0651 - val_acc: 0.0000e+00\n",
            "Epoch 1296/2000\n",
            "80/80 [==============================] - 0s 212us/step - loss: 3.0693 - acc: 0.0000e+00 - val_loss: 1.0625 - val_acc: 0.0000e+00\n",
            "Epoch 1297/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 3.0645 - acc: 0.0000e+00 - val_loss: 1.0597 - val_acc: 0.0000e+00\n",
            "Epoch 1298/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 3.0601 - acc: 0.0000e+00 - val_loss: 1.0559 - val_acc: 0.0000e+00\n",
            "Epoch 1299/2000\n",
            "80/80 [==============================] - 0s 141us/step - loss: 3.0560 - acc: 0.0000e+00 - val_loss: 1.0540 - val_acc: 0.0000e+00\n",
            "Epoch 1300/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 3.0514 - acc: 0.0000e+00 - val_loss: 1.0542 - val_acc: 0.0000e+00\n",
            "Epoch 1301/2000\n",
            "80/80 [==============================] - 0s 130us/step - loss: 3.0465 - acc: 0.0000e+00 - val_loss: 1.0528 - val_acc: 0.0000e+00\n",
            "Epoch 1302/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 3.0417 - acc: 0.0000e+00 - val_loss: 1.0512 - val_acc: 0.0000e+00\n",
            "Epoch 1303/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 3.0373 - acc: 0.0000e+00 - val_loss: 1.0496 - val_acc: 0.0000e+00\n",
            "Epoch 1304/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 3.0327 - acc: 0.0000e+00 - val_loss: 1.0477 - val_acc: 0.0000e+00\n",
            "Epoch 1305/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 3.0282 - acc: 0.0000e+00 - val_loss: 1.0471 - val_acc: 0.0000e+00\n",
            "Epoch 1306/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 3.0238 - acc: 0.0000e+00 - val_loss: 1.0455 - val_acc: 0.0000e+00\n",
            "Epoch 1307/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 3.0191 - acc: 0.0000e+00 - val_loss: 1.0441 - val_acc: 0.0000e+00\n",
            "Epoch 1308/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 3.0148 - acc: 0.0000e+00 - val_loss: 1.0412 - val_acc: 0.0000e+00\n",
            "Epoch 1309/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 3.0105 - acc: 0.0000e+00 - val_loss: 1.0376 - val_acc: 0.0000e+00\n",
            "Epoch 1310/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 3.0060 - acc: 0.0000e+00 - val_loss: 1.0344 - val_acc: 0.0000e+00\n",
            "Epoch 1311/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 3.0021 - acc: 0.0000e+00 - val_loss: 1.0315 - val_acc: 0.0000e+00\n",
            "Epoch 1312/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 2.9969 - acc: 0.0000e+00 - val_loss: 1.0320 - val_acc: 0.0000e+00\n",
            "Epoch 1313/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 2.9928 - acc: 0.0000e+00 - val_loss: 1.0310 - val_acc: 0.0000e+00\n",
            "Epoch 1314/2000\n",
            "80/80 [==============================] - 0s 145us/step - loss: 2.9876 - acc: 0.0000e+00 - val_loss: 1.0311 - val_acc: 0.0000e+00\n",
            "Epoch 1315/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 2.9836 - acc: 0.0000e+00 - val_loss: 1.0302 - val_acc: 0.0000e+00\n",
            "Epoch 1316/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 2.9786 - acc: 0.0000e+00 - val_loss: 1.0301 - val_acc: 0.0000e+00\n",
            "Epoch 1317/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 2.9743 - acc: 0.0000e+00 - val_loss: 1.0293 - val_acc: 0.0000e+00\n",
            "Epoch 1318/2000\n",
            "80/80 [==============================] - 0s 216us/step - loss: 2.9696 - acc: 0.0000e+00 - val_loss: 1.0284 - val_acc: 0.0000e+00\n",
            "Epoch 1319/2000\n",
            "80/80 [==============================] - 0s 127us/step - loss: 2.9651 - acc: 0.0000e+00 - val_loss: 1.0269 - val_acc: 0.0000e+00\n",
            "Epoch 1320/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 2.9612 - acc: 0.0000e+00 - val_loss: 1.0246 - val_acc: 0.0000e+00\n",
            "Epoch 1321/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 2.9567 - acc: 0.0000e+00 - val_loss: 1.0225 - val_acc: 0.0000e+00\n",
            "Epoch 1322/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 2.9517 - acc: 0.0000e+00 - val_loss: 1.0210 - val_acc: 0.0000e+00\n",
            "Epoch 1323/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 2.9477 - acc: 0.0000e+00 - val_loss: 1.0162 - val_acc: 0.0000e+00\n",
            "Epoch 1324/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 2.9428 - acc: 0.0000e+00 - val_loss: 1.0128 - val_acc: 0.0000e+00\n",
            "Epoch 1325/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 2.9385 - acc: 0.0000e+00 - val_loss: 1.0104 - val_acc: 0.0000e+00\n",
            "Epoch 1326/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 2.9338 - acc: 0.0000e+00 - val_loss: 1.0082 - val_acc: 0.0000e+00\n",
            "Epoch 1327/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 2.9296 - acc: 0.0000e+00 - val_loss: 1.0056 - val_acc: 0.0000e+00\n",
            "Epoch 1328/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 2.9249 - acc: 0.0000e+00 - val_loss: 1.0044 - val_acc: 0.0000e+00\n",
            "Epoch 1329/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 2.9209 - acc: 0.0000e+00 - val_loss: 1.0041 - val_acc: 0.0000e+00\n",
            "Epoch 1330/2000\n",
            "80/80 [==============================] - 0s 125us/step - loss: 2.9163 - acc: 0.0000e+00 - val_loss: 1.0017 - val_acc: 0.0000e+00\n",
            "Epoch 1331/2000\n",
            "80/80 [==============================] - 0s 135us/step - loss: 2.9115 - acc: 0.0000e+00 - val_loss: 0.9997 - val_acc: 0.0000e+00\n",
            "Epoch 1332/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 2.9070 - acc: 0.0000e+00 - val_loss: 0.9985 - val_acc: 0.0000e+00\n",
            "Epoch 1333/2000\n",
            "80/80 [==============================] - 0s 142us/step - loss: 2.9029 - acc: 0.0000e+00 - val_loss: 0.9987 - val_acc: 0.0000e+00\n",
            "Epoch 1334/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 2.8983 - acc: 0.0000e+00 - val_loss: 1.0014 - val_acc: 0.0000e+00\n",
            "Epoch 1335/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 2.8944 - acc: 0.0000e+00 - val_loss: 0.9974 - val_acc: 0.0000e+00\n",
            "Epoch 1336/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 2.8906 - acc: 0.0000e+00 - val_loss: 0.9954 - val_acc: 0.0000e+00\n",
            "Epoch 1337/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 2.8857 - acc: 0.0000e+00 - val_loss: 0.9984 - val_acc: 0.0000e+00\n",
            "Epoch 1338/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 2.8814 - acc: 0.0000e+00 - val_loss: 0.9910 - val_acc: 0.0000e+00\n",
            "Epoch 1339/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 2.8761 - acc: 0.0000e+00 - val_loss: 0.9865 - val_acc: 0.0000e+00\n",
            "Epoch 1340/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 2.8717 - acc: 0.0000e+00 - val_loss: 0.9858 - val_acc: 0.0000e+00\n",
            "Epoch 1341/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 2.8675 - acc: 0.0000e+00 - val_loss: 0.9835 - val_acc: 0.0000e+00\n",
            "Epoch 1342/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 2.8632 - acc: 0.0000e+00 - val_loss: 0.9822 - val_acc: 0.0000e+00\n",
            "Epoch 1343/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 2.8586 - acc: 0.0000e+00 - val_loss: 0.9844 - val_acc: 0.0000e+00\n",
            "Epoch 1344/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 2.8546 - acc: 0.0000e+00 - val_loss: 0.9814 - val_acc: 0.0000e+00\n",
            "Epoch 1345/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 2.8508 - acc: 0.0000e+00 - val_loss: 0.9841 - val_acc: 0.0000e+00\n",
            "Epoch 1346/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 2.8456 - acc: 0.0000e+00 - val_loss: 0.9862 - val_acc: 0.0000e+00\n",
            "Epoch 1347/2000\n",
            "80/80 [==============================] - 0s 138us/step - loss: 2.8420 - acc: 0.0000e+00 - val_loss: 0.9776 - val_acc: 0.0000e+00\n",
            "Epoch 1348/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 2.8381 - acc: 0.0000e+00 - val_loss: 0.9746 - val_acc: 0.0000e+00\n",
            "Epoch 1349/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 2.8331 - acc: 0.0000e+00 - val_loss: 0.9781 - val_acc: 0.0000e+00\n",
            "Epoch 1350/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 2.8297 - acc: 0.0000e+00 - val_loss: 0.9709 - val_acc: 0.0000e+00\n",
            "Epoch 1351/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 2.8263 - acc: 0.0000e+00 - val_loss: 0.9687 - val_acc: 0.0000e+00\n",
            "Epoch 1352/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 2.8207 - acc: 0.0000e+00 - val_loss: 0.9744 - val_acc: 0.0000e+00\n",
            "Epoch 1353/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 2.8186 - acc: 0.0000e+00 - val_loss: 0.9639 - val_acc: 0.0000e+00\n",
            "Epoch 1354/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 2.8132 - acc: 0.0000e+00 - val_loss: 0.9616 - val_acc: 0.0000e+00\n",
            "Epoch 1355/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 2.8088 - acc: 0.0000e+00 - val_loss: 0.9670 - val_acc: 0.0000e+00\n",
            "Epoch 1356/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 2.8054 - acc: 0.0000e+00 - val_loss: 0.9587 - val_acc: 0.0000e+00\n",
            "Epoch 1357/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 2.7984 - acc: 0.0000e+00 - val_loss: 0.9583 - val_acc: 0.0000e+00\n",
            "Epoch 1358/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 2.7952 - acc: 0.0000e+00 - val_loss: 0.9650 - val_acc: 0.0000e+00\n",
            "Epoch 1359/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 2.7911 - acc: 0.0000e+00 - val_loss: 0.9588 - val_acc: 0.0000e+00\n",
            "Epoch 1360/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 2.7877 - acc: 0.0000e+00 - val_loss: 0.9590 - val_acc: 0.0000e+00\n",
            "Epoch 1361/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 2.7807 - acc: 0.0000e+00 - val_loss: 0.9581 - val_acc: 0.0000e+00\n",
            "Epoch 1362/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 2.7773 - acc: 0.0000e+00 - val_loss: 0.9531 - val_acc: 0.0000e+00\n",
            "Epoch 1363/2000\n",
            "80/80 [==============================] - 0s 121us/step - loss: 2.7729 - acc: 0.0000e+00 - val_loss: 0.9545 - val_acc: 0.0000e+00\n",
            "Epoch 1364/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 2.7680 - acc: 0.0000e+00 - val_loss: 0.9607 - val_acc: 0.0000e+00\n",
            "Epoch 1365/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 2.7666 - acc: 0.0000e+00 - val_loss: 0.9505 - val_acc: 0.0000e+00\n",
            "Epoch 1366/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 2.7646 - acc: 0.0000e+00 - val_loss: 0.9497 - val_acc: 0.0000e+00\n",
            "Epoch 1367/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 2.7551 - acc: 0.0000e+00 - val_loss: 0.9528 - val_acc: 0.0000e+00\n",
            "Epoch 1368/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 2.7562 - acc: 0.0000e+00 - val_loss: 0.9476 - val_acc: 0.0000e+00\n",
            "Epoch 1369/2000\n",
            "80/80 [==============================] - 0s 121us/step - loss: 2.7560 - acc: 0.0000e+00 - val_loss: 0.9404 - val_acc: 0.0000e+00\n",
            "Epoch 1370/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 2.7449 - acc: 0.0000e+00 - val_loss: 0.9580 - val_acc: 0.0000e+00\n",
            "Epoch 1371/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 2.7538 - acc: 0.0000e+00 - val_loss: 0.9376 - val_acc: 0.0000e+00\n",
            "Epoch 1372/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 2.7364 - acc: 0.0000e+00 - val_loss: 0.9440 - val_acc: 0.0000e+00\n",
            "Epoch 1373/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 2.7425 - acc: 0.0000e+00 - val_loss: 0.9379 - val_acc: 0.0000e+00\n",
            "Epoch 1374/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 2.7305 - acc: 0.0000e+00 - val_loss: 0.9411 - val_acc: 0.0000e+00\n",
            "Epoch 1375/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 2.7279 - acc: 0.0000e+00 - val_loss: 0.9403 - val_acc: 0.0000e+00\n",
            "Epoch 1376/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 2.7273 - acc: 0.0000e+00 - val_loss: 0.9401 - val_acc: 0.0000e+00\n",
            "Epoch 1377/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 2.7133 - acc: 0.0000e+00 - val_loss: 0.9506 - val_acc: 0.0000e+00\n",
            "Epoch 1378/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 2.7177 - acc: 0.0000e+00 - val_loss: 0.9383 - val_acc: 0.0000e+00\n",
            "Epoch 1379/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 2.7147 - acc: 0.0000e+00 - val_loss: 0.9296 - val_acc: 0.0000e+00\n",
            "Epoch 1380/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 2.7063 - acc: 0.0000e+00 - val_loss: 0.9355 - val_acc: 0.0000e+00\n",
            "Epoch 1381/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 2.7054 - acc: 0.0000e+00 - val_loss: 0.9198 - val_acc: 0.0000e+00\n",
            "Epoch 1382/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 2.6945 - acc: 0.0000e+00 - val_loss: 0.9217 - val_acc: 0.0000e+00\n",
            "Epoch 1383/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 2.6970 - acc: 0.0000e+00 - val_loss: 0.9208 - val_acc: 0.0000e+00\n",
            "Epoch 1384/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 2.6860 - acc: 0.0000e+00 - val_loss: 0.9377 - val_acc: 0.0000e+00\n",
            "Epoch 1385/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 2.6874 - acc: 0.0000e+00 - val_loss: 0.9253 - val_acc: 0.0000e+00\n",
            "Epoch 1386/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 2.6799 - acc: 0.0000e+00 - val_loss: 0.9233 - val_acc: 0.0000e+00\n",
            "Epoch 1387/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 2.6765 - acc: 0.0000e+00 - val_loss: 0.9278 - val_acc: 0.0000e+00\n",
            "Epoch 1388/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 2.6708 - acc: 0.0000e+00 - val_loss: 0.9266 - val_acc: 0.0000e+00\n",
            "Epoch 1389/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 2.6659 - acc: 0.0000e+00 - val_loss: 0.9257 - val_acc: 0.0000e+00\n",
            "Epoch 1390/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 2.6651 - acc: 0.0000e+00 - val_loss: 0.9267 - val_acc: 0.0000e+00\n",
            "Epoch 1391/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 2.6565 - acc: 0.0000e+00 - val_loss: 0.9368 - val_acc: 0.0000e+00\n",
            "Epoch 1392/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 2.6591 - acc: 0.0000e+00 - val_loss: 0.9195 - val_acc: 0.0000e+00\n",
            "Epoch 1393/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 2.6513 - acc: 0.0000e+00 - val_loss: 0.9134 - val_acc: 0.0000e+00\n",
            "Epoch 1394/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 2.6457 - acc: 0.0000e+00 - val_loss: 0.9169 - val_acc: 0.0000e+00\n",
            "Epoch 1395/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 2.6450 - acc: 0.0000e+00 - val_loss: 0.9083 - val_acc: 0.0000e+00\n",
            "Epoch 1396/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 2.6368 - acc: 0.0000e+00 - val_loss: 0.9060 - val_acc: 0.0000e+00\n",
            "Epoch 1397/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 2.6359 - acc: 0.0000e+00 - val_loss: 0.9078 - val_acc: 0.0000e+00\n",
            "Epoch 1398/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 2.6285 - acc: 0.0000e+00 - val_loss: 0.9199 - val_acc: 0.0000e+00\n",
            "Epoch 1399/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 2.6278 - acc: 0.0000e+00 - val_loss: 0.9098 - val_acc: 0.0000e+00\n",
            "Epoch 1400/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 2.6197 - acc: 0.0000e+00 - val_loss: 0.9091 - val_acc: 0.0000e+00\n",
            "Epoch 1401/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 2.6164 - acc: 0.0000e+00 - val_loss: 0.9162 - val_acc: 0.0000e+00\n",
            "Epoch 1402/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 2.6131 - acc: 0.0000e+00 - val_loss: 0.9135 - val_acc: 0.0000e+00\n",
            "Epoch 1403/2000\n",
            "80/80 [==============================] - 0s 135us/step - loss: 2.6072 - acc: 0.0000e+00 - val_loss: 0.9105 - val_acc: 0.0000e+00\n",
            "Epoch 1404/2000\n",
            "80/80 [==============================] - 0s 135us/step - loss: 2.6044 - acc: 0.0000e+00 - val_loss: 0.9142 - val_acc: 0.0000e+00\n",
            "Epoch 1405/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 2.6000 - acc: 0.0000e+00 - val_loss: 0.9089 - val_acc: 0.0000e+00\n",
            "Epoch 1406/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 2.5950 - acc: 0.0000e+00 - val_loss: 0.9036 - val_acc: 0.0000e+00\n",
            "Epoch 1407/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 2.5915 - acc: 0.0000e+00 - val_loss: 0.9041 - val_acc: 0.0000e+00\n",
            "Epoch 1408/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 2.5881 - acc: 0.0000e+00 - val_loss: 0.8988 - val_acc: 0.0000e+00\n",
            "Epoch 1409/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 2.5827 - acc: 0.0000e+00 - val_loss: 0.8968 - val_acc: 0.0000e+00\n",
            "Epoch 1410/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 2.5799 - acc: 0.0000e+00 - val_loss: 0.9033 - val_acc: 0.0000e+00\n",
            "Epoch 1411/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 2.5766 - acc: 0.0000e+00 - val_loss: 0.8987 - val_acc: 0.0000e+00\n",
            "Epoch 1412/2000\n",
            "80/80 [==============================] - 0s 139us/step - loss: 2.5710 - acc: 0.0000e+00 - val_loss: 0.8912 - val_acc: 0.0000e+00\n",
            "Epoch 1413/2000\n",
            "80/80 [==============================] - 0s 142us/step - loss: 2.5703 - acc: 0.0000e+00 - val_loss: 0.8908 - val_acc: 0.0000e+00\n",
            "Epoch 1414/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 2.5632 - acc: 0.0000e+00 - val_loss: 0.8979 - val_acc: 0.0000e+00\n",
            "Epoch 1415/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 2.5666 - acc: 0.0000e+00 - val_loss: 0.8933 - val_acc: 0.0000e+00\n",
            "Epoch 1416/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 2.5679 - acc: 0.0000e+00 - val_loss: 0.8963 - val_acc: 0.0000e+00\n",
            "Epoch 1417/2000\n",
            "80/80 [==============================] - 0s 130us/step - loss: 2.5529 - acc: 0.0000e+00 - val_loss: 0.9215 - val_acc: 0.0000e+00\n",
            "Epoch 1418/2000\n",
            "80/80 [==============================] - 0s 136us/step - loss: 2.5633 - acc: 0.0000e+00 - val_loss: 0.8832 - val_acc: 0.0000e+00\n",
            "Epoch 1419/2000\n",
            "80/80 [==============================] - 0s 142us/step - loss: 2.5482 - acc: 0.0000e+00 - val_loss: 0.8746 - val_acc: 0.0000e+00\n",
            "Epoch 1420/2000\n",
            "80/80 [==============================] - 0s 132us/step - loss: 2.5475 - acc: 0.0000e+00 - val_loss: 0.8739 - val_acc: 0.0000e+00\n",
            "Epoch 1421/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 2.5379 - acc: 0.0000e+00 - val_loss: 0.8933 - val_acc: 0.0000e+00\n",
            "Epoch 1422/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 2.5416 - acc: 0.0000e+00 - val_loss: 0.8748 - val_acc: 0.0000e+00\n",
            "Epoch 1423/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 2.5345 - acc: 0.0000e+00 - val_loss: 0.8773 - val_acc: 0.0000e+00\n",
            "Epoch 1424/2000\n",
            "80/80 [==============================] - 0s 141us/step - loss: 2.5289 - acc: 0.0000e+00 - val_loss: 0.8952 - val_acc: 0.0000e+00\n",
            "Epoch 1425/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 2.5227 - acc: 0.0000e+00 - val_loss: 0.8951 - val_acc: 0.0000e+00\n",
            "Epoch 1426/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 2.5190 - acc: 0.0000e+00 - val_loss: 0.8783 - val_acc: 0.0000e+00\n",
            "Epoch 1427/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 2.5184 - acc: 0.0000e+00 - val_loss: 0.8715 - val_acc: 0.0000e+00\n",
            "Epoch 1428/2000\n",
            "80/80 [==============================] - 0s 114us/step - loss: 2.5115 - acc: 0.0000e+00 - val_loss: 0.8845 - val_acc: 0.0000e+00\n",
            "Epoch 1429/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 2.5107 - acc: 0.0000e+00 - val_loss: 0.8626 - val_acc: 0.0000e+00\n",
            "Epoch 1430/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 2.5020 - acc: 0.0000e+00 - val_loss: 0.8622 - val_acc: 0.0000e+00\n",
            "Epoch 1431/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 2.5012 - acc: 0.0000e+00 - val_loss: 0.8707 - val_acc: 0.0000e+00\n",
            "Epoch 1432/2000\n",
            "80/80 [==============================] - 0s 133us/step - loss: 2.4927 - acc: 0.0000e+00 - val_loss: 0.8864 - val_acc: 0.0000e+00\n",
            "Epoch 1433/2000\n",
            "80/80 [==============================] - 0s 119us/step - loss: 2.4935 - acc: 0.0000e+00 - val_loss: 0.8684 - val_acc: 0.0000e+00\n",
            "Epoch 1434/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 2.4940 - acc: 0.0000e+00 - val_loss: 0.8662 - val_acc: 0.0000e+00\n",
            "Epoch 1435/2000\n",
            "80/80 [==============================] - 0s 139us/step - loss: 2.4891 - acc: 0.0000e+00 - val_loss: 0.8780 - val_acc: 0.0000e+00\n",
            "Epoch 1436/2000\n",
            "80/80 [==============================] - 0s 137us/step - loss: 2.4790 - acc: 0.0000e+00 - val_loss: 0.8770 - val_acc: 0.0000e+00\n",
            "Epoch 1437/2000\n",
            "80/80 [==============================] - 0s 116us/step - loss: 2.4764 - acc: 0.0000e+00 - val_loss: 0.8669 - val_acc: 0.0000e+00\n",
            "Epoch 1438/2000\n",
            "80/80 [==============================] - 0s 133us/step - loss: 2.4795 - acc: 0.0000e+00 - val_loss: 0.8701 - val_acc: 0.0000e+00\n",
            "Epoch 1439/2000\n",
            "80/80 [==============================] - 0s 135us/step - loss: 2.4650 - acc: 0.0000e+00 - val_loss: 0.8984 - val_acc: 0.0000e+00\n",
            "Epoch 1440/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 2.4766 - acc: 0.0000e+00 - val_loss: 0.8647 - val_acc: 0.0000e+00\n",
            "Epoch 1441/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 2.4611 - acc: 0.0000e+00 - val_loss: 0.8591 - val_acc: 0.0000e+00\n",
            "Epoch 1442/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 2.4644 - acc: 0.0000e+00 - val_loss: 0.8549 - val_acc: 0.0000e+00\n",
            "Epoch 1443/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 2.4506 - acc: 0.0000e+00 - val_loss: 0.8871 - val_acc: 0.0000e+00\n",
            "Epoch 1444/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 2.4652 - acc: 0.0000e+00 - val_loss: 0.8508 - val_acc: 0.0000e+00\n",
            "Epoch 1445/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 2.4429 - acc: 0.0000e+00 - val_loss: 0.8650 - val_acc: 0.0000e+00\n",
            "Epoch 1446/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 2.4525 - acc: 0.0000e+00 - val_loss: 0.8812 - val_acc: 0.0000e+00\n",
            "Epoch 1447/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 2.4394 - acc: 0.0000e+00 - val_loss: 0.8724 - val_acc: 0.0000e+00\n",
            "Epoch 1448/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 2.4327 - acc: 0.0000e+00 - val_loss: 0.8510 - val_acc: 0.0000e+00\n",
            "Epoch 1449/2000\n",
            "80/80 [==============================] - 0s 145us/step - loss: 2.4289 - acc: 0.0000e+00 - val_loss: 0.8449 - val_acc: 0.0000e+00\n",
            "Epoch 1450/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 2.4241 - acc: 0.0000e+00 - val_loss: 0.8468 - val_acc: 0.0000e+00\n",
            "Epoch 1451/2000\n",
            "80/80 [==============================] - 0s 111us/step - loss: 2.4217 - acc: 0.0000e+00 - val_loss: 0.8462 - val_acc: 0.0000e+00\n",
            "Epoch 1452/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 2.4162 - acc: 0.0000e+00 - val_loss: 0.8517 - val_acc: 0.0000e+00\n",
            "Epoch 1453/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 2.4115 - acc: 0.0000e+00 - val_loss: 0.8657 - val_acc: 0.0000e+00\n",
            "Epoch 1454/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 2.4097 - acc: 0.0000e+00 - val_loss: 0.8631 - val_acc: 0.0000e+00\n",
            "Epoch 1455/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 2.4054 - acc: 0.0000e+00 - val_loss: 0.8467 - val_acc: 0.0000e+00\n",
            "Epoch 1456/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 2.4005 - acc: 0.0000e+00 - val_loss: 0.8441 - val_acc: 0.0000e+00\n",
            "Epoch 1457/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 2.3964 - acc: 0.0000e+00 - val_loss: 0.8450 - val_acc: 0.0000e+00\n",
            "Epoch 1458/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 2.3947 - acc: 0.0000e+00 - val_loss: 0.8436 - val_acc: 0.0000e+00\n",
            "Epoch 1459/2000\n",
            "80/80 [==============================] - 0s 145us/step - loss: 2.3900 - acc: 0.0000e+00 - val_loss: 0.8506 - val_acc: 0.0000e+00\n",
            "Epoch 1460/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 2.3845 - acc: 0.0000e+00 - val_loss: 0.8527 - val_acc: 0.0000e+00\n",
            "Epoch 1461/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 2.3819 - acc: 0.0000e+00 - val_loss: 0.8464 - val_acc: 0.0000e+00\n",
            "Epoch 1462/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 2.3787 - acc: 0.0000e+00 - val_loss: 0.8477 - val_acc: 0.0000e+00\n",
            "Epoch 1463/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 2.3733 - acc: 0.0000e+00 - val_loss: 0.8413 - val_acc: 0.0000e+00\n",
            "Epoch 1464/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 2.3700 - acc: 0.0000e+00 - val_loss: 0.8278 - val_acc: 0.0000e+00\n",
            "Epoch 1465/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 2.3699 - acc: 0.0000e+00 - val_loss: 0.8541 - val_acc: 0.0000e+00\n",
            "Epoch 1466/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 2.3728 - acc: 0.0000e+00 - val_loss: 0.8345 - val_acc: 0.0000e+00\n",
            "Epoch 1467/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 2.3597 - acc: 0.0000e+00 - val_loss: 0.8330 - val_acc: 0.0000e+00\n",
            "Epoch 1468/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 2.3613 - acc: 0.0000e+00 - val_loss: 0.8412 - val_acc: 0.0000e+00\n",
            "Epoch 1469/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 2.3510 - acc: 0.0000e+00 - val_loss: 0.8409 - val_acc: 0.0000e+00\n",
            "Epoch 1470/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 2.3485 - acc: 0.0000e+00 - val_loss: 0.8477 - val_acc: 0.0000e+00\n",
            "Epoch 1471/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 2.3677 - acc: 0.0000e+00 - val_loss: 0.8232 - val_acc: 0.0000e+00\n",
            "Epoch 1472/2000\n",
            "80/80 [==============================] - 0s 222us/step - loss: 2.3398 - acc: 0.0000e+00 - val_loss: 0.8558 - val_acc: 0.0000e+00\n",
            "Epoch 1473/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 2.3526 - acc: 0.0000e+00 - val_loss: 0.8316 - val_acc: 0.0000e+00\n",
            "Epoch 1474/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 2.3311 - acc: 0.0000e+00 - val_loss: 0.8343 - val_acc: 0.0000e+00\n",
            "Epoch 1475/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 2.3395 - acc: 0.0000e+00 - val_loss: 0.8520 - val_acc: 0.0000e+00\n",
            "Epoch 1476/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 2.3324 - acc: 0.0000e+00 - val_loss: 0.8316 - val_acc: 0.0000e+00\n",
            "Epoch 1477/2000\n",
            "80/80 [==============================] - 0s 138us/step - loss: 2.3201 - acc: 0.0000e+00 - val_loss: 0.8171 - val_acc: 0.0000e+00\n",
            "Epoch 1478/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 2.3218 - acc: 0.0000e+00 - val_loss: 0.8144 - val_acc: 0.0000e+00\n",
            "Epoch 1479/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 2.3143 - acc: 0.0000e+00 - val_loss: 0.8327 - val_acc: 0.0000e+00\n",
            "Epoch 1480/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 2.3131 - acc: 0.0000e+00 - val_loss: 0.8209 - val_acc: 0.0000e+00\n",
            "Epoch 1481/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 2.3147 - acc: 0.0000e+00 - val_loss: 0.8306 - val_acc: 0.0000e+00\n",
            "Epoch 1482/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 2.3030 - acc: 0.0000e+00 - val_loss: 0.8486 - val_acc: 0.0000e+00\n",
            "Epoch 1483/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 2.3096 - acc: 0.0000e+00 - val_loss: 0.8165 - val_acc: 0.0000e+00\n",
            "Epoch 1484/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 2.2987 - acc: 0.0000e+00 - val_loss: 0.8099 - val_acc: 0.0000e+00\n",
            "Epoch 1485/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 2.2946 - acc: 0.0000e+00 - val_loss: 0.8226 - val_acc: 0.0000e+00\n",
            "Epoch 1486/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 2.2900 - acc: 0.0000e+00 - val_loss: 0.8152 - val_acc: 0.0000e+00\n",
            "Epoch 1487/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 2.2834 - acc: 0.0000e+00 - val_loss: 0.8120 - val_acc: 0.0000e+00\n",
            "Epoch 1488/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 2.2804 - acc: 0.0000e+00 - val_loss: 0.8207 - val_acc: 0.0000e+00\n",
            "Epoch 1489/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 2.2753 - acc: 0.0000e+00 - val_loss: 0.8287 - val_acc: 0.0000e+00\n",
            "Epoch 1490/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 2.2736 - acc: 0.0000e+00 - val_loss: 0.8219 - val_acc: 0.0000e+00\n",
            "Epoch 1491/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 2.2825 - acc: 0.0000e+00 - val_loss: 0.8226 - val_acc: 0.0000e+00\n",
            "Epoch 1492/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 2.2661 - acc: 0.0000e+00 - val_loss: 0.8183 - val_acc: 0.0000e+00\n",
            "Epoch 1493/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 2.2628 - acc: 0.0000e+00 - val_loss: 0.8014 - val_acc: 0.0000e+00\n",
            "Epoch 1494/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 2.2604 - acc: 0.0000e+00 - val_loss: 0.8029 - val_acc: 0.0000e+00\n",
            "Epoch 1495/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 2.2545 - acc: 0.0000e+00 - val_loss: 0.8173 - val_acc: 0.0000e+00\n",
            "Epoch 1496/2000\n",
            "80/80 [==============================] - 0s 137us/step - loss: 2.2530 - acc: 0.0000e+00 - val_loss: 0.8021 - val_acc: 0.0000e+00\n",
            "Epoch 1497/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 2.2488 - acc: 0.0000e+00 - val_loss: 0.8051 - val_acc: 0.0000e+00\n",
            "Epoch 1498/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 2.2427 - acc: 0.0000e+00 - val_loss: 0.8265 - val_acc: 0.0000e+00\n",
            "Epoch 1499/2000\n",
            "80/80 [==============================] - 0s 251us/step - loss: 2.2480 - acc: 0.0000e+00 - val_loss: 0.8099 - val_acc: 0.0000e+00\n",
            "Epoch 1500/2000\n",
            "80/80 [==============================] - 0s 132us/step - loss: 2.2413 - acc: 0.0000e+00 - val_loss: 0.8240 - val_acc: 0.0000e+00\n",
            "Epoch 1501/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 2.2373 - acc: 0.0000e+00 - val_loss: 0.8066 - val_acc: 0.0000e+00\n",
            "Epoch 1502/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 2.2303 - acc: 0.0000e+00 - val_loss: 0.8018 - val_acc: 0.0000e+00\n",
            "Epoch 1503/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 2.2250 - acc: 0.0000e+00 - val_loss: 0.8020 - val_acc: 0.0000e+00\n",
            "Epoch 1504/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 2.2223 - acc: 0.0000e+00 - val_loss: 0.7895 - val_acc: 0.0000e+00\n",
            "Epoch 1505/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 2.2196 - acc: 0.0000e+00 - val_loss: 0.7920 - val_acc: 0.0000e+00\n",
            "Epoch 1506/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 2.2141 - acc: 0.0000e+00 - val_loss: 0.8085 - val_acc: 0.0000e+00\n",
            "Epoch 1507/2000\n",
            "80/80 [==============================] - 0s 141us/step - loss: 2.2119 - acc: 0.0000e+00 - val_loss: 0.8149 - val_acc: 0.0000e+00\n",
            "Epoch 1508/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 2.2286 - acc: 0.0000e+00 - val_loss: 0.8161 - val_acc: 0.0000e+00\n",
            "Epoch 1509/2000\n",
            "80/80 [==============================] - 0s 136us/step - loss: 2.2099 - acc: 0.0000e+00 - val_loss: 0.8028 - val_acc: 0.0000e+00\n",
            "Epoch 1510/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 2.2002 - acc: 0.0000e+00 - val_loss: 0.7922 - val_acc: 0.0000e+00\n",
            "Epoch 1511/2000\n",
            "80/80 [==============================] - 0s 133us/step - loss: 2.2043 - acc: 0.0000e+00 - val_loss: 0.8070 - val_acc: 0.0000e+00\n",
            "Epoch 1512/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 2.1988 - acc: 0.0000e+00 - val_loss: 0.7894 - val_acc: 0.0000e+00\n",
            "Epoch 1513/2000\n",
            "80/80 [==============================] - 0s 145us/step - loss: 2.1905 - acc: 0.0000e+00 - val_loss: 0.7884 - val_acc: 0.0000e+00\n",
            "Epoch 1514/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 2.1875 - acc: 0.0000e+00 - val_loss: 0.7961 - val_acc: 0.0000e+00\n",
            "Epoch 1515/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 2.1819 - acc: 0.0000e+00 - val_loss: 0.7959 - val_acc: 0.0000e+00\n",
            "Epoch 1516/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 2.1785 - acc: 0.0000e+00 - val_loss: 0.7936 - val_acc: 0.0000e+00\n",
            "Epoch 1517/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 2.1803 - acc: 0.0000e+00 - val_loss: 0.8174 - val_acc: 0.0000e+00\n",
            "Epoch 1518/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 2.1833 - acc: 0.0000e+00 - val_loss: 0.7992 - val_acc: 0.0000e+00\n",
            "Epoch 1519/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 2.1687 - acc: 0.0000e+00 - val_loss: 0.7937 - val_acc: 0.0000e+00\n",
            "Epoch 1520/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 2.1740 - acc: 0.0000e+00 - val_loss: 0.8103 - val_acc: 0.0000e+00\n",
            "Epoch 1521/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 2.1706 - acc: 0.0000e+00 - val_loss: 0.7878 - val_acc: 0.0000e+00\n",
            "Epoch 1522/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 2.1576 - acc: 0.0000e+00 - val_loss: 0.7791 - val_acc: 0.0000e+00\n",
            "Epoch 1523/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 2.1624 - acc: 0.0000e+00 - val_loss: 0.8011 - val_acc: 0.0000e+00\n",
            "Epoch 1524/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 2.1615 - acc: 0.0000e+00 - val_loss: 0.7814 - val_acc: 0.0000e+00\n",
            "Epoch 1525/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 2.1491 - acc: 0.0000e+00 - val_loss: 0.7810 - val_acc: 0.0000e+00\n",
            "Epoch 1526/2000\n",
            "80/80 [==============================] - 0s 131us/step - loss: 2.1496 - acc: 0.0000e+00 - val_loss: 0.7827 - val_acc: 0.0000e+00\n",
            "Epoch 1527/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 2.1401 - acc: 0.0000e+00 - val_loss: 0.7947 - val_acc: 0.0000e+00\n",
            "Epoch 1528/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 2.1443 - acc: 0.0000e+00 - val_loss: 0.7953 - val_acc: 0.0000e+00\n",
            "Epoch 1529/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 2.1522 - acc: 0.0000e+00 - val_loss: 0.7817 - val_acc: 0.0000e+00\n",
            "Epoch 1530/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 2.1297 - acc: 0.0000e+00 - val_loss: 0.8218 - val_acc: 0.0000e+00\n",
            "Epoch 1531/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 2.1499 - acc: 0.0000e+00 - val_loss: 0.8058 - val_acc: 0.0000e+00\n",
            "Epoch 1532/2000\n",
            "80/80 [==============================] - 0s 202us/step - loss: 2.1336 - acc: 0.0000e+00 - val_loss: 0.8188 - val_acc: 0.0000e+00\n",
            "Epoch 1533/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 2.1557 - acc: 0.0000e+00 - val_loss: 0.7736 - val_acc: 0.0000e+00\n",
            "Epoch 1534/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 2.1185 - acc: 0.0000e+00 - val_loss: 0.8128 - val_acc: 0.0000e+00\n",
            "Epoch 1535/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 2.1384 - acc: 0.0000e+00 - val_loss: 0.7855 - val_acc: 0.0000e+00\n",
            "Epoch 1536/2000\n",
            "80/80 [==============================] - 0s 133us/step - loss: 2.1182 - acc: 0.0000e+00 - val_loss: 0.8206 - val_acc: 0.0000e+00\n",
            "Epoch 1537/2000\n",
            "80/80 [==============================] - 0s 142us/step - loss: 2.1562 - acc: 0.0000e+00 - val_loss: 0.7973 - val_acc: 0.0000e+00\n",
            "Epoch 1538/2000\n",
            "80/80 [==============================] - 0s 132us/step - loss: 2.1365 - acc: 0.0000e+00 - val_loss: 0.8276 - val_acc: 0.0000e+00\n",
            "Epoch 1539/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 2.1299 - acc: 0.0000e+00 - val_loss: 0.8562 - val_acc: 0.0000e+00\n",
            "Epoch 1540/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 2.1428 - acc: 0.0000e+00 - val_loss: 0.8173 - val_acc: 0.0000e+00\n",
            "Epoch 1541/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 2.1087 - acc: 0.0000e+00 - val_loss: 0.8232 - val_acc: 0.0000e+00\n",
            "Epoch 1542/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 2.1235 - acc: 0.0000e+00 - val_loss: 0.7934 - val_acc: 0.0000e+00\n",
            "Epoch 1543/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 2.1117 - acc: 0.0000e+00 - val_loss: 0.7861 - val_acc: 0.0000e+00\n",
            "Epoch 1544/2000\n",
            "80/80 [==============================] - 0s 133us/step - loss: 2.0939 - acc: 0.0000e+00 - val_loss: 0.8086 - val_acc: 0.0000e+00\n",
            "Epoch 1545/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 2.1093 - acc: 0.0000e+00 - val_loss: 0.7891 - val_acc: 0.0000e+00\n",
            "Epoch 1546/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 2.1011 - acc: 0.0000e+00 - val_loss: 0.7979 - val_acc: 0.0000e+00\n",
            "Epoch 1547/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 2.0986 - acc: 0.0000e+00 - val_loss: 0.8217 - val_acc: 0.0000e+00\n",
            "Epoch 1548/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 2.0919 - acc: 0.0000e+00 - val_loss: 0.8429 - val_acc: 0.0000e+00\n",
            "Epoch 1549/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 2.1003 - acc: 0.0000e+00 - val_loss: 0.8002 - val_acc: 0.0000e+00\n",
            "Epoch 1550/2000\n",
            "80/80 [==============================] - 0s 195us/step - loss: 2.0726 - acc: 0.0000e+00 - val_loss: 0.8129 - val_acc: 0.0000e+00\n",
            "Epoch 1551/2000\n",
            "80/80 [==============================] - 0s 208us/step - loss: 2.1059 - acc: 0.0000e+00 - val_loss: 0.7736 - val_acc: 0.0000e+00\n",
            "Epoch 1552/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 2.0827 - acc: 0.0000e+00 - val_loss: 0.8174 - val_acc: 0.0000e+00\n",
            "Epoch 1553/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 2.0894 - acc: 0.0000e+00 - val_loss: 0.7956 - val_acc: 0.0000e+00\n",
            "Epoch 1554/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 2.0686 - acc: 0.0000e+00 - val_loss: 0.7790 - val_acc: 0.0000e+00\n",
            "Epoch 1555/2000\n",
            "80/80 [==============================] - 0s 121us/step - loss: 2.0624 - acc: 0.0000e+00 - val_loss: 0.8049 - val_acc: 0.0000e+00\n",
            "Epoch 1556/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 2.0762 - acc: 0.0000e+00 - val_loss: 0.7875 - val_acc: 0.0000e+00\n",
            "Epoch 1557/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 2.0523 - acc: 0.0000e+00 - val_loss: 0.8122 - val_acc: 0.0000e+00\n",
            "Epoch 1558/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 2.0574 - acc: 0.0000e+00 - val_loss: 0.7841 - val_acc: 0.0000e+00\n",
            "Epoch 1559/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 2.0421 - acc: 0.0000e+00 - val_loss: 0.7927 - val_acc: 0.0000e+00\n",
            "Epoch 1560/2000\n",
            "80/80 [==============================] - 0s 113us/step - loss: 2.0675 - acc: 0.0000e+00 - val_loss: 0.7946 - val_acc: 0.0000e+00\n",
            "Epoch 1561/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 2.0660 - acc: 0.0000e+00 - val_loss: 0.7745 - val_acc: 0.0000e+00\n",
            "Epoch 1562/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 2.0279 - acc: 0.0000e+00 - val_loss: 0.8081 - val_acc: 0.0000e+00\n",
            "Epoch 1563/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 2.0456 - acc: 0.0000e+00 - val_loss: 0.7894 - val_acc: 0.0000e+00\n",
            "Epoch 1564/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 2.0257 - acc: 0.0000e+00 - val_loss: 0.7908 - val_acc: 0.0000e+00\n",
            "Epoch 1565/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 2.0495 - acc: 0.0000e+00 - val_loss: 0.7687 - val_acc: 0.0000e+00\n",
            "Epoch 1566/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 2.0247 - acc: 0.0000e+00 - val_loss: 0.7948 - val_acc: 0.0000e+00\n",
            "Epoch 1567/2000\n",
            "80/80 [==============================] - 0s 115us/step - loss: 2.0236 - acc: 0.0000e+00 - val_loss: 0.7825 - val_acc: 0.0000e+00\n",
            "Epoch 1568/2000\n",
            "80/80 [==============================] - 0s 145us/step - loss: 2.0162 - acc: 0.0000e+00 - val_loss: 0.7582 - val_acc: 0.0000e+00\n",
            "Epoch 1569/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 2.0114 - acc: 0.0000e+00 - val_loss: 0.7569 - val_acc: 0.0000e+00\n",
            "Epoch 1570/2000\n",
            "80/80 [==============================] - 0s 137us/step - loss: 2.0138 - acc: 0.0000e+00 - val_loss: 0.7604 - val_acc: 0.0000e+00\n",
            "Epoch 1571/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 2.0012 - acc: 0.0000e+00 - val_loss: 0.7871 - val_acc: 0.0000e+00\n",
            "Epoch 1572/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 2.0062 - acc: 0.0000e+00 - val_loss: 0.7620 - val_acc: 0.0000e+00\n",
            "Epoch 1573/2000\n",
            "80/80 [==============================] - 0s 145us/step - loss: 1.9923 - acc: 0.0000e+00 - val_loss: 0.7624 - val_acc: 0.0000e+00\n",
            "Epoch 1574/2000\n",
            "80/80 [==============================] - 0s 125us/step - loss: 1.9998 - acc: 0.0000e+00 - val_loss: 0.7714 - val_acc: 0.0000e+00\n",
            "Epoch 1575/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 1.9879 - acc: 0.0000e+00 - val_loss: 0.7597 - val_acc: 0.0000e+00\n",
            "Epoch 1576/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 1.9822 - acc: 0.0000e+00 - val_loss: 0.7544 - val_acc: 0.0000e+00\n",
            "Epoch 1577/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 1.9801 - acc: 0.0000e+00 - val_loss: 0.7597 - val_acc: 0.0000e+00\n",
            "Epoch 1578/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 1.9764 - acc: 0.0000e+00 - val_loss: 0.7542 - val_acc: 0.0000e+00\n",
            "Epoch 1579/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 1.9724 - acc: 0.0000e+00 - val_loss: 0.7483 - val_acc: 0.0000e+00\n",
            "Epoch 1580/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 1.9699 - acc: 0.0000e+00 - val_loss: 0.7532 - val_acc: 0.0000e+00\n",
            "Epoch 1581/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 1.9658 - acc: 0.0000e+00 - val_loss: 0.7494 - val_acc: 0.0000e+00\n",
            "Epoch 1582/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 1.9621 - acc: 0.0000e+00 - val_loss: 0.7440 - val_acc: 0.0000e+00\n",
            "Epoch 1583/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 1.9593 - acc: 0.0000e+00 - val_loss: 0.7542 - val_acc: 0.0000e+00\n",
            "Epoch 1584/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 1.9604 - acc: 0.0000e+00 - val_loss: 0.7477 - val_acc: 0.0000e+00\n",
            "Epoch 1585/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 1.9633 - acc: 0.0000e+00 - val_loss: 0.7520 - val_acc: 0.0000e+00\n",
            "Epoch 1586/2000\n",
            "80/80 [==============================] - 0s 137us/step - loss: 1.9517 - acc: 0.0000e+00 - val_loss: 0.7426 - val_acc: 0.0000e+00\n",
            "Epoch 1587/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 1.9502 - acc: 0.0000e+00 - val_loss: 0.7408 - val_acc: 0.0000e+00\n",
            "Epoch 1588/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 1.9468 - acc: 0.0000e+00 - val_loss: 0.7479 - val_acc: 0.0000e+00\n",
            "Epoch 1589/2000\n",
            "80/80 [==============================] - 0s 132us/step - loss: 1.9440 - acc: 0.0000e+00 - val_loss: 0.7285 - val_acc: 0.0000e+00\n",
            "Epoch 1590/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 1.9393 - acc: 0.0000e+00 - val_loss: 0.7363 - val_acc: 0.0000e+00\n",
            "Epoch 1591/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 1.9353 - acc: 0.0000e+00 - val_loss: 0.7301 - val_acc: 0.0000e+00\n",
            "Epoch 1592/2000\n",
            "80/80 [==============================] - 0s 120us/step - loss: 1.9307 - acc: 0.0000e+00 - val_loss: 0.7552 - val_acc: 0.0000e+00\n",
            "Epoch 1593/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 1.9383 - acc: 0.0000e+00 - val_loss: 0.7352 - val_acc: 0.0000e+00\n",
            "Epoch 1594/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 1.9251 - acc: 0.0000e+00 - val_loss: 0.7517 - val_acc: 0.0000e+00\n",
            "Epoch 1595/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 1.9283 - acc: 0.0000e+00 - val_loss: 0.7360 - val_acc: 0.0000e+00\n",
            "Epoch 1596/2000\n",
            "80/80 [==============================] - 0s 122us/step - loss: 1.9218 - acc: 0.0000e+00 - val_loss: 0.7468 - val_acc: 0.0000e+00\n",
            "Epoch 1597/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 1.9217 - acc: 0.0000e+00 - val_loss: 0.7260 - val_acc: 0.0000e+00\n",
            "Epoch 1598/2000\n",
            "80/80 [==============================] - 0s 121us/step - loss: 1.9164 - acc: 0.0000e+00 - val_loss: 0.7419 - val_acc: 0.0000e+00\n",
            "Epoch 1599/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 1.9175 - acc: 0.0000e+00 - val_loss: 0.7227 - val_acc: 0.0000e+00\n",
            "Epoch 1600/2000\n",
            "80/80 [==============================] - 0s 135us/step - loss: 1.9103 - acc: 0.0000e+00 - val_loss: 0.7303 - val_acc: 0.0000e+00\n",
            "Epoch 1601/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 1.9057 - acc: 0.0000e+00 - val_loss: 0.7414 - val_acc: 0.0000e+00\n",
            "Epoch 1602/2000\n",
            "80/80 [==============================] - 0s 127us/step - loss: 1.9049 - acc: 0.0000e+00 - val_loss: 0.7274 - val_acc: 0.0000e+00\n",
            "Epoch 1603/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 1.9065 - acc: 0.0000e+00 - val_loss: 0.7294 - val_acc: 0.0000e+00\n",
            "Epoch 1604/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 1.8948 - acc: 0.0000e+00 - val_loss: 0.7338 - val_acc: 0.0000e+00\n",
            "Epoch 1605/2000\n",
            "80/80 [==============================] - 0s 141us/step - loss: 1.8958 - acc: 0.0000e+00 - val_loss: 0.7392 - val_acc: 0.0000e+00\n",
            "Epoch 1606/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 1.9080 - acc: 0.0000e+00 - val_loss: 0.7232 - val_acc: 0.0000e+00\n",
            "Epoch 1607/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 1.8846 - acc: 0.0000e+00 - val_loss: 0.7454 - val_acc: 0.0000e+00\n",
            "Epoch 1608/2000\n",
            "80/80 [==============================] - 0s 131us/step - loss: 1.8929 - acc: 0.0000e+00 - val_loss: 0.7230 - val_acc: 0.0000e+00\n",
            "Epoch 1609/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 1.8828 - acc: 0.0000e+00 - val_loss: 0.7315 - val_acc: 0.0000e+00\n",
            "Epoch 1610/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 1.8775 - acc: 0.0000e+00 - val_loss: 0.7226 - val_acc: 0.0000e+00\n",
            "Epoch 1611/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 1.8733 - acc: 0.0000e+00 - val_loss: 0.7174 - val_acc: 0.0000e+00\n",
            "Epoch 1612/2000\n",
            "80/80 [==============================] - 0s 141us/step - loss: 1.8703 - acc: 0.0000e+00 - val_loss: 0.7475 - val_acc: 0.0000e+00\n",
            "Epoch 1613/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 1.8860 - acc: 0.0000e+00 - val_loss: 0.7222 - val_acc: 0.0000e+00\n",
            "Epoch 1614/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 1.8643 - acc: 0.0000e+00 - val_loss: 0.7501 - val_acc: 0.0000e+00\n",
            "Epoch 1615/2000\n",
            "80/80 [==============================] - 0s 124us/step - loss: 1.8933 - acc: 0.0000e+00 - val_loss: 0.7190 - val_acc: 0.0000e+00\n",
            "Epoch 1616/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 1.8578 - acc: 0.0000e+00 - val_loss: 0.7579 - val_acc: 0.0000e+00\n",
            "Epoch 1617/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 1.8818 - acc: 0.0000e+00 - val_loss: 0.7334 - val_acc: 0.0000e+00\n",
            "Epoch 1618/2000\n",
            "80/80 [==============================] - 0s 129us/step - loss: 1.8601 - acc: 0.0000e+00 - val_loss: 0.7656 - val_acc: 0.0000e+00\n",
            "Epoch 1619/2000\n",
            "80/80 [==============================] - 0s 123us/step - loss: 1.8960 - acc: 0.0000e+00 - val_loss: 0.7349 - val_acc: 0.0000e+00\n",
            "Epoch 1620/2000\n",
            "80/80 [==============================] - 0s 123us/step - loss: 1.8734 - acc: 0.0000e+00 - val_loss: 0.7703 - val_acc: 0.0000e+00\n",
            "Epoch 1621/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 1.8819 - acc: 0.0000e+00 - val_loss: 0.7856 - val_acc: 0.0000e+00\n",
            "Epoch 1622/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 1.8888 - acc: 0.0000e+00 - val_loss: 0.7323 - val_acc: 0.0000e+00\n",
            "Epoch 1623/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 1.8442 - acc: 0.0000e+00 - val_loss: 0.7602 - val_acc: 0.0000e+00\n",
            "Epoch 1624/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 1.8751 - acc: 0.0000e+00 - val_loss: 0.7265 - val_acc: 0.0000e+00\n",
            "Epoch 1625/2000\n",
            "80/80 [==============================] - 0s 139us/step - loss: 1.8448 - acc: 0.0000e+00 - val_loss: 0.7738 - val_acc: 0.0000e+00\n",
            "Epoch 1626/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 1.8685 - acc: 0.0000e+00 - val_loss: 0.7792 - val_acc: 0.0000e+00\n",
            "Epoch 1627/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 1.8712 - acc: 0.0000e+00 - val_loss: 0.7168 - val_acc: 0.0000e+00\n",
            "Epoch 1628/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 1.8257 - acc: 0.0000e+00 - val_loss: 0.7399 - val_acc: 0.0000e+00\n",
            "Epoch 1629/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 1.8493 - acc: 0.0000e+00 - val_loss: 0.7232 - val_acc: 0.0000e+00\n",
            "Epoch 1630/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 1.8203 - acc: 0.0000e+00 - val_loss: 0.7520 - val_acc: 0.0000e+00\n",
            "Epoch 1631/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 1.8339 - acc: 0.0000e+00 - val_loss: 0.7234 - val_acc: 0.0000e+00\n",
            "Epoch 1632/2000\n",
            "80/80 [==============================] - 0s 136us/step - loss: 1.8157 - acc: 0.0000e+00 - val_loss: 0.7530 - val_acc: 0.0000e+00\n",
            "Epoch 1633/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 1.8554 - acc: 0.0000e+00 - val_loss: 0.7284 - val_acc: 0.0000e+00\n",
            "Epoch 1634/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 1.8355 - acc: 0.0000e+00 - val_loss: 0.7488 - val_acc: 0.0000e+00\n",
            "Epoch 1635/2000\n",
            "80/80 [==============================] - 0s 132us/step - loss: 1.8335 - acc: 0.0000e+00 - val_loss: 0.7539 - val_acc: 0.0000e+00\n",
            "Epoch 1636/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 1.8323 - acc: 0.0000e+00 - val_loss: 0.7194 - val_acc: 0.0000e+00\n",
            "Epoch 1637/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 1.8111 - acc: 0.0000e+00 - val_loss: 0.7412 - val_acc: 0.0000e+00\n",
            "Epoch 1638/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 1.8261 - acc: 0.0000e+00 - val_loss: 0.7237 - val_acc: 0.0000e+00\n",
            "Epoch 1639/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 1.8006 - acc: 0.0000e+00 - val_loss: 0.7519 - val_acc: 0.0000e+00\n",
            "Epoch 1640/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 1.8177 - acc: 0.0000e+00 - val_loss: 0.7221 - val_acc: 0.0000e+00\n",
            "Epoch 1641/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 1.7966 - acc: 0.0000e+00 - val_loss: 0.7485 - val_acc: 0.0000e+00\n",
            "Epoch 1642/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 1.8321 - acc: 0.0000e+00 - val_loss: 0.7448 - val_acc: 0.0000e+00\n",
            "Epoch 1643/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 1.8259 - acc: 0.0000e+00 - val_loss: 0.7179 - val_acc: 0.0000e+00\n",
            "Epoch 1644/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 1.7891 - acc: 0.0000e+00 - val_loss: 0.7363 - val_acc: 0.0000e+00\n",
            "Epoch 1645/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 1.7954 - acc: 0.0000e+00 - val_loss: 0.7096 - val_acc: 0.0000e+00\n",
            "Epoch 1646/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 1.7798 - acc: 0.0000e+00 - val_loss: 0.7155 - val_acc: 0.0000e+00\n",
            "Epoch 1647/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 1.7755 - acc: 0.0000e+00 - val_loss: 0.7245 - val_acc: 0.0000e+00\n",
            "Epoch 1648/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 1.7745 - acc: 0.0000e+00 - val_loss: 0.7055 - val_acc: 0.0000e+00\n",
            "Epoch 1649/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 1.7725 - acc: 0.0000e+00 - val_loss: 0.7029 - val_acc: 0.0000e+00\n",
            "Epoch 1650/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 1.7654 - acc: 0.0000e+00 - val_loss: 0.7101 - val_acc: 0.0000e+00\n",
            "Epoch 1651/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 1.7682 - acc: 0.0000e+00 - val_loss: 0.7112 - val_acc: 0.0000e+00\n",
            "Epoch 1652/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 1.7788 - acc: 0.0000e+00 - val_loss: 0.7003 - val_acc: 0.0000e+00\n",
            "Epoch 1653/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 1.7610 - acc: 0.0000e+00 - val_loss: 0.7542 - val_acc: 0.0000e+00\n",
            "Epoch 1654/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 1.7853 - acc: 0.0000e+00 - val_loss: 0.7570 - val_acc: 0.0000e+00\n",
            "Epoch 1655/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 1.7824 - acc: 0.0000e+00 - val_loss: 0.7121 - val_acc: 0.0000e+00\n",
            "Epoch 1656/2000\n",
            "80/80 [==============================] - 0s 127us/step - loss: 1.7543 - acc: 0.0000e+00 - val_loss: 0.7252 - val_acc: 0.0000e+00\n",
            "Epoch 1657/2000\n",
            "80/80 [==============================] - 0s 134us/step - loss: 1.7730 - acc: 0.0000e+00 - val_loss: 0.7055 - val_acc: 0.0000e+00\n",
            "Epoch 1658/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 1.7476 - acc: 0.0000e+00 - val_loss: 0.6935 - val_acc: 0.0000e+00\n",
            "Epoch 1659/2000\n",
            "80/80 [==============================] - 0s 139us/step - loss: 1.7442 - acc: 0.0000e+00 - val_loss: 0.7007 - val_acc: 0.0000e+00\n",
            "Epoch 1660/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 1.7593 - acc: 0.0000e+00 - val_loss: 0.6900 - val_acc: 0.0000e+00\n",
            "Epoch 1661/2000\n",
            "80/80 [==============================] - 0s 126us/step - loss: 1.7395 - acc: 0.0000e+00 - val_loss: 0.7342 - val_acc: 0.0000e+00\n",
            "Epoch 1662/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 1.7563 - acc: 0.0000e+00 - val_loss: 0.7277 - val_acc: 0.0000e+00\n",
            "Epoch 1663/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 1.7444 - acc: 0.0000e+00 - val_loss: 0.7388 - val_acc: 0.0000e+00\n",
            "Epoch 1664/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 1.7585 - acc: 0.0000e+00 - val_loss: 0.7232 - val_acc: 0.0000e+00\n",
            "Epoch 1665/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 1.7503 - acc: 0.0000e+00 - val_loss: 0.7123 - val_acc: 0.0000e+00\n",
            "Epoch 1666/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 1.7330 - acc: 0.0000e+00 - val_loss: 0.7010 - val_acc: 0.0000e+00\n",
            "Epoch 1667/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 1.7287 - acc: 0.0000e+00 - val_loss: 0.7109 - val_acc: 0.0000e+00\n",
            "Epoch 1668/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 1.7520 - acc: 0.0000e+00 - val_loss: 0.7118 - val_acc: 0.0000e+00\n",
            "Epoch 1669/2000\n",
            "80/80 [==============================] - 0s 173us/step - loss: 1.7475 - acc: 0.0000e+00 - val_loss: 0.7012 - val_acc: 0.0000e+00\n",
            "Epoch 1670/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 1.7163 - acc: 0.0000e+00 - val_loss: 0.7136 - val_acc: 0.0000e+00\n",
            "Epoch 1671/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 1.7165 - acc: 0.0000e+00 - val_loss: 0.7088 - val_acc: 0.0000e+00\n",
            "Epoch 1672/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 1.7253 - acc: 0.0000e+00 - val_loss: 0.7002 - val_acc: 0.0000e+00\n",
            "Epoch 1673/2000\n",
            "80/80 [==============================] - 0s 139us/step - loss: 1.7095 - acc: 0.0000e+00 - val_loss: 0.7185 - val_acc: 0.0000e+00\n",
            "Epoch 1674/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 1.7161 - acc: 0.0000e+00 - val_loss: 0.6906 - val_acc: 0.0000e+00\n",
            "Epoch 1675/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 1.7006 - acc: 0.0000e+00 - val_loss: 0.6970 - val_acc: 0.0000e+00\n",
            "Epoch 1676/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 1.7185 - acc: 0.0000e+00 - val_loss: 0.6842 - val_acc: 0.0000e+00\n",
            "Epoch 1677/2000\n",
            "80/80 [==============================] - 0s 122us/step - loss: 1.7003 - acc: 0.0000e+00 - val_loss: 0.7306 - val_acc: 0.0000e+00\n",
            "Epoch 1678/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 1.7187 - acc: 0.0000e+00 - val_loss: 0.7321 - val_acc: 0.0000e+00\n",
            "Epoch 1679/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 1.7110 - acc: 0.0000e+00 - val_loss: 0.7038 - val_acc: 0.0000e+00\n",
            "Epoch 1680/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 1.6992 - acc: 0.0000e+00 - val_loss: 0.6985 - val_acc: 0.0000e+00\n",
            "Epoch 1681/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 1.6957 - acc: 0.0000e+00 - val_loss: 0.7192 - val_acc: 0.0000e+00\n",
            "Epoch 1682/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 1.6982 - acc: 0.0000e+00 - val_loss: 0.7051 - val_acc: 0.0000e+00\n",
            "Epoch 1683/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 1.6925 - acc: 0.0000e+00 - val_loss: 0.6955 - val_acc: 0.0000e+00\n",
            "Epoch 1684/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 1.6981 - acc: 0.0000e+00 - val_loss: 0.6906 - val_acc: 0.0000e+00\n",
            "Epoch 1685/2000\n",
            "80/80 [==============================] - 0s 252us/step - loss: 1.6912 - acc: 0.0000e+00 - val_loss: 0.7103 - val_acc: 0.0000e+00\n",
            "Epoch 1686/2000\n",
            "80/80 [==============================] - 0s 190us/step - loss: 1.6871 - acc: 0.0000e+00 - val_loss: 0.7137 - val_acc: 0.0000e+00\n",
            "Epoch 1687/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 1.6824 - acc: 0.0000e+00 - val_loss: 0.7052 - val_acc: 0.0000e+00\n",
            "Epoch 1688/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 1.6846 - acc: 0.0000e+00 - val_loss: 0.6926 - val_acc: 0.0000e+00\n",
            "Epoch 1689/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 1.6766 - acc: 0.0000e+00 - val_loss: 0.7071 - val_acc: 0.0000e+00\n",
            "Epoch 1690/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 1.6789 - acc: 0.0000e+00 - val_loss: 0.6982 - val_acc: 0.0000e+00\n",
            "Epoch 1691/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 1.6729 - acc: 0.0000e+00 - val_loss: 0.6911 - val_acc: 0.0000e+00\n",
            "Epoch 1692/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 1.6825 - acc: 0.0000e+00 - val_loss: 0.6924 - val_acc: 0.0000e+00\n",
            "Epoch 1693/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 1.6785 - acc: 0.0000e+00 - val_loss: 0.7008 - val_acc: 0.0000e+00\n",
            "Epoch 1694/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 1.6604 - acc: 0.0000e+00 - val_loss: 0.7100 - val_acc: 0.0000e+00\n",
            "Epoch 1695/2000\n",
            "80/80 [==============================] - 0s 217us/step - loss: 1.6615 - acc: 0.0000e+00 - val_loss: 0.6937 - val_acc: 0.0000e+00\n",
            "Epoch 1696/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 1.6598 - acc: 0.0000e+00 - val_loss: 0.6853 - val_acc: 0.0000e+00\n",
            "Epoch 1697/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 1.6516 - acc: 0.0000e+00 - val_loss: 0.7035 - val_acc: 0.0000e+00\n",
            "Epoch 1698/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 1.6545 - acc: 0.0000e+00 - val_loss: 0.6872 - val_acc: 0.0000e+00\n",
            "Epoch 1699/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 1.6449 - acc: 0.0000e+00 - val_loss: 0.6958 - val_acc: 0.0000e+00\n",
            "Epoch 1700/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 1.6690 - acc: 0.0000e+00 - val_loss: 0.6923 - val_acc: 0.0000e+00\n",
            "Epoch 1701/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 1.6629 - acc: 0.0000e+00 - val_loss: 0.6919 - val_acc: 0.0000e+00\n",
            "Epoch 1702/2000\n",
            "80/80 [==============================] - 0s 122us/step - loss: 1.6400 - acc: 0.0000e+00 - val_loss: 0.7010 - val_acc: 0.0000e+00\n",
            "Epoch 1703/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 1.6406 - acc: 0.0000e+00 - val_loss: 0.6862 - val_acc: 0.0000e+00\n",
            "Epoch 1704/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 1.6404 - acc: 0.0000e+00 - val_loss: 0.6839 - val_acc: 0.0000e+00\n",
            "Epoch 1705/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 1.6349 - acc: 0.0000e+00 - val_loss: 0.6939 - val_acc: 0.0000e+00\n",
            "Epoch 1706/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 1.6293 - acc: 0.0000e+00 - val_loss: 0.6737 - val_acc: 0.0000e+00\n",
            "Epoch 1707/2000\n",
            "80/80 [==============================] - 0s 145us/step - loss: 1.6197 - acc: 0.0000e+00 - val_loss: 0.6720 - val_acc: 0.0000e+00\n",
            "Epoch 1708/2000\n",
            "80/80 [==============================] - 0s 137us/step - loss: 1.6272 - acc: 0.0000e+00 - val_loss: 0.6785 - val_acc: 0.0000e+00\n",
            "Epoch 1709/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 1.6168 - acc: 0.0000e+00 - val_loss: 0.6701 - val_acc: 0.0000e+00\n",
            "Epoch 1710/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 1.6144 - acc: 0.0000e+00 - val_loss: 0.6838 - val_acc: 0.0000e+00\n",
            "Epoch 1711/2000\n",
            "80/80 [==============================] - 0s 126us/step - loss: 1.6110 - acc: 0.0000e+00 - val_loss: 0.6820 - val_acc: 0.0000e+00\n",
            "Epoch 1712/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 1.6082 - acc: 0.0000e+00 - val_loss: 0.6686 - val_acc: 0.0000e+00\n",
            "Epoch 1713/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 1.6081 - acc: 0.0000e+00 - val_loss: 0.6794 - val_acc: 0.0000e+00\n",
            "Epoch 1714/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 1.6072 - acc: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.0000e+00\n",
            "Epoch 1715/2000\n",
            "80/80 [==============================] - 0s 137us/step - loss: 1.6011 - acc: 0.0000e+00 - val_loss: 0.6708 - val_acc: 0.0000e+00\n",
            "Epoch 1716/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 1.5979 - acc: 0.0000e+00 - val_loss: 0.6680 - val_acc: 0.0000e+00\n",
            "Epoch 1717/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 1.6041 - acc: 0.0000e+00 - val_loss: 0.6711 - val_acc: 0.0000e+00\n",
            "Epoch 1718/2000\n",
            "80/80 [==============================] - 0s 134us/step - loss: 1.5945 - acc: 0.0000e+00 - val_loss: 0.6796 - val_acc: 0.0000e+00\n",
            "Epoch 1719/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 1.5957 - acc: 0.0000e+00 - val_loss: 0.6603 - val_acc: 0.0000e+00\n",
            "Epoch 1720/2000\n",
            "80/80 [==============================] - 0s 131us/step - loss: 1.5886 - acc: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.0000e+00\n",
            "Epoch 1721/2000\n",
            "80/80 [==============================] - 0s 115us/step - loss: 1.5841 - acc: 0.0000e+00 - val_loss: 0.6553 - val_acc: 0.0000e+00\n",
            "Epoch 1722/2000\n",
            "80/80 [==============================] - 0s 137us/step - loss: 1.5831 - acc: 0.0000e+00 - val_loss: 0.6785 - val_acc: 0.0000e+00\n",
            "Epoch 1723/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 1.5917 - acc: 0.0000e+00 - val_loss: 0.6615 - val_acc: 0.0000e+00\n",
            "Epoch 1724/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 1.5767 - acc: 0.0000e+00 - val_loss: 0.6821 - val_acc: 0.0000e+00\n",
            "Epoch 1725/2000\n",
            "80/80 [==============================] - 0s 133us/step - loss: 1.5976 - acc: 0.0000e+00 - val_loss: 0.6711 - val_acc: 0.0000e+00\n",
            "Epoch 1726/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 1.5769 - acc: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.0000e+00\n",
            "Epoch 1727/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 1.5709 - acc: 0.0000e+00 - val_loss: 0.6792 - val_acc: 0.0000e+00\n",
            "Epoch 1728/2000\n",
            "80/80 [==============================] - 0s 122us/step - loss: 1.5964 - acc: 0.0000e+00 - val_loss: 0.6517 - val_acc: 0.0000e+00\n",
            "Epoch 1729/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 1.5722 - acc: 0.0000e+00 - val_loss: 0.7004 - val_acc: 0.0000e+00\n",
            "Epoch 1730/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 1.5986 - acc: 0.0000e+00 - val_loss: 0.6963 - val_acc: 0.0000e+00\n",
            "Epoch 1731/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 1.5913 - acc: 0.0000e+00 - val_loss: 0.6640 - val_acc: 0.0000e+00\n",
            "Epoch 1732/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 1.5680 - acc: 0.0000e+00 - val_loss: 0.6800 - val_acc: 0.0000e+00\n",
            "Epoch 1733/2000\n",
            "80/80 [==============================] - 0s 118us/step - loss: 1.5788 - acc: 0.0000e+00 - val_loss: 0.6547 - val_acc: 0.0000e+00\n",
            "Epoch 1734/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 1.5530 - acc: 0.0000e+00 - val_loss: 0.6913 - val_acc: 0.0000e+00\n",
            "Epoch 1735/2000\n",
            "80/80 [==============================] - 0s 136us/step - loss: 1.5788 - acc: 0.0000e+00 - val_loss: 0.6720 - val_acc: 0.0000e+00\n",
            "Epoch 1736/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 1.5654 - acc: 0.0000e+00 - val_loss: 0.6791 - val_acc: 0.0000e+00\n",
            "Epoch 1737/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 1.5755 - acc: 0.0000e+00 - val_loss: 0.6797 - val_acc: 0.0000e+00\n",
            "Epoch 1738/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 1.5713 - acc: 0.0000e+00 - val_loss: 0.6831 - val_acc: 0.0000e+00\n",
            "Epoch 1739/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 1.5567 - acc: 0.0000e+00 - val_loss: 0.6931 - val_acc: 0.0000e+00\n",
            "Epoch 1740/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 1.5604 - acc: 0.0000e+00 - val_loss: 0.6574 - val_acc: 0.0000e+00\n",
            "Epoch 1741/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 1.5385 - acc: 0.0000e+00 - val_loss: 0.6543 - val_acc: 0.0000e+00\n",
            "Epoch 1742/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 1.5371 - acc: 0.0000e+00 - val_loss: 0.6724 - val_acc: 0.0000e+00\n",
            "Epoch 1743/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 1.5440 - acc: 0.0000e+00 - val_loss: 0.6480 - val_acc: 0.0000e+00\n",
            "Epoch 1744/2000\n",
            "80/80 [==============================] - 0s 120us/step - loss: 1.5288 - acc: 0.0000e+00 - val_loss: 0.6488 - val_acc: 0.0000e+00\n",
            "Epoch 1745/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 1.5367 - acc: 0.0000e+00 - val_loss: 0.6518 - val_acc: 0.0000e+00\n",
            "Epoch 1746/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 1.5283 - acc: 0.0000e+00 - val_loss: 0.6473 - val_acc: 0.0000e+00\n",
            "Epoch 1747/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 1.5235 - acc: 0.0000e+00 - val_loss: 0.6466 - val_acc: 0.0000e+00\n",
            "Epoch 1748/2000\n",
            "80/80 [==============================] - 0s 142us/step - loss: 1.5258 - acc: 0.0000e+00 - val_loss: 0.6506 - val_acc: 0.0000e+00\n",
            "Epoch 1749/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 1.5188 - acc: 0.0000e+00 - val_loss: 0.6476 - val_acc: 0.0000e+00\n",
            "Epoch 1750/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 1.5196 - acc: 0.0000e+00 - val_loss: 0.6680 - val_acc: 0.0000e+00\n",
            "Epoch 1751/2000\n",
            "80/80 [==============================] - 0s 126us/step - loss: 1.5266 - acc: 0.0000e+00 - val_loss: 0.6519 - val_acc: 0.0000e+00\n",
            "Epoch 1752/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 1.5127 - acc: 0.0000e+00 - val_loss: 0.6904 - val_acc: 0.0000e+00\n",
            "Epoch 1753/2000\n",
            "80/80 [==============================] - 0s 126us/step - loss: 1.5510 - acc: 0.0000e+00 - val_loss: 0.6592 - val_acc: 0.0000e+00\n",
            "Epoch 1754/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 1.5264 - acc: 0.0000e+00 - val_loss: 0.6855 - val_acc: 0.0000e+00\n",
            "Epoch 1755/2000\n",
            "80/80 [==============================] - 0s 215us/step - loss: 1.5393 - acc: 0.0000e+00 - val_loss: 0.7002 - val_acc: 0.0000e+00\n",
            "Epoch 1756/2000\n",
            "80/80 [==============================] - 0s 139us/step - loss: 1.5493 - acc: 0.0000e+00 - val_loss: 0.6523 - val_acc: 0.0000e+00\n",
            "Epoch 1757/2000\n",
            "80/80 [==============================] - 0s 133us/step - loss: 1.5049 - acc: 0.0000e+00 - val_loss: 0.7106 - val_acc: 0.0000e+00\n",
            "Epoch 1758/2000\n",
            "80/80 [==============================] - 0s 116us/step - loss: 1.5531 - acc: 0.0000e+00 - val_loss: 0.7040 - val_acc: 0.0000e+00\n",
            "Epoch 1759/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 1.5469 - acc: 0.0000e+00 - val_loss: 0.6492 - val_acc: 0.0000e+00\n",
            "Epoch 1760/2000\n",
            "80/80 [==============================] - 0s 145us/step - loss: 1.4989 - acc: 0.0000e+00 - val_loss: 0.6894 - val_acc: 0.0000e+00\n",
            "Epoch 1761/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 1.5320 - acc: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.0000e+00\n",
            "Epoch 1762/2000\n",
            "80/80 [==============================] - 0s 130us/step - loss: 1.5093 - acc: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.0000e+00\n",
            "Epoch 1763/2000\n",
            "80/80 [==============================] - 0s 139us/step - loss: 1.5167 - acc: 0.0000e+00 - val_loss: 0.6657 - val_acc: 0.0000e+00\n",
            "Epoch 1764/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 1.5157 - acc: 0.0000e+00 - val_loss: 0.6550 - val_acc: 0.0000e+00\n",
            "Epoch 1765/2000\n",
            "80/80 [==============================] - 0s 138us/step - loss: 1.4935 - acc: 0.0000e+00 - val_loss: 0.6618 - val_acc: 0.0000e+00\n",
            "Epoch 1766/2000\n",
            "80/80 [==============================] - 0s 145us/step - loss: 1.4956 - acc: 0.0000e+00 - val_loss: 0.6479 - val_acc: 0.0000e+00\n",
            "Epoch 1767/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 1.4908 - acc: 0.0000e+00 - val_loss: 0.6575 - val_acc: 0.0000e+00\n",
            "Epoch 1768/2000\n",
            "80/80 [==============================] - 0s 116us/step - loss: 1.4974 - acc: 0.0000e+00 - val_loss: 0.6518 - val_acc: 0.0000e+00\n",
            "Epoch 1769/2000\n",
            "80/80 [==============================] - 0s 137us/step - loss: 1.4774 - acc: 0.0000e+00 - val_loss: 0.6521 - val_acc: 0.0000e+00\n",
            "Epoch 1770/2000\n",
            "80/80 [==============================] - 0s 131us/step - loss: 1.4769 - acc: 0.0000e+00 - val_loss: 0.6522 - val_acc: 0.0000e+00\n",
            "Epoch 1771/2000\n",
            "80/80 [==============================] - 0s 133us/step - loss: 1.4886 - acc: 0.0000e+00 - val_loss: 0.6442 - val_acc: 0.0000e+00\n",
            "Epoch 1772/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 1.4760 - acc: 0.0000e+00 - val_loss: 0.6644 - val_acc: 0.0000e+00\n",
            "Epoch 1773/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 1.4801 - acc: 0.0000e+00 - val_loss: 0.6554 - val_acc: 0.0000e+00\n",
            "Epoch 1774/2000\n",
            "80/80 [==============================] - 0s 136us/step - loss: 1.4691 - acc: 0.0000e+00 - val_loss: 0.6630 - val_acc: 0.0000e+00\n",
            "Epoch 1775/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 1.4894 - acc: 0.0000e+00 - val_loss: 0.6487 - val_acc: 0.0000e+00\n",
            "Epoch 1776/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 1.4749 - acc: 0.0000e+00 - val_loss: 0.6513 - val_acc: 0.0000e+00\n",
            "Epoch 1777/2000\n",
            "80/80 [==============================] - 0s 139us/step - loss: 1.4660 - acc: 0.0000e+00 - val_loss: 0.6408 - val_acc: 0.0000e+00\n",
            "Epoch 1778/2000\n",
            "80/80 [==============================] - 0s 141us/step - loss: 1.4590 - acc: 0.0000e+00 - val_loss: 0.6382 - val_acc: 0.0000e+00\n",
            "Epoch 1779/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 1.4614 - acc: 0.0000e+00 - val_loss: 0.6392 - val_acc: 0.0000e+00\n",
            "Epoch 1780/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 1.4574 - acc: 0.0000e+00 - val_loss: 0.6509 - val_acc: 0.0000e+00\n",
            "Epoch 1781/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 1.4541 - acc: 0.0000e+00 - val_loss: 0.6384 - val_acc: 0.0000e+00\n",
            "Epoch 1782/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 1.4443 - acc: 0.0000e+00 - val_loss: 0.6387 - val_acc: 0.0000e+00\n",
            "Epoch 1783/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 1.4442 - acc: 0.0000e+00 - val_loss: 0.6599 - val_acc: 0.0000e+00\n",
            "Epoch 1784/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 1.4557 - acc: 0.0000e+00 - val_loss: 0.6397 - val_acc: 0.0000e+00\n",
            "Epoch 1785/2000\n",
            "80/80 [==============================] - 0s 129us/step - loss: 1.4410 - acc: 0.0000e+00 - val_loss: 0.6569 - val_acc: 0.0000e+00\n",
            "Epoch 1786/2000\n",
            "80/80 [==============================] - 0s 145us/step - loss: 1.4672 - acc: 0.0000e+00 - val_loss: 0.6372 - val_acc: 0.0000e+00\n",
            "Epoch 1787/2000\n",
            "80/80 [==============================] - 0s 118us/step - loss: 1.4486 - acc: 0.0000e+00 - val_loss: 0.6644 - val_acc: 0.0000e+00\n",
            "Epoch 1788/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 1.4635 - acc: 0.0000e+00 - val_loss: 0.6695 - val_acc: 0.0000e+00\n",
            "Epoch 1789/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 1.4659 - acc: 0.0000e+00 - val_loss: 0.6307 - val_acc: 0.0000e+00\n",
            "Epoch 1790/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 1.4355 - acc: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.0000e+00\n",
            "Epoch 1791/2000\n",
            "80/80 [==============================] - 0s 128us/step - loss: 1.4587 - acc: 0.0000e+00 - val_loss: 0.6358 - val_acc: 0.0000e+00\n",
            "Epoch 1792/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 1.4416 - acc: 0.0000e+00 - val_loss: 0.6447 - val_acc: 0.0000e+00\n",
            "Epoch 1793/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 1.4435 - acc: 0.0000e+00 - val_loss: 0.6445 - val_acc: 0.0000e+00\n",
            "Epoch 1794/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 1.4416 - acc: 0.0000e+00 - val_loss: 0.6341 - val_acc: 0.0000e+00\n",
            "Epoch 1795/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 1.4387 - acc: 0.0000e+00 - val_loss: 0.6425 - val_acc: 0.0000e+00\n",
            "Epoch 1796/2000\n",
            "80/80 [==============================] - 0s 138us/step - loss: 1.4380 - acc: 0.0000e+00 - val_loss: 0.6478 - val_acc: 0.0000e+00\n",
            "Epoch 1797/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 1.4270 - acc: 0.0000e+00 - val_loss: 0.6562 - val_acc: 0.0000e+00\n",
            "Epoch 1798/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 1.4306 - acc: 0.0000e+00 - val_loss: 0.6278 - val_acc: 0.0000e+00\n",
            "Epoch 1799/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 1.4118 - acc: 0.0000e+00 - val_loss: 0.6307 - val_acc: 0.0000e+00\n",
            "Epoch 1800/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 1.4177 - acc: 0.0000e+00 - val_loss: 0.6367 - val_acc: 0.0000e+00\n",
            "Epoch 1801/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 1.4187 - acc: 0.0000e+00 - val_loss: 0.6215 - val_acc: 0.0000e+00\n",
            "Epoch 1802/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 1.4071 - acc: 0.0000e+00 - val_loss: 0.6480 - val_acc: 0.0000e+00\n",
            "Epoch 1803/2000\n",
            "80/80 [==============================] - 0s 142us/step - loss: 1.4372 - acc: 0.0000e+00 - val_loss: 0.6369 - val_acc: 0.0000e+00\n",
            "Epoch 1804/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 1.4251 - acc: 0.0000e+00 - val_loss: 0.6365 - val_acc: 0.0000e+00\n",
            "Epoch 1805/2000\n",
            "80/80 [==============================] - 0s 125us/step - loss: 1.4131 - acc: 0.0000e+00 - val_loss: 0.6469 - val_acc: 0.0000e+00\n",
            "Epoch 1806/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 1.4167 - acc: 0.0000e+00 - val_loss: 0.6266 - val_acc: 0.0000e+00\n",
            "Epoch 1807/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 1.4046 - acc: 0.0000e+00 - val_loss: 0.6313 - val_acc: 0.0000e+00\n",
            "Epoch 1808/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 1.4081 - acc: 0.0000e+00 - val_loss: 0.6122 - val_acc: 0.0000e+00\n",
            "Epoch 1809/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 1.3888 - acc: 0.0000e+00 - val_loss: 0.6307 - val_acc: 0.0000e+00\n",
            "Epoch 1810/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 1.4020 - acc: 0.0000e+00 - val_loss: 0.6217 - val_acc: 0.0000e+00\n",
            "Epoch 1811/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 1.3970 - acc: 0.0000e+00 - val_loss: 0.6252 - val_acc: 0.0000e+00\n",
            "Epoch 1812/2000\n",
            "80/80 [==============================] - 0s 151us/step - loss: 1.3882 - acc: 0.0000e+00 - val_loss: 0.6292 - val_acc: 0.0000e+00\n",
            "Epoch 1813/2000\n",
            "80/80 [==============================] - 0s 141us/step - loss: 1.3849 - acc: 0.0000e+00 - val_loss: 0.6393 - val_acc: 0.0000e+00\n",
            "Epoch 1814/2000\n",
            "80/80 [==============================] - 0s 150us/step - loss: 1.3959 - acc: 0.0000e+00 - val_loss: 0.6437 - val_acc: 0.0000e+00\n",
            "Epoch 1815/2000\n",
            "80/80 [==============================] - 0s 142us/step - loss: 1.3915 - acc: 0.0000e+00 - val_loss: 0.6334 - val_acc: 0.0000e+00\n",
            "Epoch 1816/2000\n",
            "80/80 [==============================] - 0s 117us/step - loss: 1.3840 - acc: 0.0000e+00 - val_loss: 0.6120 - val_acc: 0.0000e+00\n",
            "Epoch 1817/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 1.3801 - acc: 0.0000e+00 - val_loss: 0.6092 - val_acc: 0.0000e+00\n",
            "Epoch 1818/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 1.3825 - acc: 0.0000e+00 - val_loss: 0.6122 - val_acc: 0.0000e+00\n",
            "Epoch 1819/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 1.3773 - acc: 0.0000e+00 - val_loss: 0.6121 - val_acc: 0.0000e+00\n",
            "Epoch 1820/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 1.3725 - acc: 0.0000e+00 - val_loss: 0.6169 - val_acc: 0.0000e+00\n",
            "Epoch 1821/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 1.3741 - acc: 0.0000e+00 - val_loss: 0.6190 - val_acc: 0.0000e+00\n",
            "Epoch 1822/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 1.3652 - acc: 0.0000e+00 - val_loss: 0.6262 - val_acc: 0.0000e+00\n",
            "Epoch 1823/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 1.3663 - acc: 0.0000e+00 - val_loss: 0.6200 - val_acc: 0.0000e+00\n",
            "Epoch 1824/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 1.3641 - acc: 0.0000e+00 - val_loss: 0.6282 - val_acc: 0.0000e+00\n",
            "Epoch 1825/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 1.3658 - acc: 0.0000e+00 - val_loss: 0.6133 - val_acc: 0.0000e+00\n",
            "Epoch 1826/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 1.3552 - acc: 0.0000e+00 - val_loss: 0.6085 - val_acc: 0.0000e+00\n",
            "Epoch 1827/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 1.3558 - acc: 0.0000e+00 - val_loss: 0.6240 - val_acc: 0.0000e+00\n",
            "Epoch 1828/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 1.3632 - acc: 0.0000e+00 - val_loss: 0.6111 - val_acc: 0.0000e+00\n",
            "Epoch 1829/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 1.3534 - acc: 0.0000e+00 - val_loss: 0.6186 - val_acc: 0.0000e+00\n",
            "Epoch 1830/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 1.3640 - acc: 0.0000e+00 - val_loss: 0.6049 - val_acc: 0.0000e+00\n",
            "Epoch 1831/2000\n",
            "80/80 [==============================] - 0s 133us/step - loss: 1.3541 - acc: 0.0000e+00 - val_loss: 0.6105 - val_acc: 0.0000e+00\n",
            "Epoch 1832/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 1.3518 - acc: 0.0000e+00 - val_loss: 0.5979 - val_acc: 0.0000e+00\n",
            "Epoch 1833/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 1.3425 - acc: 0.0000e+00 - val_loss: 0.6027 - val_acc: 0.0000e+00\n",
            "Epoch 1834/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 1.3370 - acc: 0.0000e+00 - val_loss: 0.6070 - val_acc: 0.0000e+00\n",
            "Epoch 1835/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 1.3345 - acc: 0.0000e+00 - val_loss: 0.6103 - val_acc: 0.0000e+00\n",
            "Epoch 1836/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 1.3351 - acc: 0.0000e+00 - val_loss: 0.6129 - val_acc: 0.0000e+00\n",
            "Epoch 1837/2000\n",
            "80/80 [==============================] - 0s 193us/step - loss: 1.3378 - acc: 0.0000e+00 - val_loss: 0.6310 - val_acc: 0.0000e+00\n",
            "Epoch 1838/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 1.3468 - acc: 0.0000e+00 - val_loss: 0.6190 - val_acc: 0.0000e+00\n",
            "Epoch 1839/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 1.3379 - acc: 0.0000e+00 - val_loss: 0.6184 - val_acc: 0.0000e+00\n",
            "Epoch 1840/2000\n",
            "80/80 [==============================] - 0s 184us/step - loss: 1.3471 - acc: 0.0000e+00 - val_loss: 0.6035 - val_acc: 0.0000e+00\n",
            "Epoch 1841/2000\n",
            "80/80 [==============================] - 0s 186us/step - loss: 1.3336 - acc: 0.0000e+00 - val_loss: 0.6191 - val_acc: 0.0000e+00\n",
            "Epoch 1842/2000\n",
            "80/80 [==============================] - 0s 209us/step - loss: 1.3419 - acc: 0.0000e+00 - val_loss: 0.6096 - val_acc: 0.0000e+00\n",
            "Epoch 1843/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 1.3330 - acc: 0.0000e+00 - val_loss: 0.6131 - val_acc: 0.0000e+00\n",
            "Epoch 1844/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 1.3387 - acc: 0.0000e+00 - val_loss: 0.6148 - val_acc: 0.0000e+00\n",
            "Epoch 1845/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 1.3379 - acc: 0.0000e+00 - val_loss: 0.6021 - val_acc: 0.0000e+00\n",
            "Epoch 1846/2000\n",
            "80/80 [==============================] - 0s 213us/step - loss: 1.3220 - acc: 0.0000e+00 - val_loss: 0.6095 - val_acc: 0.0000e+00\n",
            "Epoch 1847/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 1.3251 - acc: 0.0000e+00 - val_loss: 0.6055 - val_acc: 0.0000e+00\n",
            "Epoch 1848/2000\n",
            "80/80 [==============================] - 0s 221us/step - loss: 1.3257 - acc: 0.0000e+00 - val_loss: 0.6014 - val_acc: 0.0000e+00\n",
            "Epoch 1849/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 1.3154 - acc: 0.0000e+00 - val_loss: 0.6383 - val_acc: 0.0000e+00\n",
            "Epoch 1850/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 1.3344 - acc: 0.0000e+00 - val_loss: 0.6458 - val_acc: 0.0000e+00\n",
            "Epoch 1851/2000\n",
            "80/80 [==============================] - 0s 144us/step - loss: 1.3366 - acc: 0.0000e+00 - val_loss: 0.6104 - val_acc: 0.0000e+00\n",
            "Epoch 1852/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 1.3105 - acc: 0.0000e+00 - val_loss: 0.6395 - val_acc: 0.0000e+00\n",
            "Epoch 1853/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 1.3383 - acc: 0.0000e+00 - val_loss: 0.6012 - val_acc: 0.0000e+00\n",
            "Epoch 1854/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 1.3084 - acc: 0.0000e+00 - val_loss: 0.6444 - val_acc: 0.0000e+00\n",
            "Epoch 1855/2000\n",
            "80/80 [==============================] - 0s 166us/step - loss: 1.3396 - acc: 0.0000e+00 - val_loss: 0.6566 - val_acc: 0.0000e+00\n",
            "Epoch 1856/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 1.3476 - acc: 0.0000e+00 - val_loss: 0.6045 - val_acc: 0.0000e+00\n",
            "Epoch 1857/2000\n",
            "80/80 [==============================] - 0s 132us/step - loss: 1.2996 - acc: 0.0000e+00 - val_loss: 0.6635 - val_acc: 0.0000e+00\n",
            "Epoch 1858/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 1.3509 - acc: 0.0000e+00 - val_loss: 0.6754 - val_acc: 0.0000e+00\n",
            "Epoch 1859/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 1.3577 - acc: 0.0000e+00 - val_loss: 0.5951 - val_acc: 0.0000e+00\n",
            "Epoch 1860/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 1.2945 - acc: 0.0000e+00 - val_loss: 0.6584 - val_acc: 0.0000e+00\n",
            "Epoch 1861/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 1.3410 - acc: 0.0000e+00 - val_loss: 0.6833 - val_acc: 0.0000e+00\n",
            "Epoch 1862/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 1.3588 - acc: 0.0000e+00 - val_loss: 0.6336 - val_acc: 0.0000e+00\n",
            "Epoch 1863/2000\n",
            "80/80 [==============================] - 0s 142us/step - loss: 1.3141 - acc: 0.0000e+00 - val_loss: 0.6317 - val_acc: 0.0000e+00\n",
            "Epoch 1864/2000\n",
            "80/80 [==============================] - 0s 194us/step - loss: 1.3133 - acc: 0.0000e+00 - val_loss: 0.6515 - val_acc: 0.0000e+00\n",
            "Epoch 1865/2000\n",
            "80/80 [==============================] - 0s 131us/step - loss: 1.3267 - acc: 0.0000e+00 - val_loss: 0.5963 - val_acc: 0.0000e+00\n",
            "Epoch 1866/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 1.2813 - acc: 0.0000e+00 - val_loss: 0.6273 - val_acc: 0.0000e+00\n",
            "Epoch 1867/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 1.3042 - acc: 0.0000e+00 - val_loss: 0.6109 - val_acc: 0.0000e+00\n",
            "Epoch 1868/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 1.2923 - acc: 0.0000e+00 - val_loss: 0.6041 - val_acc: 0.0000e+00\n",
            "Epoch 1869/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 1.2942 - acc: 0.0000e+00 - val_loss: 0.6125 - val_acc: 0.0000e+00\n",
            "Epoch 1870/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 1.2999 - acc: 0.0000e+00 - val_loss: 0.5883 - val_acc: 0.0000e+00\n",
            "Epoch 1871/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 1.2688 - acc: 0.0000e+00 - val_loss: 0.6314 - val_acc: 0.0000e+00\n",
            "Epoch 1872/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 1.2985 - acc: 0.0000e+00 - val_loss: 0.6243 - val_acc: 0.0000e+00\n",
            "Epoch 1873/2000\n",
            "80/80 [==============================] - 0s 248us/step - loss: 1.2883 - acc: 0.0000e+00 - val_loss: 0.5986 - val_acc: 0.0000e+00\n",
            "Epoch 1874/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 1.2733 - acc: 0.0000e+00 - val_loss: 0.6134 - val_acc: 0.0000e+00\n",
            "Epoch 1875/2000\n",
            "80/80 [==============================] - 0s 219us/step - loss: 1.2858 - acc: 0.0000e+00 - val_loss: 0.5893 - val_acc: 0.0000e+00\n",
            "Epoch 1876/2000\n",
            "80/80 [==============================] - 0s 200us/step - loss: 1.2586 - acc: 0.0000e+00 - val_loss: 0.5951 - val_acc: 0.0000e+00\n",
            "Epoch 1877/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 1.2659 - acc: 0.0000e+00 - val_loss: 0.5967 - val_acc: 0.0000e+00\n",
            "Epoch 1878/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 1.2744 - acc: 0.0000e+00 - val_loss: 0.5938 - val_acc: 0.0000e+00\n",
            "Epoch 1879/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 1.2659 - acc: 0.0000e+00 - val_loss: 0.6104 - val_acc: 0.0000e+00\n",
            "Epoch 1880/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 1.2677 - acc: 0.0000e+00 - val_loss: 0.6122 - val_acc: 0.0000e+00\n",
            "Epoch 1881/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 1.2655 - acc: 0.0000e+00 - val_loss: 0.6024 - val_acc: 0.0000e+00\n",
            "Epoch 1882/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 1.2639 - acc: 0.0000e+00 - val_loss: 0.5938 - val_acc: 0.0000e+00\n",
            "Epoch 1883/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 1.2563 - acc: 0.0000e+00 - val_loss: 0.5951 - val_acc: 0.0000e+00\n",
            "Epoch 1884/2000\n",
            "80/80 [==============================] - 0s 218us/step - loss: 1.2560 - acc: 0.0000e+00 - val_loss: 0.5829 - val_acc: 0.0000e+00\n",
            "Epoch 1885/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 1.2475 - acc: 0.0000e+00 - val_loss: 0.5954 - val_acc: 0.0000e+00\n",
            "Epoch 1886/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 1.2678 - acc: 0.0000e+00 - val_loss: 0.5922 - val_acc: 0.0000e+00\n",
            "Epoch 1887/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 1.2580 - acc: 0.0000e+00 - val_loss: 0.5962 - val_acc: 0.0000e+00\n",
            "Epoch 1888/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 1.2477 - acc: 0.0000e+00 - val_loss: 0.6009 - val_acc: 0.0000e+00\n",
            "Epoch 1889/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 1.2477 - acc: 0.0000e+00 - val_loss: 0.5962 - val_acc: 0.0000e+00\n",
            "Epoch 1890/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 1.2499 - acc: 0.0000e+00 - val_loss: 0.5853 - val_acc: 0.0000e+00\n",
            "Epoch 1891/2000\n",
            "80/80 [==============================] - 0s 185us/step - loss: 1.2411 - acc: 0.0000e+00 - val_loss: 0.5849 - val_acc: 0.0000e+00\n",
            "Epoch 1892/2000\n",
            "80/80 [==============================] - 0s 142us/step - loss: 1.2361 - acc: 0.0000e+00 - val_loss: 0.5739 - val_acc: 0.0000e+00\n",
            "Epoch 1893/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 1.2304 - acc: 0.0000e+00 - val_loss: 0.5746 - val_acc: 0.0000e+00\n",
            "Epoch 1894/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 1.2277 - acc: 0.0000e+00 - val_loss: 0.5734 - val_acc: 0.0000e+00\n",
            "Epoch 1895/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 1.2221 - acc: 0.0000e+00 - val_loss: 0.5749 - val_acc: 0.0000e+00\n",
            "Epoch 1896/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 1.2207 - acc: 0.0000e+00 - val_loss: 0.5768 - val_acc: 0.0000e+00\n",
            "Epoch 1897/2000\n",
            "80/80 [==============================] - 0s 181us/step - loss: 1.2209 - acc: 0.0000e+00 - val_loss: 0.5765 - val_acc: 0.0000e+00\n",
            "Epoch 1898/2000\n",
            "80/80 [==============================] - 0s 229us/step - loss: 1.2179 - acc: 0.0000e+00 - val_loss: 0.5764 - val_acc: 0.0000e+00\n",
            "Epoch 1899/2000\n",
            "80/80 [==============================] - 0s 122us/step - loss: 1.2147 - acc: 0.0000e+00 - val_loss: 0.5756 - val_acc: 0.0000e+00\n",
            "Epoch 1900/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 1.2149 - acc: 0.0000e+00 - val_loss: 0.5730 - val_acc: 0.0000e+00\n",
            "Epoch 1901/2000\n",
            "80/80 [==============================] - 0s 183us/step - loss: 1.2120 - acc: 0.0000e+00 - val_loss: 0.5698 - val_acc: 0.0000e+00\n",
            "Epoch 1902/2000\n",
            "80/80 [==============================] - 0s 176us/step - loss: 1.2092 - acc: 0.0000e+00 - val_loss: 0.5686 - val_acc: 0.0000e+00\n",
            "Epoch 1903/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 1.2087 - acc: 0.0000e+00 - val_loss: 0.5714 - val_acc: 0.0000e+00\n",
            "Epoch 1904/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 1.2076 - acc: 0.0000e+00 - val_loss: 0.5684 - val_acc: 0.0000e+00\n",
            "Epoch 1905/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 1.2058 - acc: 0.0000e+00 - val_loss: 0.5800 - val_acc: 0.0000e+00\n",
            "Epoch 1906/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 1.2109 - acc: 0.0000e+00 - val_loss: 0.5724 - val_acc: 0.0000e+00\n",
            "Epoch 1907/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 1.2052 - acc: 0.0000e+00 - val_loss: 0.5796 - val_acc: 0.0000e+00\n",
            "Epoch 1908/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 1.2044 - acc: 0.0000e+00 - val_loss: 0.5701 - val_acc: 0.0000e+00\n",
            "Epoch 1909/2000\n",
            "80/80 [==============================] - 0s 179us/step - loss: 1.1982 - acc: 0.0000e+00 - val_loss: 0.5691 - val_acc: 0.0000e+00\n",
            "Epoch 1910/2000\n",
            "80/80 [==============================] - 0s 180us/step - loss: 1.1961 - acc: 0.0000e+00 - val_loss: 0.5766 - val_acc: 0.0000e+00\n",
            "Epoch 1911/2000\n",
            "80/80 [==============================] - 0s 201us/step - loss: 1.1993 - acc: 0.0000e+00 - val_loss: 0.5713 - val_acc: 0.0000e+00\n",
            "Epoch 1912/2000\n",
            "80/80 [==============================] - 0s 141us/step - loss: 1.2002 - acc: 0.0000e+00 - val_loss: 0.5673 - val_acc: 0.0000e+00\n",
            "Epoch 1913/2000\n",
            "80/80 [==============================] - 0s 205us/step - loss: 1.1926 - acc: 0.0000e+00 - val_loss: 0.5611 - val_acc: 0.0000e+00\n",
            "Epoch 1914/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 1.1887 - acc: 0.0000e+00 - val_loss: 0.5611 - val_acc: 0.0000e+00\n",
            "Epoch 1915/2000\n",
            "80/80 [==============================] - 0s 127us/step - loss: 1.1872 - acc: 0.0000e+00 - val_loss: 0.5642 - val_acc: 0.0000e+00\n",
            "Epoch 1916/2000\n",
            "80/80 [==============================] - 0s 139us/step - loss: 1.1853 - acc: 0.0000e+00 - val_loss: 0.5660 - val_acc: 0.0000e+00\n",
            "Epoch 1917/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 1.1863 - acc: 0.0000e+00 - val_loss: 0.5794 - val_acc: 0.0000e+00\n",
            "Epoch 1918/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 1.1922 - acc: 0.0000e+00 - val_loss: 0.5643 - val_acc: 0.0000e+00\n",
            "Epoch 1919/2000\n",
            "80/80 [==============================] - 0s 191us/step - loss: 1.1797 - acc: 0.0000e+00 - val_loss: 0.5722 - val_acc: 0.0000e+00\n",
            "Epoch 1920/2000\n",
            "80/80 [==============================] - 0s 137us/step - loss: 1.1885 - acc: 0.0000e+00 - val_loss: 0.5754 - val_acc: 0.0000e+00\n",
            "Epoch 1921/2000\n",
            "80/80 [==============================] - 0s 199us/step - loss: 1.1857 - acc: 0.0000e+00 - val_loss: 0.5633 - val_acc: 0.0000e+00\n",
            "Epoch 1922/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 1.1771 - acc: 0.0000e+00 - val_loss: 0.5731 - val_acc: 0.0000e+00\n",
            "Epoch 1923/2000\n",
            "80/80 [==============================] - 0s 118us/step - loss: 1.1903 - acc: 0.0000e+00 - val_loss: 0.5537 - val_acc: 0.0000e+00\n",
            "Epoch 1924/2000\n",
            "80/80 [==============================] - 0s 197us/step - loss: 1.1729 - acc: 0.0000e+00 - val_loss: 0.5795 - val_acc: 0.0000e+00\n",
            "Epoch 1925/2000\n",
            "80/80 [==============================] - 0s 211us/step - loss: 1.1907 - acc: 0.0000e+00 - val_loss: 0.5599 - val_acc: 0.0000e+00\n",
            "Epoch 1926/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 1.1713 - acc: 0.0000e+00 - val_loss: 0.5832 - val_acc: 0.0000e+00\n",
            "Epoch 1927/2000\n",
            "80/80 [==============================] - 0s 131us/step - loss: 1.1933 - acc: 0.0000e+00 - val_loss: 0.5627 - val_acc: 0.0000e+00\n",
            "Epoch 1928/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 1.1716 - acc: 0.0000e+00 - val_loss: 0.5892 - val_acc: 0.0000e+00\n",
            "Epoch 1929/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 1.1898 - acc: 0.0000e+00 - val_loss: 0.5880 - val_acc: 0.0000e+00\n",
            "Epoch 1930/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 1.1851 - acc: 0.0000e+00 - val_loss: 0.5681 - val_acc: 0.0000e+00\n",
            "Epoch 1931/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 1.1686 - acc: 0.0000e+00 - val_loss: 0.5654 - val_acc: 0.0000e+00\n",
            "Epoch 1932/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 1.1627 - acc: 0.0000e+00 - val_loss: 0.5878 - val_acc: 0.0000e+00\n",
            "Epoch 1933/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 1.1765 - acc: 0.0000e+00 - val_loss: 0.5779 - val_acc: 0.0000e+00\n",
            "Epoch 1934/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 1.1682 - acc: 0.0000e+00 - val_loss: 0.5735 - val_acc: 0.0000e+00\n",
            "Epoch 1935/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 1.1728 - acc: 0.0000e+00 - val_loss: 0.5624 - val_acc: 0.0000e+00\n",
            "Epoch 1936/2000\n",
            "80/80 [==============================] - 0s 142us/step - loss: 1.1624 - acc: 0.0000e+00 - val_loss: 0.5821 - val_acc: 0.0000e+00\n",
            "Epoch 1937/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 1.1760 - acc: 0.0000e+00 - val_loss: 0.5821 - val_acc: 0.0000e+00\n",
            "Epoch 1938/2000\n",
            "80/80 [==============================] - 0s 159us/step - loss: 1.1741 - acc: 0.0000e+00 - val_loss: 0.5590 - val_acc: 0.0000e+00\n",
            "Epoch 1939/2000\n",
            "80/80 [==============================] - 0s 161us/step - loss: 1.1563 - acc: 0.0000e+00 - val_loss: 0.5737 - val_acc: 0.0000e+00\n",
            "Epoch 1940/2000\n",
            "80/80 [==============================] - 0s 140us/step - loss: 1.1645 - acc: 0.0000e+00 - val_loss: 0.5502 - val_acc: 0.0000e+00\n",
            "Epoch 1941/2000\n",
            "80/80 [==============================] - 0s 157us/step - loss: 1.1442 - acc: 0.0000e+00 - val_loss: 0.5572 - val_acc: 0.0000e+00\n",
            "Epoch 1942/2000\n",
            "80/80 [==============================] - 0s 189us/step - loss: 1.1498 - acc: 0.0000e+00 - val_loss: 0.5632 - val_acc: 0.0000e+00\n",
            "Epoch 1943/2000\n",
            "80/80 [==============================] - 0s 174us/step - loss: 1.1613 - acc: 0.0000e+00 - val_loss: 0.5589 - val_acc: 0.0000e+00\n",
            "Epoch 1944/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 1.1493 - acc: 0.0000e+00 - val_loss: 0.5890 - val_acc: 0.0000e+00\n",
            "Epoch 1945/2000\n",
            "80/80 [==============================] - 0s 194us/step - loss: 1.1629 - acc: 0.0000e+00 - val_loss: 0.5954 - val_acc: 0.0000e+00\n",
            "Epoch 1946/2000\n",
            "80/80 [==============================] - 0s 171us/step - loss: 1.1636 - acc: 0.0000e+00 - val_loss: 0.5645 - val_acc: 0.0000e+00\n",
            "Epoch 1947/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 1.1405 - acc: 0.0000e+00 - val_loss: 0.5902 - val_acc: 0.0000e+00\n",
            "Epoch 1948/2000\n",
            "80/80 [==============================] - 0s 170us/step - loss: 1.1639 - acc: 0.0000e+00 - val_loss: 0.5514 - val_acc: 0.0000e+00\n",
            "Epoch 1949/2000\n",
            "80/80 [==============================] - 0s 168us/step - loss: 1.1290 - acc: 0.0000e+00 - val_loss: 0.5747 - val_acc: 0.0000e+00\n",
            "Epoch 1950/2000\n",
            "80/80 [==============================] - 0s 188us/step - loss: 1.1530 - acc: 0.0000e+00 - val_loss: 0.5464 - val_acc: 0.0000e+00\n",
            "Epoch 1951/2000\n",
            "80/80 [==============================] - 0s 163us/step - loss: 1.1302 - acc: 0.0000e+00 - val_loss: 0.5683 - val_acc: 0.0000e+00\n",
            "Epoch 1952/2000\n",
            "80/80 [==============================] - 0s 178us/step - loss: 1.1541 - acc: 0.0000e+00 - val_loss: 0.5583 - val_acc: 0.0000e+00\n",
            "Epoch 1953/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 1.1383 - acc: 0.0000e+00 - val_loss: 0.5657 - val_acc: 0.0000e+00\n",
            "Epoch 1954/2000\n",
            "80/80 [==============================] - 0s 145us/step - loss: 1.1376 - acc: 0.0000e+00 - val_loss: 0.5672 - val_acc: 0.0000e+00\n",
            "Epoch 1955/2000\n",
            "80/80 [==============================] - 0s 156us/step - loss: 1.1351 - acc: 0.0000e+00 - val_loss: 0.5530 - val_acc: 0.0000e+00\n",
            "Epoch 1956/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 1.1295 - acc: 0.0000e+00 - val_loss: 0.5524 - val_acc: 0.0000e+00\n",
            "Epoch 1957/2000\n",
            "80/80 [==============================] - 0s 147us/step - loss: 1.1265 - acc: 0.0000e+00 - val_loss: 0.5495 - val_acc: 0.0000e+00\n",
            "Epoch 1958/2000\n",
            "80/80 [==============================] - 0s 141us/step - loss: 1.1187 - acc: 0.0000e+00 - val_loss: 0.5480 - val_acc: 0.0000e+00\n",
            "Epoch 1959/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 1.1169 - acc: 0.0000e+00 - val_loss: 0.5493 - val_acc: 0.0000e+00\n",
            "Epoch 1960/2000\n",
            "80/80 [==============================] - 0s 192us/step - loss: 1.1140 - acc: 0.0000e+00 - val_loss: 0.5487 - val_acc: 0.0000e+00\n",
            "Epoch 1961/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 1.1095 - acc: 0.0000e+00 - val_loss: 0.5491 - val_acc: 0.0000e+00\n",
            "Epoch 1962/2000\n",
            "80/80 [==============================] - 0s 172us/step - loss: 1.1108 - acc: 0.0000e+00 - val_loss: 0.5502 - val_acc: 0.0000e+00\n",
            "Epoch 1963/2000\n",
            "80/80 [==============================] - 0s 204us/step - loss: 1.1099 - acc: 0.0000e+00 - val_loss: 0.5461 - val_acc: 0.0000e+00\n",
            "Epoch 1964/2000\n",
            "80/80 [==============================] - 0s 196us/step - loss: 1.1065 - acc: 0.0000e+00 - val_loss: 0.5482 - val_acc: 0.0000e+00\n",
            "Epoch 1965/2000\n",
            "80/80 [==============================] - 0s 182us/step - loss: 1.1068 - acc: 0.0000e+00 - val_loss: 0.5509 - val_acc: 0.0000e+00\n",
            "Epoch 1966/2000\n",
            "80/80 [==============================] - 0s 160us/step - loss: 1.1162 - acc: 0.0000e+00 - val_loss: 0.5422 - val_acc: 0.0000e+00\n",
            "Epoch 1967/2000\n",
            "80/80 [==============================] - 0s 142us/step - loss: 1.1012 - acc: 0.0000e+00 - val_loss: 0.5561 - val_acc: 0.0000e+00\n",
            "Epoch 1968/2000\n",
            "80/80 [==============================] - 0s 198us/step - loss: 1.1096 - acc: 0.0000e+00 - val_loss: 0.5448 - val_acc: 0.0000e+00\n",
            "Epoch 1969/2000\n",
            "80/80 [==============================] - 0s 139us/step - loss: 1.1019 - acc: 0.0000e+00 - val_loss: 0.5455 - val_acc: 0.0000e+00\n",
            "Epoch 1970/2000\n",
            "80/80 [==============================] - 0s 139us/step - loss: 1.1001 - acc: 0.0000e+00 - val_loss: 0.5554 - val_acc: 0.0000e+00\n",
            "Epoch 1971/2000\n",
            "80/80 [==============================] - 0s 169us/step - loss: 1.1020 - acc: 0.0000e+00 - val_loss: 0.5411 - val_acc: 0.0000e+00\n",
            "Epoch 1972/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 1.0914 - acc: 0.0000e+00 - val_loss: 0.5425 - val_acc: 0.0000e+00\n",
            "Epoch 1973/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 1.0962 - acc: 0.0000e+00 - val_loss: 0.5533 - val_acc: 0.0000e+00\n",
            "Epoch 1974/2000\n",
            "80/80 [==============================] - 0s 225us/step - loss: 1.1025 - acc: 0.0000e+00 - val_loss: 0.5382 - val_acc: 0.0000e+00\n",
            "Epoch 1975/2000\n",
            "80/80 [==============================] - 0s 158us/step - loss: 1.0867 - acc: 0.0000e+00 - val_loss: 0.5458 - val_acc: 0.0000e+00\n",
            "Epoch 1976/2000\n",
            "80/80 [==============================] - 0s 164us/step - loss: 1.0940 - acc: 0.0000e+00 - val_loss: 0.5453 - val_acc: 0.0000e+00\n",
            "Epoch 1977/2000\n",
            "80/80 [==============================] - 0s 177us/step - loss: 1.0887 - acc: 0.0000e+00 - val_loss: 0.5420 - val_acc: 0.0000e+00\n",
            "Epoch 1978/2000\n",
            "80/80 [==============================] - 0s 165us/step - loss: 1.0858 - acc: 0.0000e+00 - val_loss: 0.5446 - val_acc: 0.0000e+00\n",
            "Epoch 1979/2000\n",
            "80/80 [==============================] - 0s 123us/step - loss: 1.0910 - acc: 0.0000e+00 - val_loss: 0.5370 - val_acc: 0.0000e+00\n",
            "Epoch 1980/2000\n",
            "80/80 [==============================] - 0s 167us/step - loss: 1.0816 - acc: 0.0000e+00 - val_loss: 0.5327 - val_acc: 0.0000e+00\n",
            "Epoch 1981/2000\n",
            "80/80 [==============================] - 0s 203us/step - loss: 1.0776 - acc: 0.0000e+00 - val_loss: 0.5347 - val_acc: 0.0000e+00\n",
            "Epoch 1982/2000\n",
            "80/80 [==============================] - 0s 131us/step - loss: 1.0779 - acc: 0.0000e+00 - val_loss: 0.5373 - val_acc: 0.0000e+00\n",
            "Epoch 1983/2000\n",
            "80/80 [==============================] - 0s 132us/step - loss: 1.0761 - acc: 0.0000e+00 - val_loss: 0.5373 - val_acc: 0.0000e+00\n",
            "Epoch 1984/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 1.0749 - acc: 0.0000e+00 - val_loss: 0.5364 - val_acc: 0.0000e+00\n",
            "Epoch 1985/2000\n",
            "80/80 [==============================] - 0s 149us/step - loss: 1.0720 - acc: 0.0000e+00 - val_loss: 0.5370 - val_acc: 0.0000e+00\n",
            "Epoch 1986/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 1.0700 - acc: 0.0000e+00 - val_loss: 0.5386 - val_acc: 0.0000e+00\n",
            "Epoch 1987/2000\n",
            "80/80 [==============================] - 0s 154us/step - loss: 1.0718 - acc: 0.0000e+00 - val_loss: 0.5469 - val_acc: 0.0000e+00\n",
            "Epoch 1988/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 1.0762 - acc: 0.0000e+00 - val_loss: 0.5311 - val_acc: 0.0000e+00\n",
            "Epoch 1989/2000\n",
            "80/80 [==============================] - 0s 126us/step - loss: 1.0659 - acc: 0.0000e+00 - val_loss: 0.5334 - val_acc: 0.0000e+00\n",
            "Epoch 1990/2000\n",
            "80/80 [==============================] - 0s 175us/step - loss: 1.0688 - acc: 0.0000e+00 - val_loss: 0.5383 - val_acc: 0.0000e+00\n",
            "Epoch 1991/2000\n",
            "80/80 [==============================] - 0s 162us/step - loss: 1.0681 - acc: 0.0000e+00 - val_loss: 0.5277 - val_acc: 0.0000e+00\n",
            "Epoch 1992/2000\n",
            "80/80 [==============================] - 0s 155us/step - loss: 1.0605 - acc: 0.0000e+00 - val_loss: 0.5320 - val_acc: 0.0000e+00\n",
            "Epoch 1993/2000\n",
            "80/80 [==============================] - 0s 142us/step - loss: 1.0619 - acc: 0.0000e+00 - val_loss: 0.5416 - val_acc: 0.0000e+00\n",
            "Epoch 1994/2000\n",
            "80/80 [==============================] - 0s 152us/step - loss: 1.0660 - acc: 0.0000e+00 - val_loss: 0.5345 - val_acc: 0.0000e+00\n",
            "Epoch 1995/2000\n",
            "80/80 [==============================] - 0s 153us/step - loss: 1.0575 - acc: 0.0000e+00 - val_loss: 0.5333 - val_acc: 0.0000e+00\n",
            "Epoch 1996/2000\n",
            "80/80 [==============================] - 0s 146us/step - loss: 1.0548 - acc: 0.0000e+00 - val_loss: 0.5347 - val_acc: 0.0000e+00\n",
            "Epoch 1997/2000\n",
            "80/80 [==============================] - 0s 143us/step - loss: 1.0542 - acc: 0.0000e+00 - val_loss: 0.5348 - val_acc: 0.0000e+00\n",
            "Epoch 1998/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 1.0576 - acc: 0.0000e+00 - val_loss: 0.5404 - val_acc: 0.0000e+00\n",
            "Epoch 1999/2000\n",
            "80/80 [==============================] - 0s 138us/step - loss: 1.0614 - acc: 0.0000e+00 - val_loss: 0.5240 - val_acc: 0.0000e+00\n",
            "Epoch 2000/2000\n",
            "80/80 [==============================] - 0s 148us/step - loss: 1.0481 - acc: 0.0000e+00 - val_loss: 0.5343 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KABSWdAQUB0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_predict= model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk_4w-UrVOgs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e31e4f22-c207-463b-83af-ad6e57160fdc"
      },
      "source": [
        "np.round(Y_predict*500)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10197.],\n",
              "       [ 2832.],\n",
              "       [ 5281.],\n",
              "       [ 2253.],\n",
              "       [12622.],\n",
              "       [ 1607.],\n",
              "       [  463.],\n",
              "       [ 1267.],\n",
              "       [  969.],\n",
              "       [ 3298.],\n",
              "       [16086.],\n",
              "       [ 3625.],\n",
              "       [11378.],\n",
              "       [ 4141.],\n",
              "       [ 8569.],\n",
              "       [ 3139.],\n",
              "       [ 4504.],\n",
              "       [ 7799.],\n",
              "       [  580.],\n",
              "       [11077.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhmCIleZVWDr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "39983100-8f5e-47e8-f862-dd004554bf89"
      },
      "source": [
        "np.round(Y_test*500)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10229.,  2817.,  5309.,  2249., 12645.,  1629.,   485.,  1305.,\n",
              "        1017.,  3285., 21017.,  3617., 11405.,  4145.,  8585.,  3125.,\n",
              "        4517.,  7817.,   617., 11105.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jsIrw9aVaT6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "684b2bfc-0dd2-4a96-bd4f-4dc22fac4638"
      },
      "source": [
        "plt.scatter(range(20), Y_predict, c='r')\n",
        "plt.scatter(range(20), Y_test, c='g')\n",
        "plt.show()"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD8CAYAAACSCdTiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCHkACBghDwABI+QBIGD/D/d5UJ6s33dwAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhQ7x9gVWK5a",
        "colab_type": "code",
        "outputId": "f5830885-de00-4da1-99af-2c805c98e884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noYuIhAkVuohImPj/vwwEVQbHlNEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUnrOsaG0cHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
